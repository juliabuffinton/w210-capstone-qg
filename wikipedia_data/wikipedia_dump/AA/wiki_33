{"id": "4582", "url": "https://en.wikipedia.org/wiki?curid=4582", "title": "Bud Selig", "text": "Bud Selig\n\nAllan Huber \"Bud\" Selig (; born July 30, 1934) is an American baseball executive who currently serves as the Commissioner Emeritus of Baseball. Previously, he served as the ninth Commissioner of Baseball. He initially served as the acting commissioner beginning in 1992 before being named the official commissioner in 1998. Selig oversaw baseball through the 1994 strike, the introduction of the wild card, interleague play, and the merging of the National and American Leagues under the Office of the Commissioner. He was instrumental in organizing the World Baseball Classic in 2006. Selig also introduced revenue sharing. He is credited for the financial turnaround of baseball during his tenure with a 400 percent increase in the revenue of MLB and annual record breaking attendance.\n\nDuring Selig's term of service, the use of steroids and other performance-enhancing drugs became a public issue. The Mitchell Report, commissioned by Selig, concluded that the MLB commissioners, club officials, the Players Association, and the players all share \"to some extent in the responsibility for the steroid era.\" Following the release of the Mitchell Report, Congressman Cliff Stearns called publicly for Selig to step down as commissioner, citing his \"glacial response\" to the \"growing stain on baseball.\" Selig has pledged on numerous occasions to rid baseball of performance-enhancing drugs, and has overseen and instituted many rule changes and penalties to that end.\n\nSelig was previously the team owner and team president of the Milwaukee Brewers. As a Milwaukee native, he is credited for keeping baseball in Milwaukee. In 1970, he purchased the Seattle Pilots in bankruptcy court and renamed them the Milwaukee Brewers after the minor league team of the same name he had watched in his youth, which existed until the arrival of the Braves in Milwaukee in 1953. The Brewers went to the 1982 World Series (but were defeated in seven games by the St. Louis Cardinals, an event that Selig laments to this very day), and won seven Organization of the Year awards during his tenure. Selig remains a resident of Milwaukee.\n\nOn January 17, 2008, Selig's contract was extended through 2012, after which he planned to retire, but he then decided to stay as commissioner until the end of the 2014 season, a move approved by the owners on January 12, 2012, which would take his leadership past his 80th birthday. Selig made $14.5 million in the 12-month period ending October 31, 2005. Selig announced on September 26, 2013, that he would retire in January 2015. On January 22, 2015, MLB announced that Selig would formally step down from the office when his current term expired on January 24, 2015. He was inducted into the Baseball Hall of Fame in 2017.\n\nSelig was born in Milwaukee, and grew up in a Jewish family. His father, Ben Selig, had come to the United States from Romania with his family when he was four years old. Selig graduated from the University of Wisconsin-Madison with a B.A. in American history and political science in 1956. He served two years in the U.S. Army before working with his father who owned a car leasing business in Milwaukee. Selig continues to be involved in the automotive industry, serving as president of the Selig Executive Lease Company.\n\nSelig's interest in baseball came from his mother. An immigrant from Ukraine, Marie Selig attended college, a rare accomplishment for a woman in the early 20th century, and became a school teacher. When Selig was only three, Marie began taking him and his older brother, Jerry, to Borchert Field, where the minor league Milwaukee Brewers played. When the Boston Braves relocated to Milwaukee in 1953, Selig switched allegiances, and eventually became the team's largest public stockholder. Selig was devastated when he learned that the Braves were going to leave Milwaukee in favor of Atlanta. In 1965, when the Braves left Milwaukee, he divested his stock in the team. As a youngster, Selig's favorite player was Hershel Martin.\n\nAs a minority owner of the Milwaukee Braves, Selig founded the organization Teams, Inc., in an attempt to prevent the majority owners (based out of Chicago) from moving the club to a larger television market. This was challenged legally on the basis that no prior team relocations (in the modern era) left a city without a team. Prior movements had all originated in cities which were home to at least two teams. When his quest to keep the team in Milwaukee finally failed after the 1965 season, he changed the group's name to Milwaukee Brewers Baseball Club, Inc., after the minor league baseball team he grew up watching, and devoted himself to returning Major League Baseball to Milwaukee.\n\nSelig arranged for major league games to be played at Milwaukee County Stadium. The first, a pre-season match-up between the Chicago White Sox and Minnesota Twins, drew more than 51,000 spectators. Selig followed this up by hosting nine White Sox regular-season games in 1968 and eleven in 1969. One of the games played in Milwaukee that year was against the expansion Seattle Pilots, the team that would become the Brewers. Those Milwaukee \"home\" games were phenomenally successful, with the handful of games accounting for about \"one-third\" of total White Sox home attendance.\n\nTo satisfy that fan base, Selig decided to purchase the White Sox (with the intention of moving them to Milwaukee) in 1969. He entered into an agreement to buy the club, but the American League vetoed the sale, preferring to keep an American League team in Chicago, which at the time was still America's second largest city. Selig turned his attention to other franchises.\n\nIn 1970, he purchased the bankrupt Seattle Pilots franchise, moving them to his hometown and officially renaming the team the \"Brewers\".\n\nDuring Selig's tenure as club president, the Brewers participated in postseason play in 1981, when the team finished first in the American League East during the second half of the season, and in 1982, when the team made it to the World Series, under the leadership of future Hall of Famers Robin Yount and Paul Molitor. Under Selig's watch, the Brewers also won seven Organization of the Year awards. Selig was part of the owners' collusion in 1985–1987, resulting in the owners paying US$280 million in damages to the players.\n\nUpon his assumption of the commissioner's role, Selig transferred his ownership interest in the Brewers to his daughter Wendy Selig-Prieb in order to remove any technical conflicts of interest, though it was widely presumed he maintained some hand in team operations. Although the team has been sold to Los Angeles investor Mark Attanasio, questions remain regarding Selig's past involvement. Selig's defenders point to the poor management of the team after Selig-Prieb took control as proof that Selig was not working behind the scenes.\n\nSelig was elected to the Wisconsin Athletic Hall of Fame in 2001.\n\nOn August 24, 2010, a statue of Selig, the \"Selig Monument\", commissioned by Brewers owner Mark Attanasio and designed by artist Brian Maughan, was unveiled outside Miller Park in Milwaukee.\n\nSelig became an increasingly vocal opponent of Commissioner Fay Vincent, and soon became the leader of a group of owners seeking his removal. Selig has never stated that the owners colluded, while Vincent has:\n\nFollowing an 18-9 no-confidence vote, Vincent resigned. Selig had by this time become chairman of the Executive Council of Major League Baseball, and as such became de facto acting commissioner.\n\nHis first major act was to institute the Wild Card and divisional playoff play, which has created much controversy amongst baseball fans. Those against the Wild Card see it as diminishing the importance of the pennant race and the regular season, with the true race often being for second rather than first place, while those in favor of it view it as an opportunity for teams to have a shot at the playoffs even when they have no chance of a first-place finish in their division, thus maintaining fan interest later in the season.\n\nSelig suspended Cincinnati Reds owner Marge Schott for a year in 1993 for repeated racially insensitive and prejudicial remarks and actions. The same year, New York Yankees owner George Steinbrenner was reinstated from a lifelong suspension that was instituted by Selig's predecessor Fay Vincent. Pete Rose has claimed that he applied for reinstatement over the years and received no such consideration. Rose, along with his close friend and former teammate Mike Schmidt (who is a strong supporter of Rose's reinstatement into baseball), met with Selig in 2002, where Rose privately admitted to Selig (two years before going public with his admission) about betting on baseball. Bud Selig was a close friend of the late Bart Giamatti, who was the commissioner when Rose was first banned from the sport in 1989.\n\nAs acting commissioner, Selig represented MLB during the 1994 players strike and cancelled the World Series, marking the first time the annual event had not been staged since 1904.\n\nAfter a six-year search for a new commissioner, the owners voted to give Selig the title on a permanent basis midway through the 1998 season.\n\nDuring his tenure the game avoided a third work stoppage in 2002, and has seen the implementation of interleague play.\n\nWhereas in the past, the National and American leagues had separate administrative organizations (which, for example, allowed for the introduction of different rules such as the designated hitter), under Selig, Major League Baseball consolidated the administrative functions of both leagues into the Commissioner's Office in 2000. The last official presidents of the NL and AL were Leonard S. Coleman Jr. and Dr. Gene Budig respectively.\n\nOn September 11, 2001, Selig ordered all baseball games postponed for a week because of the terror attacks on New York and Washington. The games were postponed not only out of respect and mourning for the victims, but also out of concern for the safety and security of fans and players.\n\nAfter the conclusion of the 2001 World Series, Selig held a vote on contracting two teams, reportedly the Minnesota Twins and Montreal Expos. This action led to Selig (along with former Expos owner Jeffrey Loria) being sued for racketeering and conspiring with Loria to deliberately defraud the Expos minority owners. If found liable, the league could have been ordered to pay as much as $500 million in total damages. The judge also ruled that the Expos could not be moved or contracted until the case was over. The case eventually went to arbitration and was settled out of court for an undisclosed sum.\n\nA week after Selig's announcement, Hennepin County Judge Harry Seymour Crump issued a temporary restraining order that forced the Twins to honor their lease and play the 2002 season at the Metrodome. In August 2002, the effort to contract the Twins officially fizzled as players and owners reached a consensus on a new labor agreement which extended the team's Metrodome lease.\n\nThe 2002 All-Star Game, played in Selig's hometown of Milwaukee, was tied 7–7 after nine innings, and remained tied after the bottom of the 11th inning. Due to the recent managerial trend of granting playing time to as many available players as possible within the regulation nine innings, both managers had used their entire roster. Concerned for the arms of the pitchers currently on the mound, Selig made the controversial decision to declare the game a tie, to the dissatisfaction of the Milwaukee fans. Selig later said that this call was \"embarrassing\" and that he was \"tremendously saddened\" by the outcome of the game.\n\nSelig subsequently tried to reinvigorate the All-Star Game by awarding the winning league home-field advantage in the World Series; that practice was initiated in 2003 and continued through 2016. The 2003 All-Star Game had the same U.S. viewership as 2002 (9.5 rating; 17 share) and the ratings declined in 2004 (8.8 rating; 15 share) and 2005 (8.1 rating; 14 share). The American television audience increased in 2006 (9.3 rating; 16 share).\n\nOn July 1, 2005, Selig suspended Texas Rangers pitcher Kenny Rogers for 20 games and fined him US$50,000. On June 29, 2005, Rogers had purposely grabbed the camera of a cameraman, resulting in one camera falling to the ground. When the cameraman proceeded to pick up his camera, Rogers went back to him in an arguably threatening way. One of the reporters then resumed filming and Rogers knocked him down again. While an appeal of his suspension was pending, Rogers appeared at the 2005 All-Star Game in Detroit, where fans loudly booed him. On July 22, 2005, Selig heard Rogers' appeal of his suspension. Selig decided to uphold the 20 games, however, an independent arbitrator ruled that Selig had exceeded his authority and reduced it to 13 games, but upheld the fine.\n\nIn 2005, Selig faced Congress on the issue of steroids. After the Congressional hearings in early 2005, and with the scrutiny of the sports and national media upon this issue, Selig put forth a proposal for a stricter performance-enhancing drug testing regime to replace the current system. This proposal also included the banning of amphetamines, a first for the major North American sports leagues. The MLB Players Association and MLB reached an agreement in November on the new policy.\n\nSelig's testimony on the subject has been contradictory. In 2005, Selig told reporters, \"I never even heard about them [steroids] until 1998 or 1999. I ran a team and nobody was closer to their players and I never heard any comment from them. It wasn't until 1998 or '99 that I heard the discussion.\" But a year later, testifying to Congress in 2006, Selig claimed personal credit for spotting the problem early: \"In 1994, before anybody was really talking about steroids in baseball, we proposed a program of testing for such substances to the MLBPA. As early as 1998, I began formulating a strategic plan to eliminate the use of performance-enhancing substances from the game.\" During the 1988 ALCS, Oakland's Jose Canseco had been repeatedly taunted by Boston fans with a chant of \"ster-oids, ster-oids, ster-oids.\" Speaking at the 2013 All-Star Game, Selig complained, \"People say, 'Well, you were slow to react.' We were not slow to react. In fact, I heard that this morning, and it aggravated me all over again.\"\n\nBy early 2006, Selig was forced to deal with the issue of steroid use. On March 30, 2006, as a response to the controversy of the use of performance-enhancing drugs and the anticipated career home run record to be set by Barry Bonds, Selig asked former U.S. Senator George J. Mitchell to lead an independent investigation into the use of steroids in baseball's recent past. Joe Sheehan from \"Baseball Prospectus\" wrote that the commission has been focusing \"blame for the era exclusively on uniformed personnel\", and failing to investigate any role played by team ownership and management.\n\nMuch controversy surrounded Selig and his involvement in Bonds' all-time home run record chase. For months, speculation surrounded Selig and the possibility that he and Henry Aaron would not attend Bonds' games as he closed in on the record. Selig announced in July 2007 when Bonds was near 755 home runs that he would attend the games. Selig was in attendance for Bonds' record-tying home run against the San Diego Padres, sitting in Padres owner John Moores' private suite. When Bonds hit his 755th home run, Selig refused to applaud Bonds' accomplishment, instead choosing to keep his hands in his pockets and have a look of disdain on his face. Bud Selig also did not attend the San Francisco Giants' game on August 7 when Barry Bonds hit his record-breaking 756th home run against the Washington Nationals; after the event, Selig released a statement congratulating Bonds.\n\nOn December 13, 2007, former senator Mitchell released his report on the use of performance-enhancing substances by MLB players. The report names many current and former players who allegedly used performance-enhancing drugs during their career.\n\nSelig has been widely criticized for not taking an active enough role to stem the tide of steroid use in baseball until it had blossomed into a debilitating problem for the industry. \"Chicago Sun-Times\" columnist Jay Mariotti called Selig the \"Steroids Commissioner.\" Selig has been called to Congress several times to testify on performance-enhancing drug use. Congressman Cliff Stearns said in December 2007 that Selig should resign because of use of performance-enhancing drugs in baseball during his tenure.\n\nSelig's decision to extend the traditional post-season schedule into November in an attempt to increase Nielsen ratings was met with widespread disdain, both inside and outside the baseball community. Mike Scioscia, manager of the American League West Division Champion Los Angeles Angels, dismissed the decision as \"Ridiculous. I don't know. Can I say it any clearer than that? We should have never had a day off last Wednesday. We should never have three days off after the season. You shouldn't even have two days off after the season.\"\n\nRelated to the contraction controversy in 2001, Rob Dibble posted an open letter to Bud Selig, criticizing his actions for benefiting only the Milwaukee Brewers. Dibble cites that the contraction of the Twins would benefit the Brewers, as they would potentially claim the Twins' share of the upper Midwest market.\n\nSelig has made some decisions involving the Houston Astros that were unpopular with their supporters. He ordered the roof at Minute Maid Park to be opened for games three and four of the 2005 World Series, pre-empting the authority held by the Astros. The roof was closed for all prior playoff games and similar weather conditions. For Hurricane Ike in 2008, Selig mandated that the Astros play two home games against the Chicago Cubs in his hometown of Milwaukee despite proximity to the visiting Cubs; the home ballparks for the Texas Rangers and Atlanta Braves were both available to host the games. The Astros subsequently were victims of a no-hitter by Carlos Zambrano and recorded a single hit in the following game. In the midst of the playoff race, this decision and its impact deeply affected the playoff race and seedings with eight teams holding winning records at the moment. The Milwaukee Brewers benefited from these events by qualifying in the playoffs as a Wild Card team, only to lose in the NLDS to the Philadelphia Phillies, the eventual World Series winner. In 2011, Selig also demanded that the Astros move to the American League West as a condition of the sale of the franchise to businessman Jim Crane; the team switched leagues in 2013 in return for $70 million discount in the purchase price.\n\nUnited States bankruptcy judge Kevin Gross rendered a stern warning to Selig in regards to the 2011 Los Angeles Dodgers ownership dispute. Treating other teams differently in regards to their media contracts drew accusations that Selig did not act in good faith with respect to the Los Angeles Dodgers. Selig rejected the television deal that Frank McCourt negotiated that intended to bring the franchise out of bankruptcy, claiming McCourt violated the Baseball Agreement. In comparison, no action was taken against New York Mets owner Fred Wilpon despite being in a similar position. Gross stated, \"Should the Commissioner falter in proving alleged wrongdoing, the Court may allow LAD (Los Angeles Dodgers) to take further, limited discovery.\" Some critics have used Selig's handling of the Dodgers to point out a double standard in treatment of MLB owners. More specifically in regards to the Mets, critics point out that with Selig's personal relationship with Wilpon has motivated him to stall any possible removal of Wilpon as that club's principal owner.\n\nSelig also notably failed to resolve a 6-year conflict between the San Francisco Giants and the Oakland Athletics regarding the Athletics' proposed move to San Jose. Selig established a blue-ribbon panel in 2009 to resolve the dispute; however, despite years to find a resolution, the blue-ribbon panel completely failed to make any progress toward resolving the issue, leading San Jose to sue MLB. The lawsuit, which is currently ongoing, questions the league's anti-trust exemption and its ability to enforce particular clubs' geographic territories.\n\nOn December 1, 2006, Selig announced that he would be retiring as commissioner of baseball upon the expiration of his contract in 2009. Selig earned $14.5 million from MLB over the timespan October 31, 2005 to October 31, 2006. However, in January 2008, Selig agreed to a three-year contract extension, announcing he planned to retire after the 2012 season. He further decided against retirement, and after a two-year extension for the previous deal was agreed to on January 12, 2012, it was announced that Selig would remain commissioner until the end of the 2014 season.\n\nBud Selig has overseen the following changes in Major League Baseball:\n\n\nDuring Selig's terms as Executive Council Chairman (from 1992–1998) and Commissioner, new stadiums have opened in Arizona, Atlanta, Cincinnati, Cleveland, Colorado, Detroit, Houston, Milwaukee, Philadelphia, Pittsburgh, San Diego, San Francisco, Seattle, Arlington, St. Louis, Washington, D.C., New York City (Flushing, Queens and the Bronx), Minneapolis, and Miami.\n\nSelig and his family served a supportive role on the Advisory Board of the Israel Baseball League during its inaugural season in 2007. In response to issues with the league's financial management, after the season, the Selig family requested that their names be removed from the list of board members.\n\nIn May 2015, the Milwaukee Brewers honored Bud Selig with the unveiling of the \"Selig Experience\" exhibit at Miller Park. The \"Selig Experience\" is a fifteen-minute documentary showing Bud Selig's life and work for the Milwaukee Brewers.\n\nSelig has been married twice. He married his first wife, Donna, in the 1950s, and they had two children: Sari (born 1957) and Wendy (born 1960). The couple divorced in 1976 after 19 years of marriage on the grounds that Selig had been \"unduly absenting yourself from the home of the parties and isolating yourself ... in pursuit of your baseball interests to the detriment of your marriage.\" Donna Selig later stated that ended the marriage because her husband \"divorced me and married baseball.\" Since 1977, Selig has been married to the former Suzanne Steinman, who has a daughter from a previous marriage.\n\nIn 2009, Selig began teaching as an adjunct professor of sports law and policy at Marquette University Law School. His classes have covered numerous topics, including \"the history of collective bargaining and free agency, baseball's antitrust exemption, revenue sharing – as well as finer points of sports law like intellectual property rights, ambush marketing, and why baseball does not allow game footage on YouTube.\"\n\nIn 2010, Selig endowed the Allan H. Selig Chair in the History of Sport and Society in the United States, as well as a Distinguished Lecture Series in Sport and Society at his alma mater, the University of Wisconsin – Madison. The inaugural lecture was given by Adrian Burgos and Prof. Sean Dinces has held the Chair since 2013.\n\nIn February 2016, Selig joined the Sandra Day O'Connor College of Law at Arizona State University.\n\nSelig was awarded the U.S. Department of the Army Outstanding Civilian Service Award in April 2015 for supporting soldiers, veterans and their families through his work in Major League Baseball. On April 6, 2015, the Milwaukee Brewers retired uniform number 1 in his honor.\n\nOn December 4, 2016, it was announced Selig was elected into the National Baseball Hall of Fame class of 2017.\n\nIn 2016, Selig was honored with the \"Lombardi Award of Excellence\" from the Vince Lombardi Cancer Foundation. The award was created to honor Coach Lombardi's legacy, and is awarded annually to an individual who exemplifies the spirit of the Coach.\n\n\n\n"}
{"id": "4583", "url": "https://en.wikipedia.org/wiki?curid=4583", "title": "Bison", "text": "Bison\n\nBison are large, even-toed ungulates in the genus \"Bison\" within the subfamily Bovinae.\n\nTwo extant and six extinct species are recognised. Of the six extinct species, five became extinct in the Quaternary extinction event. \"Bison palaeosinensis\" evolved in the Early Pleistocene in South Asia, and was the evolutionary ancestor of \"B. priscus\" (steppe bison), which was the ancestor of all other \"Bison\" species. From 2 MYA to 6,000 BC, steppe bison ranged across the mammoth steppe, inhabiting Europe and northern Asia with \"B. schoetensacki\" (woodland bison), and North America with \"B. antiquus\", \"B. latifrons\", and \"B. occidentalis.\" The last species to go extinct, \"B. occidentalis\", was succeeded at 3,000 BC by \"B. bison\".\n\nOf the two surviving species, the American bison, \"B. bison\", found only in North America, is the more numerous. Although commonly known as a buffalo in the United States and Canada, it is only distantly related to the true buffalo. The North American species is composed of two subspecies, the Plains bison, \"B. b. bison\", and the Wood bison, \"B. b. athabascae\", which is the namesake of Wood Buffalo National Park in Canada. A third subspecies, the Eastern Bison (\"B. b. pennsylvanicus\") is no longer considered a valid taxon, being a junior synonym of \"B. b. bison\". References to \"Woods Bison\" or \"Wood Bison\" from the eastern United States confusingly refer to this subspecies, not \"B. b. athabascae\", which was not found in the region. The European bison, \"B. bonasus\", or \"wisent\", is found in Europe and the Caucasus, reintroduced after being extinct in the wild.\n\nWhile all bison species are classified in their own genus, they are sometimes bred with domestic cattle (genus \"Bos\") and produce fertile offspring called beefalo or zubron.\n\nThe American bison and the European bison (wisent) are the largest surviving terrestrial animals in North America and Europe. They are typical artiodactyl (cloven hooved) ungulates, and are similar in appearance to other bovines such as cattle and true buffalo. They are broad and muscular with shaggy coats of long hair. Adults grow to approximately in length and can weigh from approximately in smaller cows, up to in large bulls. American bison tend to be slightly heavier than European bison, while European bison tend to be taller than American bison.\n\nBison are nomadic grazers and travel in herds. The bulls leave the herds of females at two or three years of age, and join a male herd, which are generally smaller than female herds. Mature bulls rarely travel alone. Towards the end of the summer, for the reproductive season, the sexes necessarily commingle.\n\nAmerican bison are known for living in the Great Plains, but formerly had a much larger range including much of the eastern United States and parts of Mexico. Both species were hunted close to extinction during the 19th and 20th centuries, but have since rebounded; the wisent owing its survival, in part, to the Chernobyl Disaster, ironically, as the Chernobyl Exclusion Zone has become a kind of wildlife preserve for wisent and other rare megafauna such as the Przewalski's Horse, though poaching has become a threat in recent years. The American Plains bison is no longer listed as endangered, but this does not mean the species is secure. Genetically pure \"B. b. bison\" currently number only ~20,000, separated into fragmented herds—all of which require active conservation measures. The Wood bison is on the endangered species list in Canada and is listed as threatened in the United States, though there have been numerous attempts by beefalo ranchers to have it entirely removed from the Endangered Species List.\n\nAlthough superficially similar, physical and behavioural differences exist between the American and European bison. The American species has 15 ribs, while the European bison has 14. The American bison has four lumbar vertebrae, while the European has five. (The difference in this case is that what would be the first lumbar vertebra has ribs attached to it in American bison and is thus counted as the 15th thoracic vertebra, compared to 14 thoracic vertebrae in wisent.) Adult American bison are less slim in build and have shorter legs. American bison tend to graze more, and browse less than their European relatives. Their anatomies reflect this behavioural difference; the American bison's head hangs lower than the European's. The body of the American bison is typically hairier, though its tail has less hair than that of the European bison. The horns of the European bison point through the plane of their faces, making them more adept at fighting through the interlocking of horns in the same manner as domestic cattle, unlike the American bison, which favours butting. American bison are more easily tamed than their European cousins, and breed with domestic cattle more readily.\n\nThe bovine tribe (Bovini) split about 5 to 10 million years ago into the buffalos (\"Bubalus\" and \"Syncerus\") and a group leading to bison and taurine cattle. Thereafter, the family lineage of bison and taurine cattle does not appear to be a straightforward \"tree\" structure as is often depicted in much evolution, because evidence of interbreeding and crossbreeding is seen between different species and members within this family, even many millions of years after their ancestors separated into different species. This crossbreeding was not sufficient to conflate the different species back together, but it has resulted in unexpected relationships between many members of this group, such as yak being related to American bison, when such relationships would otherwise not be apparent.\n\nA 2003 study of mitochondrial DNA indicated four distinct maternal lineages in tribe Bovini:\nHowever, Y chromosome analysis associated wisent and American bison. An earlier study using amplified fragment length polymorphism fingerprinting showed a close association of wisent with American bison, and probably with the yak, but noted that the interbreeding of Bovini species made determining relationships problematic.\n\nThe genus \"Bison\" diverged from the lineage that led to cattle (\"Bos primigenius\") at the Plio-Pleistocene boundary in South Asia. Two extant and six extinct species are recognised. Of the six extinct species, five went extinct in the Quaternary extinction event. Three were North American endemics: \"Bison antiquus\", \"B. latifrons\", and \"B. occidentalis\". The fourth, \"B. priscus\" (steppe bison), ranged across steppe environments from Western Europe, through Central Asia, East Asia including Japan, and onto North America. The fifth, \"B. schoetensacki\" (woodland bison), inhabited Eurasian forests, extending from western Europe to the south of Siberia.\n\nThe sixth, \"B. palaeosinensis\", evolving in the Early Pleistocene in South Asia, is presumed to have been the evolutionary ancestor of \"B. priscus\" and all successive \"Bison\" lineages. The steppe bison (\"B. priscus\") evolved from \"Bison palaeosinensis\" in the Early Pleistocene. \"B. priscus\" is seen clearly in the fossil record around 2 million years ago. The steppe bison spread across Eurasia, and all proceeding contemporary and successive species are believed to have derived from the steppe bison. Going extinct in 6,000 BCE, outlasted only by \"B. occidentalis\", \"B. bonasus\" and \"B. bison\", the steppe bison was the predominant bison pictured in the ancient cave paintings of Spain and Southern France.\n\nThe modern European bison is likely to have arisen from the steppe bison. There is no direct fossil evidence of successive species between the steppe bison and the European bison, though there are three possible lines of ancestry pertaining to the European wisent. Past research has suggested that the European bison is descended from bison that had migrated from Asia to North America, and then back to Europe, where they crossbred with existing steppe bison. However, more recent phylogenetic research points to an origin either from the phenotypically and genetically similar Pleistocene woodland bison (\"B. schoetensacki\") or as the result of an interbreeding event between the steppe bison and the aurochs (\"Bos primigenius\"), the ancestor of domesticated cattle, around 120,000 years ago. The possible hybrid is referred to in vernacular as the 'Higgs bison' as a hat-tip to the discovery process of the Higgs boson.\n\nAt one point, some steppe bison crossbred with the ancestors of the modern yak. After that crossbreeding, a population of steppe bison crossed the Bering Land Bridge to North America. The steppe bison spread through the northern parts of North America and lived in Eurasia until around 11,000 years ago and North America until 4,000 to 8,000 years ago.\n\nThe Pleistocene woodland bison (\"B\".\"schoetensacki)\" evolved in the Middle Pleistocene from \"B. priscus\", and tended to inhabit the dry conifer forests and woodland which lined the mammoth steppe, occupying a range from western Europe to the south of Siberia. Although their fossil records are far rarer than their antecedent, they are thought to have existed until at least 36,000 BCE.\n\n\"Bison latifrons\" (the \"giant\" or \"longhorn\" bison) is thought to have evolved in midcontinent North America from \"B. priscus\", after the steppe bison crossed into North America. Giant bison (\"B. latifrons\") appeared in the fossil record about 120,000 years ago. \"B. latifrons\" was one of many species of North American megafauna that became extinct during the transition from the Pleistocene to the Holocene epoch (an event referred to as the Quaternary extinction event). It is thought to have disappeared some 21,000–30,000 years ago, during the late Wisconsin glaciation.\n\n\"B. latifrons\" co-existed with the slightly smaller \"B. antiquus\" for over 100,000 years. Their predecessor, the steppe bison appeared in the North American fossil record around 190,000 years ago. \"B. latifrons\" is believed to have been a more woodland-dwelling, non-herding species, while \"B. antiquus\" was a herding grassland-dweller, very much like its descendant \"B. bison\". \"B. antiquus\" gave rise to both \"B. occidentalis,\" and later \"B. bison\", the modern American bison, some 5,000 to 10,000 years ago. \"B. antiquus\" was the most common megafaunal species on the North American continent during much of the Late Pleistocene and is the most commonly found large animal found at the La Brea Tar Pits.\n\nIn 2016, DNA extracted from \"Bison priscus\" fossil remains beneath a 130,000-year-old volcanic ashfall in the Yukon suggested recent arrival of the species. That genetic material indicated that all American bison had a common ancestor 135,000 to 195,000 years ago, during which period the Bering Land Bridge was exposed; this hypothesis precludes an earlier arrival. The researchers sequenced mitochondrial genomes from both that specimen and from the remains of a recently discovered, estimated 120,000-year-old giant, long-horned, \"B. latifrons\" from Snowmass, Colorado. The genetic information also indicated that a second, Pleistocene migration of bison over the land bridge occurred 21,000 to 45,000 years ago.\n\nDuring the population bottleneck, after the great slaughter of American bison during the 19th century, the number of bison remaining alive in North America declined to as low as 541. During that period, a handful of ranchers gathered remnants of the existing herds to save the species from extinction. These ranchers bred some of the bison with cattle in an effort to produce \"cattleo\" (today called \"beefalo\") Accidental crossings were also known to occur. Generally, male domestic bulls were crossed with buffalo cows, producing offspring of which only the females were fertile. The crossbred animals did not demonstrate any form of hybrid vigor, so the practice was abandoned. Wisent-American bison hybrids were briefly experimented with in Germany (and found to be fully fertile) and a herd of such animals is maintained in Russia. A herd of cattle-wisent crossbreeds (zubron) is maintained in Poland. First-generation crosses do not occur naturally, requiring caesarean delivery. First-generation males are infertile. The U.S. National Bison Association has adopted a code of ethics that prohibits its members from deliberately crossbreeding bison with any other species. In the United States, many ranchers are now using DNA testing to cull the residual cattle genetics from their bison herds. The proportion of cattle DNA that has been measured in introgressed individuals and bison herds today is typically quite low, ranging from 0.56 to 1.8%.\n\nThere are also remnant purebred American bison herds on public lands in North America. Herds of importance are found in Yellowstone National Park, Wind Cave National Park in South Dakota, Blue Mounds State Park in Minnesota, Elk Island National Park in Alberta, Canada and Grasslands National Park in Saskatchewan, Canada. In 2015 a purebred herd of 350 individuals was identified on public lands in the Henry Mountains of southern Utah via genetic testing of mitochondrial and nuclear DNA. This study, published in 2015, also showed the Henry Mountains bison herd to be free of brucellosis, a bacterial disease that was imported with non-native domestic cattle to North America.\n\nWallowing is a common behavior of bison. A bison wallow is a shallow depression in the soil, either wet or dry. Bison roll in these depressions, covering themselves with mud or dust. Possible explanations suggested for wallowing behavior include grooming behavior associated with moulting, male-male interaction (typically rutting behavior), social behavior for group cohesion, play behavior, relief from skin irritation due to biting insects, reduction of ectoparasite load (ticks and lice), and thermoregulation. In the process of wallowing, bison may become infected by the fatal disease anthrax, which may occur naturally in the soil.\n\nBison temperament is often unpredictable. They usually appear peaceful, unconcerned, even lazy, yet they may attack anything, often without warning or apparent reason. They can move at speeds up to and cover long distances at a lumbering gallop.\n\nTheir most obvious weapons are the horns borne by both males and females, but their massive heads can be used as battering rams, effectively using the momentum produced by what is a typical weight of (can be up to 2700 lbs) moving at . The hind legs can also be used to kill or maim with devastating effect. In the words of early naturalists, they were dangerous, savage animals that feared no other animal and in prime condition could best any foe (except for wolves and brown bears).\n\nThe rutting, or mating, season lasts from June through September, with peak activity in July and August. At this time, the older bulls rejoin the herd, and fights often take place between bulls. The herd exhibits much restlessness during breeding season. The animals are belligerent, unpredictable, and most dangerous.\n\nAmerican bison live in river valleys, and on prairies and plains. Typical habitat is open or semiopen grasslands, as well as sagebrush, semiarid lands, and scrublands. Some lightly wooded areas are also known historically to have supported bison. They also graze in hilly or mountainous areas where the slopes are not steep. Though not particularly known as high-altitude animals, bison in the Yellowstone Park bison herd are frequently found at elevations above 8,000 feet and the Henry Mountains bison herd is found on the plains around the Henry Mountains, Utah, as well as in mountain valleys of the Henry Mountains to an altitude of 10,000 feet.\n\nEuropean bison tend to live in lightly wooded to fully wooded areas and areas with increased shrubs and bushes, though they can also live on grasslands and plains.\n\nThroughout most of their historical range, landowners have sought restrictions on free-ranging bison. Herds on private land are required to be fenced in. In the state of Montana, free-ranging bison on public lands may be shot, due to concerns about transmission of disease to cattle and damage to public property. In 2013, Montana legislative measures concerning the bison were proposed and passed the legislature, but opposed by Native American tribes as they impinged on sovereign tribal rights. Three such bills were vetoed by Steve Bullock, the governor of Montana. The bison's circumstances remain an issue of contention between Native American tribes and private landowners.\n\nBison are ruminants, which allows them to derive their energy from cell walls. Bison were once thought to almost exclusively consume grasses and sedges, but are now known to consume a wide-variety of plants including woody plants and herbaceous eudicots. Over the course of the year, bison shift which plants they select in their diet based on which plants have the highest protein or energy concentrations at a given time and will reliably consume the same species of plants across years. Protein concentrations of the plants they eat tend to be highest in the spring and decline thereafter, reaching their lowest in the winter. In Yellowstone National Park, bison browsed willows and cottonwoods, not only in the winter when few other plants are available, but also in the summer. Bison are thought to migrate to optimize their diet, and will concentrate their feeding on recently burned areas due to the higher quality forage the regrows after the burn. Wisent tend to browse on shrubs and low-hanging trees more often than do the American bison, which prefer grass to shrubbery and trees.\n\nFemale bison typically do not reproduce until three years of age and can reproduce to at least 19 years of age. Female bison can produce calves annually as long as their nutrition is sufficient, but will not give birth to a calf after years where weight gain was too low. A mother's probability of reproduction the following year is strongly dependent on the mother's mass and age. Heavier female bison produce heavier calves (weighed in the fall at weaning) than light mothers, while the weight of calves is lower for older mothers (after age 8).\n\nDue to their size, bison have few predators. Five notable exceptions are humans, the wolf, mountain lion, brown bear, and coyote. The grey wolf generally takes down a bison while in a pack, but cases of a single wolf killing bison have been reported. Brown bear also consume bison, often by driving off the pack and consuming the wolves' kill. Brown bear and coyotes also prey on bison calves. Historically and prehistorically, lions, tigers, \"Smilodon\", \"Homotherium\", cave hyenas and \"Homo sp.\" had posed threats to bison.\n\nFor the American bison, the main cause of illness is malignant catarrhal fever, though brucellosis is a serious concern in the Yellowstone Park bison herd. Bison in the Antelope Island bison herd are regularly inoculated against brucellosis, parasites, \"Clostridium\" infection, infectious bovine rhinotracheitis, and bovine vibriosis.\n\nThe major concerns for illness in European bison are foot-and-mouth disease and balanoposthitis, which affects the male sex organs; a number of parasitic diseases have also been cited as threats. The inbreeding of the species caused by the small population plays a role in a number of genetic defects and immunity to diseases, which in turn poses greater risks to the population.\n\nThe term \"buffalo\" is sometimes considered to be a misnomer for this animal, as it is only distantly related to either of the two \"true buffalo\", the Asian water buffalo and the African buffalo. Samuel de Champlain applied the term buffalo (\"buffles\" in French) to the bison in 1616 (published 1619), after seeing skins and a drawing shown to him by members of the Nipissing First Nation, who said they travelled forty days (from east of Lake Huron) to trade with another nation who hunted the animals. Though \"bison\" might be considered more scientifically correct, as a result of standard usage, \"buffalo\" is also considered correct and is listed in many dictionaries as an acceptable name for American buffalo or bison. Buffalo has a much longer history than bison, which was first recorded in 1774.\n\nHumans were almost exclusively accountable for the near-extinction of the American bison in the 1800s. At the beginning of the century, tens of millions of bison roamed North America. American settlers slaughtered an estimated 50 million bison during the 19th century. Railroads were advertising \"hunting by rail\", where trains encountered large herds alongside or crossing the tracks. Men aboard fired from the trains roof or windows, leaving countless animals to rot where they died. The overhunting of the bison reduced their population to hundreds. Attempts to revive the American bison have been highly successful; farming has increased their population to nearly 150,000. The American bison is, therefore, no longer considered an endangered species.\n\nAs of July 2015, an estimated 4,900 bison lived in Yellowstone National Park, the largest U.S. bison population on public land. During 1983–1985 visitors experienced 33 bison-related injuries (range = 10–13/year), so the park implemented education campaigns. After years of success, five injuries associated with bison encounters occurred in 2015, because visitors did not maintain the required distance of 75 ft (23 m) from bison while hiking or taking pictures.\n\nBison is an excellent source of complete protein and a rich source (20% or more of the Daily Value, DV) of multiple vitamins including Riboflavin, Niacin, Vitamin B6, and Vitamin B12 and is also a rich source of minerals including iron, phosphorus, and zinc. Additionally, bison is a good source (10% or more of the Daily Value) of thiamine.\n\nBison are increasingly raised for meat, hide, wool, and dairy products. The majority of bison in the world are raised for human consumption or fur clothing. Bison meat is generally considered to taste very similar to beef, but is lower in fat and cholesterol, yet higher in protein than beef, which has led to the development of beefalo, a fertile hybrid of bison and domestic cattle. A market even exists for kosher bison meat; these bison are slaughtered at one of the few kosher mammal slaughterhouses in the U.S. and Canada, and the meat is then distributed worldwide.\n\nIn America, the commercial industry for bison has been slow to develop despite individuals, such as Ted Turner, who have long marketed bison meat. In the 1990s, Turner found limited success with restaurants for high-quality cuts of meat, which include bison steaks and tenderloin. Lower-quality cuts suitable for hamburger and hot dogs have been described as \"almost nonexistent\". This created a marketing problem for commercial farming because the majority of usable meat, about 400 pounds for each bison, is suitable for these products. In 2003, the United States Department of Agriculture purchased $10 million worth of frozen overstock to save the industry, which would later recover through better use of consumer marketing. Restaurants have played a role in popularizing bison meat, like Ted's Montana Grill, which added bison to their menus. Ruby Tuesday first offered bison on their menus in 2005.\n\nIn Canada, commercial bison farming began in the mid 1980s, concerning an unknown number of animals then. The first census of the bison occurred in 1996, which recorded 45,235 bison on 745 farms, and grew to 195,728 bison on 1,898 farms for the 2006 census.\n\nSeveral pet food companies use bison as a red meat alternative in dog foods. The companies producing these formulas include Natural Balance Pet Foods, Freshpet, The Blue Buffalo Company, Solid Gold, Canidae, and Taste of the Wild.\n\n\nFurther reading\n\n"}
{"id": "4584", "url": "https://en.wikipedia.org/wiki?curid=4584", "title": "Baryon", "text": "Baryon\n\nIn particle physics, a baryon is a type of composite subatomic particle which contains an odd number of valence quarks (at least 3). Baryons belong to the hadron family of particles, which are the quark-based particles. They are also classified as fermions, i.e., they have half-integer spin. \n\nThe name \"baryon\" comes from the Greek word for \"heavy\" (βαρύς, \"barýs\"), because, at the time of their naming, most known elementary particles had lower masses than the baryons. Each baryon has a corresponding antiparticle (antibaryon) where their corresponding antiquarks replace quarks. For example, a proton is made of two up quarks and one down quark; and its corresponding antiparticle, the antiproton, is made of two up antiquarks and one down antiquark.\n\nAs quark-based particles, baryons participate in the strong interaction, which is mediated by particles known as gluons. The most familiar baryons are protons and neutrons, both of which contain three quarks, and for this reason these particles are sometimes described as triquarks. These particles make up most of the mass of the visible matter in the universe, as well as forming the components of the nucleus of every atom. Electrons (the other major component of the atom) are members of a different family of particles, known as leptons, which do not interact via the strong force. Exotic baryons containing five quarks (known as pentaquarks) have also been discovered and studied.\n\nBaryons are strongly interacting fermions; that is, they are acted on by the strong nuclear force and are described by Fermi−Dirac statistics, which apply to all particles obeying the Pauli exclusion principle. This is in contrast to the bosons, which do not obey the exclusion principle.\n\nBaryons, along with mesons, are hadrons, particles composed of quarks. Quarks have baryon numbers of \"B\" =  and antiquarks have baryon numbers of \"B\" = −. The term \"baryon\" usually refers to \"triquarks\"—baryons made of three quarks (\"B\" =  +  +  = 1).\n\nOther exotic baryons have been proposed, such as pentaquarks—baryons made of four quarks and one antiquark (\"B\" =  +  +  +  −  = 1), but their existence is not generally accepted. The particle physics community as a whole did not view their existence as likely in 2006, and in 2008, considered evidence to be overwhelmingly against the existence of the reported pentaquarks. However, in July 2015, the LHCb experiment observed two resonances consistent with pentaquark states in the Λ → J/ψKp decay, with a combined statistical significance of 15σ.\n\nIn theory, heptaquarks (5 quarks, 2 antiquarks), nonaquarks (6 quarks, 3 antiquarks), etc. could also exist.\n\nNearly all matter that may be encountered or experienced in everyday life is baryonic matter, which includes atoms of any sort, and provides them with the property of mass. Non-baryonic matter, as implied by the name, is any sort of matter that is not composed primarily of baryons. This might include neutrinos and free electrons, dark matter, supersymmetric particles, axions, and black holes.\n\nThe very existence of baryons is also a significant issue in cosmology because it is assumed that the Big Bang produced a state with equal amounts of baryons and antibaryons. The process by which baryons came to outnumber their antiparticles is called baryogenesis.\n\nExperiments are consistent with the number of quarks in the universe being a constant and, to be more specific, the number of baryons being a constant ; in technical language, the total baryon number appears to be \"conserved.\" Within the prevailing Standard Model of particle physics, the number of baryons may change in multiples of three due to the action of sphalerons, although this is rare and has not been observed under experiment. Some grand unified theories of particle physics also predict that a single proton can decay, changing the baryon number by one; however, this has not yet been observed under experiment. The excess of baryons over antibaryons in the present universe is thought to be due to non-conservation of baryon number in the very early universe, though this is not well understood.\n\nThe concept of isospin was first proposed by Werner Heisenberg in 1932 to explain the similarities between protons and neutrons under the strong interaction. Although they had different electric charges, their masses were so similar that physicists believed they were the same particle. The different electric charges were explained as being the result of some unknown excitation similar to spin. This unknown excitation was later dubbed \"isospin\" by Eugene Wigner in 1937.\n\nThis belief lasted until Murray Gell-Mann proposed the quark model in 1964 (containing originally only the u, d, and s quarks). The success of the isospin model is now understood to be the result of the similar masses of u and d quarks. Since u and d quarks have similar masses, particles made of the same number then also have similar masses. The exact specific u and d quark composition determines the charge, as u quarks carry charge + while d quarks carry charge −. For example, the four Deltas all have different charges ( (uuu), (uud), (udd), (ddd)), but have similar masses (~1,232 MeV/c) as they are each made of a combination of three u and d quarks. Under the isospin model, they were considered to be a single particle in different charged states.\n\nThe mathematics of isospin was modeled after that of spin. Isospin projections varied in increments of 1 just like those of spin, and to each projection was associated a \"charged state\". Since the \"Delta particle\" had four \"charged states\", it was said to be of isospin \"I\" = . Its \"charged states\" , , , and , corresponded to the isospin projections \"I\" = +, \"I\" = +, \"I\" = −, and \"I\" = −, respectively. Another example is the \"nucleon particle\". As there were two nucleon \"charged states\", it was said to be of isospin . The positive nucleon (proton) was identified with \"I\" = + and the neutral nucleon (neutron) with \"I\" = −. It was later noted that the isospin projections were related to the up and down quark content of particles by the relation:<br>\nwhere the \"n\"'s are the number of up and down quarks and antiquarks.\n\nIn the \"isospin picture\", the four Deltas and the two nucleons were thought to be the different states of two particles. However, in the quark model, Deltas are different states of nucleons (the N or N are forbidden by Pauli's exclusion principle). Isospin, although conveying an inaccurate picture of things, is still used to classify baryons, leading to unnatural and often confusing nomenclature.\n\nThe strangeness flavour quantum number \"S\" (not to be confused with spin) was noticed to go up and down along with particle mass. The higher the mass, the lower the strangeness (the more s quarks). Particles could be described with isospin projections (related to charge) and strangeness (mass) (see the uds octet and decuplet figures on the right). As other quarks were discovered, new quantum numbers were made to have similar description of udc and udb octets and decuplets. Since only the u and d mass are similar, this description of particle mass and charge in terms of isospin and flavour quantum numbers works well only for octet and decuplet made of one u, one d, and one other quark, and breaks down for the other octets and decuplets (for example, ucb octet and decuplet). If the quarks all had the same mass, their behaviour would be called \"symmetric\", as they would all behave in the same way to the strong interaction. Since quarks do not have the same mass, they do not interact in the same way (exactly like an electron placed in an electric field will accelerate more than a proton placed in the same field because of its lighter mass), and the symmetry is said to be broken.\n\nIt was noted that charge (\"Q\") was related to the isospin projection (\"I\"), the baryon number (\"B\") and flavour quantum numbers (\"S\", \"C\", \"B\"′, \"T\") by the Gell-Mann–Nishijima formula:<br>\n\nwhere \"S\", \"C\", \"B\"′, and \"T\" represent the strangeness, charm, bottomness and topness flavour quantum numbers, respectively. They are related to the number of strange, charm, bottom, and top quarks and antiquark according to the relations:<br>\n\nmeaning that the Gell-Mann–Nishijima formula is equivalent to the expression of charge in terms of quark content:\n\nSpin (quantum number \"S\") is a vector quantity that represents the \"intrinsic\" angular momentum of a particle. It comes in increments of  ħ (pronounced \"h-bar\"). The ħ is often dropped because it is the \"fundamental\" unit of spin, and it is implied that \"spin 1\" means \"spin 1 ħ\". In some systems of natural units, ħ is chosen to be 1, and therefore does not appear anywhere.\n\nQuarks are fermionic particles of spin (\"S\" = ). Because spin projections vary in increments of 1 (that is 1 ħ), a single quark has a spin vector of length , and has two spin projections (\"S\" = + and \"S\" = −). Two quarks can have their spins aligned, in which case the two spin vectors add to make a vector of length \"S\" = 1 and three spin projections (\"S\" = +1, \"S\" = 0, and \"S\" = −1). If two quarks have unaligned spins, the spin vectors add up to make a vector of length \"S\" = 0 and has only one spin projection (\"S\" = 0), etc. Since baryons are made of three quarks, their spin vectors can add to make a vector of length \"S\" = , which has four spin projections (\"S\" = +, \"S\" = +, \"S\" = −, and \"S\" = −), or a vector of length \"S\" =  with two spin projections (\"S\" = +, and \"S\" = −).\n\nThere is another quantity of angular momentum, called the orbital angular momentum (azimuthal quantum number \"L\"), that comes in increments of 1 ħ, which represent the angular moment due to quarks orbiting around each other. The total angular momentum (total angular momentum quantum number \"J\") of a particle is therefore the combination of intrinsic angular momentum (spin) and orbital angular momentum. It can take any value from to , in increments of 1.\n\nParticle physicists are most interested in baryons with no orbital angular momentum (\"L\" = 0), as they correspond to ground states—states of minimal energy. Therefore, the two groups of baryons most studied are the \"S\" = ; \"L\" = 0 and \"S\" = ; \"L\" = 0, which corresponds to \"J\" =  and \"J\" = , respectively, although they are not the only ones. It is also possible to obtain \"J\" =  particles from \"S\" =  and \"L\" = 2, as well as \"S\" =  and \"L\" = 2. This phenomenon of having multiple particles in the same total angular momentum configuration is called \"degeneracy\". How to distinguish between these degenerate baryons is an active area of research in baryon spectroscopy.\n\nIf the universe were reflected in a mirror, most of the laws of physics would be identical—things would behave the same way regardless of what we call \"left\" and what we call \"right\". This concept of mirror reflection is called intrinsic parity\" or simply \"parity\" (\"P\"). Gravity, the electromagnetic force, and the strong interaction all behave in the same way regardless of whether or not the universe is reflected in a mirror, and thus are said to conserve parity (P-symmetry). However, the weak interaction does distinguish \"left\" from \"right\", a phenomenon called parity violation (P-violation).\n\nBased on this, if the wavefunction for each particle (in more precise terms, the quantum field for each particle type) were simultaneously mirror-reversed, then the new set of wavefunctions would perfectly satisfy the laws of physics (apart from the weak interaction). It turns out that this is not quite true: for the equations to be satisfied, the wavefunctions of certain types of particles have to be multiplied by −1, in addition to being mirror-reversed. Such particle types are said to have negative or odd parity (\"P\" = −1, or alternatively \"P\" = –), while the other particles are said to have positive or even parity (\"P\" = +1, or alternatively \"P\" = +).\n\nFor baryons, the parity is related to the orbital angular momentum by the relation:\n\nAs a consequence, baryons with no orbital angular momentum (\"L\" = 0) all have even parity (\"P\" = +).\n\nBaryons are classified into groups according to their isospin (\"I\") values and quark (\"q\") content. There are six groups of baryons—nucleon (), Delta (), Lambda (), Sigma (), Xi (), and Omega (). The rules for classification are defined by the Particle Data Group. These rules consider the up (), down () and strange () quarks to be \"light\" and the charm (), bottom (), and top () quarks to be \"heavy\". The rules cover all the particles that can be made from three of each of the six quarks, even though baryons made of top quarks are not expected to exist because of the top quark's short lifetime. The rules do not cover pentaquarks.\n\n\nIt is also a widespread (but not universal) practice to follow some additional rules when distinguishing between some states that would otherwise have the same symbol.\n\n\nQuarks carry a charge, so knowing the charge of a particle indirectly gives the quark content. For example, the rules above say that a contains a c quark and some combination of two u and/or d quarks. The c quark has a charge of (\"Q\" = +), therefore the other two must be a u quark (\"Q\" = +), and a d quark (\"Q\" = −) to have the correct total charge (\"Q\" = +1).\n\n\n"}
{"id": "4589", "url": "https://en.wikipedia.org/wiki?curid=4589", "title": "Braille embosser", "text": "Braille embosser\n\nA braille embosser is an impact printer that renders text as tactile braille cells. Using braille translation software, a document can be embossed with relative ease, making braille production efficient and cost-effective.\n\nBlind users tend to call other printers \"ink printers,\" to distinguish them from their braille counterparts. This is often the case regardless of the type of printer being discussed (e.g., thermal printers being called \"ink printers\" even though they use no ink).\n\nAs with ink printers and presses, embossers range from those intended for consumers to those used by large publishers. Thus, an embosser can cost roughly anywhere from US$2,000 to $150,000.\n\nThe fastest industrial braille embosser is probably the $77,000 Belgian-made NV Interpoint 55, first produced in 1991, which uses a separate air compressor to drive the embossing head and can output up to 800 braille characters per second. Adoption was slow at first; in 2000 the National Federation of the Blind said there were only three of these in the USA, one owned by the NFB itself and the other two by the Watchtower Bible and Tract Society. As of 2008 there are more than 60 in use across the world.\n\nSmaller desktop braille embossers are more common and can be found in libraries, universities, and specialist education centers, as well as being privately owned by blind individuals. Particularly with some lower-priced embossers, it may be necessary to use an acoustic cabinet or hood to dampen the noise level.\n\nBraille embossers usually need special braille paper which is thicker and more expensive than normal paper. Some high-end embossers are capable of printing on normal paper. Embossers can be either one-sided or two-sided. Duplex embossing requires lining up the dots so they do not overlap (called \"interpoint\" because the points on the other side are placed in between the points on the first side).\n\nOnce one copy of a document has been produced, printing further copies is often quicker by means of a device called a thermoform, which produces copies on soft plastic. However the resulting braille is not as easily readable as braille that has been freshly embossed, in much the same way that a poor-quality photocopy is not as readable as the original. Hence large publishers do not generally use thermoforms.\n\nSome embossers can produce \"dotty Moon\", i.e., Moon type shapes formed by dots.\n\n"}
{"id": "4592", "url": "https://en.wikipedia.org/wiki?curid=4592", "title": "Basic Role-Playing", "text": "Basic Role-Playing\n\nBasic Role-Playing (BRP) is a role-playing game system which originated in the \"RuneQuest\" fantasy role-playing game. The \"BRP\" standalone booklet was first released in 1980 in the boxed set release of the second edition of \"RuneQuest\". Greg Stafford and Lynn Willis are credited as the authors. A percentile skill-based system, \"BRP\" was used as the basis for most of the games published by Chaosium, including \"Call of Cthulhu\", \"Stormbringer\", and \"Elfquest\".\n\nThe core rules were originally written by Steve Perrin as part of his game \"RuneQuest\". It was Greg Stafford's idea to simplify the rules (eliminating such things as Strike Ranks and Hit Locations) and issue them in a 16-page booklet called \"Basic Role-Playing\". Over the years several others, including Sandy Petersen, Lynn Willis, and Steve Henderson, contributed to the system.\n\nThe \"BRP\" was notable for being the first role-playing game system to introduce a full skill system to characters regardless of their profession. This was developed in \"RuneQuest\" but was also later adopted by the more skill-oriented \"Call of Cthulhu\". \n\n\"BRP\" was conceived of as a generic system for playing any sort of RPG. Specific rule systems to support differing genres can be added to the core rules in a modular design. In order to underscore this, in 1982 Chaosium released the \"Worlds of Wonder\" box set, which contained a revised main booklet and several booklets providing the additional rules for playing in specific genres. \"Superworld\", a superhero-themed game, began as a portion of the \"Worlds of Wonder\" set. A third edition of the core booklet, now titled \"Basic Roleplaying: The Chaosium System\", was released in 2002.\n\nIn 2004, Chaosium published the \"Basic Roleplaying\" monographs, a series of paperback booklets. The first four monographs (\"Players Book\", \"Magic Book\", \"Creatures Book\", and \"Gamemaster Book\") were essentially \"RuneQuest\" 3rd Edition, but with the \"RuneQuest\" name and other trademarks removed, as Chaosium had lost the rights to the name but retained copyright of the rules text. Additional monographs allowing for new mechanics, thereby extending the system to other genres, were released in the following years. Many of these monographs reproduced rules from other Chaosium-published \"BRP\" games that had gone out of print. \n\nIn 2008 most monographs were collected and updated as a single, comprehensive book, nicknamed the \"Big Gold Book\", allowing game masters to essentially build their own game from the various subsystems included. A quickstart booklet for new players accompanied it.\n\nOther games published over the years by Chaosium using the \"BRP\" ruleset include \"Ringworld\", \"Hawkmoon\", and \"Nephilim\".\n\n\"BRP\" is similar to other generic systems such as \"GURPS\", \"Hero System\" or \"Savage Worlds\" in that it uses a simple resolution method which can be broadly applied. \"BRP\" uses a core set of seven characteristics: Size, Strength, Dexterity, Constitution, Intelligence, Power, and Appearance or Charisma. From those, a character derives scores in various skills, expressed as percentages. These skill scores are the basis of play. When attempting an action, the player rolls percentile dice trying to get a result equal to or lower than the character's current skill score. Each incarnation of the \"BRP\" rules has changed or added to the core ideas and mechanics, so that games are not identical. For example, in \"Call of Cthulhu\", skills may never be over 100%, while in \"Stormbringer\" skills in excess of 100% are within reach for all characters. Scores can increase through experience checks, the mechanics of which vary in an individual game. \n\n\"BRP\" treats armor and defense as separate functions: the act of parrying is a defensive skill that reduced an opponent's chance to successfully land an attack, and the purpose of armor is to absorb damage. \n\nThe last major element of many \"BRP\" games is that there is no difference between the player character race systems and that of the monster or opponents. By varying ability scores, the same system is used for a human hero as a troll villain. This approach allows for players to play a wide variety of non-human species.\n\nChaosium was an early adopter of licensing out its \"BRP\" system to other companies, something that was unique at the time they began but rather commonplace now thanks to the d20 licenses. This places the \"BRP\" in the notable position of being one of the first products to allow other game companies to develop games or game aids for their work. Companies such as Green Knight and Pagan Publishing built their earliest works to support Chaosium's games.\n\nOther, non-Chaosium games have used \"BRP\" for its core rules. For example, \"Other Suns\", published by Fantasy Games Unlimited (FGU), used them under license. \"BRP\" was also used as the base for the highly successful Swedish game \"Drakar och Demoner\" from Target Games.\n\nRonald Pehr reviewed \"Basic Role-Playing\" in \"The Space Gamer\" No. 41. Pehr commented that \"\"Basic Role-Playing\" is too little too late. \"RuneQuest\" is long established, does an adequate job of teaching role-playing, and there are now even more games to choose from. If you want to teach role-playing to a very young, but literate, child, \"Basic Role-Playing\" is excellent. Otherwise, for all its charm, it's not much use.\"\n\nThe \"BRP\" itself has been the recipient, via its games, of many awards. Most notable was the 1981 Origins Award for \"Best Roleplaying Rules\" for \"Call of Cthulhu\". Other editions of \"Call of Cthulhu\" have also won Origins Awards including the Hall of Fame award. The \"BRP\" Character Generation software has also won awards for its design.\n\n\n"}
{"id": "4594", "url": "https://en.wikipedia.org/wiki?curid=4594", "title": "Block cipher", "text": "Block cipher\n\nIn cryptography, a block cipher is a deterministic algorithm operating on fixed-length groups of bits, called a \"block\", with an unvarying transformation that is specified by a symmetric key. Block ciphers operate as important elementary components in the design of many cryptographic protocols, and are widely used to implement encryption of bulk data.\n\nThe modern design of block ciphers is based on the concept of an iterated product cipher. In his seminal 1949 publication, \"Communication Theory of Secrecy Systems\", Claude Shannon analyzed product ciphers and suggested them as a means of effectively improving security by combining simple operations such as substitutions and permutations. Iterated product ciphers carry out encryption in multiple rounds, each of which uses a different subkey derived from the original key. One widespread implementation of such ciphers, named a Feistel network after Horst Feistel, is notably implemented in the DES cipher. Many other realizations of block ciphers, such as the AES, are classified as substitution–permutation networks.\n\nThe publication of the DES cipher by the United States National Bureau of Standards (subsequently the U.S. National Institute of Standards and Technology, NIST) in 1977 was fundamental in the public understanding of modern block cipher design. It also influenced the academic development of cryptanalytic attacks. Both differential and linear cryptanalysis arose out of studies on the DES design. there is a palette of attack techniques against which a block cipher must be secure, in addition to being robust against brute-force attacks.\n\nEven a secure block cipher is suitable only for the encryption of a single block under a fixed key. A multitude of modes of operation have been designed to allow their repeated use in a secure way, commonly to achieve the security goals of confidentiality and authenticity. However, block ciphers may also feature as building blocks in other cryptographic protocols, such as universal hash functions and pseudo-random number generators.\n\nA block cipher consists of two paired algorithms, one for encryption, \"E\", and the other for decryption, \"D\". Both algorithms accept two inputs: an input block of size \"n\" bits and a key of size \"k\" bits; and both yield an \"n\"-bit output block. The decryption algorithm \"D\" is defined to be the inverse function of encryption, i.e., \"D\" = \"E\". More formally, a block cipher is specified by an encryption function\nwhich takes as input a key \"K\" of bit length \"k\", called the \"key size\", and a bit string \"P\" of length \"n\", called the \"block size\", and returns a string \"C\" of \"n\" bits. \"P\" is called the plaintext, and \"C\" is termed the ciphertext. For each \"K\", the function \"E\"(\"P\") is required to be an invertible mapping on {0,1}. The inverse for \"E\" is defined as a function\ntaking a key \"K\" and a ciphertext \"C\" to return a plaintext value \"P\", such that\n\nFor example, a block cipher encryption algorithm might take a 128-bit block of plaintext as input, and output a corresponding 128-bit block of ciphertext. The exact transformation is controlled using a second input – the secret key. Decryption is similar: the decryption algorithm takes, in this example, a 128-bit block of ciphertext together with the secret key, and yields the original 128-bit block of plain text.\n\nFor each key \"K\", \"E\" is a permutation (a bijective mapping) over the set of input blocks. Each key selects one permutation from the set of formula_4 possible permutations.\n\nMost block cipher algorithms are classified as \"iterated block ciphers\" which means that they transform fixed-size blocks of plaintext into identical size blocks of ciphertext, via the repeated application of an invertible transformation known as the \"round function\", with each iteration referred to as a \"round\".\n\nUsually, the round function \"R\" takes different \"round keys\" \"K\" as second input, which are derived from the original key:\nwhere formula_6 is the plaintext and formula_7 the ciphertext, with \"r\" being the number of rounds.\n\nFrequently, key whitening is used in addition to this. At the beginning and the end, the data is modified with key material (often with XOR, but simple arithmetic operations like adding and subtracting are also used):\n\nGiven one of the standard iterated block cipher design schemes, it is fairly easy to construct a block cipher that is cryptographically secure, simply by using a large number of rounds. However, this will make the cipher inefficient. Thus, efficiency is the most important additional design criterion for professional ciphers. Further, a good block cipher is designed to avoid side-channel attacks, such as input-dependent memory accesses that might leak secret data via the cache state or the execution time. In addition, the cipher should be concise, for small hardware and software implementations. Finally, the cipher should be easily cryptanalyzable, such that it can be shown how many rounds the cipher needs to be reduced to, so that the existing cryptographic attacks would work – and, conversely, that it can be shown that the number of actual rounds is large enough to protect against them.\n\nOne important type of iterated block cipher known as a \"substitution–permutation network (SPN)\" takes a block of the plaintext and the key as inputs, and applies several alternating rounds consisting of a substitution stage followed by a permutation stage—to produce each block of ciphertext output. The non-linear substitution stage mixes the key bits with those of the plaintext, creating Shannon's \"confusion\". The linear permutation stage then dissipates redundancies, creating \"diffusion\".\n\nA \"substitution box (S-box)\" substitutes a small block of input bits with another block of output bits. This substitution must be one-to-one, to ensure invertibility (hence decryption). A secure S-box will have the property that changing one input bit will change about half of the output bits on average, exhibiting what is known as the avalanche effect—i.e. it has the property that each output bit will depend on every input bit.\n\nA \"permutation box (P-box)\" is a permutation of all the bits: it takes the outputs of all the S-boxes of one round, permutes the bits, and feeds them into the S-boxes of the next round. A good P-box has the property that the output bits of any S-box are distributed to as many S-box inputs as possible.\n\nAt each round, the round key (obtained from the key with some simple operations, for instance, using S-boxes and P-boxes) is combined using some group operation, typically XOR.\n\nDecryption is done by simply reversing the process (using the inverses of the S-boxes and P-boxes and applying the round keys in reversed order).\n\nIn a \"Feistel cipher\", the block of plain text to be encrypted is split into two equal-sized halves. The round function is applied to one half, using a subkey, and then the output is XORed with the other half. The two halves are then swapped.\n\nLet formula_11 be the round function and let\nformula_12 be the sub-keys for the rounds formula_13 respectively.\n\nThen the basic operation is as follows:\n\nSplit the plaintext block into two equal pieces, (formula_14, formula_15)\n\nFor each round formula_16, compute\n\nThen the ciphertext is formula_19.\n\nDecryption of a ciphertext formula_19 is accomplished by computing for formula_21\n\nThen formula_24 is the plaintext again.\n\nOne advantage of the Feistel model compared to a substitution–permutation network is that the round function formula_11 does not have to be invertible.\n\nThe Lai–Massey scheme offers security properties similar to those of the Feistel structure. It also shares its advantage that the round function formula_26 does not have to be invertible. Another similarity is that is also splits the input block into two equal pieces. However, the round function is applied to the difference between the two, and the result is then added to both half blocks.\n\nLet formula_26 be the round function and formula_28 a half-round function and let formula_29 be the sub-keys for the rounds formula_13 respectively.\n\nThen the basic operation is as follows:\n\nSplit the plaintext block into two equal pieces, (formula_14, formula_15)\n\nFor each round formula_16, compute\n\nwhere formula_35 and formula_36\n\nThen the ciphertext is formula_37.\n\nDecryption of a ciphertext formula_38 is accomplished by computing for formula_21\n\nwhere formula_41 and formula_42\n\nThen formula_43 is the plaintext again.\n\nMany modern block ciphers and hashes are ARX algorithms—their round function involves only three operations: modular addition, rotation with fixed rotation amounts, and XOR (ARX). Examples include ChaCha20, Speck, XXTEA, and BLAKE.\nMany authors draw an ARX network, a kind of data flow diagram, to illustrate such a round function.\n\nThese ARX operations are popular because they are relatively fast and cheap in hardware and software,\nand also because they run in constant time, and are therefore immune to timing attacks.\nThe rotational cryptanalysis technique attempts to attack such round functions.\n\nOther operations often used in block ciphers include\ndata-dependent rotations as in RC5 and RC6,\na substitution box implemented as a lookup table as in Data Encryption Standard and Advanced Encryption Standard,\na permutation box,\nand multiplication as in IDEA.\n\nA block cipher by itself allows encryption only of a single data block of the cipher's block length. For a variable-length message, the data must first be partitioned into separate cipher blocks. In the simplest case, known as the Electronic Codebook (ECB) mode, a message is first split into separate blocks of the cipher's block size (possibly extending the last block with padding bits), and then each block is encrypted and decrypted independently. However, such a naive method is generally insecure because equal plaintext blocks will always generate equal ciphertext blocks (for the same key), so patterns in the plaintext message become evident in the ciphertext output.\n\nTo overcome this limitation, several so called block cipher modes of operation have been designed and specified in national recommendations such as NIST 800-38A and BSI TR-02102 and international standards such as ISO/IEC 10116. The general concept is to use randomization of the plaintext data based on an additional input value, frequently called an initialization vector, to create what is termed probabilistic encryption. In the popular cipher block chaining (CBC) mode, for encryption to be secure the initialization vector passed along with the plaintext message must be a random or pseudo-random value, which is added in an exclusive-or manner to the first plaintext block before it is being encrypted. The resultant ciphertext block is then used as the new initialization vector for the next plaintext block. In the cipher feedback (CFB) mode, which emulates a self-synchronizing stream cipher, the initialization vector is first encrypted and then added to the plaintext block. The output feedback (OFB) mode repeatedly encrypts the initialization vector to create a key stream for the emulation of a synchronous stream cipher. The newer counter (CTR) mode similarly creates a key stream, but has the advantage of only needing unique and not (pseudo-)random values as initialization vectors; the needed randomness is derived internally by using the initialization vector as a block counter and encrypting this counter for each block.\n\nFrom a security-theoretic point of view, modes of operation must provide what is known as semantic security. Informally, it means that given some ciphertext under an unknown key one cannot practically derive any information from the ciphertext (other than the length of the message) over what one would have known without seeing the ciphertext. It has been shown that all of the modes discussed above, with the exception of the ECB mode, provide this property under so-called chosen plaintext attacks.\n\nSome modes such as the CBC mode only operate on complete plaintext blocks. Simply extending the last block of a message with zero-bits is insufficient since it does not allow a receiver to easily distinguish messages that differ only in the amount of padding bits. More importantly, such a simple solution gives rise to very efficient padding oracle attacks. A suitable padding scheme is therefore needed to extend the last plaintext block to the cipher's block size. While many popular schemes described in standards and in the literature have been shown to be vulnerable to padding oracle attacks, a solution which adds a one-bit and then extends the last block with zero-bits, standardized as \"padding method 2\" in ISO/IEC 9797-1, has been proven secure against these attacks.\n\n This property results in the cipher's security degrading quadratically, and needs to be taken into account when selecting a block size. There is a trade-off though as large block sizes can result in the algorithm becoming inefficient to operate. Earlier block ciphers such as the DES have typically selected a 64-bit block size, while newer designs such as the AES support block sizes of 128 bits or more, with some ciphers supporting a range of different block sizes.\n\n\"Linear cryptanalysis\" is a form of cryptanalysis based on finding affine approximations to the action of a cipher. Linear cryptanalysis is one of the two most widely used attacks on block ciphers; the other being differential cryptanalysis.\n\nThe discovery is attributed to Mitsuru Matsui, who first applied the technique to the FEAL cipher (Matsui and Yamagishi, 1992).\n\n\"Integral cryptanalysis\" is a cryptanalytic attack that is particularly applicable to block ciphers based on substitution–permutation networks. Unlike differential cryptanalysis, which uses pairs of chosen plaintexts with a fixed XOR difference, integral cryptanalysis uses sets or even multisets of chosen plaintexts of which part is held constant and another part varies through all possibilities. For example, an attack might use 256 chosen plaintexts that have all but 8 of their bits the same, but all differ in those 8 bits. Such a set necessarily has an XOR sum of 0, and the XOR sums of the corresponding sets of ciphertexts provide information about the cipher's operation. This contrast between the differences of pairs of texts and the sums of larger sets of texts inspired the name \"integral cryptanalysis\", borrowing the terminology of calculus.\n\nIn addition to linear and differential cryptanalysis, there is a growing catalog of attacks: truncated differential cryptanalysis, partial differential cryptanalysis, integral cryptanalysis, which encompasses square and integral attacks, slide attacks, boomerang attacks, the XSL attack, impossible differential cryptanalysis and algebraic attacks. For a new block cipher design to have any credibility, it must demonstrate evidence of security against known attacks.\n\nWhen a block cipher is used in a given mode of operation, the resulting algorithm should ideally be about as secure as the block cipher itself. ECB (discussed above) emphatically lacks this property: regardless of how secure the underlying block cipher is, ECB mode can easily be attacked. On the other hand, CBC mode can be proven to be secure under the assumption that the underlying block cipher is likewise secure. Note, however, that making statements like this requires formal mathematical definitions for what it means for an encryption algorithm or a block cipher to \"be secure\". This section describes two common notions for what properties a block cipher should have. Each corresponds to a mathematical model that can be used to prove properties of higher level algorithms, such as CBC.\n\nThis general approach to cryptography – proving higher-level algorithms (such as CBC) are secure under explicitly stated assumptions regarding their components (such as a block cipher) – is known as \"provable security\".\n\nInformally, a block cipher is secure in the standard model if an attacker cannot tell the difference between the block cipher (equipped with a random key) and a random permutation.\n\nTo be a bit more precise, let \"E\" be an \"n\"-bit block cipher. We imagine the following game:\n\nThe attacker, which we can model as an algorithm, is called an \"adversary\". The function \"f\" (which the adversary was able to query) is called an \"oracle\".\n\nNote that an adversary can trivially ensure a 50% chance of winning simply by guessing at random (or even by, for example, always guessing \"heads\"). Therefore, let \"P(A)\" denote the probability that the adversary \"A\" wins this game against \"E\", and define the \"advantage\" of \"A\" as 2(\"P(A)\" − 1/2). It follows that if \"A\" guesses randomly, its advantage will be 0; on the other hand, if \"A\" always wins, then its advantage is 1. The block cipher \"E\" is a \"pseudo-random permutation\" (PRP) if no adversary has an advantage significantly greater than 0, given specified restrictions on \"q\" and the adversary's running time. If in Step 2 above adversaries have the option of learning \"f(X)\" instead of \"f(X)\" (but still have only small advantages) then \"E\" is a \"strong\" PRP (SPRP). An adversary is \"non-adaptive\" if it chooses all \"q\" values for \"X\" before the game begins (that is, it does not use any information gleaned from previous queries to choose each \"X\" as it goes).\n\nThese definitions have proven useful for analyzing various modes of operation. For example, one can define a similar game for measuring the security of a block cipher-based encryption algorithm, and then try to show (through a reduction argument) that the probability of an adversary winning this new game is not much more than \"P(A)\" for some \"A\". (The reduction typically provides limits on \"q\" and the running time of \"A\".) Equivalently, if \"P(A)\" is small for all relevant \"A\", then no attacker has a significant probability of winning the new game. This formalizes the idea that the higher-level algorithm inherits the block cipher's security.\n\nBlock ciphers may be evaluated according to multiple criteria in practice. Common factors include:\n\nLucifer is generally considered to be the first civilian block cipher, developed at IBM in the 1970s based on work done by Horst Feistel. A revised version of the algorithm was adopted as a U.S. government Federal Information Processing Standard: FIPS PUB 46 Data Encryption Standard (DES). It was chosen by the U.S. National Bureau of Standards (NBS) after a public invitation for submissions and some internal changes by NBS (and, potentially, the NSA). DES was publicly released in 1976 and has been widely used.\n\nDES was designed to, among other things, resist a certain cryptanalytic attack known to the NSA and rediscovered by IBM, though unknown publicly until rediscovered again and published by Eli Biham and Adi Shamir in the late 1980s. The technique is called differential cryptanalysis and remains one of the few general attacks against block ciphers; linear cryptanalysis is another, but may have been unknown even to the NSA, prior to its publication by Mitsuru Matsui. DES prompted a large amount of other work and publications in cryptography and cryptanalysis in the open community and it inspired many new cipher designs.\n\nDES has a block size of 64 bits and a key size of 56 bits. 64-bit blocks became common in block cipher designs after DES. Key length depended on several factors, including government regulation. Many observers in the 1970s commented that the 56-bit key length used for DES was too short. As time went on, its inadequacy became apparent, especially after a special purpose machine designed to break DES was demonstrated in 1998 by the Electronic Frontier Foundation. An extension to DES, Triple DES, triple-encrypts each block with either two independent keys (112-bit key and 80-bit security) or three independent keys (168-bit key and 112-bit security). It was widely adopted as a replacement. As of 2011, the three-key version is still considered secure, though the National Institute of Standards and Technology (NIST) standards no longer permit the use of the two-key version in new applications, due to its 80-bit security level.\n\nThe \"International Data Encryption Algorithm\" (\"IDEA\") is a block cipher designed by James Massey of ETH Zurich and Xuejia Lai; it was first described in 1991, as an intended replacement for DES.\n\nIDEA operates on 64-bit blocks using a 128-bit key, and consists of a series of eight identical transformations (a \"round\") and an output transformation (the \"half-round\"). The processes for encryption and decryption are similar. IDEA derives much of its security by interleaving operations from different groups – modular addition and multiplication, and bitwise \"exclusive or (XOR)\" – which are algebraically \"incompatible\" in some sense.\n\nThe designers analysed IDEA to measure its strength against differential cryptanalysis and concluded that it is immune under certain assumptions. No successful linear or algebraic weaknesses have been reported. , the best attack which applies to all keys can break full 8.5-round IDEA using a narrow-bicliques attack about four times faster than brute force.\n\nRC5 is a block cipher designed by Ronald Rivest in 1994 which, unlike many other ciphers, has a variable block size (32, 64 or 128 bits), key size (0 to 2040 bits) and number of rounds (0 to 255). The original suggested choice of parameters were a block size of 64 bits, a 128-bit key and 12 rounds.\n\nA key feature of RC5 is the use of data-dependent rotations; one of the goals of RC5 was to prompt the study and evaluation of such operations as a cryptographic primitive. RC5 also consists of a number of modular additions and XORs. The general structure of the algorithm is a Feistel-like network. The encryption and decryption routines can be specified in a few lines of code. The key schedule, however, is more complex, expanding the key using an essentially one-way function with the binary expansions of both e and the golden ratio as sources of \"nothing up my sleeve numbers\". The tantalising simplicity of the algorithm together with the novelty of the data-dependent rotations has made RC5 an attractive object of study for cryptanalysts.\n\n12-round RC5 (with 64-bit blocks) is susceptible to a differential attack using 2 chosen plaintexts. 18–20 rounds are suggested as sufficient protection.\n\nThe \"Rijndael\" cipher developed by Belgian cryptographers, Joan Daemen and Vincent Rijmen was one of the competing designs to replace DES. It won the 5-year public competition to become the AES, (Advanced Encryption Standard). \n\nAdopted by NIST in 2001, AES has a fixed block size of 128 bits and a key size of 128, 192, or 256 bits, whereas Rijndael can be specified with block and key sizes in any multiple of 32 bits, with a minimum of 128 bits. The blocksize has a maximum of 256 bits, but the keysize has no theoretical maximum. AES operates on a 4×4 column-major order matrix of bytes, termed the \"state\" (versions of Rijndael with a larger block size have additional columns in the state).\n\n\"Blowfish\" is a block cipher, designed in 1993 by Bruce Schneier and included in a large number of cipher suites and encryption products. Blowfish has a 64-bit block size and a variable key length from 1 bit up to 448 bits. It is a 16-round Feistel cipher and uses large key-dependent S-boxes. Notable features of the design include the key-dependent S-boxes and a highly complex key schedule.\n\nIt was designed as a general-purpose algorithm, intended as an alternative to the ageing DES and free of the problems and constraints associated with other algorithms. At the time Blowfish was released, many other designs were proprietary, encumbered by patents or were commercial/government secrets. Schneier has stated that, \"Blowfish is unpatented, and will remain so in all countries. The algorithm is hereby placed in the public domain, and can be freely used by anyone.\" The same applies to Twofish, a successor algorithm from Schneier.\n\nM. Liskov, R. Rivest, and D. Wagner have described a generalized version of block ciphers called \"tweakable\" block ciphers. A tweakable block cipher accepts a second input called the \"tweak\" along with its usual plaintext or ciphertext input. The tweak, along with the key, selects the permutation computed by the cipher. If changing tweaks is sufficiently lightweight (compared with a usually fairly expensive key setup operation), then some interesting new operation modes become possible. The disk encryption theory article describes some of these modes.\n\nBlock ciphers traditionally work over a binary alphabet. That is, both the input and the output are binary strings, consisting of \"n\" zeroes and ones. In some situations, however, one may wish to have a block cipher that works over some other alphabet; for example, encrypting 16-digit credit card numbers in such a way that the ciphertext is also a 16-digit number might facilitate adding an encryption layer to legacy software. This is an example of \"format-preserving encryption\". More generally, format-preserving encryption requires a keyed permutation on some finite language. This makes format-preserving encryption schemes a natural generalization of (tweakable) block ciphers. In contrast, traditional encryption schemes, such as CBC, are not permutations because the same plaintext can encrypt to multiple different ciphertexts, even when using a fixed key.\n\nBlock ciphers can be used to build other cryptographic primitives, such as those below. For these other primitives to be cryptographically secure, care has to be taken to build them the right way.\n\n\nJust as block ciphers can be used to build hash functions, hash functions can be used to build block ciphers. Examples of such block ciphers are SHACAL, BEAR and LION.\n\n\n"}
{"id": "4595", "url": "https://en.wikipedia.org/wiki?curid=4595", "title": "Wireless broadband", "text": "Wireless broadband\n\nWireless broadband is telecommunications technology that provides high-speed wireless Internet access or computer networking access over a wide area. The term comprises both fixed and mobile broadband.\n\nOriginally the word \"broadband\" had a technical meaning, but became a marketing term for any kind of relatively high-speed computer network or Internet access technology.\nAccording to the 802.16-2004 standard, broadband means \"having instantaneous bandwidths greater than 1 MHz and supporting data rates greater than about 1.5 Mbit/s.\"\nThe Federal Communications Commission (FCC) recently re-defined the definition to mean download speeds of at least 25 Mbit/s and upload speeds of at least 3 Mbit/s.\n\nWireless networks can feature data rates roughly equivalent to some wired networks, such as that of asymmetric digital subscriber line (ADSL) or a cable modem. Wireless networks can also be symmetrical, meaning the same rate in both directions (downstream and upstream), which is most commonly associated with fixed wireless networks. A fixed wireless network link is a stationary terrestrial wireless connection, which can support higher data rates for the same power as mobile or satellite systems.\n\nFew wireless Internet service providers (WISPs) provide download speeds of over 100 Mbit/s; most broadband wireless access (BWA) services are estimated to have a range of from a tower. Technologies used include LMDS and MMDS, as well as heavy use of the ISM bands and one particular access technology was standardized by IEEE 802.16, with products known as WiMAX.\n\nWiMAX is highly popular in Europe but has not met full acceptance in the United States because cost of deployment does not meet return on investment figures. In 2005 the Federal Communications Commission adopted a Report and Order that revised the FCC’s rules to open the 3650 MHz band for terrestrial wireless broadband operations.\n\nOn November 14, 2007 the Commission released Public Notice DA 07-4605 in which the Wireless Telecommunications Bureau announced the start date for licensing and registration process for the 3650–3700 MHz band.\nIn 2010 the FCC adopted the TV White Space Rules (TVWS) and allowed some of the better no line of sight frequency (700 MHz) into the FCC Part-15 Rules. The Wireless Internet Service Providers Association, a national association of WISPs, petitioned the FCC and won.\n\nInitially, WISPs were only found in rural areas not covered by cable or DSL. These early WISPs would employ a high-capacity T-carrier, such as a T1 or DS3 connection, and then broadcast the signal from a high elevation, such as at the top of a water tower. To receive this type of Internet connection, consumers mount a small dish to the roof of their home or office and point it to the transmitter. Line of sight is usually necessary for WISPs operating in the 2.4 and 5 GHz bands with 900 MHz offering better NLOS (non-line-of-sight) performance.\n\nProviders of fixed wireless broadband services typically provide equipment to customers and install a small antenna or dish somewhere on the roof. This equipment is usually deployed as a service and maintained by the company providing that service. Fixed wireless services have become particularly popular in many rural areas where Cable, DSL or other typical home Internet services are not available.\n\nMany companies in the US and worldwide have started using wireless alternatives to incumbent and local providers for internet and voice service. These providers tend to offer competitive services and options in areas where there is a difficulty getting affordable Ethernet connections from terrestrial providers such as ATT, Comcast, Verizon and others. Also, companies looking for full diversity between carriers for critical uptime requirements may seek wireless alternatives to local options.\n\nTo cope with increased demand for wireless broadband, increased spectrum would be needed. Studies began in 2009, and while some unused spectrum was available, it appeared broadcasters would have to give up at least some spectrum. This led to strong objections from the broadcasting community. In 2013, auctions were planned, and for now any action by broadcasters is voluntary.\n\nCalled mobile broadband, wireless broadband technologies include services from mobile phone service providers such as Verizon Wireless, Sprint Corporation, and AT&T Mobility,and T-Mobile which allow a more mobile version of Internet access. Consumers can purchase a PC card, laptop card, or USB equipment to connect their PC or laptop to the Internet via cell phone towers. This type of connection would be stable in almost any area that could also receive a strong cell phone connection. These connections can cost more for portable convenience as well as having speed limitations in all but urban environments.\n\nOn June 2, 2010, after months of discussion, AT&T became the first wireless Internet provider in the USA to announce plans to charge according to usage. As the only iPhone service in the United States, AT&T experienced the problem of heavy Internet use more than other providers. About 3 percent of AT&T smart phone customers account for 40 percent of the technology's use. 98 percent of the company's customers use less than 2 gigabytes (4000 page views, 10,000 emails or 200 minutes of streaming video), the limit under the $25 monthly plan, and 65 percent use less than 200 megabytes, the limit for the $15 plan. For each gigabyte in excess of the limit, customers would be charged $10 a month starting June 7, 2010, though existing customers would not be required to change from the $30 a month unlimited service plan. The new plan would become a requirement for those upgrading to the new iPhone technology later in the summer.\n\nA wireless connection can be either licensed or unlicensed. In the U.S., licensed connections use a private spectrum the user has secured rights to from the Federal Communications Commission (FCC). In other countries, spectrum is licensed from the country's national radio communications authority (such as the ACMA in Australia or Nigerian Communications Commission in Nigeria (NCC)). Licensing is usually expensive and often reserved for large companies who wish to guarantee private access to spectrum for use in point to point communication. Because of this, most wireless ISP's use unlicensed spectrum which is publicly shared.\n\n\n \n\n"}
{"id": "4601", "url": "https://en.wikipedia.org/wiki?curid=4601", "title": "Björn Borg", "text": "Björn Borg\n\nBjörn Rune Borg (; born 6 June 1956) is a Swedish former world No. 1 tennis player widely considered to be one of the greatest in the history of the sport. Between 1974 and 1981 he became the first man in the Open Era to win 11 Grand Slam singles titles (six at the French Open and five consecutive at Wimbledon). He also won three year-end championships and 15 Grand Prix Super Series titles. Overall, he set numerous records that still stand.\n\nA teenage sensation at the start of his career, Borg's unprecedented stardom and consistent success helped propel the rising popularity of tennis during the 1970s. As a result, the professional tour became more lucrative, and in 1979 he was the first player to earn more than one million dollars in prize money in a single season. He also made millions in endorsements throughout his career. The downside, however, was that the constant attention and pressure eventually caused burnout and his retirement at the age of 26.\n\nBjörn Borg was born in Stockholm, Sweden, on 6 June 1956, as the only child of Rune (1932-2008) and Margaretha Borg (b. 1934). He grew up in nearby Södertälje. As a child, Borg became fascinated with a golden tennis racket that his father won at a table-tennis tournament. His father gave him the racket, beginning his tennis career.\n\nA player of great athleticism and endurance, he had a distinctive style and appearance—bowlegged and very fast. His muscularity allowed him to put heavy topspin on both his forehand and two-handed backhand. He followed Jimmy Connors in using the two-handed backhand. By the time he was 13 he was beating the best of Sweden's under-18 players, and Davis Cup captain Lennart Bergelin (who served as Borg's primary coach throughout his professional career) cautioned against anyone trying to change Borg's rough-looking, jerky strokes.\n\nAt the age of 15 Borg represented Sweden in the 1972 Davis Cup and won his debut singles rubber in five sets against veteran Onny Parun of New Zealand. Later that year, he won the Wimbledon junior singles title, recovering from a 5–2 deficit in the final set to overcome Britain's Buster Mottram. Then in December he won the Orange Bowl Junior Championship for boys, 18 and under after a straight sets victory in the final over Vitas Gerulaitis. Borg joined the professional circuit in 1973, and reached his first singles final in April at the Monte Carlo Open which he lost to Ilie Năstase. He was unseeded at his first French Open and reached the fourth round where he lost in four sets to eight-seeded Adriano Panatta. Borg was seeded sixth at his first Wimbledon Championships, in large part due to a boycott by the ATP, and reached the quarterfinal where he was defeated in a five-set match by Roger Taylor. In the second half of 1973 he was runner-up in San Francisco, Stockholm and Buenos Aires and finished the year ranked No. 18.\n\nBorg made his only appearance at the Australian Open, at the age of 17, and reached the third round where he lost in straight sets to eventual finalist Phil Dent. In January he won his first career singles title at the New Zealand Open, followed by titles in London and São Paulo in February and March respectively. Just before his 18th birthday in June 1974, Borg won his first top-level singles title at the Italian Open, defeating defending champion and top-seeded Ilie Năstase in the final and becoming its youngest winner. Two weeks later he won the singles title at the French Open, his first Grand Slam tournament title, defeating Manuel Orantes in the final in five sets. Barely 18, Borg was the youngest-ever male French Open champion up to that point.\n\nIn early 1975, Borg defeated Rod Laver, then 36 years old, in a semifinal of the World Championship Tennis (WCT) finals in Dallas, Texas, in five sets. Borg subsequently lost to Arthur Ashe in the final.\nBorg retained his French Open title in 1975, beating Guillermo Vilas in the final in straight sets. Borg then reached the Wimbledon quarterfinals, where he lost to eventual champion Ashe. Borg did not lose another match at Wimbledon until 1981. Borg won two singles and one doubles rubber in the 1975 Davis Cup final, as Sweden beat Czechoslovakia 3–2. With these singles wins, Borg had won 19 consecutive Davis Cup singles rubbers since 1973. That was already a record at the time. However, Borg never lost another Davis Cup singles rubber, and, by the end of his career, he had stretched that winning streak to 33.\n\nIn early 1976, Borg won the World Championship Tennis year-end WCT Finals in Dallas, Texas, with a four-set victory over Guillermo Vilas in the final. At the 1976 French Open, Borg lost to the Italian Adriano Panatta, who remains the only player to defeat Borg at this tournament. Panatta did it twice: in the fourth round in 1973, and in the 1976 quarterfinals. Borg won Wimbledon in 1976 without losing a set, defeating the favored Ilie Năstase in the final. Borg became the youngest male Wimbledon champion of the modern era at 20 years and 1 month (a record subsequently broken by Boris Becker, who won Wimbledon aged 17 in 1985). It would be the last time Borg played Wimbledon as an underdog. Năstase later exclaimed, \"We're playing tennis, he's [Borg] playing something else.\" Borg also reached the final of the 1976 U.S. Open, which was then being played on clay courts. Borg lost in four sets to world no. 1 Jimmy Connors.\n\nIn February 1977 World Championship Tennis (WCT) sued Borg and his management company IMG claiming that Borg had committed a breach of contract by electing to participate in the competing 1977 Grand Prix circuit instead of the WCT circuit. Borg eventually played, and won, a single WCT event, the Monte Carlo WCT. An out-of-court settlement was reached whereby Borg committed to play six or eight WCT events in 1978 which were then part of the Grand Prix circuit.\n\nBorg skipped the French Open in 1977 because he was under contract with WTT, but he repeated his Wimbledon triumph, although this time he was pushed much harder. He defeated his good friend Vitas Gerulaitis in a semifinal in five sets. In the 1977 final Borg was pushed to five sets for the third time in the tournament, this time by Connors. The win propelled Borg to the no. 1 ranking on the computer, albeit for just one week in August. Prior to the 1977 US Open, Borg aggravated a shoulder injury while waterskiing with Vitas Gerulaitis. This injury ultimately forced him to retire from the Open during a Round of 16 match vs Dick Stockton. Through 1977, he had never lost to a player younger than himself.\n\nBorg was at the height of his career from 1978 through 1980, completing the French Open-Wimbledon double all three years. In 1978, Borg won the French Open with a win over Vilas in the final. Borg did not drop a set during the tournament, a feat only he, Năstase (in 1973), and Rafael Nadal (in 2008, 2010 and 2017) have accomplished at the French Open during the open era. Borg defeated Connors in straight sets in the 1978 Wimbledon final. At the 1978 US Open, now held on hard courts in Flushing Meadow, New York, he lost the final in straight sets to Connors. Borg was suffering from a bad blister on his thumb that required pre-match injections. That autumn, Borg faced John McEnroe for the first time in a semifinal of the Stockholm Open, and lost.\nBorg lost to McEnroe again in four sets in the final of the 1979 WCT Finals but was now overtaking Connors for the top ranking. Borg established himself firmly in the top spot with his fourth French Open singles title and fourth straight Wimbledon singles title, defeating Connors in a straight-set semifinal at the latter tournament. At the 1979 French Open, Borg defeated big-serving Victor Pecci in a four-set final, and in the 1979 Wimbledon final Borg came from behind to overcome an even bigger server, Roscoe Tanner. Borg was upset by Tanner at the US Open, in a four-set quarterfinal played under the lights. At the season-ending Masters tournament in January 1980, Borg survived a close semifinal against McEnroe. He then beat Gerulaitis in straight sets, winning his first Masters and first title in New York.\n\nIn June 1980 he overcame Gerulaitis, again in straight sets, for his fifth French Open title. Again, he did not drop a set.\n\nBorg won his fifth consecutive Wimbledon singles title, the 1980 Wimbledon Men's Singles final, by defeating McEnroe in a five-set match, often cited as the best Wimbledon final ever played – the only comparable match being the 2008 Federer – Nadal final. Having lost the opening set to an all-out McEnroe assault, Borg took the next two and had two championship points at 5–4 in the fourth. However, McEnroe averted disaster and went on to level the match in Wimbledon's most memorable 34-point tiebreaker, which he won 18–16. In the fourth-set tiebreak, McEnroe saved five match points, and Borg six set points, before McEnroe won the set. Björn served first to begin the 5th set and fell behind 15–40. Borg then won 19 straight points on serve in the deciding set and prevailed after 3 hours, 53 minutes. Borg himself commented years later that this was the first time that he was afraid that he would lose, as well as feeling that it was the beginning of the end of his dominance.\n\nIn September, 1980 Borg reached the final of the U.S. Open for the third time, losing to John McEnroe in five sets in a match that cemented what had become the greatest contemporary rivalry, albeit it short-lived, in men's tennis.\n\nHe defeated McEnroe in the final of the 1980 Stockholm Open, and faced him one more time that year, in the round-robin portion of the year-end Masters, actually played in January 1981. With 19,103 fans in attendance, Borg won a deciding third-set tie-break for the second year in a row. Borg then defeated Ivan Lendl for his second Masters title.\n\nBorg won his last Grand Slam title at the French Open in 1981, defeating Lendl in a five-set final. Borg's six French Open Grand Slam titles was a record bettered only by Rafael Nadal in 2012.\n\nIn reaching the Wimbledon final in 1981, Borg stretched his winning streak at the All England Club to a record 41 matches. In a semifinal, Borg was down to Connors by two sets to love, before coming back to win the match. However, Borg's streak was brought to an end by McEnroe, who defeated him in four sets. Years afterward, Borg remarked \"And when I lost what shocked me was I wasn't even upset. That was not me: losing a Wimbledon final and not upset. I hate to lose.\" Borg around that time felt that his desire to play was gone, despite McEnroe's desperate efforts to persuade him not to retire and continue their rivalry.\n\nBorg went on to lose to McEnroe at the 1981 US Open. After that defeat, Borg walked off the court and out of the stadium before the ceremonies and press conference had begun, and headed straight for the airport. There are reports that Borg received threats after his semifinal win over Connors. In later years, Borg apologized to McEnroe. The 1981 US Open would be the Swede's last Grand Slam final. Major tournaments and tour organizers were enforcing a new rule; by 1982, that players had to play at least 10 official tournaments per year. However, Borg wanted to curtail his schedule after many years of winning so often. Although he felt in good condition physically, he recognized that the relentless drive to win and defy tour organizers had begun to fade.\n\nBorg failed to win the US Open in nine tries, losing four finals, 1976 and 1978 to Jimmy Connors, and 1980 and 1981 to John McEnroe. He played on hard courts at the US Open from 1978 to 1981 and reached the final there on three occasions, in 1978, 1980 and 1981. He led 3–2 in the fifth set of the 1980 final, before losing. That match followed Borg's classic encounter with McEnroe at the 1980 Wimbledon. In 1978, 1979 and 1980, Borg was halfway to a Grand Slam after victories at the French and Wimbledon (the Australian Open being the last Grand Slam tournament of each year at the time) only to falter at Flushing Meadow, lefty Tanner his conqueror in 1979.\n\nIn 1982, Borg played only one tournament, losing to Yannick Noah in the quarterfinals of Monte Carlo in April. Nevertheless, Borg's announcement in January 1983 that he was retiring from the game at the age of 26 was a shock to the tennis world. McEnroe tried unsuccessfully to persuade Borg to continue. He did, however, play Monte Carlo again in March 1983, reaching the second round, and Stuttgart in July 1984.\n\nUpon retirement, Borg had three residences, a penthouse in Monte Carlo, not far from his pro shop, a mansion on Long Island, New York and a small island off the Swedish coast.\n\nBorg later bounced back as the owner of the Björn Borg fashion label. In Sweden his label has become very successful, second only to Calvin Klein.\n\nIn 1991–1993, Borg attempted a comeback on the men's professional tennis tour, coached by Welsh karate expert Ron Thatcher. Before his 1991 return, Borg grew his hair out as it had been during his previous professional tennis career and he returned to using a wooden racket; he had kept his hair cut and used modern graphite rackets in exhibitions he played during the late 1980s. Borg, however, failed to win a single match. He faced Jordi Arrese in his first match back, again at Monte Carlo but without practising or playing any exhibition matches, and fell in two sets. In his first nine matches, played in 1991 and 1992, Borg failed to win a single set. He fared slightly better in 1993, taking a set off his opponent in each of the three matches he played. He came closest to getting a win in what turned out to be his final tour match, falling to Alexander Volkov.\n\nIn 1992 Borg, aged 35, using a graphite racket, defeated John Lloyd, 37, at the Inglewood Forum Tennis Challenge. Borg later joined the Champions tour, returning to shorter hair and using modern rackets.\n\nBorg married Romanian tennis pro Mariana Simionescu in Bucharest on 24 July 1980. The marriage ended in divorce in 1984. He fathered a child by the Swedish model Jannike Björling, and he was married to the Italian singer Loredana Bertè from 1989 to 1993. \n\nOn 8 June 2002, Borg married for a third time; his new wife being Patricia Östfeld. Together they have a son, Leo, born in 2003.\n\nHe narrowly avoided personal bankruptcy when business ventures failed.\n\nIn March 2006, Bonhams Auction House in London announced that it would auction Borg's Wimbledon trophies and two of his winning rackets on 21 June 2006. Several players then called Borg in an attempt to make him reconsider, including Jimmy Connors and Andre Agassi who volunteered to buy them to keep them together. According to \"Dagens Nyheter\" – who had talked to Borg – McEnroe called Borg from New York and asked, \"What's up? Have you gone mad?\" and said \"What the hell are you doing?\" The conversation with McEnroe, paired with pleas from Connors and Agassi, eventually persuaded Borg to buy out the trophies from Bonhams for an undisclosed amount.\n\n\nWith 11 Grand Slam titles, Borg ranks sixth in the list of male tennis players who have won the most Grand Slam singles titles behind Roger Federer (20), Rafael Nadal (17), Novak Djokovic (15), Pete Sampras (14) and Roy Emerson (12). The French Open—Wimbledon double he achieved three times consecutively was called by Wimbledon officials \"the most difficult double in tennis\" and \"a feat considered impossible among today's players.\" Only Nadal (in 2008 and 2010) and Federer (in 2009) have managed to achieve this double since, and Andre Agassi, Nadal, Federer and Djokovic are the only male players since Borg to have won the French Open and Wimbledon men's singles titles over their career. Ilie Năstase once said about Borg, \"We're playing tennis, and he's playing something else\".\n\nIn his 1979 autobiography, Jack Kramer, the long-time tennis promoter and great player himself, had already included Borg in his list of the 21 greatest players of all time. And in 2003, Bud Collins chose Borg as one of his top-five male players of all time.\n\nIn 2008, ESPN.com asked tennis analysts, writers, and former players to build the perfect open era player. Borg was the only player mentioned in four categories: defense, footwork, intangibles, and mental toughness—with his mental game and footwork singled out as the best in open era history.\n\nBorg famously never won the US Open, losing in the final four times. Borg also never won the Australian Open, as he only played in the event once, in 1974 as a 17-year-old. The only players to defeat Borg in a Grand Slam final were fellow World No. 1 tennis players John McEnroe and Jimmy Connors. Even though it was then played on grass, a surface where he enjoyed much success, Borg chose to play the Australian Open only once, in 1974, where he lost in the third round. Phil Dent, a contemporary of Borg, has pointed out that skipping Grand Slam tournaments—especially the Australian Open—was not unusual then, before counting Grand Slam titles became the norm. Additionally, another contemporary Arthur Ashe told \"Sports Illustrated\", \"I think Bjorn could have won the U.S. Open. I think he could have won the Grand Slam, but by the time he left, the historical challenge didn't mean anything. He was bigger than the game. He was like Elvis or Liz Taylor or somebody.\"\n\nBorg had one of the most distinctive playing styles in the Open Era. He played from the baseline, with powerful ground-strokes. His highly unorthodox backhand involved taking his racket back with both hands but actually generating his power with his dominant right hand, letting go of the grip with his left hand around point of contact, and following through with his swing as a one-hander. He hit the ball hard and high from the back of the court and brought it down with considerable topspin, which made his ground strokes very consistent. There had been other players, particularly Rod Laver and Arthur Ashe, who played with topspin on both the forehand and backhand, yet Laver and Ashe used topspin only as a way to mix up their shots to pass their opponents at the net easily. Borg was one of the first top players to use heavy topspin on his shots consistently.\n\nComplementing his consistent ground-strokes was his fitness. Both of these factors allowed Borg to be dominant at the French Open.\n\nOne of the factors that made Borg unique was his dominance on the grass courts of Wimbledon, where, since World War II, baseliners did not usually succeed. Some experts attributed his dominance on this surface to his consistency, an underrated serve, equally underrated volleys, and his adaptation to grass courts. Against the best players, he almost always served-and-volleyed on his first serves, while he naturally played from the baseline after his second serves.\n\nAnother trait usually associated with Borg is his grace under pressure. His calm court demeanor earned him the nickname of the \"Ice Man\" or \"Ice-Borg.\"\n\nBorg's physical conditioning was unrivalled by contemporaries. He could outlast most of his opponents under the most grueling conditions. Contrary to popular belief, however, this was not due to his exceptionally low resting heart rate, often reported to be near 35 beats per minute. In his introduction to Borg's autobiography \"My Life and Game\", Eugene Scott relates that this rumor arose from a medical exam the 18-year-old Borg once took for military service, where his pulse was recorded as 38. Scott goes on to reveal Borg's true pulse rate as \"about 50 when he wakes up and around 60 in the afternoon.\" Borg is credited with helping to develop the style of play that has come to dominate the game today.\n\nFrom 22–24 September 2017, Borg was the victorious captain of Team Europe in the first ever edition of the Laver Cup, held in Prague, Czech Republic. Borg's Team Europe defeated a rest of the world team, known as Team World, who were coached by Borg's old rival, John McEnroe. Europe won the contest 15 points to 9, with Roger Federer achieving a narrow vital victory over Nick Kyrgios in the last match played.\n\nBorg returned as the coach of Team Europe for the second edition in Chicago, Illinois from September 21-23, 2018. McEnroe also returned as the coach for Team World. Borg again lead Europe to victory as Alexander Zverev defeated Kevin Anderson to secure the title 13-8, after trailing Anderson in the match tiebreak until the last few points.\n\n\n\n\n\n\n\n"}
{"id": "4603", "url": "https://en.wikipedia.org/wiki?curid=4603", "title": "Booch method", "text": "Booch method\n\nThe Booch method is a method for object-oriented software development. It is composed of an object modeling language, an iterative object-oriented development process, and a set of recommended practices.\n\nThe method was authored by Grady Booch when he was working for Rational Software (acquired by IBM), published in 1992 and revised in 1994. It was widely used in software engineering for object-oriented analysis and design and benefited from ample documentation and support tools.\n\nThe notation aspect of the Booch method was superseded by the Unified Modeling Language (UML), which features graphical elements from the Booch method along with elements from the object-modeling technique (OMT) and object-oriented software engineering (OOSE). Methodological aspects of the Booch method have been incorporated into several methodologies and processes, the primary such methodology being the Rational Unified Process (RUP).\n\nThe Booch notation is characterized by cloud shapes to represent classes and distinguishes the following diagrams:\nThe process is organized around a macro and a micro process.\n\nThe macro process identifies the following activities cycle: \n\nThe micro process is applied to new classes, structures or behaviors that emerge during the macro process. It is made of the following cycle: \n\n"}
{"id": "4606", "url": "https://en.wikipedia.org/wiki?curid=4606", "title": "Battle of the Nile", "text": "Battle of the Nile\n\nThe Battle of the Nile (also known as the Battle of Aboukir Bay; ) was a major naval battle fought between the British Royal Navy and the Navy of the French Republic at Aboukir Bay on the Mediterranean coast off the Nile Delta of Egypt from the 1st to the 3rd of August 1798. The battle was the climax of a naval campaign that had raged across the Mediterranean during the previous three months, as a large French convoy sailed from Toulon to Alexandria carrying an expeditionary force under General Napoleon Bonaparte. The British fleet was led in the battle by Rear-Admiral Sir Horatio Nelson; they decisively defeated the French under Vice-Admiral François-Paul Brueys d'Aigalliers.\n\nBonaparte sought to invade Egypt as the first step in a campaign against British India, part of a greater effort to drive Britain out of the French Revolutionary Wars. As Bonaparte's fleet crossed the Mediterranean, it was pursued by a British force under Nelson who had been sent from the British fleet in the Tagus to learn the purpose of the French expedition and to defeat it. He chased the French for more than two months, on several occasions missing them only by a matter of hours. Bonaparte was aware of Nelson's pursuit and enforced absolute secrecy about his destination. He was able to capture Malta and then land in Egypt without interception by the British naval forces.\n\nWith the French army ashore, the French fleet anchored in Aboukir Bay, northeast of Alexandria. Commander Vice-Admiral François-Paul Brueys d'Aigalliers believed that he had established a formidable defensive position. The British fleet arrived off Egypt on 1 August and discovered Brueys's dispositions, and Nelson ordered an immediate attack. His ships advanced on the French line and split into two divisions as they approached. One cut across the head of the line and passed between the anchored French and the shore, while the other engaged the seaward side of the French fleet.\n\nTrapped in a crossfire, the leading French warships were battered into surrender during a fierce three-hour battle, while the centre succeeded in repelling the initial British attack. As British reinforcements arrived, the centre came under renewed assault and, at 22:00, the French flagship \"Orient\" exploded. The rear division of the French fleet attempted to break out of the bay, with Brueys dead and his vanguard and centre defeated, but only two ships of the line and two frigates escaped from a total of 17 ships engaged.\n\nThe battle reversed the strategic situation between the two nations' forces in the Mediterranean and entrenched the Royal Navy in the dominant position that it retained for the rest of the war. It also encouraged other European countries to turn against France, and was a factor in the outbreak of the War of the Second Coalition. Bonaparte's army was trapped in Egypt, and Royal Navy dominance off the Syrian coast contributed significantly to the French defeat at the Siege of Acre in 1799 which preceded Bonaparte's return to Europe. Nelson had been wounded in the battle, and he was proclaimed a hero across Europe and was subsequently made Baron Nelson—although he was privately dissatisfied with his rewards. His captains were also highly praised and went on to form the nucleus of the legendary Nelson's Band of Brothers. The legend of the battle has remained prominent in the popular consciousness, with perhaps the best-known representation being Felicia Hemans' 1826 poem \"Casabianca\".\n\nNapoleon Bonaparte's victories in northern Italy over the Austrian Empire helped secure victory for the French in the War of the First Coalition in 1797, and Great Britain remained the only major European power still at war with the French Republic. The French Directory investigated a number of strategic options to counter British opposition, including projected invasions of Ireland and Britain and the expansion of the French Navy to challenge the Royal Navy at sea. Despite significant efforts, British control of Northern European waters rendered these ambitions impractical in the short term, and the Royal Navy remained firmly in control of the Atlantic Ocean. However, the French navy was dominant in the Mediterranean, following the withdrawal of the British fleet after the outbreak of war between Britain and Spain in 1796. This allowed Bonaparte to propose an invasion of Egypt as an alternative to confronting Britain directly, believing that the British would be too distracted by an imminent Irish uprising to intervene in the Mediterranean.\n\nBonaparte believed that, by establishing a permanent presence in Egypt (nominally part of the neutral Ottoman Empire), the French would obtain a staging point for future operations against British India, possibly in conjunction with the Tipu Sultan of Seringapatam, that might successfully drive the British out of the war. The campaign would sever the chain of communication that connected Britain with India, an essential part of the British Empire whose trade generated the wealth that Britain required to prosecute the war successfully. The French Directory agreed with Bonaparte's plans, although a major factor in their decision was a desire to see the politically ambitious Bonaparte and the fiercely loyal veterans of his Italian campaigns travel as far from France as possible. During the spring of 1798, Bonaparte assembled more than 35,000 soldiers in Mediterranean France and Italy and developed a powerful fleet at Toulon. He also formed the \"Commission des Sciences et des Arts\", a body of scientists and engineers intended to establish a French colony in Egypt. Napoleon kept the destination of the expedition top secret—most of the army's officers did not know of its target, and Bonaparte did not publicly reveal his goal until the first stage of the expedition was complete.\n\nBonaparte's armada sailed from Toulon on 19 May 1798, making rapid progress through the Ligurian Sea and collecting more ships at Genoa, before sailing southwards along the Sardinian coast and passing Sicily on 7 June. On 9 June, the fleet arrived off Malta, then under the ownership of the Knights of St. John of Jerusalem, ruled by Grand Master Ferdinand von Hompesch zu Bolheim. Bonaparte demanded that his fleet be permitted entry to the fortified harbour of Valletta. When the Knights refused, the French general responded by ordering a large scale invasion of the Maltese Islands, overrunning the defenders after 24 hours of skirmishing. The Knights formally surrendered on 12 June and, in exchange for substantial financial compensation, handed the islands and all of their resources over to Bonaparte, including the extensive property of the Roman Catholic Church on Malta. Within a week, Bonaparte had resupplied his ships, and on 19 June, his fleet departed for Alexandria in the direction of Crete, leaving 4,000 men at Valletta under General Claude-Henri Vaubois to ensure French control of the islands.\n\nWhile Bonaparte was sailing to Malta, the Royal Navy re-entered the Mediterranean for the first time in more than a year. Alarmed by reports of French preparations on the Mediterranean coast, Lord Spencer at the Admiralty sent a message to Vice-Admiral Earl St. Vincent, commander of the Mediterranean Fleet based in the Tagus River, to despatch a squadron to investigate. This squadron, consisting of three ships of the line and three frigates, was entrusted to Rear-Admiral Sir Horatio Nelson.\n\nNelson was a highly experienced officer who had been blinded in one eye during fighting in Corsica in 1794 and subsequently commended for his capture of two Spanish ships of the line at the Battle of Cape St. Vincent in February 1797. In July 1797, he lost an arm at the Battle of Santa Cruz de Tenerife and had been forced to return to Britain to recuperate. Returning to the fleet at the Tagus in late April 1798, he was ordered to collect the squadron stationed at Gibraltar and sail for the Ligurian Sea. On 21 May, as Nelson's squadron approached Toulon, it was struck by a fierce gale and Nelson's flagship, HMS \"Vanguard\", lost its topmasts and was almost wrecked on the Corsican coast. The remainder of the squadron was scattered. The ships of the line sheltered at San Pietro Island off Sardinia; the frigates were blown to the west and failed to return.\n\nOn 7 June, following hasty repairs to his flagship, a fleet consisting of ten ships of the line and a fourth-rate joined Nelson off Toulon. The fleet, under the command of Captain Thomas Troubridge, had been sent by Earl St. Vincent to reinforce Nelson, with orders that he was to pursue and intercept the Toulon convoy. Although he now had enough ships to challenge the French fleet, Nelson suffered two great disadvantages: He had no intelligence regarding the destination of the French, and no frigates to scout ahead of his force. Striking southwards in the hope of collecting information about French movements, Nelson's ships stopped at Elba and Naples, where the British ambassador, Sir William Hamilton, reported that the French fleet had passed Sicily headed in the direction of Malta. Despite pleas from Nelson and Hamilton, King Ferdinand of Naples refused to lend his frigates to the British fleet, fearing French reprisals. On 22 June, a brig sailing from Ragusa brought Nelson the news that the French had sailed eastwards from Malta on 16 June. After conferring with his captains, the admiral decided that the French target must be Egypt and set off in pursuit. Incorrectly believing the French to be five days ahead rather than two, Nelson insisted on a direct route to Alexandria without deviation.\n\nOn the evening of 22 June, Nelson's fleet passed the French in the darkness, overtaking the slow invasion convoy without realising how close they were to their target. Making rapid time on a direct route, Nelson reached Alexandria on 28 June and discovered that the French were not there. After a meeting with the suspicious Ottoman commander, Sayyid Muhammad Kurayyim, Nelson ordered the British fleet northwards, reaching the coast of Anatolia on 4 July and turning westwards back towards Sicily. Nelson had missed the French by less than a day—the scouts of the French fleet arrived off Alexandria in the evening of 29 June.\n\nConcerned by his near encounter with Nelson, Bonaparte ordered an immediate invasion, his troops coming ashore in a poorly managed amphibious operation in which at least 20 drowned. Marching along the coast, the French army stormed Alexandria and captured the city, after which Bonaparte led the main force of his army inland. He instructed his naval commander, Vice-Admiral François-Paul Brueys D'Aigalliers, to anchor in Alexandria harbour, but naval surveyors reported that the channel into the harbour was too shallow and narrow for the larger ships of the French fleet. As a result, the French selected an alternative anchorage at Aboukir Bay, northeast of Alexandria.\n\nNelson's fleet reached Syracuse in Sicily on 19 July and took on essential supplies. There the admiral wrote letters describing the events of the previous months: \"It is an old saying, 'the Devil's children have the Devil's luck.' I cannot find, or at this moment learn, beyond vague conjecture where the French fleet are gone to. All my ill fortune, hitherto, has proceeded from want of frigates.\" Meanwhile, the French were securing Egypt by the Battle of the Pyramids. By 24 July, the British fleet was resupplied and, having determined that the French must be somewhere in the Eastern Mediterranean, Nelson sailed again in the direction of the Morea. On 28 July, at Coron, Nelson finally obtained intelligence describing the French attack on Egypt and turned south across the Mediterranean. His scouts, HMS \"Alexander\" and HMS \"Swiftsure\", sighted the French transport fleet at Alexandria on the afternoon of 1 August.\n\nWhen Alexandria harbour had proved inadequate for his fleet, Brueys had gathered his captains and discussed their options. Bonaparte had ordered the fleet to anchor in Aboukir Bay, a shallow and exposed anchorage, but had supplemented the orders with the suggestion that, if Aboukir Bay was too dangerous, Brueys could sail north to Corfu, leaving only the transports and a handful of lighter warships at Alexandria. Brueys refused, in the belief that his squadron could provide essential support to the French army on shore, and called his captains aboard his 120-gun flagship \"Orient\" to discuss their response should Nelson discover the fleet in its anchorage. Despite vocal opposition from Contre-amiral Armand Blanquet, who insisted that the fleet would be best able to respond in open water, the rest of the captains agreed that anchoring in a line of battle inside the bay presented the strongest tactic for confronting Nelson. It is possible that Bonaparte envisaged Aboukir Bay as a temporary anchorage: on 27 July, he expressed the expectation that Brueys had already transferred his ships to Alexandria, and three days later, he issued orders for the fleet to make for Corfu in preparation for naval operations against the Ottoman territories in the Balkans, although Bedouin partisans intercepted and killed the courier carrying the instructions.\n\nAboukir Bay is a coastal indentation across, stretching from the village of Abu Qir in the west to the town of Rosetta to the east, where one of the mouths of the River Nile empties into the Mediterranean. In 1798, the bay was protected at its western end by extensive rocky shoals which ran into the bay from a promontory guarded by Aboukir Castle. A small fort situated on an island among the rocks protected the shoals. The fort was garrisoned by French soldiers and armed with at least four cannon and two heavy mortars. Brueys had augmented the fort with his bomb vessels and gunboats, anchored among the rocks to the west of the island in a position to give support to the head of the French line. Further shoals ran unevenly to the south of the island and extended across the bay in a rough semicircle approximately from the shore. These shoals were too shallow to permit the passage of larger warships, and so Brueys ordered his thirteen ships of the line to form up in a line of battle following the northeastern edge of the shoals to the south of the island, a position that allowed the ships to disembark supplies from their port sides while covering the landings with their starboard batteries. Orders were issued for each ship to attach strong cables to the bow and stern of their neighbours, which would effectively turn the line into a long battery forming a theoretically impregnable barrier. Brueys positioned a second, inner line of four frigates approximately west of the main line, roughly halfway between the line and the shoal. The van of the French line was led by \"Guerrier\", positioned southeast of Aboukir Island and about from the edge of the shoals that surrounded the island. The line stretched southeast, with the centre bowed seawards away from the shoal. The French ships were spaced at intervals of and the whole line was long, with the flagship \"Orient\" at the centre and two large 80-gun ships anchored on either side. The rear division of the line was under the command of Contre-amiral Pierre-Charles Villeneuve in \"Guillaume Tell\".\n\nIn deploying his ships in this way, Brueys hoped that the British would be forced by the shoals to attack his strong centre and rear, allowing his van to use the prevailing northeasterly wind to counterattack the British once they were engaged. However, he had made a serious misjudgement: he had left enough room between \"Guerrier\" and the shoals for an enemy ship to cut across the head of the French line and proceed between the shoals and the French ships, allowing the unsupported vanguard to be caught in a crossfire by two divisions of enemy ships. Compounding this error, the French only prepared their ships for battle on their starboard (seaward) sides, from which they expected the attack would have to come; their landward port sides were unprepared.\nThe port side gun ports were closed, and the decks on that side were uncleared, with various stored items blocking access to the guns. Brueys' dispositions had a second significant flaw: The 160-yard gaps between ships were large enough for a British ship to push through and break the French line. Furthermore, not all of the French captains had followed Brueys' orders to attach cables to their neighbours' bow and stern, which would have prevented such a manoeuvre. The problem was exacerbated by orders to only anchor at the bow, which allowed the ships to swing with the wind and widened the gaps. It also created areas within the French line not covered by the broadside of any ship. British vessels could anchor in those spaces and engage the French without reply. In addition, the deployment of Brueys' fleet prevented the rear from effectively supporting the van due to the prevailing winds.\n\nA more pressing problem for Brueys was a lack of food and water for the fleet: Bonaparte had unloaded almost all of the provisions carried aboard and no supplies were reaching the ships from the shore. To remedy this, Brueys sent foraging parties of 25 men from each ship along the coast to requisition food, dig wells, and collect water. Constant attacks by Bedouin partisans, however, required escorts of heavily armed guards for each party. Hence, up to a third of the fleet's sailors were away from their ships at any one time. Brueys wrote a letter describing the situation to Minister of Marine Étienne Eustache Bruix, reporting that \"Our crews are weak, both in number and quality. Our rigging, in general, out of repair, and I am sure it requires no little courage to undertake the management of a fleet furnished with such tools.\"\n\nAlthough initially disappointed that the main French fleet was not at Alexandria, Nelson knew from the presence of the transports that they must be nearby. At 14:00 on 1 August, lookouts on HMS \"Zealous\" reported the French anchored in Aboukir Bay, its signal lieutenant just beating the lieutenant on HMS \"Goliath\" with the signal, but inaccurately describing 16 French ships of the line instead of 13. At the same time, French lookouts on \"Heureux\", the ninth ship in the French line, sighted the British fleet approximately nine nautical miles off the mouth of Aboukir Bay. The French initially reported just 11 British ships – \"Swiftsure\" and \"Alexander\" were still returning from their scouting operations at Alexandria, and so were to the west of the main fleet, out of sight. Troubridge's ship, HMS \"Culloden\"\",\" was also some distance from the main body, towing a captured merchant ship. At the sight of the French, Troubridge abandoned the vessel and made strenuous efforts to rejoin Nelson. Due to the need for so many sailors to work onshore, Brueys had not deployed any of his lighter warships as scouts, which left him unable to react swiftly to the sudden appearance of the British.\n\nAs his ships readied for action, Brueys ordered his captains to gather for a conference on \"Orient\" and hastily recalled his shore parties, although most had still not returned by the start of the battle. To replace them, large numbers of men were taken out of the frigates and distributed among the ships of the line. Brueys also hoped to lure the British fleet onto the shoals at Aboukir Island, sending the brigs \"Alerte\" and \"Railleur\" to act as decoys in the shallow waters. By 16:00, \"Alexander\" and \"Swiftsure\" were also in sight, although some distance from the main British fleet. Brueys gave orders to abandon the plan to remain at anchor and instead for his line to set sail. Blanquet protested the order on the grounds that there were not enough men aboard the French ships to both sail the ships and man the guns. Nelson gave orders for his leading ships to slow down, to allow the British fleet to approach in a more organised formation. This convinced Brueys that rather than risk an evening battle in confined waters, the British were planning to wait for the following day. He rescinded his earlier order to sail. Brueys may have been hoping that the delay would allow him to slip past the British during the night and thus follow Bonaparte's orders not to engage the British fleet directly if he could avoid it.\n\nNelson ordered the fleet to slow down at 16:00 to allow his ships to rig \"springs\" on their anchor cables, a system of attaching the bow anchor that increased stability and allowed his ships to swing their broadsides to face an enemy while stationary. It also increased manoeuvrability and therefore reduced the risk of coming under raking fire. Nelson's plan, shaped through discussion with his senior captains during the return voyage to Alexandria, was to advance on the French and pass down the seaward side of the van and centre of the French line, so that each French ship would face two British ships and the massive \"Orient\" would be fighting against three. The direction of the wind meant that the French rear division would be unable to join the battle easily and would be cut off from the front portions of the line. To ensure that in the smoke and confusion of a night battle his ships would not accidentally open fire on one another, Nelson ordered that each ship prepare four horizontal lights at the head of their mizzen mast and hoist an illuminated White Ensign, which was different enough from the French tricolour that it would not be mistaken in poor visibility, reducing the risk that British ships might fire on one another in the darkness. As his ship was readied for battle, Nelson held a final dinner with \"Vanguard\"<nowiki>'</nowiki>s officers, announcing as he rose: \"Before this time tomorrow I shall have gained a peerage or Westminster Abbey,\" in reference to the rewards of victory or the traditional burial place of British military heroes.\nShortly after the French order to set sail was abandoned, the British fleet began rapidly approaching once more. Brueys, now expecting to come under attack that night, ordered each of his ships to place springs on their anchor cables and prepare for action. He sent the \"Alerte\" ahead, which passed close to the leading British ships and then steered sharply to the west over the shoal, in the hope that the ships of the line might follow and become grounded. None of Nelson's captains fell for the ruse and the British fleet continued undeterred. At 17:30, Nelson hailed one of his two leading ships, HMS \"Zealous\" under Captain Samuel Hood, which had been racing \"Goliath\" to be the first to fire on the French. The admiral ordered Hood to establish the safest course into the harbour. The British had no charts of the depth or shape of the bay, except a rough sketch map \"Swiftsure\" had obtained from a merchant captain, an inaccurate British atlas on \"Zealous\", and a 35-year-old French map aboard \"Goliath\". Hood replied that he would take careful soundings as he advanced to test the depth of the water, and that, \"If you will allow the honour of leading you into battle, I will keep the lead going.\" Shortly afterwards, Nelson paused to speak with the brig HMS \"Mutine\", whose commander, Lieutenant Thomas Hardy, had seized some maritime pilots from a small Alexandrine vessel. As \"Vanguard\" came to a stop, the following ships slowed. This caused a gap to open up between \"Zealous\" and \"Goliath\" and the rest of the fleet. To counter this effect, Nelson ordered HMS \"Theseus\" under Captain Ralph Miller to pass his flagship and join \"Zealous\" and \"Goliath\" in the vanguard. By 18:00, the British fleet was again under full sail, \"Vanguard\" sixth in the line of ten ships as \"Culloden\" trailed behind to the north and \"Alexander\" and \"Swiftsure\" hastened to catch up to the west. Following the rapid change from a loose formation to a rigid line of battle both fleets raised their colours; each British ship added additional Union Flags in its rigging in case its main flag was shot away. At 18:20, as \"Goliath\" and \"Zealous\" rapidly bore down on them, the leading French ships \"Guerrier\" and \"Conquérant\" opened fire.\nTen minutes after the French opened fire \"Goliath\", ignoring fire from the fort to starboard and from \"Guerrier\" to port, most of which was too high to trouble the ship, crossed the head of the French line. Captain Thomas Foley had noticed as he approached that there was an unexpected gap between \"Guerrier\" and the shallow water of the shoal. On his own initiative, Foley decided to exploit this tactical error and changed his angle of approach to sail through the gap. As the bow of \"Guerrier\" came within range, \"Goliath\" opened fire, inflicting severe damage with a double-shotted raking broadside as the British ship turned to port and passed down the unprepared port side of \"Guerrier.\" Foley's Royal Marines and a company of Austrian grenadiers joined the attack, firing their muskets. Foley had intended to anchor alongside the French ship and engage it closely, but his anchor took too long to descend and his ship passed \"Guerrier\" entirely. \"Goliath\" eventually stopped close to the bow of \"Conquérant\", opening fire on the new opponent and using the unengaged starboard guns to exchange occasional shots with the frigate \"Sérieuse\" and bomb vessel \"Hercule,\" which were anchored inshore of the battle line.\n\nFoley's attack was followed by Hood in \"Zealous\", who also crossed the French line and successfully anchored next to \"Guerrier\" in the space Foley had intended, engaging the lead ship's bow from close range. Within five minutes \"Guerrier\"<nowiki>'</nowiki>s foremast had fallen, to cheers from the crews of the approaching British ships. The speed of the British advance took the French captains by surprise; they were still aboard \"Orient\" in conference with the admiral when the firing started. Hastily launching their boats, they returned to their vessels. Captain Jean-François-Timothée Trullet of \"Guerrier\" shouted orders from his barge for his men to return fire on \"Zealous\".\n\nThe third British ship into action was HMS \"Orion\" under Captain Sir James Saumarez, which rounded the engagement at the head of the battle line and passed between the French main line and the frigates that lay closer inshore. As he did so, the frigate \"Sérieuse\" opened fire on \"Orion\", wounding two men. The convention in naval warfare of the time was that ships of the line did not attack frigates when there were ships of equal size to engage, but in firing first French Captain Claude-Jean Martin had negated the rule. Saumarez waited until the frigate was at close range before replying. \"Orion\" needed just one broadside to reduce the frigate to a wreck, and Martin's disabled ship drifted away over the shoal. During the delay this detour caused, two other British ships joined the battle: Theseus, which had been disguised as a first-rate ship, followed Foley's track across \"Guerrier\"<nowiki>'</nowiki>s bow. Miller steered his ship through the middle of the melee between the anchored British and French ships until he encountered the third French ship, \"Spartiate\". Anchoring to port, Miller's ship opened fire at close range. HMS \"Audacious\" under Captain Davidge Gould crossed the French line between \"Guerrier\" and \"Conquérant\", anchoring between the ships and raking them both. \"Orion\" then rejoined the action further south than intended, firing on the fifth French ship, \"Peuple Souverain,\" and Admiral Blanquet's flagship, \"Franklin\".\n\nThe next three British ships, \"Vanguard\" in the lead followed by HMS \"Minotaur\" and HMS \"Defence\", remained in line of battle formation and anchored on the starboard side of the French line at 18:40. Nelson focused his flagship's fire on \"Spartiate\", while Captain Thomas Louis in \"Minotaur\" attacked the unengaged \"Aquilon\" and Captain John Peyton in \"Defence\" joined the attack on \"Peuple Souverain\". With the French vanguard now heavily outnumbered, the following British ships, HMS \"Bellerophon\" and HMS \"Majestic\"\",\" passed by the melee and advanced on the so far unengaged French centre. Both ships were soon fighting enemies much more powerful than they and began to take severe damage. Captain Henry Darby on \"Bellerophon\" missed his intended anchor near \"Franklin\" and instead found his ship underneath the main battery of the French flagship. Captain George Blagdon Westcott on \"Majestic\" also missed his station and almost collided with \"Heureux\", coming under heavy fire from \"Tonnant\". Unable to stop in time, Westcott's jib boom became entangled with \"Tonnant\"s shroud.\n\nThe French suffered too, Admiral Brueys on \"Orient\" was severely wounded in the face and hand by flying debris during the opening exchange of fire with \"Bellerophon\". The final ship of the British line, \"Culloden\" under Troubridge, sailed too close to Aboukir Island in the growing darkness and became stuck fast on the shoal. Despite strenuous efforts from the \"Culloden\"<nowiki>'</nowiki>s boats, the brig \"Mutine\" and the 50-gun HMS \"Leander\" under Captain Thomas Thompson, the ship of the line could not be moved, and the waves drove \"Culloden\" further onto the shoal, inflicting severe damage to the ship's hull.\n\nAt 19:00 the identifying lights in the mizzenmasts of the British fleet were lit. By this time, \"Guerrier\" had been completely dismasted and heavily battered. \"Zealous\" by contrast was barely touched: Hood had situated \"Zealous\" outside the arc of most of the French ship's broadsides, and in any case \"Guerrier\" was not prepared for an engagement on both sides simultaneously, with its port guns blocked by stores. Although their ship was a wreck, the crew of \"Guerrier\" refused to surrender, continuing to fire the few functional guns whenever possible despite heavy answering fire from \"Zealous\". In addition to his cannon fire, Hood called up his marines and ordered them to fire volleys of musket shot at the deck of the French ship, driving the crew out of sight but still failing to secure the surrender from Captain Trullet. It was not until 21:00, when Hood sent a small boat to \"Guerrier\" with a boarding party, that the French ship finally surrendered. \"Conquérant\" was defeated more rapidly, after heavy broadsides from passing British ships and the close attentions of \"Audacious\" and \"Goliath\" brought down all three masts before 19:00. With his ship immobile and badly damaged, the mortally wounded Captain Etienne Dalbarade struck his colours and a boarding party seized control. Unlike \"Zealous\", these British ships suffered relatively severe damage in the engagement. \"Goliath\" lost most of its rigging, suffered damage to all three masts and suffered more than 60 casualties. With his opponents defeated, Captain Gould on \"Audacious\" used the spring on his cable to transfer fire to \"Spartiate\", the next French ship in line. To the west of the battle the battered \"Sérieuse\" sank over the shoal. Its masts protruded from the water as survivors scrambled into boats and rowed for the shore.\n\nThe transfer of \"Audacious\"<nowiki>'</nowiki>s broadside to \"Spartiate\" meant that Captain Maurice-Julien Emeriau now faced three opponents. Within minutes all three of his ship's masts had fallen, but the battle around \"Spartiate\" continued until 21:00, when the badly wounded Emeriau ordered his colours struck. Although \"Spartiate\" was outnumbered, it had been supported by the next in line, \"Aquilon\", which was the only ship of the French van squadron fighting a single opponent, \"Minotaur\". Captain Antoine René Thévenard used the spring on his anchor cable to angle his broadside into a raking position across the bow of Nelson's flagship, which consequently suffered more than 100 casualties, including the admiral. At approximately 20:30, an iron splinter fired in a langrage shot from \"Spartiate \"struck Nelson over his blinded right eye. The wound caused a flap of skin to fall across his face, rendering him temporarily completely blind. Nelson collapsed into the arms of Captain Edward Berry and was carried below. Certain that his wound was fatal, he cried out \"I am killed, remember me to my wife\", and called for his chaplain, Stephen Comyn. The wound was immediately inspected by \"Vanguard\"<nowiki>'</nowiki>s surgeon Michael Jefferson, who informed the admiral that it was a simple flesh wound and stitched the skin together. Nelson subsequently ignored Jefferson's instructions to remain inactive, returning to the quarterdeck shortly before the explosion on \"Orient\" to oversee the closing stages of the battle. Although Thévenard's manoeuvre was successful, it placed his own bow under \"Minotaur\"s guns and by 21:25 the French ship was dismasted and battered, Captain Thévenard killed and his junior officers forced to surrender. With his opponent defeated, Captain Thomas Louis then took \"Minotaur\" south to join the attack on \"Franklin\".\n\n\"Defence\" and \"Orion \"attacked the fifth French ship, \"Peuple Souverain\", from either side and the ship rapidly lost the fore and main masts. Aboard the \"Orion\", a wooden block was smashed off one of the ship's masts, killing two men before wounding Captain Saumarez in the thigh. On \"Peuple Souverain\", Captain Pierre-Paul Raccord was badly wounded and ordered his ship's anchor cable cut in an effort to escape the bombardment. \"Peuple Souverain\" drifted south towards the flagship \"Orient\", which mistakenly opened fire on the darkened vessel. \"Orion\" and \"Defence\" were unable to immediately pursue. \"Defence\" had lost its fore topmast and an improvised fireship that drifted through the battle narrowly missed \"Orion\". The origin of this vessel, an abandoned and burning ship's boat laden with highly flammable material, is uncertain, but it may have been launched from \"Guerrier\" as the battle began. \"Peuple Souverain\" anchored not far from \"Orient\", but took no further part in the fighting. The wrecked ship surrendered during the night. \"Franklin\" remained in combat, but Blanquet had suffered a severe head wound and Captain Gillet had been carried below unconscious with severe wounds. Shortly afterwards, a fire broke out on the quarterdeck after an arms locker exploded, which was eventually extinguished with difficulty by the crew.\n\nTo the south, HMS \"Bellerophon\" was in serious trouble as the huge broadside of \"Orient\" pounded the ship. At 19:50 the mizzenmast and main mast both collapsed and fires broke out simultaneously at several points. Although the blazes were extinguished, the ship had suffered more than 200 casualties. Captain Darby recognised that his position was untenable and ordered the anchor cables cut at 20:20. The battered ship drifted away from the battle under continued fire from \"Tonnant\" as the foremast collapsed as well. \"Orient\" had also suffered significant damage and Admiral Brueys had been struck in the midriff by a cannonball that almost cut him in half. He died fifteen minutes later, remaining on deck and refusing to be carried below. \"Orient\"<nowiki>'</nowiki>s captain, Luc-Julien-Joseph Casabianca, was also wounded, struck in the face by flying debris and knocked unconscious, while his twelve-year-old son had a leg torn off by a cannonball as he stood beside his father. The most southerly British ship, \"Majestic\", had become briefly entangled with the 80-gun \"Tonnant\", and in the resulting battle, suffered heavy casualties. Captain George Blagdon Westcott was among the dead, killed by French musket fire. Lieutenant Robert Cuthbert assumed command and successfully disentangled his ship, allowing the badly damaged \"Majestic\" to drift further southwards so that by 20:30 it was stationed between \"Tonnant\" and the next in line, \"Heureux\", engaging both. To support the centre, Captain Thompson of \"Leander\" abandoned the futile efforts to drag the stranded \"Culloden\" off the shoal and sailed down the embattled French line, entering the gap created by the drifting \"Peuple Souverain\" and opening a fierce raking fire on \"Franklin\" and \"Orient\".\n\nWhile the battle raged in the bay, the two straggling British ships made strenuous efforts to join the engagement, focusing on the flashes of gunfire in the darkness. Warned away from the Aboukir shoals by the grounded \"Culloden\", Captain Benjamin Hallowell in \"Swiftsure\" passed the melee at the head of the line and aimed his ship at the French centre. Shortly after 20:00, a dismasted hulk was spotted drifting in front of \"Swiftsure\" and Hallowell initially ordered his men to fire before rescinding the order, concerned for the identity of the strange vessel. Hailing the battered ship, Hallowell received the reply \"Bellerophon, going out of action disabled.\" Relieved that he had not accidentally attacked one of his own ships in the darkness, Hallowell pulled up between \"Orient\" and \"Franklin\" and opened fire on them both. \"Alexander\", the final unengaged British ship, which had followed \"Swiftsure\", pulled up close to \"Tonnant\", which had begun to drift away from the embattled French flagship. Captain Alexander Ball then joined the attack on \"Orient\".\n\nAt 21:00, the British observed a fire on the lower decks of the \"Orient\", the French flagship. Identifying the danger this posed to the \"Orient\", Captain Hallowell directed his gun crews to fire their guns directly into the blaze. Sustained British gun fire spread the flames throughout the ship's stern and prevented all efforts to extinguish them. Within minutes the fire had ascended the rigging and set the vast sails alight. The nearest British ships, \"Swiftsure\", \"Alexander\", and \"Orion\", all stopped firing, closed their gunports, and began edging away from the burning ship in anticipation of the detonation of the enormous ammunition supplies stored on board. In addition, they took crews away from the guns to form fire parties and to soak the sails and decks in seawater to help contain any resulting fires. Likewise the French ships \"Tonnant\", \"Heureux\", and \"Mercure\" all cut their anchor cables and drifted southwards away from the burning ship. At 22:00 the fire reached the magazines, and the \"Orient\" was destroyed by a massive explosion. The concussion of the blast was powerful enough to rip open the seams of the nearest ships, and flaming wreckage landed in a huge circle, much of it flying directly over the surrounding ships into the sea beyond. Falling wreckage started fires on \"Swiftsure\", \"Alexander\", and \"Franklin\", although in each case teams of sailors with water buckets succeeded in extinguishing the flames, despite a secondary explosion on \"Franklin\".\n\nIt has never been firmly established how the fire on \"Orient\" broke out, but one common account is that jars of oil and paint had been left on the poop deck, instead of being properly stowed after painting of the ship's hull had been completed shortly before the battle. Burning wadding from one of the British ships is believed to have floated onto the poop deck and ignited the paint. The fire rapidly spread through the admiral's cabin and into a ready magazine that stored carcass ammunition, which was designed to burn more fiercely in water than in air. Alternatively, Fleet Captain Honoré Ganteaume later reported the cause as an explosion on the quarterdeck, preceded by a series of minor fires on the main deck among the ship's boats. Whatever its origin, the fire spread rapidly through the ship's rigging, unchecked by the fire pumps aboard, which had been smashed by British shot. A second blaze then began at the bow, trapping hundreds of sailors in the ship's waist. Subsequent archaeological investigation found debris scattered over of seabed and evidence that the ship was wracked by two huge explosions one after the other. Hundreds of men dove into the sea to escape the flames, but fewer than 100 survived the blast. British boats picked up approximately 70 survivors, including the wounded staff officer Léonard-Bernard Motard. A few others, including Ganteaume, managed to reach the shore on rafts. The remainder of the crew, numbering more than 1,000 men, were killed, including Captain Casabianca and his son, Giocante.\n\nFor ten minutes after the explosion there was no firing; sailors from both sides were either too shocked by the blast or desperately extinguishing fires aboard their own ships to continue the fight. During the lull, Nelson gave orders that boats be sent to pull survivors from the water around the remains of \"Orient\". At 22:10, \"Franklin\" restarted the engagement by firing on \"Swiftsure\". Isolated and battered, Blanquet's ship was soon dismasted and the admiral, suffering a severe head wound, was forced to surrender by the combined firepower of \"Swiftsure\" and \"Defence\". More than half of \"Franklin\"<nowiki>'</nowiki>s crew had been killed or wounded.\n\nBy midnight only \"Tonnant\" remained engaged, as Commodore Aristide Aubert Du Petit Thouars continued his fight with \"Majestic\" and fired on \"Swiftsure\" when the British ship moved within range. By 03:00, after more than three hours of close quarter combat, \"Majestic\" had lost its main and mizzen masts while \"Tonnant\" was a dismasted hulk. Although Captain Du Petit Thouars had lost both legs and an arm he remained in command, insisting on having the tricolour nailed to the mast to prevent it from being struck and giving orders from his position propped up on deck in a bucket of wheat. Under his guidance, the battered \"Tonnant\" gradually drifted southwards away from the action to join the southern division under Villeneuve, who failed to bring these ships into effective action. Throughout the engagement the French rear had kept up an arbitrary fire on the battling ships ahead. The only noticeable effect was the smashing of \"Timoléon\"s rudder by misdirected fire from the neighbouring \"Généreux\".\n\nAs the sun rose at 04:00 on 2 August, firing broke out once again between the French southern division of \"Guillaume Tell\", \"Tonnant\", \"Généreux\" and \"Timoléon\" and the battered \"Alexander\" and \"Majestic\". Although briefly outmatched, the British ships were soon joined by \"Goliath\" and \"Theseus\". As Captain Miller manoeuvred his ship into position, \"Theseus\" briefly came under fire from the frigate \"Artémise\". Miller turned his ship towards \"Artémise\", but Captain Pierre-Jean Standelet struck his flag and ordered his men to abandon the frigate. Miller sent a boat under Lieutenant William Hoste to take possession of the empty vessel, but Standelet had set fire to his ship as he left and \"Artémise\" blew up shortly afterwards. The surviving French ships of the line, covering their retreat with gunfire, gradually pulled to the east away from the shore at 06:00. \"Zealous\" pursued, and was able to prevent the frigate \"Justice\" from boarding \"Bellerophon\", which was anchored at the southern point of the bay undergoing hasty repairs.\n\nTwo other French ships still flew the tricolour, but neither was in a position to either retreat or fight. When \"Heureux\" and \"Mercure\" had cut their anchor cables to escape the exploding \"Orient\", their crews had panicked and neither captain (both of whom were wounded) had managed to regain control of his ship. As a result, both vessels had drifted onto the shoal. \"Alexander\", \"Goliath\", \"Theseus\" and \"Leander\" attacked the stranded and defenceless ships, and both surrendered within minutes. The distractions provided by \"Heureux\", \"Mercure\" and \"Justice\" allowed Villeneuve to bring most of the surviving French ships to the mouth of the bay at 11:00. On the dismasted \"Tonnant\", Commodore Du Petit Thouars was now dead from his wounds and thrown overboard at his own request. As the ship was unable to make the required speed it was driven ashore by its crew. \"Timoléon\" was too far south to escape with Villeneuve and, in attempting to join the survivors, had also grounded on the shoal. The force of the impact dislodged the ship's foremast. The remaining French vessels: the ships of the line \"Guillaume Tell\" and \"Généreux\" and the frigates \"Justice\" and \"Diane\", formed up and stood out to sea, pursued by \"Zealous\". Despite strenuous efforts, Captain Hood's isolated ship came under heavy fire and was unable to cut off the trailing \"Justice\" as the French survivors escaped seawards. \"Zealous\" was struck by a number of French shot and lost one man killed.\n\nFor the remainder of 2 August Nelson's ships made improvised repairs and boarded and consolidated their prizes. \"Culloden\" especially required assistance. Troubridge, having finally dragged his ship off the shoal at 02:00, found that he had lost his rudder and was taking on more than of water an hour. Emergency repairs to the hull and fashioning a replacement rudder from a spare topmast took most of the next two days. On the morning of 3 August, Nelson sent \"Theseus\" and \"Leander\" to force the surrender of the grounded \"Tonnant\" and \"Timoléon\". The \"Tonnant\", its decks crowded with 1,600 survivors from other French vessels, surrendered as the British ships approached while \"Timoléon\" was set on fire by its remaining crew who then escaped to the shore in small boats. \"Timoléon\" exploded shortly after midday, the eleventh and final French ship of the line destroyed or captured during the battle.\n\nBritish casualties in the battle were recorded with some accuracy in the immediate aftermath as 218 killed and approximately 677 wounded, although the number of wounded who subsequently died is not known. The ships that suffered most were \"Bellerophon\" with 201 casualties and \"Majestic\" with 193. Other than \"Culloden\" the lightest loss was on \"Zealous\", which had one man killed and seven wounded.\n\nThe casualty list included Captain Westcott, five lieutenants and ten junior officers among the dead, and Admiral Nelson, Captains Saumarez, Ball and Darby, and six lieutenants wounded. Other than \"Culloden\", the only British ships seriously damaged in their hulls were \"Bellerophon\", \"Majestic,\" and \"Vanguard\". \"Bellerophon\" and \"Majestic\" were the only ships to lose masts: \"Majestic\" the main and mizzen and \"Bellerophon\" all three.\n\nFrench casualties are harder to calculate but were significantly higher. Estimates of French losses range from 2,000 to 5,000, with a suggested median point of 3,500, which includes more than 1,000 captured wounded and nearly 2,000 killed, half of whom died on \"Orient\". In addition to Admiral Brueys killed and Admiral Blanquet wounded, four captains died and seven others were seriously wounded. The French ships suffered severe damage: Two ships of the line and two frigates were destroyed (as well as a bomb vessel scuttled by its crew), and three other captured ships were too battered ever to sail again. Of the remaining prizes, only three were ever sufficiently repaired for frontline service. For weeks after the battle, bodies washed up along the Egyptian coast, decaying slowly in the intense, dry heat.\n\nNelson, who on surveying the bay on the morning of 2 August said, \"Victory is not a name strong enough for such a scene\", remained at anchor in Aboukir Bay for the next two weeks, preoccupied with recovering from his wound, writing dispatches, and assessing the military situation in Egypt using documents captured on board one of the prizes. Nelson's head wound was recorded as being \"three inches long\" with \"the cranium exposed for one inch\". He suffered pain from the injury for the rest of his life and was badly scarred, styling his hair to disguise it as much as possible. As their commander recovered, his men stripped the wrecks of useful supplies and made repairs to their ships and prizes.\n\nThroughout the week, Aboukir Bay was surrounded by bonfires lit by Bedouin tribesmen in celebration of the British victory. On 5 August, \"Leander\" was despatched to Cadiz with messages for Earl St. Vincent carried by Captain Edward Berry. Over the next few days the British landed all but 200 of the captured prisoners on shore under strict terms of parole, although Bonaparte later ordered them to be formed into an infantry unit and added to his army. The wounded officers taken prisoner were held on board \"Vanguard\", where Nelson regularly entertained them at dinner. Historian Joseph Allen recounts that on one occasion Nelson, whose eyesight was still suffering following his wound, offered toothpicks to an officer who had lost his teeth and then passed a snuff-box to an officer whose nose had been torn off, causing much embarrassment. On 8 August the fleet's boats stormed Aboukir Island, which surrendered without a fight. The landing party removed four of the guns and destroyed the rest along with the fort they were mounted in, renaming the island \"Nelson's Island\".\n\nOn 10 August, Nelson sent Lieutenant Thomas Duval from \"Zealous\" with messages to the government in India. Duval travelled across the Middle East overland via camel train to Aleppo and took the East India Company ship \"Fly\" from Basra to Bombay, acquainting Governor-General of India Viscount Wellesley with the situation in Egypt. On 12 August the frigates HMS \"Emerald\" under Captain Thomas Moutray Waller and HMS \"Alcmene\" under Captain George Johnstone Hope, and the sloop HMS \"Bonne Citoyenne\" under Captain Robert Retalick, arrived off Alexandria. Initially the British mistook the frigate squadron for French warships and \"Swiftsure\" chased them away. They returned the following day once the error had been realised. The same day as the frigates arrived, Nelson sent \"Mutine\" to Britain with dispatches, under the command of Lieutenant Thomas Bladen Capel, who had replaced Hardy after the latter's promotion to captain of \"Vanguard\". On 14 August, Nelson sent \"Orion\", \"Majestic\", \"Bellerophon\", \"Minotaur\", \"Defence\", \"Audacious\", \"Theseus\", \"Franklin\", \"Tonnant\", \"Aquilon\", \"Conquérant\", \"Peuple Souverain,\" and \"Spartiate\" to sea under the command of Saumarez. Many ships had only jury masts and it took a full day for the convoy to reach the mouth of the bay, finally sailing into open water on 15 August. On 16 August the British burned and destroyed the grounded prize \"Heureux\" as no longer fit for service and on 18 August also burned \"Guerrier\" and \"Mercure\". On 19 August, Nelson sailed for Naples with \"Vanguard\", \"Culloden,\" and \"Alexander\", leaving Hood in command of \"Zealous\", \"Goliath\", \"Swiftsure,\" and the recently joined frigates to watch over French activities at Alexandria.\n\nThe first message to reach Bonaparte regarding the disaster that had overtaken his fleet arrived on 14 August at his camp on the road between Salahieh and Cairo. The messenger was a staff officer sent by the Governor of Alexandria General Jean Baptiste Kléber, and the report had been hastily written by Admiral Ganteaume, who had subsequently rejoined Villeneuve's ships at sea. One account reports that when he was handed the message, Bonaparte read it without emotion before calling the messenger to him and demanding further details. When the messenger had finished, the French general reportedly announced \"\"Nous n'avons plus de flotte: eh bien. Il faut rester en ces contrées, ou en sortir grands comme les anciens\"\" (\"We no longer have a fleet: well, we must either remain in this country or quit it as great as the ancients\"). Another story, as told by the general's secretary, Bourienne, claims that Bonaparte was almost overcome by the news and exclaimed \"Unfortunate Brueys, what have you done!\" Bonaparte later placed much of the blame for the defeat on the wounded Admiral Blanquet, falsely accusing him of surrendering \"Franklin\" while his ship was undamaged. Protestations from Ganteaume and Minister Étienne Eustache Bruix later reduced the degree of criticism Blanquet faced, but he never again served in a command capacity. Bonaparte's most immediate concern however was with his own officers, who began to question the wisdom of the entire expedition. Inviting his most senior officers to dinner, Bonaparte asked them how they were. When they replied that they were \"marvellous,\" Bonaparte responded that it was just as well, since he would have them shot if they continued \"fostering mutinies and preaching revolt.\" To quell any uprising among the native inhabitants, Egyptians overheard discussing the battle were threatened with having their tongues cut out.\n\nNelson's first set of dispatches were captured when \"Leander\" was intercepted and defeated by \"Généreux\" in a fierce engagement off the western shore of Crete on 18 August 1798. As a result, reports of the battle did not reach Britain until Capel arrived in \"Mutine\" on 2 October, entering the Admiralty at 11:15 and personally delivering the news to Lord Spencer, who collapsed unconscious when he heard the report. Although Nelson had previously been castigated in the press for failing to intercept the French fleet, rumours of the battle had begun to arrive in Britain from the continent in late September and the news Capel brought was greeted with celebrations right across the country. Within four days Nelson had been elevated to Baron Nelson of the Nile and Burnham Thorpe, a title with which he was privately dissatisfied, believing his actions deserved better reward. King George III addressed the Houses of Parliament on 20 November with the words:\n\nSaumarez's convoy of prizes stopped first at Malta, where Saumarez provided assistance to a rebellion on the island among the Maltese population. It then sailed to Gibraltar, arriving on 18 October to the cheers of the garrison. Saumarez wrote that, \"We can never do justice to the warmth of their applause, and the praises they all bestowed on our squadron.\" On 23 October, following the transfer of the wounded to the military hospital and provision of basic supplies, the convoy sailed on towards Lisbon, leaving \"Bellerophon\" and \"Majestic\" behind for more extensive repairs. \"Peuple Souverain\" also remained at Gibraltar: The ship was deemed too badly damaged for the Atlantic voyage to Britain and so was converted to a guardship under the name of HMS \"Guerrier\". The remaining prizes underwent basic repairs and then sailed for Britain, spending some months at the Tagus and joining with the annual merchant convoy from Portugal in June 1799 under the escort of a squadron commanded by Admiral Sir Alan Gardner, before eventually arriving at Plymouth. Their age and battered state meant that neither \"Conquérant\" nor \"Aquilon\" were considered fit for active service in the Royal Navy and both were subsequently hulked, although they had been bought into the service for £20,000 (the equivalent of £ as of 2019) each as HMS \"Conquerant\" and HMS \"Aboukir\" to provide a financial reward to the crews that had captured them. Similar sums were also paid out for \"Guerrier\", \"Mercure\", \"Heureux\" and \"Peuple Souverain\", while the other captured ships were worth considerably more. Constructed of Adriatic oak, \"Tonnant\" had been built in 1792 and \"Franklin\" and \"Spartiate\" were less than a year old. \"Tonnant\" and \"Spartiate\", both of which later fought at the Battle of Trafalgar, joined the Royal Navy under their old names while \"Franklin\", considered to be \"the finest two-decked ship in the world\", was renamed HMS \"Canopus\". The total value of the prizes captured at the Nile and subsequently bought into the Royal Navy was estimated at just over £130,000 (the equivalent of £ as of 2019).\nAdditional awards were presented to the British fleet: Nelson was awarded £2,000 (£ as of 2019) a year for life by the Parliament of Great Britain and £1,000 per annum by the Parliament of Ireland, although the latter was inadvertently discontinued after the Act of Union dissolved the Irish Parliament. Both parliaments gave unanimous votes of thanks, each captain who served in the battle was presented with a specially minted gold medal and the first lieutenant of every ship engaged in the battle was promoted to commander. Troubridge and his men, initially excluded, received equal shares in the awards after Nelson personally interceded for the crew of the stranded \"Culloden, \"even though they did not directly participate in the engagement. The Honourable East India Company presented Nelson with £10,000 (£ as of 2019) in recognition of the benefit his action had on their holdings and the cities of London, Liverpool and other municipal and corporate bodies made similar awards. Nelson's own captains presented him with a sword and a portrait as \"proof of their esteem.\" Nelson publicly encouraged this close bond with his officers and on 29 September 1798 described them as \"We few, we happy few, we band of brothers\", echoing William Shakespeare's play \"Henry V\". From this grew the notion of the Nelsonic Band of Brothers, a cadre of high-quality naval officers that served with Nelson for the remainder of his life. Nearly five decades later the battle was among the actions recognised by a clasp attached to the Naval General Service Medal, awarded upon application to all British participants still living in 1847.\n\nOther rewards were bestowed by foreign states, particularly the Ottoman Emperor Selim III, who made Nelson the first Knight Commander of the newly created Order of the Crescent, and presented him with a chelengk, a diamond studded rose, a sable fur and numerous other valuable presents. Tsar Paul I of Russia sent, among other rewards, a gold box studded with diamonds, and similar gifts in silver arrived from other European rulers. On his return to Naples, Nelson was greeted with a triumphal procession led by King Ferdinand IV and Sir William Hamilton and was introduced for only the third time to Sir William's wife Emma, Lady Hamilton, who fainted violently at the meeting, and apparently took several weeks to recover from her injuries. Lauded as a hero by the Neapolitan court, Nelson was later to dabble in Neapolitan politics and become the Duke of Bronté, actions for which he was criticised by his superiors and his reputation suffered. British general John Moore, who met Nelson in Naples at this time, described him as \"covered with stars, medals and ribbons, more like a Prince of Opera than the Conqueror of the Nile.\"\n\nRumours of a battle first appeared in the French press as early as 7 August, although credible reports did not arrive until 26 August, and even these claimed that Nelson was dead and Bonaparte a British prisoner. When the news became certain, the French press insisted that the defeat was the result both of an overwhelmingly large British force and unspecified \"traitors.\" Among the anti-government journals in France, the defeat was blamed on the incompetence of the French Directory and on supposed lingering Royalist sentiments in the Navy. Villeneuve came under scathing attack on his return to France for his failure to support Brueys during the battle. In his defence, he pleaded that the wind had been against him and that Brueys had not issued orders for him to counterattack the British fleet. Writing many years later, Bonaparte commented that if the French Navy had adopted the same tactical principles as the British:\nBy contrast, the British press were jubilant; many newspapers sought to portray the battle as a victory for Britain over anarchy, and the success was used to attack the supposedly pro-republican Whig politicians Charles James Fox and Richard Brinsley Sheridan.\n\nThere has been extensive historiographical debate over the comparative strengths of the fleets, although they were ostensibly evenly matched in size, each containing 13 ships of the line. However, the loss of \"Culloden\", the relative sizes of \"Orient\" and \"Leander\" and the participation in the action by two of the French frigates and several smaller vessels, as well as the theoretical strength of the French position, leads most historians to the conclusion that the French were marginally more powerful. This is accentuated by the weight of broadside of several of the French ships: \"Spartiate\", \"Franklin\", \"Orient\", \"Tonnant\" and \"Guillaume Tell\" were each significantly larger than any individual British ship in the battle. However inadequate deployment, reduced crews, and the failure of the rear division under Villeneuve to meaningfully participate, all contributed to the French defeat.\n\nThe Battle of the Nile has been called \"arguably, the most decisive naval engagement of the great age of sail\", and \"the most splendid and glorious success which the British Navy gained.\" Historian and novelist C. S. Forester, writing in 1929, compared the Nile to the great naval actions in history and concluded that \"it still only stands rivalled by Tsu-Shima as an example of the annihilation of one fleet by another of approximately equal material force\". The effect on the strategic situation in the Mediterranean was immediate, reversing the balance of the conflict and giving the British control at sea that they maintained for the remainder of the war. The destruction of the French Mediterranean fleet allowed the Royal Navy to return to the sea in force, as British squadrons set up blockades off French and allied ports. In particular, British ships cut Malta off from France, aided by the rebellion among the native Maltese population that forced the French garrison to retreat to Valletta and shut the gates. The ensuing Siege of Malta lasted for two years before the defenders were finally starved into surrender. In 1799, British ships harassed Bonaparte's army as it marched east and north through Palestine, and played a crucial part in Bonaparte's defeat at the Siege of Acre, when the barges carrying the siege train were captured and the French storming parties were bombarded by British ships anchored offshore. It was during one of these latter engagements that Captain Miller of \"Theseus\" was killed in an ammunition explosion. The defeat at Acre forced Bonaparte to retreat to Egypt and effectively ended his efforts to carve an empire in the Middle East. The French general returned to France without his army late in the year, leaving Kléber in command of Egypt.\n\nThe Ottomans, with whom Bonaparte had hoped to conduct an alliance once his control of Egypt was complete, were encouraged by the Battle of the Nile to go to war against France. This led to a series of campaigns that slowly sapped the strength from the French army trapped in Egypt. The British victory also encouraged the Austrian Empire and the Russian Empire, both of whom were mustering armies as part of a Second Coalition, which declared war on France in 1799. With the Mediterranean undefended, a Russian fleet entered the Ionian Sea, while Austrian armies recaptured much of the Italian territory lost to Bonaparte in the previous war. Without their best general and his veterans, the French suffered a series of defeats and it was not until Bonaparte returned to become First Consul that France once again held a position of strength on mainland Europe. In 1801 a British Expeditionary Force defeated the demoralised remains of the French army in Egypt. The Royal Navy used its dominance in the Mediterranean to invade Egypt without the fear of ambush while anchored off the Egyptian coast.\n\nIn spite of the overwhelming British victory in the climactic battle, the campaign has sometimes been considered a strategic success for France. Historian Edward Ingram noted that if Nelson had successfully intercepted Bonaparte at sea as ordered, the ensuing battle could have annihilated both the French fleet and the transports. As it was, Bonaparte was free to continue the war in the Middle East and later to return to Europe personally unscathed. The potential of a successful engagement at sea to change the course of history is underscored by the list of French army officers carried aboard the convoy who later formed the core of the generals and marshals under Emperor Napoleon. In addition to Bonaparte himself, Louis-Alexandre Berthier, Auguste de Marmont, Jean Lannes, Joachim Murat, Louis Desaix, Jean Reynier, Antoine-François Andréossy, Jean-Andoche Junot, Louis-Nicolas Davout and Dumas were all passengers on the cramped Mediterranean crossing.\n\nThe Battle of the Nile remains one of the Royal Navy's most famous victories, and has remained prominent in the British popular imagination, sustained by its depiction in a large number of cartoons, paintings, poems, and plays. One of the best known poems about the battle is \"Casabianca\", which was written by Felicia Dorothea Hemans in 1826 and describes a fictional account of the death of Captain Casabianca's son on \"Orient\".\n\nMonuments were raised, including Cleopatra's Needle in London. Muhammad Ali of Egypt gave the monument in 1819 in recognition of the battle of 1798 and the campaign of 1801 but Great Britain did not erect it on the Victoria Embankment until 1878. Another memorial, the Nile Clumps near Amesbury, consists of stands of beech trees purportedly planted by Lord Queensbury at the bequest of Lady Hamilton and Thomas Hardy after Nelson's death. The trees form a plan of the battle; each clump represents the position of a British or French ship. A similar arboreal memorial is thought to have been planted near Alnwick by Nelson's agent Alexander Davison.\n\nThe composer Joseph Haydn had just completed the Missa in Angustiis (mass for troubled times) after Napoleon Bonaparte had defeated the Austrian army in four major battles. The well received news of France's defeat at the Nile however resulted in the mass gradually acquiring the nickname \"Lord Nelson Mass\". The title became indelible when, in 1800, Nelson himself visited the Palais Esterházy, accompanied by his mistress, Lady Hamilton, and may have heard the mass performed.\n\nThe Royal Navy commemorated the battle with the ship names HMS \"Aboukir\" and HMS \"Nile\"\",\" and in 1998 commemorated the 200th anniversary of the battle with a visit to Aboukir Bay by the modern frigate HMS \"Somerset\", whose crew laid wreaths in memory of those who lost their lives in the battle.\n\nAlthough Nelson biographer Ernle Bradford assumed in 1977 that the remains of \"Orient\" \"are almost certainly unrecoverable,\" the first archaeological investigation into the battle began in 1983, when a French survey team under Jacques Dumas discovered the wreck of the French flagship. Franck Goddio later took over the work, leading a major project to explore the bay in 1998. He found that material was scattered over an area in diameter. In addition to military and nautical equipment, Goddio recovered a large number of gold and silver coins from countries across the Mediterranean, some from the 17th century. It is likely that these were part of the treasure taken from Malta that was lost in the explosion aboard \"Orient\". In 2000, Italian archaeologist Paolo Gallo led an excavation focusing on ancient ruins on Nelson's Island. It uncovered a number of graves that date from the battle, as well as others buried there during the 1801 invasion. These graves, which included a woman and three children, were relocated in 2005 to a cemetery at Shatby in Alexandria. The reburial was attended by sailors from the modern frigate HMS \"Chatham\" and a band from the Egyptian Navy, as well as a descendant of the only identified burial, Commander James Russell.\n\n\n"}
{"id": "4607", "url": "https://en.wikipedia.org/wiki?curid=4607", "title": "Barnabas", "text": "Barnabas\n\nBarnabas (; Greek: Βαρνάβας), born Joseph, was an early Christian, one of the prominent Christian disciples in Jerusalem. According to Acts 4:36, Barnabas was a Cypriot Jew. Named an apostle in Acts 14:14, he and Paul the Apostle undertook missionary journeys together and defended Gentile converts against the Judaizers. They traveled together making more converts (c. 45–47), and participated in the Council of Jerusalem (c. 50) Barnabas and Paul successfully evangelized among the \"God-fearing\" Gentiles who attended synagogues in various Hellenized cities of Anatolia.\n\nBarnabas' story appears in the Acts of the Apostles, and Paul mentions him in some of his epistles. Tertullian named him as the author of the Epistle to the Hebrews, but this and other attributions are conjecture. Clement of Alexandria and some scholars have ascribed the Epistle of Barnabas to him, but his authorship is disputed.\n\nAlthough the date, place, and circumstances of his death are historically unverifiable, Christian tradition holds that Barnabas was martyred at Salamis, Cyprus, in 61 AD. He is traditionally identified as the founder of the Cypriot Orthodox Church. The feast day of Barnabas is celebrated on June 11.\n\nBarnabas is usually identified as the cousin of Mark the Evangelist on the basis of Colossians 4. Infrequent occurrence in the Septuagint to its presence in Josephus and Philo, \"anepsios\" consistently carries the connotation of \"cousin\". Some traditions hold that Aristobulus of Britannia, one of the Seventy Disciples, was the brother of Barnabas.\n\nHis Hellenic Jewish parents called him Joseph (although the Byzantine text-type calls him , \"Iōsēs\", 'Joses', a Greek variant of 'Joseph'), but when he sold all his goods and gave the money to the apostles in Jerusalem, they gave him a new name: Barnabas. This name appears to be from the Aramaic , \"\", meaning 'son (of) consolation'. The Greek text of the explains the name as , \"hyios paraklēseōs\", meaning \"\"son of consolation\" or \"son of encouragement\".\"\n\nBarnabas appears mainly in Acts, a history of the early Christian church. He also appears in several of Paul's epistles.\n\nBarnabas, a native of Cyprus and a Levite, is first mentioned in the Acts of the Apostles as a member of the early Christian community in Jerusalem, who sold some land that he owned and gave the proceeds to the community (Acts 4:36-37). When the future Apostle Paul returned to Jerusalem after his conversion, Barnabas introduced him to the apostles (9:27). Easton, in his Bible Dictionary, supposes that they had been fellow students in the school of Gamaliel.\n\nThe successful preaching of Christianity at Antioch to non-Jews led the church at Jerusalem to send Barnabas there to oversee the movement (Acts 11:20–22). He found the work so extensive and weighty that he went to Tarsus in search of Paul (still referred to as Saul), \"an admirable colleague\", to assist him. Paul returned with him to Antioch and labored with him for a whole year (Acts 11:25–26). At the end of this period, the two were sent up to Jerusalem (44 AD) with contributions from the church at Antioch for the relief of the poorer Christians in Judea.\n\nThey returned to Antioch taking John Mark with them, the cousin or nephew of Barnabas. Later, they went to Cyprus and some of the principal cities of Pamphylia, Pisidia, and Lycaonia (Acts 13:14). After recounting what the governor of Cyprus Sergius Paulus believed, Acts 13:9 speaks of Barnabas's companion no longer as Saul, but as Paul, his Roman name, and generally refers to the two no longer as \"Barnabas and Saul\" as heretofore (11:30; 12:25; 13:2, 7), but as \"Paul and Barnabas\" (13:43, 46, 50; 14:20; 15:2, 22, 35). Only in 14:14 and 15:12-25 does Barnabas again occupy the first place, in the first passage with recollection of 14:12, in the last 2, because Barnabas stood in closer relation to the Jerusalem church than Paul. Paul appears as the more eloquent missionary (13:16; 14:8-9; 19-20), whence the Lystrans regarded him as Hermes and Barnabas as Zeus. The King James Version renders the Greek name \"Zeus\" by the Latin name \"Jupiter\" (14:12).\n\nReturning from this first missionary journey to Antioch, they were again sent up to Jerusalem to consult with the church there regarding the relation of Gentiles to the church (Acts 15:2; Galatians 2:1). According to Galatians 2:9-10, Barnabas was included with Paul in the agreement made between them, on the one hand, and James, Peter, and John, on the other, that the two former should in the future preach to the pagans, not forgetting the poor at Jerusalem. This matter having been settled, they returned again to Antioch, bringing the agreement of the council that Gentiles were to be admitted into the church without having to adopt Jewish practices.\n\nAfter they had returned to Antioch from the Jerusalem council, they spent some time there (15:35). Peter came and associated freely there with the Gentiles, eating with them, until criticized for this by some disciples of James, as against Mosaic law. Upon their remonstrances, Peter yielded apparently through fear of displeasing them, and refused to eat any longer with the Gentiles. Barnabas followed his example. Paul considered that they \"walked not uprightly according to the truth of the gospel\" and upbraided them before the whole church (Galatians 2:11-15).\n\nPaul then asked Barnabas to accompany him on another journey (15:36). Barnabas wished to take John Mark along, but Paul did not, as he had left them on the earlier journey (15:37-38). The dispute ended by Paul and Barnabas taking separate routes. Paul took Silas as his companion, and journeyed through Syria and Cilicia; while Barnabas took John Mark to visit Cyprus (15:36-41). John Francis Fenlon suggests that Paul may have been somewhat influenced by the attitude recently taken by Barnabas, which might have proven prejudicial to their work.\n\nBarnabas is not mentioned again in the Acts of the Apostles. However, Gal. 2:11-13 says, \"And when Kephas came to Antioch, I opposed him to his face because he clearly was wrong. For, until some people came from James, he used to eat with the Gentiles; but when they came, he began to draw back and separated himself, because he was afraid of the circumcised. And the rest of the Jews (also) acted hypocritically along with him, with the result that even Barnabas was carried away by their hypocrisy.\" Barnabas is also mentioned in the First Epistle to the Corinthians, in which it is mentioned that he and Paul funded their missions by working side jobs and (it is implied) went without wives and other benefits other apostles received (1 Cor. 9:6); Paul states that he and Barnabas forsook those benefits \"that we may cause no hindrance to the Good News of Christ\" (1 Cor. 9:12).\n\nAntioch, the third-most important city of the Roman Empire, then the capital city of Syria province, today Antakya, Turkey, was where Christians were first called thus.\nSome of those who had been scattered by the persecution that arose because of Stephen went to Antioch, which became the site of an early Christian community. A considerable minority of the Antioch church of Barnabas's time belonged to the merchant class, and they provided support to the poorer Jerusalem church.\n\nBarnabas participated in the Council of Jerusalem, which dealt with the admission of Gentiles into the Christian community, a crucial problem in early Christianity. Paul and Barnabas proposed that Gentiles be allowed into the community without being circumcised.\n\nChurch tradition developed outside of the canon of the New Testament describes the martyrdom of many saints, including the legend of the martyrdom of Barnabas. It relates that certain Jews coming to Syria and Salamis, where Barnabas was then preaching the gospel, being highly exasperated at his extraordinary success, fell upon him as he was disputing in the synagogue, dragged him out, and, after the most inhumane tortures, stoned him to death. His kinsman, John Mark, who was a spectator of this barbarous action, privately interred his body.\n\nAlthough it is believed he was martyred by being stoned, the apocryphal Acts of Barnabas states that he was bound with a rope by the neck, and then being dragged only to the site where he would be burned to death. This is highly unlikely since the apocryphal Acts states that his bones were burnt to dust and that relics of some of his bones are stored in a church today; on the other hand, the fire in the apocryphal Acts could have cremated only some of his bones.\n\nAccording to the History of the Cyprus Church, in 478 Barnabas appeared in a dream to the Archbishop of Constantia (Salamis, Cyprus) Anthemios and revealed to him the place of his sepulchre beneath a carob-tree. The following day Anthemios found the tomb and inside it the remains of Barnabas with a manuscript of Matthew's Gospel on his breast. Anthemios presented the Gospel to Emperor Zeno at Constantinople and received from him the privileges of the Greek Orthodox Church of Cyprus, that is, the purple cloak which the Greek Archbishop of Cyprus wears at festivals of the church, the imperial sceptre and the red ink with which he affixes his signature.\n\nAnthemios then placed the venerable remains of Barnabas in a church which he founded near the tomb. Excavations near the site of a present-day church and monastery, have revealed an early church with two empty tombs, believed to be that of St. Barnabas and Anthemios.\n\nSt. Barnabas is venerated as the Patron Saint of Cyprus.\n\nAlthough many assume that the biblical Mark the Cousin of Barnabas (Colossians 4:10) is the same as John Mark (Acts 12:12, 25; 13:5, 13; 15: 37) and Mark the Evangelist, the traditionally believed author of the Gospel of Mark, according to Hippolytus of Rome, the three \"Marks are distinct persons. They were all members of the Seventy Apostles of Christ, including Barnabas himself. There are two people named Barnabas among Hippolytus' list of Seventy Disciples, one (#13) became the bishop of Milan, the other (#25) the bishop of Heraclea. Most likely one of these two is the biblical Barnabas; the first one is more likely, because the numbering by Hippolytus seems to indicate a level of significance. Clement of Alexandria (\"Stromata\", ii, 20) also makes Barnabas one of the Seventy Disciples that are mentioned in the Gospel of Luke 10:1ff.\n\nOther sources bring Barnabas to Rome and Alexandria. In the \"Clementine Recognitions\" (i, 7) he is depicted as preaching in Rome even during Christ's lifetime.\n\nNot older than the 3rd century is the tradition of the later activity and martyrdom of Barnabas in Cyprus, where his remains are said to have been discovered under the Emperor Zeno. The question whether Barnabas was an apostle was often discussed during the Middle Ages.\n\nTertullian and other Western writers regard Barnabas as the author of the Letter to the Hebrews. This may have been the Roman tradition—which Tertullian usually follows—and in Rome the epistle may have had its first readers. Modern biblical scholarship considers its authorship unknown, though Barnabas amongst others has been proposed as potential authors.\n\n“Photius of the ninth century, refers to some in his day who were uncertain whether the Acts was written by Clement of Rome, Barnabas, or Luke. Yet Photius is certain that the work must be ascribed to Luke.” \n\nHe is also traditionally associated with the Epistle of Barnabas, although some modern scholars think it more likely that the epistle was written in Alexandria in the 130s. John Dominic Crossan quotes Koester as stating that New Testament writings are used \"neither explicitly nor tacitly\" in the Epistle of Barnabas and that this \"would argue for an early date, perhaps even before the end of the first century AD.\" Crossan continues (The Cross that Spoke, p. 121):\nRichardson and Shukster have also argued for a first-century date. Among several arguments they point to the detail of \"a little king, who shall subdue three of the kings under one\" and \"a little crescent horn, and that it subdued under one three of the great horns\" in Barnabas 4:4-5. They propose a composition \"date during or immediately after the reign of Nerva (96-8 AD.) . . . viewed as bringing to an end the glorious Flavian dynasty of Vespasian, Titus, and Domitian . . . when a powerful, distinguished, and successful dynasty was brought low, humiliated by an assassin's knife\" (33, 40).\nIn 16:3-4, the Epistle of Barnabas says: \"Furthermore he says again, 'Lo, they who destroyed this temple shall themselves build it.' That is happening now. For owing to the war it was destroyed by the enemy; at present even the servants of the enemy will build it up again.\" This clearly places Barnabas after the destruction of the temple in 70 AD. But it also places Barnabas before the Bar Kochba revolt in 132 AD, after which there could have been no hope that the Romans would help to rebuild the temple. This shows that the document comes from the period between these two revolts.\nJay Curry Treat states on the dating of Barnabas (The Anchor Bible Dictionary, v. 1, pp. 613–614):\nSince Barnabas 16:3 refers to the destruction of the temple, Barnabas must be written after 70 C.E. It must be written before its first indisputable use in Clement of Alexandria, ca. 190. Since 16:4 expects the temple to be rebuilt, it was most likely written before Hadrian built a Roman temple on the site ca. 135. Attempts to use 4:4-5 and 16:1-5 to specify the time of origin more exactly have not won wide agreement. It is important to remember that traditions of varying ages have been incorporated into this work.\nTreat comments on the provenance of the Epistle of Barnabas (op. cit., p. 613):\nBarnabas does not give enough indications to permit confident identification of either the teacher's location or the location to which he writes. His thought, hermeneutical methods, and style have many parallels throughout the known Jewish and Christian worlds. Most scholars have located the work's origin in the area of Alexandria, on the grounds that it has many affinities with Alexandrian Jewish and Christian thought and because its first witnesses are Alexandrian. Recently, Prigent (Prigent and Kraft 1971: 20-24), Wengst (1971: 114-18), and Scorza Barcellona (1975: 62-65) have suggested other origins based on affinities in Palestine, Syria, and Asia Minor. The place of origin must remain an open question, although the Gk-speaking E. Mediterranean appears most probable.\nConcerning the relationship between Barnabas and the New Testament, Treat writes (op. cit., p. 614):\nAlthough Barnabas 4:14 appears to quote Matt 22:14, it must remain an open question whether the Barnabas circle knew written gospels. Based on Koester's analysis (1957: 125-27, 157), it appears more likely that Barnabas stood in the living oral tradition used by the written gospels. For example, the reference to gall and vinegar in Barnabas 7:3, 5 seems to preserve an early stage of tradition that influenced the formation of the passion narratives in the Gospel of Peter and the synoptic gospels.\n\nThe 5th century \"Decretum Gelasianum\" includes a \"Gospel of Barnabas\" amongst works condemned as apocryphal; but no certain text or quotation from this work has been identified.\n\nAnother book using that same title, the Gospel of Barnabas, survives in two post-medieval manuscripts in Italian and Spanish. Contrary to the canonical Christian Gospels, and in accordance with the Islamic view of Jesus, this later Gospel of Barnabas states that Jesus was not the son of God, but a prophet and messenger.\n\nThe Catholic religious order officially known as \"Clerics Regular of St. Paul\" (\"Clerici Regulares Sancti Pauli\"), founded in the 16th Century, was in 1538 given the grand old Monastery of Saint Barnabas by the city wall of Milan. This being their main seat, the Order was thenceforth known by the popular name of \"Barnabites\".\n\n\n\n\n"}
{"id": "4608", "url": "https://en.wikipedia.org/wiki?curid=4608", "title": "Birka", "text": "Birka\n\nBirka (\"Birca\" in medieval sources), on the island of Björkö (literally: \"Birch Island\") in present-day Sweden, was an important Viking Age trading center which handled goods from Scandinavia and Finland as well as Central and Eastern Europe and the Orient. Björkö is located in Lake Mälaren, 30 kilometers west of contemporary Stockholm, in the municipality of Ekerö. Birka was founded around AD 750 and it flourished for more than 200  years. It was abandoned c. AD 975, around the same time Sigtuna was founded as a Christian town some 35 km to the northeast. It has been estimated that the population in Viking Age Birka was between 500 and 1000 people.\n\nThe archaeological sites of Birka and Hovgården, on the neighbouring island of Adelsö, make up an archaeological complex which illustrates the elaborate trading networks of Viking Scandinavia and their influence on the subsequent history of Europe. Generally regarded as Sweden's oldest town, Birka (along with Hovgården) has been a UNESCO World Heritage Site since 1993. A silver ring from a Viking-era grave in Birka is the first ring with Arabic inscription from that era found in Scandinavia.\n\nBirka was founded around AD 750 by either a king in order to control and expand trade or it emerged from a seasonal trading place around. It is one of the earliest urban settlements in Scandinavia. Birka was the Baltic link in the river and portage route through Ladoga (Aldeigja) and Novgorod (Holmsgard) to the Byzantine Empire and the Abbasid Califate. Birka was also important as the site of the first known Christian in Sweden, founded in 831 by Saint Ansgar.\n\nAs a trading center Birka most likely offered furs and iron goods as well as craft products, in exchange for various materials from much of Europe and western Asia. Furs were obtained from the Sami, Finns, and people in northwestern Russia as well as from local trappers. Furs included bear, fox, marten, otter, beaver and other species. Reindeer antler was an important item in exchange as well as hand-carved combs made from antler. Also walrus teeth, amber, and honey were exchanged. Foreign goods found from the graves of Birka include glass and metal ware, pottery from the Rhineland, clothing and textiles including Chinese silk, Byzantine embroidery with extremely fine gold thread, brocades with gold passementerie and plaited cords of high quality. From the ninth century onwards coins minted at Haithabu in northern Germany and elsewhere in Scandinavia start to appear. The vast majority of the coins found at Birka are however silver dirhams from the Caliphate. English and Carolingian coins are rare. \n\nSources of Birka are mainly archaeological remains. No texts survive from this area, though the written text \"Vita Ansgari\" (\"The life of Ansgar\") by Rimbert (c. 865) describes the missionary work of Ansgar around 830 at Birka, and \"Gesta Hammaburgensis Ecclesiae Pontificum\" (Deeds of Bishops of the Hamburg Church) by Adam of Bremen in 1075 describes the archbishop Unni, who died at Birka in 936. St Ansgar's work was the first attempt to convert the inhabitants from the Norse religion to Christianity, and it was unsuccessful.\n\nBoth Rimbert and Adam were German clergymen writing in Latin. There are no known Norse sources mentioning the name of the settlement, or even the settlement itself, and the original Norse name of Birka is unknown. \"Birca\" is the Latinised form given in the sources and \"Birka\" its contemporary, unhistorical Swedish form. The Latin name is probably derived from an Old Norse word \"birk\" which probably meant a market place. Related to this was the \"Bjärköa law\" (bjärköarätt) which regulated the life on market places in Denmark, Norway and Sweden. Both terms in different forms are very common in Scandinavian place names still today leading to speculation that all references to Birca especially by Adam of Bremen were not about the same location.\n\nBoth publications are silent on Birca's size, layout and appearance. Based on Rimbert's account, Birca was significant because it had a port and it was the place for the regional ting. Adam only mentions the port, but otherwise Birca seems to have been significant to him because it had been the bridgehead of Ansgar's Christian mission and because archbishop Unni had been buried there.\n\n\"Vita Ansgari\" and \"Gesta\" are sometimes ambiguous, which has caused some controversy as to whether Birca and the Björkö settlement were the same location. Many other locations have been suggested through the years. However, Björkö is the only location that can show remains of a town of Birca's significance, which is why the vast majority of scholars regard Björkö as the location of Birca.\n\nBirka was abandoned during the later half of the 10th century. Based on the coin finds, the city seems to have silenced around 960. Roughly around the same time, the nearby settlement of Sigtuna supplanted Birka as the main trading centre in the Mälaren area. The reasons for Birka's decline are disputed. A contributing factor may have been the post-glacial rebound, which lowered the water level of Mälaren changing it from an arm of the sea into a lake and cut Birka off from the nearest (southern) access to the Baltic Sea. The Baltic island of Gotland was also in a better strategic position for Russian-Byzantine trade, and was gaining eminence as a mercantile stronghold. Historian Neil Kent has speculated that the area may have been the victim of an enemy assault.\n\nThe Varangian trade stations in Russia suffered a serious decline at roughly the same date.\n\nIn \"Vita Ansgari\" (\"The life of Ansgar\") monk and later archbishop of Hamburg-Bremen Rimbert gives the first known description of Birka. The town was the center of Catholic missionary activities in the 9th century Sweden. Rimbert's interests were in the Christian faith, not so much in the Swedish geopolicy, so his descriptions of Birka remain approximate at best.\n\nThis is how it all started in 829:\n\nMeanwhile it happened that Swedish ambassadors had come to the Emperor Louis the Pious, and, amongst other matters which they had been ordered to bring to the attention of the emperor, they informed him that there were many belonging to their nation who desired to embrace the Christian religion, and that their king so far favoured this suggestion that he would permit God's priests to reside there, provided that they might be deemed worthy of such a favour and that the emperor would send them suitable preachers. (Chapter IX)\n\nAnsgar then undertook the mission committed to him by the emperor, who desired that he should go to the Swedes and discover whether this people was prepared to accept the faith as their messengers had declared. (Chapter X)\n\nAnsgar was already experienced in the missionary work in Denmark, and set forth to Sweden. Rimbert describes the trip very generally:\n\nIt may suffice for me to say that while they were in the midst of their journey they fell into the hands of pirates. The merchants with whom they were travelling, defended themselves vigorously and for a time successfully, but eventually they were conquered and overcome by the pirates, who took from them their ships and all that they possessed, whilst they themselves barely escaped on. foot to land. —With great difficulty they accomplished their long journey on foot, traversing also the intervening seas (maria), where it was possible, by ship, and eventually arrived at the Swedish port called Birka. (Chapters X and XI)\n\nRimbert does not say where Ansgar sailed off or where he landed. Noteworthy is just his note about several \"seas\" that they had to cross to get to Birka from the place they had landed to. Since Rimbert mentions them to have crossed the seas by ship \"where it was possible\" they clearly had the alternative of going around them as well, meaning that the seas were probably the numerous lakes in southern Sweden. When Ansgar again travelled to Birka from Germany about 852, it went easier:\n\nAnsgar accomplished the journey on which he had set out, and after spending nearly twenty days in a ship, he arrived at Birka (Chapter XXVI)\n\nThis might mean that he sailed off from Hamburg or Bremen instead of some port in Baltic Sea, since the later account by Adam of Bremen gives the distance of Scania and Birka to be only five days at sea.\n\nSeveral Swedish kings of the 9th century, Björn, Anund and Olof, are all mentioned in \"Vita\" to have spent time in Birka. None of them is however said to have had his residence there, as the Swedish king and his retinue periodically moved between the Husbys, parts of the network of royal estates called Uppsala öd.\n\nKing Björn met Ansgar in Birka when he arrived there in 829 (Chapter XI). Later King Olof met him there as well during his last trip in 852 (Chapter XXVI).\n\nAnsgar's missionary work resulted in first churches to be built in Sweden. Talking about Herigar, the prefect of Birka:\n\nA little later he built a church on his own ancestral property and served God with the utmost devotion. (Chapter XI)\n\nHerigar's church was not far from the place where tings were held:\n\nOn one occasion he himself was sitting in an assembly of people, a stage having been arranged for a council on an open plain. He then summoned his servants and told them to carry him to his church. (Chapter XIX)\n\nAnother church was also built in Sweden, however location is left open:\n\nThis Gautbert, who at his consecration received the honoured name of the apostle Simeon, went to Sweden, and was honourably received by the king and the people; and he began, amidst general goodwill and approval, to build a church there (Chapter XIV)\n\nThe exiled Swedish King Anund Uppsale confirms that either one of the churches was in Birka itself when he ponders if Birka should be plundered:\n\n\"There are there,\" he said, \"many great and powerful gods, and in former time a church was built there, and there are many Christians there who worship Christ\" (Chapter XIX)\n\nDanes attacked Birka, accompanied with the deposed king Anund, which caused great distress in the town.\n\nBeing in great difficulty they fled to a neighbouring city (ad civitatem, quæ iuxta erat, confugerunt) and began to promise and offer to their gods—But inasmuch as the city was not strong and there were few to offer resistance, they sent messengers to the Danes and asked for friendship and alliance. —Hergeir, the faithful servant of the Lord, was angry with them and said, \"They will lead away your wives and sons as captives, they will burn our city (urbs) and town (vicus)\" and will destroy you with the sword (Chapter XIX)\n\nAs the neighbouring \"city\" is not mentioned in any other context than during the Danish attack as a place where people took refuge, it probably meant a nearby fortress. Eventually Danes left, sparing Birka from destruction.\n\nWhen Ansgar asked if King Olof would permit him to establish the Christian religion in the kingdom during his second visit in 852, the king said to him:\n\nOn this account I have not the power, nor do I dare, to approve the objects of your mission until I can consult our gods by the casting of lots and until I can enquire the will of the people in regard to this matter. Let your messenger attend with me the next assembly (Chapter XXVI)\n\nWhen the day for the assembly which was held in the town of Birka drew near, in accordance with their national custom the king caused a proclamation to be made to the people by the voice of a herald, in order that they might be informed concerning the object of their mission. —The king then rose up from amongst the assembly and forthwith directed one of his own messengers to accompany the bishop's messenger, and to tell him that the people were unanimously inclined to accept his proposal and at the same time to tell him that, whilst their action was entirely agreeable to him, he could not give his full consent until, in another assembly, which was to be held in another part of his kingdom, he could announce this resolution to the people who lived in that district. (Chapter XXVII)\n\nTings were huge open-air events, which required plenty of space. The more important ting that king Olof talked about was probably the \"Ting of all Swedes\", which was held at the end of February in Uppsala, during the Disting. The king was obliged to obey the common decisions made at this ting, and the most powerful man at this assembly was not the king, but the lawspeaker of Tiundaland. Locally important tings were the Westrogothic \"Ting of all Geats\" in Skara and the Ostrogothic \"Lionga ting\" in the vicinity of today's Linköping.\n\nIn \"Gesta Hammaburgensis ecclesiae pontificum\" (Deeds of Bishops of the Hamburg Church), Adam of Bremen mentions Birka many times, and the book is the main source of information on the city. After its initial release in 1075/6, \"Gesta\" was complemented with supplementary \"Scholias\" until the death of Adam in the 1080s. Birca is described as an existing city in the original version, but then as destroyed in \"Scholia 138\".\n\nOne of Adam's main sources had been the German bishop Adalvard the Younger of Sigtuna and later of Skara as hinted in \"Scholia 119\". He was also very familiar with Rimbert's work. Adam himself never visited Birka.\n\nAdam described Birka as a Geatish port town and had gathered many details about it.\n\nBirka is the main Geatish town (oppidum Gothorum), situated in the middle of Sweden (Suevoniae), not far (non longe) from the temple called Uppsala (Ubsola) which the Swedes (Sueones) held in the highest esteem when it comes to the worship of the gods; here forms an inlet of the Baltic or the Barbaric Sea a port facing north which welcomes all the wild peoples all around this sea but which is risky for those who are careless or ignorant of such places ... they have therefore blocked this inlet of the troubled sea with hidden masses of rocks along more than 100 stadions (18 km). On this anchorage, being the best sheltered within the maritime region of Sweden (Suevoniae), all the ships belonging to Danes (Danorum) known as Norwegians (Nortmannorum) as well as to Slavs (Sclavorum), Sembrians (Semborum) and other Scythian (Scithiae) peoples use to convene every year for sundry necessary commerce. (I 62)\n\nTurning from the northern parts to the mouth of the Baltic Sea we first meet the Norwegians (Nortmanni), then the Danish region of Skåne (Sconia) stands out, and beyond these live the Geats (Gothi) for a long stretch all the way to Birka. (IV 14)\n\nHaving described Västergötland and Skara, Adam writes:\n\nBeyond it Östergötland (Ostrogothia) extends along the sea, that is called the Baltic Sea, all the way to Birka. (IV 23)\n\nNoteworthy in the following statement is the usage of the term \"not far\" (non longe) which was also used to describe the distance between Birka and the Uppsala temple:\n\nFurthermore we have been told that there are many more islands in that sea, one of which is called the Great Estland (Aestland) -- And this island is told to be quite close to the Woman Land (terrae feminarum), which is not far (non longe) away from Birka of the Swedes. (IV 17)\n\nAdam also had travel instructions from Skåne to Sigtuna:\n\nFrom Skåne (Sconia) of the Danes one reaches Sigtuna (Sictonam) or Birka after five days at sea, for they are indeed alike. But by land from Skåne across the Geatish people (Gothorum populos) and cities Skara (Scaranem), Telgas and Birka, one reaches Sigtuna only after a full month. (IV 28)\n\n\"Telgas\" is not mentioned anywhere else, and it remains as speculative as Birka. The most popular identification among many telge names in Sweden is Södertälje. \"Scholia 121\" of IV 20 tells also:\n\nFor those who sail from Skåne (Sconia) of the Danes to Birka, the journey takes five days, from Birka to Russia (Ruzziam) likewise five days at sea. (Scholia 121)\n\nThe following definition remains even more mysterious:\n\nIn pity of their errors, our archbishop ordained as their diocesan capital Birka, which is in the middle of Sweden (Sueoniae) facing Jumne (Iumnem), the capital of the Slavs, and equally distant from all the coasts of the surrounding sea. (IV 20)\n\nSince it is physically impossible for any Swedish town to face Jumne, the latter being situated along River Oder, Adam's statement is probably a misunderstanding. No place having a similar name to Birka is known to have situated on the opposite shore of Oder, so it may be possible that something similar to Jumne was located opposite to Birka.\n\nArchbishopric of Hamburg-Bremen that oversaw the missionary work in Scandinavia until 1103, had appointed bishops to Sweden at least from 1014 onwards, the first see being in Skara. Several bishops were appointed for Sweden in 1060s, one also for Birka.\n\nFor Sweden, six were consecrated: Adalvard the Elder (Adalwardum) and Acilinum, also Adalvard the Younger (Adalwardum) and Tadicum, and furthermore Simeon (Symeonem) and the monk John (Iohannem). (III 70)\n\n\"Scholia 94\" appends this as follows:\n\nAdalvard the Elder (Adalwardus senior) was to superintend both lands of the Geats (uterque praefectus est Gothiae), Adalvard the Younger Sigtuna (Sictunam) and Uppsala (Ubsalam), Simeon (Symon) the Sami people (Scritefingos), John (Iohannes) the islands of the Baltic Sea. (Scholia 94)\n\nFurthermore, the following was said about John's location after talking about Birka:\n\nFor this city he ordained, as the first among our people, the abbot Hiltin, whom he wanted to call John. (IV 20)\n\nJohn seems to have been situated in Birka in order to prepare for the missionary work among the many heathen people that flooded to Birca from around the Baltic coasts. This was a logical continuation to Birka's position as the first missionary town in Sweden. Noteworthy here is that the biggest islands in the Baltic Sea, Öland and Gotland, were part of the diocese of Linköping in the Middle Ages, covering also Östergötland and eastern Småland.\n\n\"Scholia 122\" of IV 20 locates the tomb of Hamburg's archbishop Unni in Birka:\n\nThere is the port of Saint Ansgar and the tomb of the holy Archbishop Unni, and a familiar haven, it is said, for the holy confessors of our diocese. (Scholia 122)\n\nAccording to \"Gesta\", Unni had died in 936 (I 64).\n\nAfter having consistently described Birka as an existing city, \"Scholia 138\" of IV 29 describes Birka's sudden demise. Talking about Adalvard the Younger, the bishop of Sigtuna and later that of Skara, Adam or a later copyist has written:\n\nDuring his journey he seized the opportunity to make a detour to Birka, which is now reduced to loneliness so that one can hardly find vestiges of the city; therefore impossible to come upon the tomb of the holy Archbishop Unni. (Scholia 138)\n\nThe remark does not make it clear if Adalvard found the city destroyed or if that had happened after his visit and the later remark was just to warn the future pilgrims not to go there anymore in vain. As Adalvard was back in Bremen already by 1069 and is mentioned as one of Adam's sources of information, it would have been expected that word about Birka's destruction had reached also Adam before he published his work half a decade later.\n\nThe exact location of Birka was also lost during the centuries, leading to speculation from Swedish historians. However, the island of Björkö was first claimed to have been Birka already about 1450 in the so-called \"Chronicle of Sweden\" (\"Prosaiska krönikan\"):\n\nAnd there were three capitals in Sweden two of which were not long away from Uppsala (Vpsala). The one was called Sigtuna (siktuna) and the other Birka (birka). Birka was on an island in Lake Mälaren (mälar) that is called Björkö (birköö). The third was in Westgötaland (westergötlandh) and was called Skara (skara).\n\nIn search of Birka, National Antiquarian Johan Hadorph was the first to attempt excavations on Björkö in the late 17th century.\n\nIn the late 19th century, Hjalmar Stolpe, an entomologist by education, arrived on Björkö to study fossilized insects found in amber on the island. Stolpe found very large amounts of amber on the island, which is unusual since amber is not normally found in lake Mälaren. Stolpe speculated that the island may have been an important trading post, prompting him to conduct a series of archeological excavations between 1871-95. The excavations soon indicated that a major settlement had been located on the island and eventually Stolpe spent two decades excavating the island. After Björkö came to be identified with ancient Birka, it has been assumed that the original name of Birka was simply \"Bierkø\" (sometimes spelt \"Bjärkö\"), an earlier form of \"Björkö\".\n\nOwnership of Björkö is today mainly in private hands, and used for farming. The settlement site, however is an archaeological site, and a museum has been built nearby for exhibition of finds (mostly replicas), models and reconstructions. It is a popular site to visit during the summer times. The complete collection of archaeological finds from the excavations on Björkö are held by The Swedish History Museum in Stockholm, and many of the artefacts are on display there.\n\nThe archaeological remains are located in the north part of Björkö and span an area of about 7 hectares (17 acres). The remains are both burial-sites and buildings, and in the south part of this area, there is also a hill fort called \"Borgen\" (\"The Fortress\"). The construction technique of the buildings is still unknown, but the main material was wood. An adjacent island holds the remains of Hovgården, an estate which housed the King's retinue during visits.\n\nApproximately 700 people lived at Birka when it was at its largest, and about 3,000 graves have been found. Its administrative center was supposedly located outside of the settlement itself, on the nearby island of Adelsö.\n\nThe most recent large excavation was undertaken between 1990-95 in a region of dark earth, believed to be the site of the main settlement. Björkö is today mainly agricultural, and shipping lines carry tourists to the island, where a museum showcases a view of life during the Viking era.\n\n"}
{"id": "4609", "url": "https://en.wikipedia.org/wiki?curid=4609", "title": "Beta-lactamase", "text": "Beta-lactamase\n\nBeta-lactamases are enzymes () produced by bacteria that provide multi-resistance to β-lactam antibiotics such as penicillins, cephalosporins, cephamycins, and carbapenems (ertapenem), although carbapenems are relatively resistant to beta-lactamase. Beta-lactamase provides antibiotic resistance by breaking the antibiotics' structure. These antibiotics all have a common element in their molecular structure: a four-atom ring known as a β-lactam. Through hydrolysis, the lactamase enzyme breaks the β-lactam ring open, deactivating the molecule's antibacterial properties.\n\nBeta-lactam antibiotics are typically used to treat a broad spectrum of Gram-positive and Gram-negative bacteria.\n\nBeta-lactamases produced by Gram-negative organisms are usually secreted, especially when antibiotics are present in the environment.\n\nThe structure of a \"Streptomyces\" β-lactamase is given by .\n\nPenicillinase is a specific type of β-lactamase, showing specificity for penicillins, again by hydrolysing the β-lactam ring. Molecular weights of the various penicillinases tend to cluster near 50 kiloDaltons.\n\nPenicillinase was the first β-lactamase to be identified. It was first isolated by Abraham and Chain in 1940 from Gram-negative \"E. coli\" even before penicillin entered clinical use, but penicillinase production quickly spread to bacteria that previously did not produce it or produced it only rarely. Penicillinase-resistant beta-lactams such as methicillin were developed, but there is now widespread resistance to even these.\n\nAmong Gram-negative bacteria, the emergence of resistance to expanded-spectrum cephalosporins has been a major concern. It appeared initially in a limited number of bacterial species (\"E. cloacae\", \"C. freundii\", \"S. marcescens\", and \"P. aeruginosa\") that could mutate to hyperproduce their chromosomal class C β-lactamase. A few years later, resistance appeared in bacterial species not naturally producing AmpC enzymes (\"K. pneumoniae\", \"Salmonella\" spp., \"P. mirabilis\") due to the production of TEM- or SHV-type ESBLs (extended spectrum beta lactamases). Characteristically, such resistance has included oxyimino- (for example ceftizoxime, cefotaxime, ceftriaxone, and ceftazidime, as well as the oxyimino-monobactam aztreonam), but not 7-alpha-methoxy-cephalosporins (cephamycins; in other words, cefoxitin and cefotetan); has been blocked by inhibitors such as clavulanate, sulbactam or tazobactam and did not involve carbapenems and temocillin. Chromosomal-mediated AmpC β-lactamases represent a new threat, since they confer resistance to 7-alpha-methoxy-cephalosporins (cephamycins) such as cefoxitin or cefotetan but are not affected by commercially available β-lactamase inhibitors, and can, in strains with loss of outer membrane porins, provide resistance to carbapenems.\nMembers of the family commonly express plasmid-encoded β-lactamases (e.g., TEM-1, TEM-2, and SHV-1), which confer resistance to penicillins but not to expanded-spectrum cephalosporins. In the mid-1980s, a new group of enzymes, the extended-spectrum β-lactamases (ESBLs), was detected (first detected in 1979). The prevalence of ESBL-producing bacteria have been gradually increasing in acute care hospitals. ESBLs are beta-lactamases that hydrolyze extended-spectrum cephalosporins with an oxyimino side chain. These cephalosporins include cefotaxime, ceftriaxone, and ceftazidime, as well as the oxyimino-monobactam aztreonam. Thus ESBLs confer multi-resistance to these antibiotics and related oxyimino-beta lactams. In typical circumstances, they derive from genes for TEM-1, TEM-2, or SHV-1 by mutations that alter the amino acid configuration around the active site of these β-lactamases. A broader set of β-lactam antibiotics are susceptible to hydrolysis by these enzymes. An increasing number of ESBLs not of TEM or SHV lineage have recently been described. The ESBLs are frequently plasmid encoded. Plasmids responsible for ESBL production frequently carry genes encoding resistance to other drug classes (for example, aminoglycosides). Therefore, antibiotic options in the treatment of ESBL-producing organisms are extremely limited. Carbapenems are the treatment of choice for serious infections due to ESBL-producing organisms, yet carbapenem-resistant (primarily ertapenem resistant) isolates have recently been reported. ESBL-producing organisms may appear susceptible to some extended-spectrum cephalosporins. However, treatment with such antibiotics has been associated with high failure rates.\n\nTEM-1 is the most commonly encountered beta-lactamase in Gram-negative bacteria. Up to 90% of ampicillin resistance in \"E. coli\" is due to the production of TEM-1. Also responsible for the ampicillin and penicillin resistance that is seen in \"H. influenzae\" and \"N. gonorrhoeae\" in increasing numbers. Although TEM-type beta-lactamases are most often found in \"E. coli\" and \"K. pneumoniae\", they are also found in other species of Gram-negative bacteria with increasing frequency. The amino acid substitutions responsible for the extended-spectrum beta lactamase (ESBL) phenotype cluster around the active site of the enzyme and change its configuration, allowing access to oxyimino-beta-lactam substrates. Opening the active site to beta-lactam substrates also typically enhances the susceptibility of the enzyme to β-lactamase inhibitors, such as clavulanic acid. Single amino acid substitutions at positions 104, 164, 238, and 240 produce the ESBL phenotype, but ESBLs with the broadest spectrum usually have more than a single amino acid substitution. Based upon different combinations of changes, currently 140 TEM-type enzymes have been described. TEM-10, TEM-12, and TEM-26 are among the most common in the United States. The term TEM comes from the name of the Athenian patient (Temoniera) from which the isolate was recovered in 1963.\n\nSHV-1 shares 68 percent of its amino acids with TEM-1 and has a similar overall structure. The SHV-1 beta-lactamase is most commonly found in \"K. pneumoniae\" and is responsible for up to 20% of the plasmid-mediated ampicillin resistance in this species. ESBLs in this family also have amino acid changes around the active site, most commonly at positions 238 or 238 and 240. More than 60 SHV varieties are known. SHV-5 and SHV-12 are among the most common.\n\nThese enzymes were named for their greater activity against cefotaxime than other oxyimino-beta-lactam substrates (e.g., ceftazidime, ceftriaxone, or cefepime). Rather than arising by mutation, they represent examples of plasmid acquisition of beta-lactamase genes normally found on the chromosome of \"Kluyvera\" species, a group of rarely pathogenic commensal organisms. These enzymes are not very closely related to TEM or SHV beta-lactamases in that they show only approximately 40% identity with these two commonly isolated beta-lactamases. More than 80 CTX-M enzymes are currently known. Despite their name, a few are more active on ceftazidime than cefotaxime. They have mainly been found in strains of \"Salmonella enterica\" serovar \"Typhimurium\" and \"E. coli\", but have also been described in other species of Enterobacteriaceae and are the predominant ESBL type in parts of South America. (They are also seen in eastern Europe) CTX-M-14, CTX-M-3, and CTX-M-2 are the most widespread. CTX-M-15 is currently (2006) the most widespread type in \"E. coli\" the UK and is widely prevalent in the community. An example of beta-lactamase CTX-M-15, along with IS\"Ecp1\", has been found to have recently transposed onto the chromosome of \"Klebsiella pneumoniae\" ATCC BAA-2146.\n\nOXA beta-lactamases were long recognized as a less common but also plasmid-mediated beta-lactamase variety that could hydrolyze oxacillin and related anti-staphylococcal penicillins. These beta-lactamases differ from the TEM and SHV enzymes in that they belong to molecular class D and functional group 2d . The OXA-type beta-lactamases confer resistance to ampicillin and cephalothin and are characterized by their high hydrolytic activity against oxacillin and cloxacillin and the fact that they are poorly inhibited by clavulanic acid. Amino acid substitutions in OXA enzymes can also give the ESBL phenotype. While most ESBLs have been found in \"E. coli\", \"K. pneumoniae\", and other Enterobacteriaceae, the OXA-type ESBLs have been found mainly in \"P. aeruginosa\". OXA-type ESBLs have been found mainly in \"Pseudomonas aeruginosa\" isolates from Turkey and France. The OXA beta-lactamase family was originally created as a phenotypic rather than a genotypic group for a few beta-lactamases that had a specific hydrolysis profile. Therefore, there is as little as 20% sequence homology among some of the members of this family. However, recent additions to this family show some degree of homology to one or more of the existing members of the OXA beta-lactamase family. Some confer resistance predominantly to ceftazidime, but OXA-17 confers greater resistance to cefotaxime and cefepime than it does resistance to ceftazidime.\n\nOther plasmid-mediated ESBLs, such as PER, VEB, GES, and IBC beta-lactamases, have been described but are uncommon and have been found mainly in \"P. aeruginosa\" and at a limited number of geographic sites. PER-1 in isolates in Turkey, France, and Italy; VEB-1 and VEB-2 in strains from Southeast Asia; and GES-1, GES-2, and IBC-2 in isolates from South Africa, France, and Greece. PER-1 is also common in multiresistant acinetobacter species in Korea and Turkey. Some of these enzymes are found in Enterobacteriaceae as well, whereas other uncommon ESBLs (such as BES-1, IBC-1, SFO-1, and TLA-1) have been found only in Enterobacteriaceae.\n\nWhile ESBL-producing organisms were previously associated with hospitals and institutional care, these organisms are now increasingly found in the community. CTX-M-15-positive E. coli are a cause of community-acquired urinary infections in the UK, and tend to be resistant to all oral β-lactam antibiotics, as well as quinolones and sulfonamides. Treatment options may include nitrofurantoin, fosfomycin, mecillinam and chloramphenicol. In desperation, once-daily ertapenem or gentamicin injections may also be used.\n\nAlthough the inhibitor-resistant β-lactamases are not ESBLs, they are often discussed with ESBLs because they are also derivatives of the classical TEM- or SHV-type enzymes. These enzymes were at first given the designation IRT for inhibitor-resistant TEM β-lactamase; however, all have subsequently been renamed with numerical TEM designations. There are at least 19 distinct inhibitor-resistant TEM β-lactamases. Inhibitor-resistant TEM β-lactamases have been found mainly in clinical isolates of \"E. coli\", but also some strains of \"K. pneumoniae\", \"Klebsiella oxytoca\", \"P. mirabilis\", and \"Citrobacter freundii\". Although the inhibitor-resistant TEM variants are resistant to inhibition by clavulanic acid and sulbactam, thereby showing clinical resistance to the beta-lactam—lactamase inhibitor combinations of amoxicillin-clavulanate (co-amoxiclav), ticarcillin-clavulanate (co-ticarclav), and ampicillin/sulbactam, they normally remain susceptible to inhibition by tazobactam and subsequently the combination of piperacillin/tazobactam, although resistance has been described. This is no longer a primarily European epidemiology, it is found in northern parts of America often and should be tested for with complex UTI's.\n\nAmpC type β-lactamases are commonly isolated from extended-spectrum cephalosporin-resistant Gram-negative bacteria. AmpC β-lactamases (also termed class C or group 1) are typically encoded on the chromosome of many Gram-negative bacteria including \"Citrobacter\", \"Serratia\" and \"Enterobacter\" species where its expression is usually inducible; it may also occur on \"Escherichia coli\" but is not usually inducible, although it can be hyperexpressed. AmpC type β-lactamases may also be carried on plasmids. AmpC β-lactamases, in contrast to ESBLs, hydrolyse broad and extended-spectrum cephalosporins (cephamycins as well as to oxyimino-β-lactams) but are not inhibited by β-lactamase inhibitors such as clavulanic acid. AmpC-type β-lactamase organisms are often clinically grouped through the acronym, \"SPACE\": \"Serratia, Pseudomonas\" or \"Proteus, Acinetobacter, Citrobacter\", and \"Enterobacter\".\n\nCarbapenems are famously stable to AmpC β-lactamases and extended-spectrum-β-lactamases. Carbapenemases are a diverse group of β-lactamases that are active not only against the oxyimino-cephalosporins and cephamycins but also against the carbapenems. Aztreonam is stable to the metallo-β-lactamases,\nbut many IMP and VIM producers are resistant, owing to other mechanisms. Carbapenemases were formerly believed to derive only from classes A, B, and D, but a class C carbapenemase has been described.\n\nPlasmid-mediated IMP-type carbapenemases, 19 varieties of which are currently known, became established in Japan in the 1990s both in enteric Gram-negative organisms and in \"Pseudomonas\" and \"Acinetobacter\" species. IMP enzymes spread slowly to other countries in the Far East, were reported from Europe in 1997, and have been found in Canada and Brazil.\n\nA second growing family of carbapenemases, the VIM family, was reported from Italy in 1999 and now includes 10 members, which have a wide geographic distribution in Europe, South America, and the Far East and have been found in the United States. VIM-1 was discovered in \"P. aeruginosa\" in Italy in 1996; since then, VIM-2 - now the predominant variant - was found repeatedly in Europe and the Far East; VIM-3 and -4 are minor variants of VIM-2 and -1, respectively. VIM enzymes occur mostly in \"P. aeruginosa\", also \"P. putida\" and, very rarely, Enterobacteriaceae.\n\nAmino acid sequence diversity is up to 10% in the VIM family, 15% in the IMP family, and 70% between VIM and IMP. Enzymes of both the families, nevertheless, are similar. Both are integron-associated, sometimes within plasmids. Both hydrolyse all β-lactams except monobactams, and evade all β-lactam inhibitors. The VIM enzymes are among the most widely distributed MBLs, with >40 VIM variants having been reported. Biochemical and biophysical studies revealed that VIM variants have only small variations in their kinetic parameters but substantial differences in their thermal stabilities and inhibition profiles.\n\nThe OXA group of β-lactamases occur mainly in Acinetobacter species and are divided into two clusters. OXA carbapenemases hydrolyse carbapenems very slowly \"in vitro\", and the high MICs seen for some Acinetobacter hosts (>64 mg/L) may reflect secondary mechanisms. They are sometimes augmented in clinical isolates by additional resistance mechanisms, such as impermeability or efflux. OXA carbapenemases also tend to have a reduced hydrolytic efficiency towards penicillins and cephalosporins.\n\nA few class A enzymes, most noted the plasmid-mediated KPC enzymes, are effective carbapenemases as well. Ten variants, KPC-2 through KPC-11 are known, and they are distinguished by one or two amino acid substitutions (KPC-1 was re-sequenced in 2008 and found to be 100% homologous to published sequences of KPC-2). KPC-1 was found in North Carolina, KPC-2 in Baltimore and KPC-3 in New York. They have only 45% homology with SME and NMC/IMI enzymes and, unlike them, can be encoded by self-transmissible plasmids.\n\n, the class A \"Klebsiella pneumoniae\" carbapenemase (KPC) globally has been the most common carbapenemase, and was first detected in 1996 in North Carolina, USA. A 2010 publication indicated that KPC producing Enterobacteriaceae were becoming common in the United States.\n\nThe first class C carbapenemase was described in 2006 and was isolated from a virulent strain of \"Enterobacter aerogenes\". It is carried on a plasmid, pYMG-1, and is therefore transmissible to other bacterial strains.\n\nIn general, these are of little clinical significance.\n\nCcrA (CfiA). Its gene occurs in ca. 1-3% of \"B. fragilis\" isolates, but fewer produce the enzyme since expression demands appropriate migration of an insertion sequence. CcrA was known before imipenem was introduced, and producers have shown little subsequent increase.\n\nOriginally described from New Delhi in 2009, this gene is now widespread in \"Escherichia coli\" and \"Klebsiella pneumoniae\" from India and Pakistan. As of mid-2010, NDM-1 carrying bacteria have been introduced to other countries (including the United States and UK), most probably due to the large number of tourists travelling the globe, who may have picked up the strain from the environment, as strains containing the NDM-1 gene have been found in environmental samples in India. NDM have several variants which share different properties.\n\nIn general, an isolate is suspected to be an ESBL producer when it shows \"in vitro\" susceptibility to the second-generation cephalosporins (cefoxitin, cefotetan) but resistance to the third-generation cephalosporins and to aztreonam. Moreover, one should suspect these strains when treatment with these agents for Gram-negative infections fails despite reported \"in vitro\" susceptibility. Once an ESBL-producing strain is detected, the laboratory should report it as \"resistant\" to all penicillins, cephalosporins, and aztreonam, even if it is tested (in vitro) as susceptible. Associated resistance to aminoglycosides and trimethoprim-sulfamethoxazole, as well as high frequency of co-existence of fluoroquinolone resistance, creates problems. Beta-lactamase inhibitors such as clavulanate, sulbactam, and tazobactam \"in vitro\" inhibit most ESBLs, but the clinical effectiveness of beta-lactam/beta-lactamase inhibitor combinations cannot be relied on consistently for therapy. Cephamycins (cefoxitin and cefotetan) are not hydrolyzed by majority of ESBLs, but are hydrolyzed by associated AmpC-type β-lactamase. Also, β-lactam/β-lactamase inhibitor combinations may not be effective against organisms that produce AmpC-type β-lactamase. Sometimes these strains decrease the expression of outer membrane proteins, rendering them resistant to cephamycins. \"In vivo\" studies have yielded mixed results against ESBL-producing \"K. pneumoniae\". (Cefepime, a fourth-generation cephalosporin, has demonstrated \"in vitro\" stability in the presence of many ESBL/AmpC strains.) Currently, carbapenems are, in general, regarded as the preferred agent for treatment of infections due to ESBL-producing organisms. Carbapenems are resistant to ESBL-mediated hydrolysis and exhibit excellent \"in vitro\" activity against strains of Enterobacteriaceae expressing ESBLs.\n\nStrains producing only ESBLs are susceptible to cephamycins and carbapenems \"in vitro\" and show little if any inoculum effect with these agents.\n\nFor organisms producing TEM and SHV type ESBLs, apparent \"in vitro\" sensitivity to cefepime and to piperacillin/tazobactam is common, but both drugs show an inoculum effect, with diminished susceptibility as the size of the inoculum is increased from 10 to 10 organisms.\n\nStrains with some CTX-M–type and OXA-type ESBLs are resistant to cefepime on testing, despite the use of a standard inoculum.\n\nAlthough the inhibitor-resistant TEM variants are resistant to inhibition by clavulanic acid and sulbactam, thereby showing clinical resistance to the beta-lactam—beta lactamase inhibitor combinations of amoxicillin-clavulanate (Co-amoxiclav), ticarcillin-clavulanate, and ampicillin/sulbactam, they remain susceptible to inhibition by tazobactam and subsequently the combination of piperacillin/tazobactam.\n\nAmpC-producing strains are typically resistant to oxyimino-beta lactams and to cephamycins and are susceptible to carbapenems; however, diminished porin expression can make such a strain carbapenem-resistant as well.\n\nStrains with IMP-, VIM-, and OXA-type carbapenemases usually remain susceptible. Resistance to non-beta-lactam antibiotics is common in strains making any of these enzymes, such that alternative options for non-beta-lactam therapy need to be determined by direct susceptibility testing. Resistance to fluoroquinolones and aminoglycosides is especially high.\n\nFor infections caused by ESBL-producing \"Escherichia coli\" or \"Klebsiella\" species, treatment with imipenem or meropenem has been associated with the best outcomes in terms of survival and bacteriologic clearance. Cefepime and piperacillin/tazobactam have been less successful. Ceftriaxone, cefotaxime, and ceftazidime have failed even more often, despite the organism's susceptibility to the antibiotic \"in vitro\". Several reports have documented failure of cephamycin therapy as a result of resistance due to porin loss. Some patients have responded to aminoglycoside or quinolone therapy, but, in a recent comparison of ciprofloxacin and imipenem for bacteremia involving an ESBL-producing \"K. pneumoniae\", imipenem produced the better outcome\n\nThere have been few clinical studies to define the optimal therapy for infections caused by ESBL producing \"Pseudomonas aeruginosa\" strains.\n\nBeta-lactamase enzymatic activity can be detected using nitrocefin, a chromogenic cephalosporin substrate which changes color from yellow to red upon beta-lactamase mediated hydrolysis.\n\nBeta-lactamases are ancient bacterial enzymes. The class B beta-lactamases (the metallo-beta-lactamases) are divided into three subclasses: B1, B2 and B3. Subclasses B1 and B2 are theorized to have evolved about one billion years ago and subclass B3s is theorized to have evolved before the divergence of the Gram-positive and Gram-negative eubacteria about two billion years ago.\n\nThe other three groups are serine enzymes that show little homology to each other. Structural studies have shown that groups A and D are sister taxa and that group C diverged before A and D. These serine-based enzymes, like the group B betalactamases, are of ancient origin and are theorized to have evolved about two billion years ago.\n\nThe OXA group (in class D) in particular is theorized to have evolved on chromosomes and moved to plasmids on at least two separate occasions.\n\nThe \"β\" (beta) refers to the nitrogen's position on the second carbon in the ring. \"Lactam\" is a portmanteau of \"lactone\" (from the Latin \"lactis\", \"milk\", since lactic acid was isolated from soured milk) and \"amide\". The suffix \"-ase\", indicating an enzyme, is derived from \"diastase\" (from the Greek \"diastasis\", \"separation\"), the first enzyme discovered in 1833 by Payen and Persoz.\n\n\n"}
{"id": "4611", "url": "https://en.wikipedia.org/wiki?curid=4611", "title": "Burhanuddin Rabbani", "text": "Burhanuddin Rabbani\n\nBurhānuddīn Rabbānī (Persian/Pashto: ; b. 20 September 1940, d. 20 September 2011) was an Afghan politician who served as President of the Islamic State of Afghanistan from 1992 to 1996 (\"de jure\" until 2001). After the Taliban government was toppled during Operation Enduring Freedom, Rabbani returned to Kabul and served as President from November to December 20, 2001, when Hamid Karzai was chosen at the Bonn International Conference on Afghanistan. Rabbani was also the leader of Jamiat-e Islami Afghanistan (Islamic Society of Afghanistan).\n\nHe was one of the earliest founders and movement leaders of the Mujahideen in the early 1970s, right before the Soviet–Afghan War. He served as the political head of the Northern Alliance (or United Front), an alliance of various political groups who fought against the Taliban regime in Afghanistan. His government was recognized by many countries, as well as the United Nations. He later became head of Afghanistan National Front (known in the media as United National Front), the largest political opposition to Hamid Karzai's government. On 20 September 2011, Rabbani was assassinated by a suicide bomber entering his home in Kabul. As suggested by the Afghan parliament, Afghanistan's President Hamid Karzai gave him the title of \"Martyr of Peace\". His son Salahuddin Rabbani was chosen in April 2012 to lead efforts to forge peace in Afghanistan with the Taliban.\n\nRabbani, son of Muhammed Yousuf, was born in the northern province of Badakhshan. He was a Persian-speaking ethnic Tajik. After finishing school in his native province, he went to Darul-uloom-e-Sharia (Abu-Hanifa), a religious school in Kabul. When he graduated from Abu-Hanifa, he attended Kabul University to study Islamic Law and Theology, graduating in 1963.\n\nSoon after his graduation in 1963, he was hired as a professor at Kabul University. In order to enhance himself, Rabbani went to Egypt in 1966, and he entered the Al-Azhar University in Cairo where he developed close ties to the Muslim Brotherhood leadership. In two years, he received his masters degree in Islamic Philosophy. Rabbani was one of the first Afghans to translate the works of Sayyid Qutb into Persian. Later he returned to Egypt to complete his PhD in Islamic philosophy and his thesis was titled \"The Philosophy and Teachings of Abd al-Rahman Muhammad Jami.\" In 2004 he received Afghanistan's highest academic and scientific title \"Academician\" from the Academy of Sciences of Afghanistan.\n\nRabbani returned to Afghanistan in 1968, where the High Council of Jamiat-e Islami gave him the duty of organizing the University students. Due to his knowledge, reputation, and active support for the cause of Islam, in 1972, a 15-member council selected him as head of Jamiat-e Islami of Afghanistan; the founder of Jamiat-e Islami of Afghanistan, Ghulam M. Niyazi was also present. Jamiat-e Islami was primarily composed of Tajiks.\n\nIn the spring of 1974, the police came to Kabul University to arrest Rabbani for his pro-Islamic stance, but with the help of his students the police were unable to capture him, and he managed to escape to the countryside. In Pakistan, Rabbani gathered important people and established the party. Sayed Noorullah Emad, who was then a young Muslim in the University of Kabul, became the General Secretary of the party and, later, its deputy chief.\n\nWhen the Soviets intervened in 1979, Rabbani helped lead Jamiat-e Islami in resistance to the People's Democratic Party of Afghanistan regime. Rabbani's forces were the first Mujahideen elements to enter Kabul in 1992 when the PDPA government fell from power. He took over as President from 1992 in accordance to the Peshawar Accords. Rabbani was the second ever ethnic Tajik leader of Afghanistan after Habibullah Kalakani in 1929 (and possibly including Babrak Karmal, whose ethnicity was disputed). He ruled until the Taliban's conquest of Kabul in 1996. For the next five years, he and the Northern Alliance were busy fighting the Taliban until the 2001 US-led Operation Enduring Freedom in which the Taliban government was toppled. Rabbani was head of Afghanistan's High Peace Council, which had been formed in 2010 to initiate peace talks with the Taliban and other groups in the insurgency, until his death.\n\nRabbani was killed in a suicide bombing at his home in Kabul on 20 September 2011, his 71st birthday. Two men posing as Taliban representatives approached him to offer a hug and detonated their explosives. At least one of them had hidden the explosives in his turban. The suicide bomber claimed to be a Taliban commander and said he wanted to \"discuss peace\" with Rabbani. Four other members of Afghanistan’s High Peace Council were also killed in the blast.\n\nAfghan officials blamed the Quetta Shura, which is the leadership of the Afghan Taliban hiding in the affluent Satellite Town of Quetta in Pakistan. The Pakistani government confirmed that Rabbani's assassination was linked to Afghan refugees in Pakistan. A senior Pakistani official stated that over 90% of terrorist attacks in Pakistan are traced back to Afghan elements and that their presence in the country was \"an important issue for Pakistan\" and \"a problem for Afghanistan\". Pakistani foreign minister Hina Rabbani Khar said that \"We are not responsible if Afghan refugees crossed the border and entered Kabul, stayed in a guest house and attacked Professor Rabbani\".\n\nIn 2011, just days before he died, Rabbani was trying to persuade Islamic scholars to issue a religious edict banning suicide bombings. The former president's 29-year-old daughter said in an interview that her father died shortly after he spoke at a conference on \"Islamic Awakening\" in Tehran. \"Right before he was assassinated, he talked about the suicide bombing issue,\" Fatima Rabbani told Reuters. \"He called on all Islamic scholars in the conference to release a fatwa\" against the tactic.\n\nUnited States President Barack Obama and several NATO military leaders condemned the assassination. Japan also offered its condolences at the Sixty-sixth session of the United Nations General Assembly. Afghan President Hamid Karzai cut short his trip for the General debate of the sixty-sixth session of the United Nations General Assembly following his assassination. Rabbani's son Salahuddin then took over chairmanship of the High Peace Council from his father.\n\n\n"}
{"id": "4614", "url": "https://en.wikipedia.org/wiki?curid=4614", "title": "Boeing 747", "text": "Boeing 747\n\nThe Boeing 747 is an American wide-body commercial jet airliner and cargo aircraft, often referred to by its original nickname, \"Jumbo Jet\". Its distinctive hump upper deck along the forward part of the aircraft has made it one of the most recognizable aircraft, and it was the first wide-body airplane produced. Manufactured by Boeing's Commercial Airplane unit in the United States, the 747 was originally envisioned to have 150 percent greater capacity than the Boeing 707, a common large commercial aircraft of the 1960s. First flown commercially in 1970, the 747 held the passenger capacity record for 37 years.\n\nThe quadjet 747 uses a double-deck configuration for part of its length and is available in passenger, freighter and other versions. Boeing designed the 747's hump-like upper deck to serve as a first–class lounge or extra seating, and to allow the aircraft to be easily converted to a cargo carrier by removing seats and installing a front cargo door. Boeing expected supersonic airliners—the development of which was announced in the early 1960s—to render the 747 and other subsonic airliners obsolete, while the demand for subsonic cargo aircraft would remain robust well into the future. Though the 747 was expected to become obsolete after 400 were sold, it exceeded critics' expectations with production surpassing 1,000 in 1993. By July 2018, 1,546 aircraft had been built, with 22 of the 747-8 variants remaining on order. , the 747 has been involved in 60 hull losses, resulting in fatalities.\n\nThe 747-400, the most common variant in service, has a high-subsonic cruise speed of Mach 0.85–0.855 (up to ) with an intercontinental range of 7,260 nautical miles (8,350 statute miles or 13,450 km). The 747-400 can accommodate 416 passengers in a typical three-class layout, 524 passengers in a typical two-class layout, or 660 passengers in a high–density one-class configuration. The newest version of the aircraft, the 747-8, is in production and received certification in 2011. Deliveries of the 747-8F freighter version began in October 2011; deliveries of the 747-8I passenger version began in May 2012.\n\nIn 1963, the United States Air Force started a series of study projects on a very large strategic transport aircraft. Although the C-141 Starlifter was being introduced, they believed that a much larger and more capable aircraft was needed, especially the capability to carry outsized cargo that would not fit in any existing aircraft. These studies led to initial requirements for the CX-Heavy Logistics System (CX-HLS) in March 1964 for an aircraft with a load capacity of and a speed of Mach 0.75 (), and an unrefueled range of with a payload of . The payload bay had to be wide by high and long with access through doors at the front and rear.\n\nFeaturing only four engines, the design also required new engine designs with greatly increased power and better fuel economy. In May 1964, airframe proposals arrived from Boeing, Douglas, General Dynamics, Lockheed, and Martin Marietta; engine proposals were submitted by General Electric, Curtiss-Wright, and Pratt & Whitney. After a downselect, Boeing, Douglas, and Lockheed were given additional study contracts for the airframe, along with General Electric and Pratt & Whitney for the engines.\n\nAll three of the airframe proposals shared a number of features. As the CX-HLS needed to be able to be loaded from the front, a door had to be included where the cockpit usually was. All of the companies solved this problem by moving the cockpit above the cargo area; Douglas had a small \"pod\" just forward and above the wing, Lockheed used a long \"spine\" running the length of the aircraft with the wing spar passing through it, while Boeing blended the two, with a longer pod that ran from just behind the nose to just behind the wing. In 1965 Lockheed's aircraft design and General Electric's engine design were selected for the new C-5 Galaxy transport, which was the largest military aircraft in the world at the time. The nose door and raised cockpit concepts would be carried over to the design of the 747.\n\nThe 747 was conceived while air travel was increasing in the 1960s. The era of commercial jet transportation, led by the enormous popularity of the Boeing 707 and Douglas DC-8, had revolutionized long-distance travel. Even before it lost the CX-HLS contract, Boeing was asked by Juan Trippe, president of Pan American World Airways (Pan Am), one of their most important airline customers, to build a passenger aircraft more than twice the size of the 707. During this time, airport congestion, worsened by increasing numbers of passengers carried on relatively small aircraft, became a problem that Trippe thought could be addressed by a larger new aircraft.\n\nIn 1965, Joe Sutter was transferred from Boeing's 737 development team to manage the design studies for the new airliner, already assigned the model number 747. Sutter initiated a design study with Pan Am and other airlines, to better understand their requirements. At the time, it was widely thought that the 747 would eventually be superseded by supersonic transport aircraft. Boeing responded by designing the 747 so that it could be adapted easily to carry freight and remain in production even if sales of the passenger version declined. In the freighter role, the clear need was to support the containerized shipping methodologies that were being widely introduced at about the same time. Standard shipping containers are square at the front (slightly higher due to attachment points) and available in lengths. This meant that it would be possible to support a 2-wide 2-high stack of containers two or three ranks deep with a fuselage size similar to the earlier CX-HLS project.\nIn April 1966, Pan Am ordered 25 747-100 aircraft for US$525 million. During the ceremonial 747 contract-signing banquet in Seattle on Boeing's 50th Anniversary, Juan Trippe predicted that the 747 would be \"... a great weapon for peace, competing with intercontinental missiles for mankind's destiny\". As launch customer, and because of its early involvement before placing a formal order, Pan Am was able to influence the design and development of the 747 to an extent unmatched by a single airline before or since.\n\nUltimately, the high-winged CX-HLS Boeing design was not used for the 747, although technologies developed for their bid had an influence. The original design included a full-length double-deck fuselage with eight-across seating and two aisles on the lower deck and seven-across seating and two aisles on the upper deck. However, concern over evacuation routes and limited cargo-carrying capability caused this idea to be scrapped in early 1966 in favor of a wider single deck design. The cockpit was, therefore, placed on a shortened upper deck so that a freight-loading door could be included in the nose cone; this design feature produced the 747's distinctive \"bulge\". In early models it was not clear what to do with the small space in the pod behind the cockpit, and this was initially specified as a \"lounge\" area with no permanent seating. (A different configuration that had been considered in order to keep the flight deck out of the way for freight loading had the pilots below the passengers, and was dubbed the \"anteater\".)\nOne of the principal technologies that enabled an aircraft as large as the 747 to be drawn up was the high-bypass turbofan engine. The engine technology was thought to be capable of delivering double the power of the earlier turbojets while consuming one–third less fuel. General Electric had pioneered the concept but was committed to developing the engine for the C-5 Galaxy and did not enter the commercial market until later. Pratt & Whitney was also working on the same principle and, by late 1966, Boeing, Pan Am and Pratt & Whitney agreed to develop a new engine, designated the JT9D to power the 747.\n\nThe project was designed with a new methodology called fault tree analysis, which allowed the effects of a failure of a single part to be studied to determine its impact on other systems. To address concerns about safety and flyability, the 747's design included structural redundancy, redundant hydraulic systems, quadruple main landing gear and dual control surfaces. Additionally, some of the most advanced high-lift devices used in the industry were included in the new design, to allow it to operate from existing airports. These included slats running almost the entire length of the wing, as well as complex three-part slotted flaps along the trailing edge of the wing. The wing's complex three-part flaps increase wing area by 21 percent and lift by 90 percent when fully deployed compared to their non-deployed configuration.\n\nBoeing agreed to deliver the first 747 to Pan Am by the end of 1969. The delivery date left 28 months to design the aircraft, which was two-thirds of the normal time. The schedule was so fast-paced that the people who worked on it were given the nickname \"The Incredibles\". Developing the aircraft was such a technical and financial challenge that management was said to have \"bet the company\" when it started the project.\n\nAs Boeing did not have a plant large enough to assemble the giant airliner, they chose to build a new plant. The company considered locations in about 50 cities, and eventually decided to build the new plant some north of Seattle on a site adjoining a military base at Paine Field near Everett, Washington. It bought the site in June 1966.\n\nDeveloping the 747 had been a major challenge, and building its assembly plant was also a huge undertaking. Boeing president William M. Allen asked Malcolm T. Stamper, then head of the company's turbine division, to oversee construction of the Everett factory and to start production of the 747. To level the site, more than of earth had to be moved. Time was so short that the 747's full-scale mock-up was built before the factory roof above it was finished. The plant is the largest building by volume ever built, and has been substantially expanded several times to permit construction of other models of Boeing wide-body commercial jets.\n\nBefore the first 747 was fully assembled, testing began on many components and systems. One important test involved the evacuation of 560 volunteers from a cabin mock-up via the aircraft's emergency chutes. The first full-scale evacuation took two and a half minutes instead of the maximum of 90 seconds mandated by the Federal Aviation Administration (FAA), and several volunteers were injured. Subsequent test evacuations achieved the 90-second goal but caused more injuries. Most problematic was evacuation from the aircraft's upper deck; instead of using a conventional slide, volunteer passengers escaped by using a harness attached to a reel. Tests also involved taxiing such a large aircraft. Boeing built an unusual training device known as \"Waddell's Wagon\" (named for a 747 test pilot, Jack Waddell) that consisted of a mock-up cockpit mounted on the roof of a truck. While the first 747s were still being built, the device allowed pilots to practice taxi maneuvers from a high upper-deck position.\n\nOn September 30, 1968, the first 747 was rolled out of the Everett assembly building before the world's press and representatives of the 26 airlines that had ordered the airliner. Over the following months, preparations were made for the first flight, which took place on February 9, 1969, with test pilots Jack Waddell and Brien Wygle at the controls and Jess Wallick at the flight engineer's station. Despite a minor problem with one of the flaps, the flight confirmed that the 747 handled extremely well. The 747 was found to be largely immune to \"Dutch roll\", a phenomenon that had been a major hazard to the early swept-wing jets.\nDuring later stages of the flight test program, flutter testing showed that the wings suffered oscillation under certain conditions. This difficulty was partly solved by reducing the stiffness of some wing components. However, a particularly severe high-speed flutter problem was solved only by inserting depleted uranium counterweights as ballast in the outboard engine nacelles of the early 747s. This measure caused anxiety when these aircraft crashed, for example El Al Flight 1862 at Amsterdam in 1992 with of uranium in the tailplane (horizontal stabilizer).\n\nThe flight test program was hampered by problems with the 747's JT9D engines. Difficulties included engine stalls caused by rapid throttle movements and distortion of the turbine casings after a short period of service. The problems delayed 747 deliveries for several months; up to 20 aircraft at the Everett plant were stranded while awaiting engine installation. The program was further delayed when one of the five test aircraft suffered serious damage during a landing attempt at Renton Municipal Airport, site of the company's Renton factory. On December 13, 1969 a test aircraft was being taken to have test equipment removed and a cabin installed when pilot Ralph C. Cokely undershot the airport's short runway. The 747's right, outer landing gear was torn off and two engine nacelles were damaged. However, these difficulties did not prevent Boeing from taking a test aircraft to the 28th Paris Air Show in mid-1969, where it was displayed to the public for the first time. The 747 received its FAA airworthiness certificate in December 1969, clearing it for introduction into service.\n\nThe huge cost of developing the 747 and building the Everett factory meant that Boeing had to borrow heavily from a banking syndicate. During the final months before delivery of the first aircraft, the company had to repeatedly request additional funding to complete the project. Had this been refused, Boeing's survival would have been threatened. The firm's debt exceeded $2 billion, with the $1.2 billion owed to the banks setting a record for all companies. Allen later said, \"It was really too large a project for us.\" Ultimately, the gamble succeeded, and Boeing held a monopoly in very large passenger aircraft production for many years.\n\nOn January 15, 1970, First Lady of the United States Pat Nixon christened Pan Am's first 747, at Dulles International Airport (later Washington Dulles International Airport) in the presence of Pan Am chairman Najeeb Halaby. Instead of champagne, red, white, and blue water was sprayed on the aircraft. The 747 entered service on January 22, 1970, on Pan Am's New York–London route; the flight had been planned for the evening of January 21, but engine overheating made the original aircraft unusable. Finding a substitute delayed the flight by more than six hours to the following day when Clipper Victor was used.\nThe 747 enjoyed a fairly smooth introduction into service, overcoming concerns that some airports would not be able to accommodate an aircraft that large. Although technical problems occurred, they were relatively minor and quickly solved. After the aircraft's introduction with Pan Am, other airlines that had bought the 747 to stay competitive began to put their own 747s into service. Boeing estimated that half of the early 747 sales were to airlines desiring the aircraft's long range rather than its payload capacity. While the 747 had the lowest potential operating cost per seat, this could only be achieved when the aircraft was fully loaded; costs per seat increased rapidly as occupancy declined. A moderately loaded 747, one with only 70 percent of its seats occupied, used more than 95 percent of the fuel needed by a fully occupied 747. Nonetheless, many flag-carriers purchased the 747 due to its prestige \"even if it made no sense economically\" to operate. During the 1970s and 1980s, there was often over 30 regularly scheduled 747s at John F. Kennedy International Airport.\n\nThe recession of 1969-1970 greatly affected Boeing. For the year and a half after September 1970 it only sold two 747s in the world, and did not sell any to an American carrier for almost three years. When economic problems in the US and other countries after the 1973 oil crisis led to reduced passenger traffic, several airlines found they did not have enough passengers to fly the 747 economically, and they replaced them with the smaller and recently introduced McDonnell Douglas DC-10 and Lockheed L-1011 TriStar trijet wide bodies (and later the 767 and A300/A310 twinjets). Having tried replacing coach seats on its 747s with piano bars in an attempt to attract more customers, American Airlines eventually relegated its 747s to cargo service and in 1983 exchanged them with Pan Am for smaller aircraft; Delta Air Lines also removed its 747s from service after several years. Later, Delta acquired 747s again in 2008 as part of its merger with Northwest Airlines, although it retired the 747-400 fleet in December 2017.\nInternational flights bypassing traditional hub airports and landing at smaller cities became more common throughout the 1980s, thus eroding the 747's original market. Many international carriers continued to use the 747 on Pacific routes. In Japan, 747s on domestic routes were configured to carry nearly the maximum passenger capacity.\n\nAfter the initial 747-100, Boeing developed the , a higher maximum takeoff weight (MTOW) variant, and the (Short Range), with higher passenger capacity. Increased maximum takeoff weight allows aircraft to carry more fuel and have longer range. The model followed in 1971, featuring more powerful engines and a higher MTOW. Passenger, freighter and combination passenger-freighter versions of the were produced. The shortened 747SP (special performance) with a longer range was also developed, and entered service in 1976.\n\nThe 747 line was further developed with the launch of the 747-300 in 1980. The 300 series resulted from Boeing studies to increase the seating capacity of the 747, during which modifications such as fuselage plugs and extending the upper deck over the entire length of the fuselage were rejected. The first 747-300, completed in 1983, included a stretched upper deck, increased cruise speed, and increased seating capacity. The -300 variant was previously designated 747SUD for stretched upper deck, then 747-200 SUD, followed by 747EUD, before the 747-300 designation was used. Passenger, short range and combination freighter-passenger versions of the 300 series were produced.\n\nIn 1985, development of the longer range 747-400 began. The variant had a new glass cockpit, which allowed for a cockpit crew of two instead of three, new engines, lighter construction materials, and a redesigned interior. Development cost soared, and production delays occurred as new technologies were incorporated at the request of airlines. Insufficient workforce experience and reliance on overtime contributed to early production problems on the 747-400. The -400 entered service in 1989.\n\nIn 1991, a record-breaking 1,087 passengers were airlifted aboard a 747 to Israel as part of Operation Solomon. The 747 remained the heaviest commercial aircraft in regular service until the debut of the Antonov An-124 Ruslan in 1982; variants of the 747-400 surpassed the An-124's weight in 2000. The Antonov An-225 \"Mriya\" cargo transport, which debuted in 1988, remains the world's largest aircraft by several measures (including the most accepted measures of maximum takeoff weight and length); one aircraft has been completed and is in service . The Hughes H-4 Hercules is the largest aircraft by wingspan, but completed a single flight.\n\nSince the arrival of the 747-400, several stretching schemes for the 747 have been proposed. Boeing announced the larger 747-500X and preliminary designs in 1996. The new variants would have cost more than US$5 billion to develop, and interest was not sufficient to launch the program. In 2000, Boeing offered the more modest 747X and 747X stretch derivatives as alternatives to the Airbus A3XX. However, the 747X family was unable to attract enough interest to enter production. A year later, Boeing switched from the 747X studies to pursue the Sonic Cruiser, and after the Sonic Cruiser program was put on hold, the 787 Dreamliner. Some of the ideas developed for the 747X were used on the 747-400ER, a longer range variant of the 747-400.\n\nAfter several variants were proposed but later abandoned, some industry observers became skeptical of new aircraft proposals from Boeing. However, in early 2004, Boeing announced tentative plans for the 747 Advanced that were eventually adopted. Similar in nature to the 747-X, the stretched 747 Advanced used technology from the 787 to modernize the design and its systems. The 747 remained the largest passenger airliner in service until the Airbus A380 began airline service in 2007.\n\nOn November 14, 2005, Boeing announced it was launching the 747 Advanced as the Boeing 747-8. The last 747-400s were completed in 2009. , most orders of the 747-8 have been for the freighter variant. On February 8, 2010, the 747-8 Freighter made its maiden flight. The first delivery of the 747-8 went to Cargolux in 2011. The 1,500th produced Boeing 747 was delivered in June 2014.\n\nIn January 2016, Boeing stated it was reducing 747-8 production to six a year beginning in September 2016, incurring a $569 million post-tax charge against its fourth-quarter 2015 profits. At the end of 2015, the company had 20 orders outstanding. On January 29, 2016, Boeing announced that it had begun the preliminary work on the modifications to a commercial 747-8 for the next Air Force One Presidential aircraft, expected to be operational by 2020.\n\nOn July 12, 2016, Boeing announced that it had finalized terms of acquisition with Volga-Dnepr Group for 20 747-8 freighters, valued at $7.58 billion at list prices. Four aircraft were delivered beginning in 2012. Volga-Dnepr Group is the parent of three major Russian air-freight carriers – Volga-Dnepr Airlines, AirBridgeCargo Airlines and Atran Airlines. The new 747-8 freighters will replace AirBridgeCargo's current 747-400 aircraft and expand the airline's fleet and will be acquired through a mix of direct purchases and leasing over the next six years, Boeing said.\n\nOn July 27, 2016, in its quarterly report to the Securities and Exchange Commission, Boeing discussed the potential termination of 747 production due to insufficient demand and market for the aircraft. With a firm order backlog of 21 aircraft and a production rate of six per year, program accounting has been reduced to 1,555 aircraft, and the 747 line could be closed in the third quarter of 2019. In October 2016, UPS Airlines ordered 14 -8Fs to add capacity, along with 14 options, which it took in February 2018 bringing the total ordered to 28 and increases the backlog to 25 – including some to refractory airlines – with deliveries scheduled through 2022.\n\nThe Boeing 747 is a large, wide-body (two-aisle) airliner with four wing-mounted engines. Its wings have a high sweep angle of 37.5 degrees for a fast, efficient cruise of Mach 0.84 to 0.88, depending on the variant. The sweep also reduces the wingspan, allowing the 747 to use existing hangars. Its seating capacity is over 366 with a 3–4–3 seat arrangement (a cross section of 3 seats, an aisle, 4 seats, another aisle, and 3 seats) in economy class and a 2–3–2 layout in first class on the main deck. The upper deck has a 3–3 seat arrangement in economy class and a 2–2 layout in first class.\nRaised above the main deck, the cockpit creates a hump. This raised cockpit allows front loading of cargo on freight variants. The upper deck behind the cockpit provides space for a lounge and/or extra seating. The \"stretched upper deck\" became available as an alternative on the 747-100B variant and later as standard beginning on the 747-300. The upper deck was stretched more on the 747-8. The 747 cockpit roof section also has an escape hatch from which crew can exit during the events of an emergency if they cannot do so through the cabin.\n\nThe 747's maximum takeoff weight ranges from 735,000 pounds (333,400 kg) for the -100 to 970,000 lb (439,985 kg) for the -8. Its range has increased from 5,300 nautical miles (6,100 mi, 9,800 km) on the -100 to 8,000 nmi (9,200 mi, 14,815 km) on the -8I.\n\nThe 747 has redundant structures along with four redundant hydraulic systems and four main landing gears each with four wheels; these provide a good spread of support on the ground and safety in case of tire blow-outs. The main gear are redundant so that landing can be performed on two opposing landing gears if the others are not functioning properly. The 747 also has split control surfaces and was designed with sophisticated triple-slotted flaps that minimize landing speeds and allow the 747 to use standard-length runways. \n\nFor transportation of spare engines, the 747 can accommodate a non-functioning fifth-pod engine under the aircraft's port wing between the inner functioning engine and the fuselage. This fifth engine mount point is also used by Virgin Orbit's LauncherOne program. Virgin Orbit's 747-400, dubbed Cosmic Girl, carries the orbital-class rocket to cruise altitude, where the rocket is deployed and then carries its small satellite payload the rest of the way to space.\n\nThe 747-100 was the original variant launched in 1966. The 747-200 soon followed, with its launch in 1968. The 747-300 was launched in 1980 and was followed by the 747-400 in 1985. Ultimately, the 747-8 was announced in 2005. Several versions of each variant have been produced, and many of the early variants were in production simultaneously. The International Civil Aviation Organization (ICAO) classifies variants using a shortened code formed by combining the model number and the variant designator (e.g. \"B741\" for all -100 models).\n\nThe first 747-100s were built with six upper deck windows (three per side) to accommodate upstairs lounge areas. Later, as airlines began to use the upper deck for premium passenger seating instead of lounge space, Boeing offered a ten-window upper deck as an option. Some early -100s were retrofitted with the new configuration. The -100 was equipped with Pratt & Whitney JT9D-3A engines. No freighter version of this model was developed, but many 747-100s were converted into freighters. A total of 168 747-100s were built; 167 were delivered to customers, while Boeing kept the prototype, \"City of Everett\".\n\nResponding to requests from Japanese airlines for a high-capacity aircraft to serve domestic routes between major cities, Boeing developed the 747SR as a short-range version of the 747-100 with lower fuel capacity and greater payload capability. With increased economy class seating, up to 498 passengers could be carried in early versions and up to 550 in later models. The 747SR had an economic design life objective of 52,000 flights during 20 years of operation, compared to 24,600 flights in 20 years for the standard 747. The initial 747SR model, the -100SR, had a strengthened body structure and landing gear to accommodate the added stress accumulated from a greater number of takeoffs and landings. Extra structural support was built into the wings, fuselage, and the landing gear along with a 20% reduction in fuel capacity.\nThe initial order for the -100SR – four aircraft for Japan Air Lines (JAL, later Japan Airlines) – was announced on October 30, 1972; rollout occurred on August 3, 1973, and the first flight took place on August 31, 1973. The type was certified by the FAA on September 26, 1973, with the first delivery on the same day. The -100SR entered service with JAL, the type's sole customer, on October 7, 1973, and typically operated flights within Japan. Seven -100SRs were built between 1973 and 1975, each with a MTOW and Pratt & Whitney JT9D-7A engines derated to of thrust.\n\nFollowing the -100SR, Boeing produced the -100BSR, a 747SR variant with increased takeoff weight capability. Debuting in 1978, the -100BSR also incorporated structural modifications for a high cycle-to-flying hour ratio; a related standard -100B model debuted in 1979. The -100BSR first flew on November 3, 1978, with first delivery to All Nippon Airways (ANA) on December 21, 1978. A total of twenty -100BSRs were produced for ANA and JAL. The -100BSR had a 600,000 lb MTOW and was powered by the same JT9D-7A or General Electric CF6-45 engines used on the -100SR. ANA operated this variant on domestic Japanese routes with 455 or 456 seats until retiring its last aircraft in March 2006.\n\nIn 1986, two -100BSR SUD models, featuring the stretched upper deck (SUD) of the -300, were produced for JAL. The type's maiden flight occurred on February 26, 1986, with FAA certification and first delivery on March 24, 1986. JAL operated the -100BSR SUD with 563 seats on domestic routes until their retirement in the third quarter of 2006. While only two -100BSR SUDs were produced, in theory, standard -100Bs can be modified to the SUD certification. Overall, twenty-nine 747SRs were built, consisting of seven -100SRs, twenty -100BSRs, and two -100BSR SUDs.\n\nThe 747-100B model was developed from the -100SR, using its stronger airframe and landing gear design. The type had an increased fuel capacity of , allowing for a range with a typical 452-passenger payload, and an increased MTOW of was offered. The first -100B order, one aircraft for Iran Air, was announced on June 1, 1978. This aircraft first flew on June 20, 1979, received FAA certification on August 1, 1979, and was delivered the next day. Nine -100Bs were built, one for Iran Air and eight for Saudi Arabian Airlines. Unlike the original -100, the -100B was offered with Pratt & Whitney JT9D-7A, General Electric CF6-50, or Rolls-Royce RB211-524 engines. However, only RB211-524 (Saudia) and JT9D-7A (Iran Air) engines were ordered. The last 747-100B, EP-IAM was retired by Iran Air in 2014, the last commercial operator of the 747-100 and -100B.\n\nThe development of the 747SP stemmed from a joint request between Pan American World Airways and Iran Air, who were looking for a high-capacity airliner with enough range to cover Pan Am's New York–Middle Eastern routes and Iran Air's planned Tehran–New York route. The Tehran–New York route, when launched, was the longest non-stop commercial flight in the world. The 747SP is shorter than the 747-100. Fuselage sections were eliminated fore and aft of the wing, and the center section of the fuselage was redesigned to fit mating fuselage sections. The SP's flaps used a simplified single-slotted configuration. The 747SP, compared to earlier variants, had a tapering of the aft upper fuselage into the empennage, a double-hinged rudder, and longer vertical and horizontal stabilizers. Power was provided by Pratt & Whitney JT9D-7(A/F/J/FW) or Rolls-Royce RB211-524 engines.\n\nThe 747SP was granted a supplemental certificate on February 4, 1976 and entered service with launch customers Pan Am and Iran Air that same year. The aircraft was chosen by airlines wishing to serve major airports with short runways. A total of 45 747SPs were built, with the 44th 747SP delivered on August 30, 1982. In 1987, Boeing re-opened the 747SP production line after five years to build one last 747SP for an order by the United Arab Emirates government. In addition to airline use, one 747SP was modified for the NASA/German Aerospace Center SOFIA experiment. Iran Air is the last civil operator of the type; its final 747-SP (EP-IAC) was to be retired in June 2016.\n\nWhile the 747-100 powered by Pratt & Whitney JT9D-3A engines offered enough payload and range for medium-haul operations, it was marginal for long-haul route sectors. The demand for longer range aircraft with increased payload quickly led to the improved -200, which featured more powerful engines, increased MTOW, and greater range than the -100. A few early -200s retained the three-window configuration of the -100 on the upper deck, but most were built with a ten-window configuration on each side. The 747-200 was produced in passenger (-200B), freighter (-200F), convertible (-200C), and combi (-200M) versions.\n\nThe 747-200B was the basic passenger version, with increased fuel capacity and more powerful engines; it entered service in February 1971. In its first three years of production, the -200 was equipped with Pratt & Whitney JT9D-7 engines (initially the only engine available). Range with a full passenger load started at over and increased to with later engines. Most -200Bs had an internally stretched upper deck, allowing for up to 16 passenger seats. The freighter model, the 747-200F, could be fitted with or without a side cargo door, and had a capacity of 105 tons (95.3 tonnes) and an MTOW of up to 833,000 lb (378,000 kg). It entered service in 1972 with Lufthansa. The convertible version, the 747-200C, could be converted between a passenger and a freighter or used in mixed configurations, and featured removable seats and a nose cargo door. The -200C could also be fitted with an optional side cargo door on the main deck.\nThe combi model, the 747-200M, could carry freight in the rear section of the main deck via a side cargo door. A removable partition on the main deck separated the cargo area at the rear from the passengers at the front. The -200M could carry up to 238 passengers in a three-class configuration with cargo carried on the main deck. The model was also known as the 747-200 Combi. As on the -100, a stretched upper deck (SUD) modification was later offered. A total of 10 converted 747-200s were operated by KLM. Union de Transports Aériens (UTA) also had two aircraft converted.\n\nAfter launching the -200 with Pratt & Whitney JT9D-7 engines, on August 1, 1972 Boeing announced that it had reached an agreement with General Electric to certify the 747 with CF6-50 series engines to increase the aircraft's market potential. Rolls-Royce followed 747 engine production with a launch order from British Airways for four aircraft. The option of RB211-524B engines was announced on June 17, 1975. The -200 was the first 747 to provide a choice of powerplant from the three major engine manufacturers.\n\nA total of 393 of the 747-200 versions had been built when production ended in 1991. Of these, 225 were -200B, 73 were -200F, 13 were -200C, 78 were -200M, and 4 were military. Many 747-200s remained in operation, although most large carriers have retired them from their fleets and sold them to smaller operators as of the early 2000s. Large carriers have sped up fleet retirement following the September 11 attacks and the subsequent drop in demand for air travel, scrapping some or turning others into freighters. Iran Air retired the last passenger 747-200 in May 2016, 36 years after it was delivered. , eight 747-200s remain in service as freighters.\n\nThe 747-300 features a upper deck than the -200. The stretched upper deck has two emergency exit doors and is the most visible difference between the -300 and previous models. Before being made standard on the 747-300, the stretched upper deck was previously offered as a retrofit, and appeared on two Japanese 747-100SR aircraft. The 747-300 introduced a new straight stairway to the upper deck, instead of a spiral staircase on earlier variants, which creates room above and below for more seats. Minor aerodynamic changes allowed the -300's cruise speed to reach Mach 0.85 compared with Mach 0.84 on the -200 and -100 models, while retaining the same takeoff weight. The -300 could be equipped with the same Pratt & Whitney and Rolls-Royce powerplants as on the -200, as well as updated General Electric CF6-80C2B1 engines.\n\nSwissair placed the first order for the 747-300 on June 11, 1980. The variant revived the 747-300 designation, which had been previously used on a design study that did not reach production. The 747-300 first flew on October 5, 1982, and the type's first delivery went to Swissair on March 23, 1983. Besides the passenger model, two other versions (-300M, -300SR) were produced. The 747-300M features cargo capacity on the rear portion of the main deck, similar to the -200M, but with the stretched upper deck it can carry more passengers. The 747-300SR, a short range, high-capacity domestic model, was produced for Japanese markets with a maximum seating for 584. No production freighter version of the 747-300 was built, but Boeing began modifications of used passenger -300 models into freighters in 2000.\n\nA total of 81 747-300 series aircraft were delivered, 56 for passenger use, 21 -300M and 4 -300SR versions. In 1985, just two years after the -300 entered service, the type was superseded by the announcement of the more advanced 747-400. The last 747-300 was delivered in September 1990 to Sabena. While some -300 customers continued operating the type, several large carriers replaced their 747-300s with 747-400s. Air France, Air India, Pakistan International Airlines, and Qantas were some of the last major carriers to operate the 747-300. On December 29, 2008, Qantas flew its last scheduled 747-300 service, operating from Melbourne to Los Angeles via Auckland. In July 2015, Pakistan International Airlines retired their final 747-300 after 30 years of service. , only five 747-300s remain in commercial service, with Max Air (3), Mahan Air (1) and TransAVIAexport Airlines (1).\n\nThe 747-400 is an improved model with increased range. It has wingtip extensions of and winglets of , which improve the type's fuel efficiency by four percent compared to previous 747 versions. The 747-400 introduced a new glass cockpit designed for a flight crew of two instead of three, with a reduction in the number of dials, gauges and knobs from 971 to 365 through the use of electronics. The type also features tail fuel tanks, revised engines, and a new interior. The longer range has been used by some airlines to bypass traditional fuel stops, such as Anchorage. Powerplants include the Pratt & Whitney PW4062, General Electric CF6-80C2, and Rolls-Royce RB211-524. As a result of the Boeing 767 development overlapping with the 747-400's development, both aircraft can use the same three powerplants and are even interchangeable between the two aircraft models.\n\nThe was offered in passenger (-400), freighter (-400F), combi (-400M), domestic (-400D), extended range passenger (-400ER), and extended range freighter (-400ERF) versions. Passenger versions retain the same upper deck as the , while the freighter version does not have an extended upper deck. The 747-400D was built for short-range operations with maximum seating for 624. Winglets were not included, but they can be retrofitted. Cruising speed is up to Mach 0.855 on different versions of the 747-400.\nThe passenger version first entered service in February 1989 with launch customer Northwest Airlines on the Minneapolis to Phoenix route. The combi version entered service in September 1989 with KLM, while the freighter version entered service in November 1993 with Cargolux. The 747-400ERF entered service with Air France in October 2002, while the 747-400ER entered service with Qantas, its sole customer, in November 2002. In January 2004, Boeing and Cathay Pacific launched the Boeing 747-400 Special Freighter program, later referred to as the Boeing Converted Freighter (BCF), to modify passenger 747-400s for cargo use. The first 747-400BCF was redelivered in December 2005.\n\nIn March 2007, Boeing announced that it had no plans to produce further passenger versions of the -400. However, orders for 36 -400F and -400ERF freighters were already in place at the time of the announcement. The last passenger version of the 747-400 was delivered in April 2005 to China Airlines. Some of the last built 747-400s were delivered with Dreamliner livery along with the modern Signature interior from the Boeing 777. A total of 694 of the 747-400 series aircraft were delivered. At various times, the largest 747-400 operator has included Singapore Airlines, Japan Airlines, and British Airways with 36 . , 339 747-400s remain in service.\n\nThe 747-400 Dreamlifter (originally called the 747 Large Cargo Freighter or LCF) is a Boeing-designed modification of existing 747-400s to a larger configuration to ferry 787 Dreamliner sub-assemblies. Evergreen Aviation Technologies Corporation of Taiwan was contracted to complete modifications of 747-400s into Dreamlifters in Taoyuan. The aircraft flew for the first time on September 9, 2006 in a test flight. Modification of four aircraft was completed by February 2010. The Dreamlifters have been placed into service transporting sub-assemblies for the 787 program to the Boeing plant in Everett, Washington, for final assembly. The aircraft is certified to carry only essential crew and not passengers.\n\nBoeing announced a new 747 variant, the 747-8, on November 14, 2005. Referred to as the 747 Advanced prior to its launch, the 747-8 uses the same engine and cockpit technology as the 787, hence the use of the \"8\". The variant is designed to be quieter, more economical, and more environmentally friendly. The 747-8's fuselage is lengthened from 232 to 251 feet (70.8 to 76.4 m), marking the first stretch variant of the aircraft. Power is supplied by General Electric GEnx-2B67 engines.\nThe 747-8 Freighter, or 747-8F, is derived from the 747-400ERF. The variant has 16% more payload capacity than its predecessor, allowing it to carry seven more standard air cargo containers, with a maximum payload capacity of 154 tons (140 tonnes) of cargo. As on previous 747 freighters, the 747-8F features an overhead nose-door and a side-door on the main deck plus a side-door on the lower deck (\"belly\") to aid loading and unloading. The 747-8F made its maiden flight on February 8, 2010. The variant received its amended type certificate jointly from the FAA and the European Aviation Safety Agency (EASA) on August 19, 2011. The -8F was first delivered to Cargolux on October 12, 2011.\n\nThe passenger version, named 747-8 Intercontinental or 747-8I, is designed to carry up to 467 passengers in a 3-class configuration and fly more than at Mach 0.855. As a derivative of the already common 747-400, the 747-8 has the economic benefit of similar training and interchangeable parts. The type's first test flight occurred on March 20, 2011. The 747-8 has surpassed the Airbus A340-600 as the world's longest airliner. The first -8I was delivered in May 2012 to Lufthansa. The 747-8 has received 150 total orders, including 103 for the -8F and 47 for the -8I .\n\n\nBoeing has studied a number of 747 variants that have not gone beyond the concept stage.\n\nDuring the late 1960s and early 1970s, Boeing studied the development of a shorter 747 with three engines, to compete with the smaller Lockheed L-1011 TriStar and McDonnell Douglas DC-10. The center engine would have been fitted in the tail with an S-duct intake similar to the L-1011's. Overall, the 747 trijet would have had more payload, range, and passenger capacity than both of them. However, engineering studies showed that a major redesign of the 747 wing would be necessary. Maintaining the same 747 handling characteristics would be important to minimize pilot retraining. Boeing decided instead to pursue a shortened four-engine 747, resulting in the 747SP.\n\nBoeing announced the 747 ASB (\"Advanced Short Body\") in 1986 as a response to the Airbus A340 and the McDonnell Douglas MD-11. This aircraft design would have combined the advanced technology used on the 747-400 with the foreshortened 747SP fuselage. The aircraft was to carry 295 passengers a range of . However, airlines were not interested in the project and it was canceled in 1988 in favor of the 777.\n\nBoeing announced the 747-500X and -600X at the 1996 Farnborough Airshow. The proposed models would have combined the 747's fuselage with a new 251 ft (77 m) span wing derived from the 777. Other changes included adding more powerful engines and increasing the number of tires from two to four on the nose landing gear and from 16 to 20 on the main landing gear.\n\nThe 747-500X concept featured an increased fuselage length of 18 ft (5.5 m) to 250 ft (76.2 m) long, and the aircraft was to carry 462 passengers over a range up to 8,700 nautical miles (10,000 mi, 16,100 km), with a gross weight of over 1.0 Mlb (450 tonnes). The 747-600X concept featured a greater stretch to 279 ft (85 m) with seating for 548 passengers, a range of up to 7,700 nmi (8,900 mi, 14,300 km), and a gross weight of 1.2 Mlb (540 tonnes). A third study concept, the 747-700X, would have combined the wing of the 747-600X with a widened fuselage, allowing it to carry 650 passengers over the same range as a 747-400. The cost of the changes from previous 747 models, in particular the new wing for the 747-500X and -600X, was estimated to be more than US$5 billion. Boeing was not able to attract enough interest to launch the aircraft.\n\nAs Airbus progressed with its A3XX study, Boeing offered a 747 derivative as an alternative in 2000; a more modest proposal than the previous -500X and -600X that retained the 747's overall wing design and add a segment at the root, increasing the span to . Power would have been supplied by either the Engine Alliance GP7172 or the Rolls-Royce Trent 600, which were also proposed for the 767-400ERX. A new flight deck based on the 777's would be used. The 747X aircraft was to carry 430 passengers over ranges of up to 8,700 nmi (10,000 mi, 16,100 km). The 747X Stretch would be extended to long, allowing it to carry 500 passengers over ranges of up to 7,800 nmi (9,000 mi, 14,500 km). Both would feature an interior based on the 777. Freighter versions of the 747X and 747X Stretch were also studied.\n\nLike its predecessor, the 747X family was unable to garner enough interest to justify production, and it was shelved along with the 767-400ERX in March 2001, when Boeing announced the Sonic Cruiser concept. Though the 747X design was less costly than the 747-500X and -600X, it was criticized for not offering a sufficient advance from the existing 747-400. The 747X did not make it beyond the drawing board, but the 747-400X being developed concurrently moved into production to become the 747-400ER.\n\nAfter the end of the 747X program, Boeing continued to study improvements that could be made to the 747. The 747-400XQLR (Quiet Long Range) was meant to have an increased range of 7,980 nmi (9,200 mi, 14,800 km), with improvements to boost efficiency and reduce noise. Improvements studied included raked wingtips similar to those used on the 767-400ER and a sawtooth engine nacelle for noise reduction. Although the 747-400XQLR did not move to production, many of its features were used for the 747 Advanced, which has now been launched as the 747-8.\n\n, 462 Boeing 747s are in airline service, with British Airways being the largest operator with 36 747-400s.\n\nThe last US passenger Boeing 747 was retired from Delta Air Lines in December 2017, after it flew for every American major carrier since its 1970 introduction.\nDelta flew three of its last four aircraft on a farewell tour, from Seattle to Atlanta on December 19 then to Los Angeles and Minneapolis/St Paul on December 20.\n\nAs the IATA forecast an increase in air freight from 4% to 5% in 2018 fuelled by booming trade for time-sensitive goods, from smartphones to fresh flowers, demand for freighters is strong while passenger 747s are phased out.\nOf the 1,544 produced, 890 are retired; , a small subset of those which were intended to be parted-out get $3 million D-checks before flying again.\nYoung -400s are sold for 320 million yuan ($50 million) and Boeing stopped converting freighters, which used to cost nearly $30 million.\nThis comeback helped the airframer financing arm Boeing Capital to shrink its exposure to the 747-8 from $1.07 billion in 2017 to $481 million.\n\nBoeing 747 orders and deliveries (cumulative, by year):\n\n\n\nThe 747 has been involved in 146 aviation accidents and incidents, including 61 accidents and hull losses which resulted in 3722 fatalities. The last crash was Turkish Airlines Flight 6491 in January 2017. There were also 24 deaths in 32 aircraft hijackings, such as Pan Am Flight 73 where a Boeing 747-121 was hijacked by four terrorists and resulted in 20 deaths.\n\nFew crashes have been attributed to design flaws of the 747. The Tenerife airport disaster resulted from pilot error and communications failure, while the Japan Airlines Flight 123 and China Airlines Flight 611 crashes stemmed from improper aircraft repair. United Airlines Flight 811, which suffered an explosive decompression mid-flight on February 24, 1989, led the National Transportation Safety Board (NTSB) to issue a recommendation that 747-200 cargo doors similar to those on the Flight 811 aircraft be modified. Korean Air Lines Flight 007 was shot down by a Soviet fighter aircraft in 1983 after it had strayed into Soviet territory, causing U.S. President Ronald Reagan to authorize the then-strictly military global positioning system (GPS) for civilian use.\n\nAccidents due to design deficiencies included TWA Flight 800, where a 747-100 exploded in mid-air on July 17, 1996, probably due to sparking electricity wires inside the fuel tank; this finding led the FAA to propose a rule requiring installation of an inerting system in the center fuel tank of most large aircraft that was adopted in July 2008, after years of research into solutions. At the time, the new safety system was expected to cost US$100,000 to $450,000 per aircraft and weigh approximately . El Al Flight 1862 crashed after the fuse pins for an engine broke off shortly after take-off due to metal fatigue. Instead of dropping away from the wing, the engine knocked off the adjacent engine and damaged the wing.\n\nAs increasing numbers of \"classic\" 747-100 and 747-200 series aircraft have been retired, some have found their way into museums or other uses. In recent years, some older 747-300s and 747-400s have also found their way into museums as well.\n\nUpon its retirement from service, the 747 number two in the production line was dismantled and shipped to Hopyeong, Namyangju, Gyeonggi-do, South Korea where it was re-assembled, repainted in a livery similar to that of Air Force One and converted into a restaurant. Originally flown commercially by Pan Am as N747PA, \"Clipper Juan T. Trippe\", and repaired for service following a tailstrike, it stayed with the airline until its bankruptcy. The restaurant closed by 2009, and the aircraft was scrapped in 2010.\n\nA former British Airways 747-200B, G-BDXJ, is parked at the Dunsfold Aerodrome in Surrey, England and has been used as a movie set for productions such as the 2006 James Bond film, \"Casino Royale\". The plane also appears frequently in the BBC television series \"Top Gear\", which is filmed at Dunsfold.\n\nThe \"Jumbohostel\", using a converted 747-200 formerly registered as 9V-SQE, opened at Arlanda Airport, Stockholm in January 2009.\n\nThe wings of a 747 have been recycled as roofs of a house in Malibu, California.\n\nFollowing its debut, the 747 rapidly achieved iconic status, appearing in numerous film productions such as \"Airport 1975\" and \"Airport '77\" disaster films, \"Air Force One\", \"Die Hard 2\", and \"Executive Decision\". Appearing in over 300 film productions the 747 is one of the most widely depicted civilian aircraft and is considered by many as one of the most iconic in film history. The aircraft entered the cultural lexicon as the original \"Jumbo Jet\", a term coined by the aviation media to describe its size, and was also nicknamed \"Queen of the Skies.\"\n\n\n"}
{"id": "4615", "url": "https://en.wikipedia.org/wiki?curid=4615", "title": "Battle of Agincourt", "text": "Battle of Agincourt\n\nThe Battle of Agincourt (; ; ) was a major English victory in the Hundred Years' War. It took place on 25 October 1415 (Saint Crispin's Day) in the County of Saint-Pol, Artois, some 40 km south of Calais (now Azincourt in northern France). England's unexpected victory at Agincourt against a numerically superior French army boosted English morale and prestige, crippled France, and started a new period in the war during which the English began enjoying great military successes.\n\nAfter several decades of relative peace, the English had renewed their war effort in 1415 amid the failure of negotiations with the French. In the ensuing campaign, many soldiers died due to disease and the English numbers dwindled; they tried to withdraw to English-held Calais but found their path blocked by a considerably larger French army. Despite the disadvantage, the following battle ended in an overwhelming tactical victory for the English.\n\nKing Henry V of England led his troops into battle and participated in hand-to-hand fighting. King Charles VI of France did not command the French army himself, as he suffered from severe psychotic illnesses with moderate mental incapacitation. Instead, the French were commanded by Constable Charles d'Albret and various prominent French noblemen of the Armagnac party.\n\nThis battle is notable for the use of the English longbow in very large numbers, with the English and Welsh archers making up nearly 80 percent of Henry's army. The devastation of the French cavalry at their hands signaled the decline of cavalry and the increasing dominance of ranged weapons on the battlefield.\n\nAgincourt is one of England's most celebrated victories and was one of the most important English triumphs in the Hundred Years' War, along with the Battle of Crécy (1346) and Battle of Poitiers (1356). It forms the centrepiece of the play \"Henry V\" by William Shakespeare.\n\nThe Battle of Agincourt is well documented by at least seven contemporary accounts, three from eyewitnesses. The approximate location of the battle has never been in dispute and the place remains relatively unaltered after 600 years. Immediately after the battle, Henry summoned the heralds of the two armies who had watched the battle together with principal French herald Montjoie, and they settled on the name of the battle as Azincourt after the nearest fortified place. Two of the most frequently cited accounts come from Burgundian sources, one from Jean Le Fèvre de Saint-Remy who was present at the battle, and the other from Enguerrand de Monstrelet. The English eyewitness account comes from the anonymous \"Gesta Henrici Quinti\", believed to be written by a chaplain in the King's household who would have been in the baggage train at the battle. A recent re-appraisal of Henry's strategy of the Agincourt campaign incorporates these three accounts and argues that war was seen as a legal due process for solving the disagreement over claims to the French throne.\n\nHenry V invaded France following the failure of negotiations with the French. He claimed the title of King of France through his great-grandfather Edward III, although in practice the English kings were generally prepared to renounce this claim if the French would acknowledge the English claim on Aquitaine and other French lands (the terms of the Treaty of Brétigny). He initially called a Great Council in the spring of 1414 to discuss going to war with France, but the lords insisted that he should negotiate further and moderate his claims. In the following negotiations Henry said that he would give up his claim to the French throne if the French would pay the 1.6 million crowns outstanding from the ransom of John II (who had been captured at the Battle of Poitiers in 1356), and concede English ownership of the lands of Normandy, Touraine, Anjou, Brittany and Flanders, as well as Aquitaine. Henry would marry Catherine, the young daughter of Charles VI, and receive a dowry of 2 million crowns. The French responded with what they considered the generous terms of marriage with Catherine, a dowry of 600,000 crowns, and an enlarged Aquitaine. By 1415, negotiations had ground to a halt, with the English claiming that the French had mocked their claims and ridiculed Henry himself. In December 1414, the English parliament was persuaded to grant Henry a \"double subsidy\", a tax at twice the traditional rate, to recover his inheritance from the French. On 19 April 1415, Henry again asked the Great Council to sanction war with France, and this time they agreed.\n\nHenry's army landed in northern France on 13 August 1415, carried by a fleet described by Shakespeare as \"a city on the inconstant billows dancing / For so appears this fleet majestical\", often reported to comprise 1,500 ships, but probably far smaller, and besieged the port of Harfleur with an army of about 12,000, and up to 20,000 horses. The siege took longer than expected. The town surrendered on 22 September, and the English army did not leave until 8 October. The campaign season was coming to an end, and the English army had suffered many casualties through disease. Rather than retire directly to England for the winter, with his costly expedition resulting in the capture of only one town, Henry decided to march most of his army (roughly 9,000) through Normandy to the port of Calais, the English stronghold in northern France, to demonstrate by his presence in the territory at the head of an army that his right to rule in the duchy was more than a mere abstract legal and historical claim. He also intended the manoeuvre as a deliberate provocation to battle aimed at the dauphin, who had failed to respond to Henry's personal challenge to combat at Harfleur.\n\nThe French had raised an army during the siege which assembled around Rouen. This was not strictly a feudal army, but an army paid through a system similar to the English. The French hoped to raise 9,000 troops, but the army was not ready in time to relieve Harfleur. After Henry V marched to the north, the French moved to block them along the River Somme. They were successful for a time, forcing Henry to move south, away from Calais, to find a ford. The English finally crossed the Somme south of Péronne, at Béthencourt and Voyennes and resumed marching north. Without a river obstacle to defend, the French were hesitant to force a battle. They shadowed Henry's army while calling a \"semonce des nobles\", calling on local nobles to join the army. By 24 October, both armies faced each other for battle, but the French declined, hoping for the arrival of more troops. The two armies spent the night of 24 October on open ground. The next day the French initiated negotiations as a delaying tactic, but Henry ordered his army to advance and to start a battle that, given the state of his army, he would have preferred to avoid, or to fight defensively: that was how Crécy and the other famous longbow victories had been won. The English had very little food, had marched in two and a half weeks, were suffering from sickness such as dysentery, and faced much larger numbers of well-equipped French men at arms. The French army blocked Henry's way to the safety of Calais, however, and delaying battle would only further weaken his tired army and allow more French troops to arrive.\n\nThe location of the battle is not precisely fixed in contemporary accounts. Most authors believe it was fought in the narrow strip of open land formed between the woods of Tramecourt and Azincourt (close to the modern village of Azincourt). However, the lack of archaeological evidence at this traditional site has led to suggestions it was fought to the west of Azincourt.\n\nEarly on the 25th, Henry deployed his army (approximately 1,500 men-at-arms and 7,000 longbowmen) across a part of the defile. The army was organised into three \"battles\" or divisions: the vanguard, led by the Duke of York; the main battle led by Henry himself; and the rearguard, led by Lord Camoys. In addition, Sir Thomas Erpingham, one of Henry's most experienced household knights, had a role in marshalling the archers. It is likely that the English adopted their usual battle line of longbowmen on either flank, with men-at-arms and knights in the centre. They might also have deployed some archers in the centre of the line. The English men-at-arms in plate and mail were placed shoulder to shoulder four deep. The English and Welsh archers on the flanks drove pointed wooden stakes, or palings, into the ground at an angle to force cavalry to veer off. This use of stakes could have been inspired by the Battle of Nicopolis of 1396, where forces of the Ottoman Empire used the tactic against French cavalry.\n\nThe English made their confessions before the battle, as was customary. Henry, worried about the enemy launching surprise raids, and wanting his troops to remain focused, ordered all his men to spend the night before the battle in silence, on pain of having an ear cut off. He told his men that he would rather die in the coming battle than be captured and ransomed.\n\nHenry made a speech emphasising the justness of his cause, and reminding his army of previous great defeats the kings of England had inflicted on the French. The Burgundian sources have him concluding the speech by telling his men that the French had boasted that they would cut off two fingers from the right hand of every archer, so that he could never draw a longbow again. Whether this was true is open to question; as previously noted, death was the normal fate of any soldier who could not be ransomed.\n\nThe French force was not only larger than that of the English, but their noble men-at-arms would have considered themselves superior to the large number of archers in the English army, whom the French (based on their experience in recent memory of using and facing archers) considered relatively insignificant. For example, the chronicler Edmond de Dyntner stated that there were \"ten French nobles against one English\", ignoring the archers completely. Several French accounts emphasise that the French leaders were so eager to defeat the English (and win the ransoms of the English men-at-arms) that they insisted on being in the first line; as one of the contemporary accounts put it: \"All the lords wanted to be in the vanguard, against the opinion of the constable and the experienced knights.\"\n\nThe French were arrayed in three lines or \"battles\". The first line was led by Constable d'Albret, Marshal Boucicault, and the Dukes of Orléans and Bourbon, with attached cavalry wings under the Count of Vendôme and Sir Clignet de Brebant. The second line was commanded by the Dukes of Bar and Alençon and the Count of Nevers. The third line was under the Counts of Dammartin and Fauconberg. The Burgundian chronicler Jean de Wavrin said there were 8,000 men-at-arms, 4,000 archers and 1,500 crossbowmen in the vanguard, with two wings of 600 and 800 mounted men-at-arms, and a main battle comprising \"as many knights, esquires and archers as in the vanguard\", with the rearguard containing \"all of the rest of the men-at-arms\". The Herald of Berry gave figures of 4,800 men-at-arms in the first line, 3,000 men in the second line, with two \"wings\" containing 600 mounted men-at-arms each, and a total of \"10,000 men-at-arms\", but does not mention a third line.\n\nThousands of troops appear to have been in the rearguard, containing servants and commoners whom the French were either unable or unwilling to deploy. Wavrin gives the total French army size as 50,000: \"They had plenty of archers and crossbowmen but nobody wanted to let them fire . The reason for this was that the site was so narrow that there was only enough room for the men-at-arms.\" A different source says that the French did not even deploy 4,000 of the best crossbowmen \"on the pretext they had no need of their help\".\n\nThe field of battle was arguably the most significant factor in deciding the outcome. The recently ploughed land hemmed in by dense woodland favoured the English, both because of its narrowness, and because of the thick mud through which the French knights had to walk.\n\nAccounts of the battle describe the French engaging the English men-at-arms before being rushed from the sides by the longbowmen as the mêlée developed. The English account in the \"Gesta Henrici\" says: \"For when some of them, killed when battle was first joined, fall at the front, so great was the undisciplined violence and pressure of the mass of men behind them that the living fell on top of the dead, and others falling on top of the living were killed as well.\"\n\nAlthough the French initially pushed the English back, they became so closely packed that they were described as having trouble using their weapons properly. The French monk of St. Denis says: \"Their vanguard, composed of about 5,000 men, found itself at first so tightly packed that those who were in the third rank could scarcely use their swords,\" and the Burgundian sources have a similar passage.\n\nAs the battle was fought on a recently ploughed field, and there had recently been heavy rain leaving it very muddy, it proved very tiring to walk through in full plate armour. The French monk of St. Denis describes the French troops as \"marching through the middle of the mud where they sank up to their knees. So they were already overcome with fatigue even before they advanced against the enemy\". The deep, soft mud particularly favoured the English force because, once knocked to the ground, the heavily armoured French knights had a hard time getting back up to fight in the mêlée. Barker states that some knights, encumbered by their armour, actually drowned in their helmets.\n\nOn the morning of 25 October, the French were still waiting for additional troops to arrive. The Duke of Brabant (about 2,000 men), the Duke of Anjou (about 600 men), and the Duke of Brittany (6,000 men, according to Monstrelet), were all marching to join the army.\n\nFor three hours after sunrise there was no fighting. Military textbooks of the time stated: \"Everywhere and on all occasions that foot soldiers march against their enemy face to face, those who march lose and those who remain standing still and holding firm win.\" On top of this, the French were expecting thousands of men to join them if they waited. They were blocking Henry's retreat, and were perfectly happy to wait for as long as it took. There had even been a suggestion that the English would run away rather than give battle when they saw that they would be fighting so many French princes.\n\nHenry's men, on the other hand, were already very weary from hunger, illness and marching. Even though Henry knew as well as the French did that his army would perform better on the defensive, he was eventually forced to take a calculated risk, and move his army further forward to start the battle. This entailed abandoning his chosen position and pulling out, advancing, and then re-installing the long sharpened wooden stakes pointed outwards toward the enemy, which helped protect the longbowmen from cavalry charges. (The use of stakes was an innovation for the English: during the Battle of Crécy, for example, the archers had been instead protected by pits and other obstacles.)\n\nThe tightness of the terrain also seems to have restricted the planned deployment of the French forces. The French had originally drawn up a battle plan that had archers and crossbowmen in front of their men-at-arms, with a cavalry force at the rear specifically designed to \"fall upon the archers, and use their force to break them,\" but in the event, the French archers and crossbowmen were deployed \"behind\" and to the sides of the men-at-arms (where they seem to have played almost no part, except possibly for an initial volley of arrows at the start of the battle). The cavalry force, which could have devastated the English line if it had attacked while they moved their stakes, charged only \"after\" the initial volley of arrows from the English. It is unclear whether the delay occurred because the French were hoping the English would launch a frontal assault (and were surprised when the English instead started shooting from their new defensive position), or whether the French mounted knights instead did not react quickly enough to the English advance. French chroniclers agree that when the mounted charge did come, it did not contain as many men as it should have; Gilles le Bouvier states that some had wandered off to warm themselves and others were walking or feeding their horses.\n\nThe French cavalry, despite being disorganised and not at full numbers, charged towards the longbowmen, but it was a disaster, with the French knights unable to outflank the longbowmen (because of the encroaching woodland) and unable to charge through the forest of sharpened stakes that protected the archers. John Keegan argues that the longbows' main influence on the battle at this point was injuries to horses: armoured only on the head, many horses would have become dangerously out of control when struck in the back or flank from the high-elevation long range shots used as the charge started. The mounted charge and subsequent retreat churned up the already muddy terrain between the French and the English. Juliet Barker quotes a contemporary account by a monk of St. Denis who reports how the wounded and panicking horses galloped through the advancing infantry, scattering them and trampling them down in their headlong flight from the battlefield.\n\nThe plate armour of the French men-at-arms allowed them to close the 1,000 yards or so to the English lines while being under what the French monk of Saint Denis described as \"a terrifying hail of arrow shot\". A complete coat of plate was considered such good protection that shields were generally not used, although the Burgundian contemporary sources distinguish between Frenchmen who used shields and those who did not, and Rogers has suggested that the front elements of the French force used axes and shields. Modern historians are divided on how effective the longbow fire would have been against plate armour of the time, with some suggesting that arrows could not penetrate, especially the better quality steel armour, but others suggesting arrows could penetrate, especially the poorer quality wrought iron armour. Rogers suggested that the longbow could penetrate a wrought iron breastplate at short range and penetrate the thinner armour on the limbs even at . He considered a knight in the best-quality steel armour invulnerable to an arrow on the breastplate or top of the helmet, but vulnerable to shots hitting the limbs, particularly at close range. In any case, to protect themselves as much as possible from the arrows, the French had to lower their visors and bend their helmeted heads to avoid being shot in the face, as the eye- and air-holes in their helmets were among the weakest points in the armour. This head-lowered position restricted their breathing and their vision. Then they had to walk a few hundred yards (metres) through thick mud and a press of comrades while wearing armour weighing , gathering sticky clay all the way. Increasingly, they had to walk around or over fallen comrades.\n\nThe surviving French men-at-arms reached the front of the English line and pushed it back, with the longbowmen on the flanks continuing to shoot at point-blank range. When the archers ran out of arrows, they dropped their bows and using hatchets, swords and the mallets they had used to drive their stakes in, attacked the now disordered, fatigued and wounded French men-at-arms massed in front of them. The French could not cope with the thousands of lightly armoured longbowmen assailants (who were much less hindered by the mud and weight of their armour) combined with the English men-at-arms. The impact of thousands of arrows, combined with the slog in heavy armour through the mud, the heat and difficulty breathing in plate armour with the visor down, and the crush of their numbers meant the French men-at-arms could \"scarcely lift their weapons\" when they finally engaged the English line. The exhausted French men-at-arms were unable to get up after being knocked to the ground by the English. As the mêlée developed, the French second line also joined the attack, but they too were swallowed up, with the narrow terrain meaning the extra numbers could not be used effectively. Rogers suggested that the French at the back of their deep formation would have been attempting to literally add their weight to the advance, without realising that they were hindering the ability of those at the front to manoeuvre and fight by pushing them into the English formation of lancepoints. After the initial wave, the French would have had to fight over and on the bodies of those who had fallen before them. In such a \"press\" of thousands of men, Rogers suggested that many could have suffocated in their armour, as was described by several sources, and which was also known to have happened in other battles.\n\nThe French men-at-arms were taken prisoner or killed in the thousands. The fighting lasted about three hours, but eventually the leaders of the second line were killed or captured, as those of the first line had been. The English \"Gesta Henrici\" described three great heaps of the slain around the three main English standards.\nAccording to contemporary English accounts, Henry fought hand to hand. Upon hearing that his youngest brother Humphrey, Duke of Gloucester had been wounded in the groin, Henry took his household guard and stood over his brother, in the front rank of the fighting, until Humphrey could be dragged to safety. The king received an axe blow to the head, which knocked off a piece of the crown that formed part of his helmet.\n\nThe only French success was an attack on the lightly protected English baggage train, with Ysembart d'Azincourt (leading a small number of men-at-arms and varlets plus about 600 peasants) seizing some of Henry's personal treasures, including a crown. Whether this was part of a deliberate French plan or an act of local brigandage is unclear from the sources. Certainly, d'Azincourt was a local knight but he might have been chosen to lead the attack because of his local knowledge and the lack of availability of a more senior soldier. In some accounts the attack happened towards the end of the battle, and led the English to think they were being attacked from the rear. Barker, following the \"Gesta Henrici\", believed to have been written by an English chaplain who was actually in the baggage train, concluded that the attack happened at the \"start\" of the battle.\n\nRegardless of when the baggage assault happened, at some point after the initial English victory, Henry became alarmed that the French were regrouping for another attack. The \"Gesta Henrici\" places this after the English had overcome the onslaught of the French men-at-arms and the weary English troops were eyeing the French rearguard (\"in incomparable number and still fresh\"). Le Fèvre and Wavrin similarly say that it was signs of the French rearguard regrouping and \"marching forward in battle order\" which made the English think they were still in danger. A slaughter of the French prisoners ensued. It seems it was purely a decision of Henry, since the English knights found it contrary to chivalry, and contrary to their interests to kill valuable hostages for whom it was commonplace to ask ransom. Henry threatened to hang whoever did not obey his orders.\n\nIn any event, Henry ordered the slaughter of what were perhaps several thousand French prisoners, sparing only the highest ranked (presumably those most likely to fetch a large ransom under the chivalric system of warfare). According to most chroniclers, Henry's fear was that the prisoners (who, in an unusual turn of events, actually outnumbered their captors) would realize their advantage in numbers, rearm themselves with the weapons strewn about the field and overwhelm the exhausted English forces. Contemporary chroniclers did not criticise him for it. In his study of the battle, John Keegan argued that the main aim was not to actually kill the French knights but rather to terrorise them into submission and quell any possibility they might resume the fight, which would probably have caused the uncommitted French reserve forces to join the fray, as well. Such an event would have posed a risk to the still-outnumbered English and could have easily turned a stunning victory into a mutually-destructive defeat, as the English forces were now largely intermingled with the French and would have suffered grievously from the arrows of their own longbowmen had they needed to resume shooting. Keegan also speculated that due to the relatively low number of archers actually involved in killing the French knights (roughly 200 by his estimate), together with the refusal of the English knights to assist in a duty they saw as distastefully unchivalrous and combined with the sheer difficulty of killing such a large number of prisoners in such a short space of time, the actual number of French knights killed might not have even reached the hundreds before the reserves fled the field and Henry called an end to the slaughter.\n\nThe lack of reliable sources makes it impossible to give a precise figure for the French and English casualties (dead, wounded, taken prisoner). However, it is clear that though the English were outnumbered, their losses were far lower than those of the French. The French sources all give 4,000–10,000 French dead, with up to 1,600 English dead. The lowest ratio in these French sources has the French losing six times more men than the English. It has been possible to name at least 500 individuals from the French army killed in the battle and over 300 prisoners.\n\nThe English sources vary between about 1,500 and 11,000 for the French dead, with English dead put at no more than 100. Barker identifies from the available records \"at least\" 112 Englishmen killed in the fighting, including Edward of Norwich, 2nd Duke of York, a grandson of Edward III. One widely used estimate puts the English casualties at 450, a significant number in an army of about 8,500, but far fewer than the thousands the French lost, nearly all of whom were killed or captured. Using the lowest French estimate of their own dead of 4,000 would imply a ratio of nearly 9 to 1 in favour of the English, or over 10 to 1 if the prisoners are included.\n\nThe French suffered heavily. Three dukes, at least eight counts, a viscount, and an archbishop died, along with numerous other nobles. Of the great royal office holders, France lost her Constable, Admiral, Master of the Crossbowmen and \"prévôt\" of the marshals. The \"baillis\" of nine major northern towns were killed, often along with their sons, relatives and supporters. In the words of Juliet Barker, the battle \"cut a great swath through the natural leaders of French society in Artois, Ponthieu, Normandy, Picardy.\" Estimates of the number of prisoners vary between 700 and 2,200, amongst them the Duke of Orléans (the famous poet Charles d'Orléans) and Jean Le Maingre (known as Boucicault), Marshal of France.\n\nAlthough the victory had been militarily decisive, its impact was complex. It did not lead to further English conquests immediately as Henry's priority was to return to England, which he did on 16 November, to be received in triumph in London on the 23rd. Henry returned a conquering hero, in the eyes of his subjects and European powers outside France, blessed by God. It established the legitimacy of the Lancastrian monarchy and the future campaigns of Henry to pursue his \"rights and privileges\" in France. Other benefits to the English were longer term. Very quickly after the battle, the fragile truce between the Armagnac and Burgundian factions broke down. The brunt of the battle had fallen on the Armagnacs and it was they who suffered the majority of senior casualties and carried the blame for the defeat. The Burgundians seized on the opportunity and within 10 days of the battle had mustered their armies and marched on Paris. This lack of unity in France allowed Henry eighteen months to prepare militarily and politically for a renewed campaign. When that campaign took place, it was made easier by the damage done to the political and military structures of Normandy by the battle.\n\nNotable casualties (most named by Enguerrand de Monstrelet) include:\n\nLeading officers:\n\nThree dukes:\n\nSix counts (seven with d'Albret):\n\nand some 90 bannerets and others, including:\n\nNotable casualties included:\n\nAmong the \"circa\" 1,500 prisoners taken by the English, were the following French notables:\n\nAnne Curry in her 2005 book \"Agincourt: A New History\", argues (based on research into the surviving administrative records) that the French army was about 12,000 strong, and the English army about 9,000, giving proportions of four to three. By contrast, Juliet Barker in her book \"Agincourt: The King, the Campaign, the Battle\" (also published in 2005) argues the English and Welsh were outnumbered \"at least four to one and possibly as much as six to one\". She suggests figures of about 6,000 for the English and 36,000 for the French, based on the \"Gesta Henrici\"s figures of 5,000 archers and 900 men-at-arms for the English, and Jean de Wavrin’s statement \"that the French were six times more numerous than the English\". The 2009 \"Encyclopædia Britannica\" uses the figures of about 6,000 for the English and 20,000 to 30,000 for the French. The 1911 \"Britannica\" use somewhat different figures of 6,000 archers, 1,000 men-at-arms and \"a few thousands of other foot\" for the English, with the French outnumbering them by \"at least four times\".\n\nWhile not necessarily agreeing with the exact numbers Curry uses, Bertrand Schnerb, a professor of medieval history at the University of Lille, states the French probably had 12,000–15,000 troops. Ian Mortimer, in his 2009 book \"1415: Henry V's Year of Glory\", notes how Curry \"minimises French numbers (by limiting her figures to those in the basic army and a few specific additional companies) and maximises English numbers (by assuming the numbers sent home from Harfleur were no greater than sick lists)\", but agrees that previous estimates have exaggerated the odds, and suggests that \"the most extreme imbalance which is credible is fifteen thousand French troops against 8,100 English: a ratio of about two-to-one\".\n\nHowever, Clifford J. Rogers, professor of history at the United States Military Academy at West Point, has recently argued that archival records are too incomplete to substantially change his view that the English were outnumbered about 4–1. Juliet Barker also disagrees with Curry's arguments in the acknowledgements section of her 2005 book on Agincourt, saying: \"Surviving administrative records on both sides, but especially the French, are simply too incomplete to support [Curry's] assertion that nine thousand English were pitted against an army only twelve thousand strong. And if the differential really was as low as three to four then this makes a nonsense of the course of the battle as described by eyewitnesses and contemporaries.\"\n\nThose supporting a greater imbalance have generally put more store by contemporary (and especially eyewitness) accounts. The \"Gesta Henrici\" gives plausible figures for the English of 5,000 archers and 900 men-at-arms, but Mortimer notes it is \"wildly inaccurate\" in stating the English were outnumbered 30–1, and there have also been doubts as to how much it was written as propaganda for Henry V. The proportions also seem incorrect, as from surviving records we know that Henry set out with about four times as many archers as men-at-arms, not five and a half times as many. Those who have supported the Gesta figures for the English army have generally thought that although the English army may have left Harfleur with eight or nine thousand men, it is plausible that after weeks of campaigning and disease in hostile territory they would have lost two or three thousand fighting men; however Mortimer states: \"Despite the trials of the march, Henry had lost very few men to illness or death; and we have independent testimony that no more than 160 had been captured on the way.\" \n\nAs Mortimer notes, the Burgundian numbers for the size of the French vanguard of 8,000 men-at-arms in the vanguard with 1,400 (or 2,400) men-at-arms in the wings correspond roughly with the figures of ten thousand men-at-arms recorded by the duke of Berry's herald. The Burgundians also recorded 4,000 archers and 1,500 crossbowmen in the \"vanguard\", which would suggest \"fourteen or fifteen thousand fighting men\". (It should be noted that the Burgundians actually give the total size of the French army as an implausible 50,000, and the numbers they use do not correspond closely to the odds they describe. Using very similar numbers, Jean Le Fevre states that the English were outnumbered 3–1, whereas Wavrin states that the English were outnumbered 6–1.)\n\nOne particular cause of confusion may have been the number of servants on both sides. Mortimer suggests that because there were a much higher proportion of men-at-arms on the French side, the number of non-combatants was much higher. Each man-at-arms could be expected to have a page, who would have ridden one of his spare horses. If the French army had an extra 10,000 mounted men (as opposed to only 1,500 extra for the English), then \"the English probably did see an army about three times the size of their own fighting force\".\n\nIt is open to debate whether these should all be counted as non-combatants; Rogers (for example) accepts that the French probably had about 10,000 men-at-arms, but explicitly includes one \"gros valet\" (an armed, armoured and mounted military servant) per French man-at-arms in his calculation of the odds.\n\nSoon after the English victory at Agincourt, a number of popular folk songs were created about the battle, the most famous being the \"Agincourt Carol\", produced in the first half of the 15th century. Other ballads followed, including \"King Henry Fifth's Conquest of France\", raising the popular prominence of particular events mentioned only in passing by the original chroniclers, such as the gift of tennis balls before the campaign.\n\nThe most famous cultural depiction of the battle today is William Shakespeare's \"Henry V\", written in 1599. The play focuses on the pressures of kingship, the tensions between how a king should \"appear\" – chivalric, honest, and just – and how a king must sometimes \"act\" – Machiavellian and ruthless. Shakespeare illustrates these tensions by depicting Henry's decision to kill some of the French prisoners, whilst attempting to justify it and distance himself from the event. This moment of the battle is portrayed both as a break with the traditions of chivalry and as key example of the paradox of kingship.\n\nShakespeare's depiction of the battle also plays on the theme of modernity. He contrasts the modern, English king and his army with the medieval, chivalric, older model of the French.\n\nShakespeare's play presented Henry as leading a truly English force into battle, playing on the importance of the link between the monarch and the common soldiers in the fight. The original play does not, however, feature any scenes of the actual battle itself, leading critic Rose Zimbardo to characterise it as \"full of warfare, yet empty of conflict.\"\n\nThe play introduced the famous St Crispin's Day Speech, considered one of Shakespeare's most heroic speeches, in which Henry delivers movingly to his soldiers just before the battle, urging his \"band of brothers\" to stand together in the forthcoming fight. Critic David Margolies describes how it \"oozes honour, military glory, love of country and self-sacrifice\", and forms one of the first instances of English literature linking solidarity and comradeship to success in battle. Partially as a result, the battle was used as a metaphor at the beginning of the First World War, when the British Expeditionary Force's attempts to stop the German advances were widely likened to it.\nShakespeare's version of the battle of Agincourt has been turned into (several minor and) two major films, starring Laurence Olivier in 1944 and Kenneth Branagh in 1989. Made just prior to the invasion of Normandy, Olivier's rendition gives the battle what Sarah Hatchuel has termed an \"exhilarating and heroic\" tone, with an artificial, cinematic look to the battle scenes. Branagh's version gives a longer, more realist portrayal of the battle itself, drawing on both historical sources and images from the Vietnam and Falkland Wars. In his 2007 film adaptation, director Peter Babakitis uses digital effects to exaggerate realist features during the battle scenes, producing a more \"avant-garde\" interpretation of the fighting at Agincourt. \nThe battle remains an important symbol in popular culture. For example, a mock trial of Henry V for the crimes associated with the slaughter of the prisoners was held in Washington, D.C. in March 2010, drawing from both the historical record and Shakespeare's play. Participating as judges were Justices Samuel Alito and Ruth Bader Ginsburg. The trial ranged widely over whether there was just cause for war and not simply the prisoner issue. Although an audience vote was \"too close to call\", Henry was unanimously found guilty by the court on the basis of \"evolving standards of civil society\".\n\nThere is a modern museum in Azincourt village dedicated to the battle. The museum lists the names of combatants of both sides who died in the battle.\n\n\n\n"}
{"id": "4616", "url": "https://en.wikipedia.org/wiki?curid=4616", "title": "Burgundian", "text": "Burgundian\n\nBurgundian can refer to any of the following:\n\n\n"}
{"id": "4620", "url": "https://en.wikipedia.org/wiki?curid=4620", "title": "Bronze Age", "text": "Bronze Age\n\nThe Bronze Age is a historical period characterized by the use of bronze, and in some areas proto-writing, and other early features of urban civilization. The Bronze Age is the second principal period of the three-age Stone-Bronze-Iron system, as proposed in modern times by Christian Jürgensen Thomsen, for classifying and studying ancient societies.\n\nAn ancient civilization is defined to be in the Bronze Age either by producing bronze by smelting its own copper and alloying with tin, arsenic, or other metals, or by trading for bronze from production areas elsewhere. Bronze itself is harder and more durable than other metals available at the time, allowing Bronze Age civilizations to gain a technological advantage.\n\nCopper-tin ores are rare, as reflected in the fact that there were no tin bronzes in Western Asia before trading in bronze began in the third millennium BC. Worldwide, the Bronze Age generally followed the Neolithic period, with the Chalcolithic serving as a transition. Although the Iron Age generally followed the Bronze Age, in some areas (such as Sub-Saharan Africa), the Iron Age intruded directly on the Neolithic.\n\nBronze Age cultures differed in their development of the first writing. According to archaeological evidence, cultures in Mesopotamia (cuneiform script) and Egypt (hieroglyphs) developed the earliest viable writing systems.\nThe overall period is characterized by widespread use of bronze, though the place and time of the introduction and development of bronze technology were not universally synchronous. Human-made tin bronze technology requires set production techniques. Tin must be mined (mainly as the tin ore cassiterite) and smelted separately, then added to molten copper to make bronze alloy. The Bronze Age was a time of extensive use of metals and of developing trade networks (See \"Tin sources and trade in ancient times\"). A 2013 report suggests that the earliest tin-alloy bronze dates to the mid-5th millennium BC in a Vinča culture site in Pločnik (Serbia), although this culture is not conventionally considered part of the Bronze Age. The dating of the foil has been disputed.\n\nWestern Asia and the Near East was the first region to enter the Bronze Age, which began with the rise of the Mesopotamian civilization of Sumer in the mid 4th millennium BC. Cultures in the ancient Near East (often called one of \"the cradles of civilization\") practiced intensive year-round agriculture, developed a writing system, invented the potter's wheel, created a centralized government, written law codes, city and nation states and empires, embarked on advanced architectural projects, introduced social stratification, economic and civil administration, slavery, and practiced organized warfare, medicine and religion. Societies in the region laid the foundations for astronomy, mathematics and astrology.\n\nThe Ancient Near East Bronze Age can be divided as following:\n\nThe Hittite Empire was established in Hattusa in northern Anatolia from the 18th century BC. In the 14th century BC, the Hittite Kingdom was at its height, encompassing central Anatolia, southwestern Syria as far as Ugarit, and upper Mesopotamia. After 1180 BC, amid general turmoil in the Levant conjectured to have been associated with the sudden arrival of the Sea Peoples, the kingdom disintegrated into several independent \"Neo-Hittite\" city-states, some of which survived until as late as the 8th century BC.\n\nArzawa in Western Anatolia during the second half of the second millennium BC likely extended along southern Anatolia in a belt that reaches from near the Turkish Lakes Region to the Aegean coast. Arzawa was the western neighbor – sometimes a rival and sometimes a vassal – of the Middle and New Hittite Kingdoms.\n\nThe Assuwa league was a confederation of states in western Anatolia that was defeated by the Hittites under an earlier Tudhaliya I, around 1400 BC. Arzawa has been associated with the much more obscure Assuwa generally located to its north. It probably bordered it, and may even be an alternative term for it (at least during some periods).\n\nIn Ancient Egypt the Bronze Age begins in the Protodynastic period, BC. The archaic \"early Bronze Age of Egypt\", known as the Early Dynastic Period of Egypt, immediately follows the unification of Lower and Upper Egypt, BC. It is generally taken to include the First and Second Dynasties, lasting from the Protodynastic Period of Egypt until about 2686 BC, or the beginning of the Old Kingdom. With the First Dynasty, the capital moved from Abydos to Memphis with a unified Egypt ruled by an Egyptian god-king. Abydos remained the major holy land in the south. The hallmarks of ancient Egyptian civilization, such as art, architecture and many aspects of religion, took shape during the Early Dynastic period. Memphis in the Early Bronze Age was the largest city of the time.\nThe Old Kingdom of the regional Bronze Age is the name given to the period in the 3rd millennium BC when Egypt attained its first continuous peak of civilization in complexity and achievement – the first of three \"Kingdom\" periods, which mark the high points of civilization in the lower Nile Valley (the others being Middle Kingdom and the New Kingdom).\n\nThe First Intermediate Period of Egypt, often described as a \"dark period\" in ancient Egyptian history, spanned about 100 years after the end of the Old Kingdom from about 2181 to 2055 BC. Very little monumental evidence survives from this period, especially from the early part of it. The First Intermediate Period was a dynamic time when the rule of Egypt was roughly divided between two competing power bases: Heracleopolis in Lower Egypt and Thebes in Upper Egypt. These two kingdoms would eventually come into conflict, with the Theban kings conquering the north, resulting in the reunification of Egypt under a single ruler during the second part of the 11th Dynasty.\n\nThe Middle Kingdom of Egypt lasted from 2055 to 1650 BC. During this period, the Osiris funerary cult rose to dominate Egyptian popular religion. The period comprises two phases: the 11th Dynasty, which ruled from Thebes and the 12th and 13th Dynasties centered on el-Lisht. The unified kingdom was previously considered to comprise the 11th and 12th Dynasties, but historians now at least partially consider the 13th Dynasty to belong to the Middle Kingdom.\n\nDuring the Second Intermediate Period, Ancient Egypt fell into disarray for a second time, between the end of the Middle Kingdom and the start of the New Kingdom. It is best known for the Hyksos, whose reign comprised the 15th and 16th dynasties. The Hyksos first appeared in Egypt during the 11th Dynasty, began their climb to power in the 13th Dynasty, and emerged from the Second Intermediate Period in control of Avaris and the Delta. By the 15th Dynasty, they ruled lower Egypt, and they were expelled at the end of the 17th Dynasty.\n\nThe New Kingdom of Egypt, also referred to as the Egyptian Empire, lasted from the 16th to the 11th century BC. The New Kingdom followed the Second Intermediate Period and was succeeded by the Third Intermediate Period. It was Egypt's most prosperous time and marked the peak of Egypt's power. The later New Kingdom, i.e. the 19th and 20th Dynasties (1292–1069 BC), is also known as the Ramesside period, after the eleven pharaohs that took the name of Ramesses.\n\nElam was a \"pre-Iranic\" ancient civilization located to the east of Mesopotamia. In the Old Elamite period (Middle Bronze Age), Elam consisted of kingdoms on the Iranian Plateau, centered in Anshan, and from the mid-2nd millennium BC, it was centered in Susa in the Khuzestan lowlands. Its culture played a crucial role in the Gutian Empire and especially during the Iranic Achaemenid dynasty that succeeded it.\n\nThe Oxus civilization was a Bronze Age Central Asian culture dated to –1700 BC and centered on the upper Amu Darya (Oxus). In the Early Bronze Age the culture of the Kopet Dag oases and Altyndepe developed a proto-urban society. This corresponds to level IV at Namazga-Tepe. Altyndepe was a major centre even then. Pottery was wheel-turned. Grapes were grown. The height of this urban development was reached in the Middle Bronze Age BC, corresponding to level V at Namazga-Depe. This Bronze Age culture is called the Bactria–Margiana Archaeological Complex (BMAC).\n\nThe Kulli culture, similar to those of the Indus Valley Civilisation, was located in southern Balochistan (Gedrosia) –2000 BC. Agriculture was the economical base of this people. At several places dams were found, providing evidence for a highly developed water management system.\n\nKonar Sandal is associated with the hypothesized \"Jiroft culture\", a 3rd-millennium-BC culture postulated on the basis of a collection of artifacts confiscated in 2001.\n\nIn modern scholarship the chronology of the Bronze Age Levant is divided into Early/Proto Syrian; corresponding to the Early Bronze. Old Syrian; corresponding to the Middle Bronze. Middle Syrian; corresponding to the Late Bronze. The term Neo-Syria is used to designate the early Iron Age.\n\nThe old Syrian period was dominated by the Eblaite first kingdom, Nagar and the Mariote second kingdom. The Akkadian conquered large areas of the Levant and were followed by the Amorite kingdoms, –1600 BC, which arose in Mari, Yamhad, Qatna, Assyria. From the 15th century BC onward, the term Amurru is usually applied to the region extending north of Canaan as far as Kadesh on the Orontes River.\n\nThe earliest known Ugarit contact with Egypt (and the first exact dating of Ugaritic civilization) comes from a carnelian bead identified with the Middle Kingdom pharaoh Senusret I, 1971–1926 BC. A stela and a statuette from the Egyptian pharaohs Senusret III and Amenemhet III have also been found. However, it is unclear at what time these monuments got to Ugarit. In the Amarna letters, messages from Ugarit BC written by Ammittamru I, Niqmaddu II, and his queen, were discovered. From the 16th to the 13th century BC, Ugarit remained in constant touch with Egypt and Cyprus (named Alashiya).\n\nThe Mitanni was a loosely organized state in northern Syria and south-east Anatolia from –1300 BC. Founded by an Indo-Aryan ruling class that governed a predominantly Hurrian population, Mitanni came to be a regional power after the Hittite destruction of Kassite Babylon created a power vacuum in Mesopotamia. At its beginning, Mitanni's major rival was Egypt under the Thutmosids. However, with the ascent of the Hittite empire, Mitanni and Egypt made an alliance to protect their mutual interests from the threat of Hittite domination. At the height of its power, during the 14th century BC, it had outposts centered on its capital, Washukanni, which archaeologists have located on the headwaters of the Khabur River. Eventually, Mitanni succumbed to Hittite, and later Assyrian attacks, and was reduced to a province of the Middle Assyrian Empire.\n\nThe Israelites were an ancient Semitic-speaking people of the Ancient Near East who inhabited part of Canaan during the tribal and monarchic periods (15th to 6th centuries BC), and lived in the region in smaller numbers after the fall of the monarchy. The name \"Israel\" first appears BC, at the end of the Late Bronze Age and the very beginning of the Iron Age, on the Merneptah Stele raised by the Egyptian pharaoh Merneptah.\n\nThe Arameans were a Northwest Semitic semi-nomadic and pastoralist people who originated in what is now modern Syria (Biblical Aram) during the Late Bronze Age and the early Iron Age. Large groups migrated to Mesopotamia, where they intermingled with the native Akkadian (Assyrian and Babylonian) population. The Aramaeans never had a unified empire; they were divided into independent kingdoms all across the Near East. After the Bronze Age collapse, their political influence was confined to a number of Syro-Hittite states, which were entirely absorbed into the Neo-Assyrian Empire by the 8th century BC.\n\nIn Mesopotamia, the Mesopotamian Bronze Age began about 3500 BC and ended with the Kassite period ( BC – BC). The usual tripartite division into an Early, Middle and Late Bronze Age is not used. Instead, a division primarily based on art-historical and historical characteristics is more common.\n\nThe cities of the Ancient Near East housed several tens of thousands of people. Ur, Kish, Isin, Larsa and Nippur in the Middle Bronze Age and Babylon, Calah and Assur in the Late Bronze Age similarly had large populations. The Akkadian Empire (2335–2154 BC) became the dominant power in the region, and after its fall the Sumerians enjoyed a renaissance with the Neo-Sumerian Empire. Assyria was extant from as early as the 25th century BC, and became a regional power with the Old Assyrian Empire (–1750 BC). The earliest mention of Babylon (then a small administrative town) appears on a tablet from the reign of Sargon of Akkad in the 23rd century BC. The Amorite dynasty established the city-state of Babylon in the 19th century BC. Over 100 years later, it briefly took over the other city-states and formed the short lived First Babylonian Empire during what is also called the Old Babylonian Period. Akkad, Assyria and Babylonia all used the written East Semitic Akkadian language for official use and as a spoken language. By that time, the Sumerian language was no longer spoken, but was still in religious use in Assyria and Babylonia, and would remain so until the 1st century AD. The Akkadian and Sumerian traditions played a major role in later Assyrian and Babylonian culture, even though Babylonia (unlike the more militarily powerful Assyria) itself was founded by non-native Amorites and often ruled by other non-indigenous peoples, such as Kassites, Arameans and Chaldeans, as well as its Assyrian neighbours.\n\nThe Altai Mountains in what is now southern Russia and central Mongolia have been identified as the point of origin of a cultural enigma termed the Seima-Turbino Phenomenon. It is conjectured that changes in climate in this region around 2000 BC and the ensuing ecological, economic and political changes triggered a rapid and massive migration westward into northeast Europe, eastward into China and southward into Vietnam and Thailand\nHowever, recent genetic testings of sites in south Siberia and Kazakhstan (Andronovo horizon) would rather support a spreading of the bronze technology via Indo-European migrations eastwards, as this technology was well known for quite a while in western regions.\n\nIn China, the earliest bronze artifacts have been found in the Majiayao culture site (between 3100 and 2700 BC),\n\nThe term \"Bronze Age\" has been transferred to the archaeology of China from that of Western Eurasia, and there is no consensus or universally used convention delimiting the \"Bronze Age\" in the context of Chinese prehistory.\n\nBy convention, the \"Early Bronze Age\" in China is sometimes taken as equivalent to the \"Shang dynasty\" period of Chinese prehistory (16th to 11th centuries BC), and the \"Later Bronze Age\" as equivalent to the \"Zhou dynasty\" period (11th to 3rd centuries BC, from the 5th century also dubbed \"Iron Age\"), although there is an argument to be made that the \"Bronze Age\" proper never ended in China, as there is no recognizable transition to an \"Iron Age\". Significantly, together with the jade art that precedes it, bronze was seen as a \"fine\" material for ritual art when compared with iron or stone, stone only becoming popular for tombs in the Han on probable Indian influence (replacing wooden temple in that instance).\n\nBronze metallurgy in China originated in what is referred to as the Erlitou () period, which some historians argue places it within the range of dates controlled by the Shang dynasty. Others believe the Erlitou sites belong to the preceding Xia () dynasty. The U.S. National Gallery of Art defines the Chinese Bronze Age as the \"period between about 2000 BC and 771 BC,\" a period that begins with the Erlitou culture and ends abruptly with the disintegration of Western Zhou rule.\n\nThe widespread use of bronze in Chinese metallurgy and culture dates to significantly later, probably due to Western influence. While there may be reason to believe that bronzework developed inside China separately from outside influence, the discovery of Europoid mummies in Xinjiang suggests a possible route of transmission from the West beginning in the early second millennium BC.\n\nThe Shang dynasty (also known as the Yin dynasty) of the Yellow River Valley rose to power after the Xia dynasty around 1600 BC. While some direct information about the Shang dynasty comes from Shang-era inscriptions on bronze artifacts, most comes from oracle bones – turtle shells, cattle scapulae, or other bones – which bear glyphs that form the first significant corpus of recorded Chinese characters.\n\nIron is found from the Zhou dynasty, but its use is minimal. Chinese literature dating to the 6th century BC attests knowledge of iron smelting, yet bronze continues to occupy the seat of significance in the archaeological and historical record for some time after this. Historian W.C. White argues that iron did not supplant bronze \"at any period before the end of the Zhou dynasty (256 BC)\" and that bronze vessels make up the majority of metal vessels all the way through the Later Han period, or to 221 BC.\n\nThe Chinese bronze artifacts generally are either utilitarian, like spear points or adze heads, or \"ritual bronzes\", which are more elaborate versions in precious materials of everyday vessels, as well as tools and weapons. Examples are the numerous large sacrificial tripods known as dings in Chinese; there are many other distinct shapes. Surviving identified Chinese ritual bronzes tend to be highly decorated, often with the \"taotie\" motif, which involves highly stylized animal faces. These appear in three main motif types: those of demons, of symbolic animals, and of abstract symbols. Many large bronzes also bear cast inscriptions that are the great bulk of the surviving body of early Chinese writing and have helped historians and archaeologists piece together the history of China, especially during the Zhou dynasty (1046–256 BC).\n\nThe bronzes of the Western Zhou dynasty document large portions of history not found in the extant texts that were often composed by persons of varying rank and possibly even social class. Further, the medium of cast bronze lends the record they preserve a permanence not enjoyed by manuscripts. These inscriptions can commonly be subdivided into four parts: a reference to the date and place, the naming of the event commemorated, the list of gifts given to the artisan in exchange for the bronze, and a dedication. The relative points of reference these vessels provide have enabled historians to place most of the vessels within a certain time frame of the Western Zhou period, allowing them to trace the evolution of the vessels and the events they record.\n\nThe beginning of the Bronze Age on the peninsula is around 1000–800 BC. Although the Korean Bronze Age culture derives from the Liaoning and Manchuria, it exhibits unique typology and styles, especially in ritual objects.\n\nThe Mumun pottery period is named after the Korean name for undecorated or plain cooking and storage vessels that form a large part of the pottery assemblage over the entire length of the period, but especially 850–550 BC. The Mumun period is known for the origins of intensive agriculture and complex societies in both the Korean Peninsula and the Japanese Archipelago.\n\nThe Middle Mumun pottery period culture of the southern Korean Peninsula gradually adopted bronze production (–600? BC) after a period when Liaoning-style bronze daggers and other bronze artifacts were exchanged as far as the interior part of the Southern Peninsula (–700 BC). The bronze daggers lent prestige and authority to the personages who wielded and were buried with them in high-status megalithic burials at south-coastal centres such as the Igeum-dong site. Bronze was an important element in ceremonies and as for mortuary offerings until 100.\n\nThe Japanese archipelago experienced the introduction of bronze during the beginning of the Early Yayoi period (~300 BC), which saw the introduction of metalworking and agricultural practices bought in by settlers arriving from the continent. Bronze and iron smelting techniques spread to the Japanese archipelago through contact with other ancient East Asian civilizations, particularly immigration and trade from the Korean peninsula and ancient Mainland China. Iron was mainly used for agricultural and other tools, whereas ritual and ceremonial artifacts were mainly made of bronze.\n\nThe Bronze Age on the Indian subcontinent began around 3300 BC with the beginning of the Indus Valley civilization. Inhabitants of the Indus Valley, the Harappans, developed new techniques in metallurgy and produced copper, bronze, lead and tin. The Late Harappan culture, which dates from 1900–1400 BC, overlapped the transition from the Bronze Age to the Iron Age; thus it is difficult to date this transition accurately. It has been claimed that a 6,000 year old copper amulet manufactured in Mehrgarh in the shape of wheel spoke is the earliest example of lost wax casting in the world.\n\nDating back to the Neolithic Age, the first bronze drum, called the Dong Son drum, were uncovered in and around the Red River Delta regions of Northern Vietnam and Southern China. These relate to the prehistoric Dong Son Culture of Vietnam. In Ban Chiang, Thailand, (Southeast Asia) bronze artifacts have been discovered dating to 2100 BC. However, according to the radiocarbon dating on the human and pig bones in Ban Chiang, some scholars propose that the initial Bronze Age in Ban Chiang was in late 2nd millennium. In Nyaunggan, Burma, bronze tools have been excavated along with ceramics and stone artifacts. Dating is still currently broad (3500–500 BC). Ban Non Wat, excavated by Charles Higham, was a rich site with over 640 graves excavated that gleaned many complex bronze items that may have had social value connected to them.\n\nBan Chiang, however, is the most thoroughly documented site while having the clearest evidence of metallurgy when it comes to Southeast Asia. With a rough date range of late 3rd millennium BC to the first millennium AD, this site alone has various artifacts such as burial pottery (dating from 2100–1700 BC), fragments of Bronze, copper-base bangles, and much more. What's interesting about this site, however, isn't just the old age of the artifacts but the fact that this technology suggested on-site casting from the very beginning. The on-site casting supports the theory that Bronze was first introduced in Southeast Asia as fully developed which therefore shows that Bronze was actually innovated from a different country. Some scholars believe that the copper-based metallurgy was disseminated from northwest and central China via south and southwest areas such as Guangdong province and Yunnan province and finally into southeast Asia around 1000 BC.\n\nArchaeological research in Northern Vietnam indicates an increase in rates of infectious disease following the advent of metallurgy; skeletal fragments in sites dating to the early and mid-Bronze Age evidence a greater proportion of lesions than in sites of earlier periods. There are a few possible implications of this. One is the increase contact with bacterial and/or fungal pathogens due to increased population density and land clearing/ cultivation. The other one is decreased levels of immunocompetence in the Metal age due to changes in diet caused by agriculture. The last is that there may have been an emergence of infectious disease in the Da But period that evolved into a more virulent form in the metal period. Archaeology also suggests that Bronze Age metallurgy may not have been as significant a catalyst in social stratification and warfare in Southeast Asia as in other regions, social distribution shifting away from chiefdom-states to a heterarchical network. Data analyses of sites such as Ban Lum Khao, Ban Na Di, Non Nok Tha, Khok Phanom Di, and Nong Nor have consistently led researchers to conclude that there was no forentrenched hierarchy.\n\nA few examples of named Bronze Age cultures in Europe in roughly relative order.\n\nThe oldest securely dated tin bronze artefact are found in the heart of the Balkans in Serbia. A tin bronze foil from the Pločnik (archaeological site) are dated to 4650 BC. The foil are not the only tin bronze artefact from the fifth millennium BC. 14 other artefacts from Serbia and Bulgaria are dated to before 4000 BC. The recent discoveries indicate that early tin bronze was more common than previously thought, and developed independently in Europe 1500 years before the first tin bronze alloys in the Near East.\n\nThe production of complex tin bronzes lasted for c. 500 years in the Balkans. Shortly before the end of the fifth millennium BC, there are no longer evidence for production of tin bronze. This coincides with the collapse of large cultural complexes in the Balkans.\nTin bronze would be reintroduced to the area again some 1500 years later.\n\nThe Aegean Bronze Age began around 3200 BC, when civilizations first established a far-ranging trade network. This network imported tin and charcoal to Cyprus, where copper was mined and alloyed with the tin to produce bronze. Bronze objects were then exported far and wide, and supported the trade. Isotopic analysis of tin in some Mediterranean bronze artifacts suggests that they may have originated from Great Britain.\n\nKnowledge of navigation was well developed at this time, and reached a peak of skill not exceeded (except perhaps by Polynesian sailors) until 1730 when the invention of the chronometer enabled the precise determination of longitude.\n\nThe Minoan civilization based in Knossos on the island of Crete appears to have coordinated and defended its Bronze Age trade. Illyrians are also believed to have roots in the early Bronze Age. Ancient empires valued luxury goods in contrast to staple foods, leading to famine.\n\nBronze Age collapse theories have described aspects of the end of the Age in this region. At the end of the Bronze Age in the Aegean region, the Mycenaean administration of the regional trade empire followed the decline of Minoan primacy. Several Minoan client states lost much of their population to famine and/or pestilence. This would indicate that the trade network may have failed, preventing the trade that would previously have relieved such famines and prevented illness caused by malnutrition. It is also known that in this era the breadbasket of the Minoan empire, the area north of the Black Sea, also suddenly lost much of its population, and thus probably some capacity to cultivate crops.Drought and famine in Anatolia may have also led to the Aegean Collapse by disrupting trade networks, and therefore preventing the Aegean from accessing bronze and luxury goods.\n\nThe Aegean Collapse has been attributed to the exhaustion of the Cypriot forests causing the end of the bronze trade. These forests are known to have existed into later times, and experiments have shown that charcoal production on the scale necessary for the bronze production of the late Bronze Age would have exhausted them in less than fifty years.\n\nThe Aegean Collapse has also been attributed to the fact that as iron tools became more common, the main justification for the tin trade ended, and that trade network ceased to function as it did formerly. The colonies of the Minoan empire then suffered drought, famine, war, or some combination of those three, and had no access to the distant resources of an empire by which they could easily recover.\n\nThe Thera eruption occurred around the Aegean Collapse, north of Crete. Speculation include a tsunami from Thera (more commonly known today as Santorini) destroyed Cretan cities. A tsunami may have destroyed the Cretan navy in its home harbour, which then lost crucial naval battles; so that in the LMIB/LMII event ( BC) the cities of Crete burned and the Mycenaean civilization took over Knossos. If the eruption occurred in the late 17th century BC (as most chronologists now think) then its immediate effects belong to the Middle to Late Bronze Age transition, and not to the end of the Late Bronze Age; but it could have triggered the instability that led to the collapse first of Knossos and then of Bronze Age society overall. One such theory highlights the role of Cretan expertise in administering the empire, post-Thera. If this expertise was concentrated in Crete, then the Mycenaeans may have made political and commercial mistakes in administering the Cretan empire.\n\nArchaeological findings, including some on the island of Thera, suggest that the centre of Minoan Civilization at the time of the eruption was actually on Thera rather than on Crete. According to this theory, the catastrophic loss of the political, administrative and economic centre by the eruption as well as the damage wrought by the tsunami to the coastal towns and villages of Crete precipitated the decline of the Minoans. A weakened political entity with a reduced economic and military capability and fabled riches would have then been more vulnerable to human predators. Indeed, the Santorini Eruption is usually dated to BC, while the Mycenaean Greeks first enter the historical record a few decades later, BC. Thus, the later Mycenaean assaults on Crete ( BC) and Troy ( BC) are revealed as mere continuations of the steady encroachments of the Greeks upon the weakened Minoan world.\n\nIn Central Europe, the early Bronze Age Unetice culture (1800–1600 BC) includes numerous smaller groups like the Straubing, Adlerberg and Hatvan cultures. Some very rich burials, such as the one located at Leubingen with grave gifts crafted from gold, point to an increase of social stratification already present in the Unetice culture. All in all, cemeteries of this period are rare and of small size. The Unetice culture is followed by the middle Bronze Age (1600–1200 BC) Tumulus culture, which is characterised by inhumation burials in tumuli (barrows). In the eastern Hungarian Körös tributaries, the early Bronze Age first saw the introduction of the Mako culture, followed by the Otomani and Gyulavarsand cultures.\n\nThe late Bronze Age Urnfield culture (1300–700 BC) is characterized by cremation burials. It includes the Lusatian culture in eastern Germany and Poland (1300–500 BC) that continues into the Iron Age. The Central European Bronze Age is followed by the Iron Age Hallstatt culture (700–450 BC).\n\nImportant sites include:\n\nThe Bronze Age in Central Europe has been described in the chronological schema of German prehistorian Paul Reinecke. He described Bronze A1 (Bz A1) period (2300–2000 BC : triangular daggers, flat axes, stone wrist-guards, flint arrowheads) and Bronze A2 (Bz A2) period (1950–1700 BC : daggers with metal hilt, flanged axes, halberds, pins with perforated spherical heads, solid bracelets) and phases Hallstatt A and B (Ha A and B).\n\nThe Apennine culture (also called Italian Bronze Age) is a technology complex of central and southern Italy spanning the Chalcolithic and Bronze Age proper. The Camuni were an ancient people of uncertain origin (according to Pliny the Elder, they were Euganei; according to Strabo, they were Rhaetians) who lived in Val Camonica – in what is now northern Lombardy – during the Iron Age, although human groups of hunters, shepherds and farmers are known to have lived in the area since the Neolithic.\n\nLocated in Sardinia and Corsica, the Nuragic civilization lasted from the early Bronze Age (18th century BC) to the 2nd century AD, when the islands were already Romanized. They take their name from the characteristic nuragic towers, which evolved from the pre-existing megalithic culture, which built dolmens and menhirs. The nuraghe towers are unanimously considered the best preserved and largest megalithic remains in Europe. Their effective use is still debated: some scholars considered them as monumental tombs, others as Houses of the Giants, other as fortresses, ovens for metal fusion, prisons or, finally, temples for a solar cult. Around the end of the 3rd millennium BC, Sardinia exported towards Sicily a \"Culture\" that built small dolmens, trilithic or polygonal shaped, that served as tombs as it has been ascertained in the Sicilian dolmen of “Cava dei Servi”. From this region they reached Malta island and other countries of Mediterranean basin.\n\nThe Terramare was an early Indo-European civilization in the area of what is now Pianura Padana (northern Italy) before the arrival of the Celts, and in other parts of Europe. They lived in square villages of wooden stilt houses. These villages were built on land, but generally near a stream, with roads that crossed each other at right angles. The whole complex denoted the nature of a fortified settlement. Terramare were widespread in the Pianura Padana (specially along the Panaro river, between Modena and Bologna) and in the rest of Europe. The civilization developed in the Middle and Late Bronze Age, between the 17th and the 13th centuries BC.\n\nThe Castellieri culture developed in Istria during the Middle Bronze Age. It lasted for more than a millennium, from the 15th century BC until the Roman conquest in the 3rd century BC. It takes its name from the fortified boroughs (\"Castellieri\", Friulian \"cjastelir\") that characterized the culture.\n\nThe Canegrate culture developed from the mid-Bronze Age (13th century BC) until the Iron Age in the Pianura Padana, in what are now western Lombardy, eastern Piedmont and Ticino. It takes its name from the township of Canegrate where, in the 20th century, some fifty tombs with ceramics and metal objects were found. The Canegrate culture migrated from the northwest part of the Alps and descended to Pianura Padana from the Swiss Alps passes and the Ticino.\n\nThe Golasecca culture developed starting from the late Bronze Age in the Po plain. It takes its name from Golasecca, a locality next to the Ticino where, in the early 19th century, abbot Giovanni Battista Giani excavated its first findings (some fifty tombs with ceramics and metal objects). Remains of the Golasecca culture span an area of c. 20,000 square kilometers south to the Alps, between the Po, Sesia and Serio rivers, dating from the 9th to the 4th century BC.\n\nThe Atlantic Bronze Age is a cultural complex of the period of approximately 1300–700 BC that includes different cultures in Portugal, Andalusia, Galicia and the British Isles. It is marked by economic and cultural exchange. Commercial contacts extend to Denmark and the Mediterranean. The Atlantic Bronze Age was defined by a number of distinct regional centres of metal production, unified by a regular maritime exchange of some of their products.\n\nIn Great Britain, the Bronze Age is considered to have been the period from around 2100 to 750 BC. Migration brought new people to the islands from the continent. Recent tooth enamel isotope research on bodies found in early Bronze Age graves around Stonehenge indicate that at least some of the migrants came from the area of modern Switzerland. Another example site is Must Farm, near Whittlesey, which has recently been host to the most complete Bronze Age wheel ever to be found. The Beaker culture displayed different behaviours from the earlier Neolithic people, and cultural change was significant. Integration is thought to have been peaceful, as many of the early henge sites were seemingly adopted by the newcomers. The rich Wessex culture developed in southern Britain at this time. Additionally, the climate was deteriorating; where once the weather was warm and dry it became much wetter as the Bronze Age continued, forcing the population away from easily defended sites in the hills and into the fertile valleys. Large livestock farms developed in the lowlands and appear to have contributed to economic growth and inspired increasing forest clearances. The Deverel-Rimbury culture began to emerge in the second half of the Middle Bronze Age ( –1100 BC) to exploit these conditions. Devon and Cornwall were major sources of tin for much of western Europe and copper was extracted from sites such as the Great Orme mine in northern Wales. Social groups appear to have been tribal but with growing complexity and hierarchies becoming apparent.\n\nThe burial of the dead (which, until this period, had usually been communal) became more individual. For example, whereas in the Neolithic a large chambered cairn or long barrow housed the dead, Early Bronze Age people buried their dead in individual barrows (also commonly known and marked on modern British Ordnance Survey maps as tumuli), or sometimes in cists covered with cairns.\n\nThe greatest quantities of bronze objects in England were discovered in East Cambridgeshire, where the most important finds were recovered in Isleham (more than 6500 pieces).\nAlloying of copper with zinc or tin to make brass or bronze was practised soon after the discovery of copper itself. One copper mine at Great Orme in North Wales, extended to a depth of 70 meters. At Alderley Edge in Cheshire, carbon dates have established mining at around 2280 to 1890 BC (at 95% probability). The earliest identified metalworking site (Sigwells, Somerset) is much later, dated by Globular Urn style pottery to approximately the 12th century BC. The identifiable sherds from over 500 mould fragments included a perfect fit of the hilt of a sword in the Wilburton style held in Somerset County Museum.\n\nThe Bronze Age in Ireland commenced around 2000 BC, when copper was alloyed with tin and used to manufacture Ballybeg type flat axes and associated metalwork. The preceding period is known as the Copper Age and is characterised by the production of flat axes, daggers, halberds and awls in copper. The period is divided into three phases: Early Bronze Age (2000–1500 BC), Middle Bronze Age (1500–1200 BC), and Late Bronze Age (1200– BC). Ireland is also known for a relatively large number of Early Bronze Age burials.\n\nOne of the characteristic types of artifact of the Early Bronze Age in Ireland is the flat axe. There are five main types of flat axes: Lough Ravel ( BC), Ballybeg ( BC), Killaha ( BC), Ballyvalley (–1600 BC), Derryniggin ( BC), and a number of metal ingots in the shape of axes.\n\nThe Bronze Age in Northern Europe spans the entire 2nd millennium BC (Unetice culture, Urnfield culture, Tumulus culture, Terramare culture, Lusatian culture) lasting until BC. The Northern Bronze Age was both a period and a Bronze Age culture in Scandinavian pre-history, –500 BC, with sites that reached as far east as Estonia. Succeeding the Late Neolithic culture, its ethnic and linguistic affinities are unknown in the absence of written sources. It is followed by the Pre-Roman Iron Age.\n\nEven though Northern European Bronze Age cultures were relatively late, and came into existence via trade, sites present rich and well-preserved objects made of wool, wood and imported Central European bronze and gold. Many rock carvings depict ships, and the large stone burial monuments known as stone ships suggest that shipping played an important role. Thousands of rock carvings depict ships, most probably representing sewn plank built canoes for warfare, fishing and trade. These may have a history as far back as the neolithic period and continue into the Pre-Roman Iron Age, as shown by the Hjortspring boat. There are many mounds and rock carving sites from the period. Numerous artifacts of bronze and gold are found. No written language existed in the Nordic countries during the Bronze Age. The rock carvings have been dated through comparison with depicted artifacts.\n\nArsenical bronze artifacts of the Maykop culture in the North Caucasus have been dated around the 4th millennium BC. This innovation resulted in the circulation of arsenical bronze technology over southern and eastern Europe.\n\nThe Yamnaya culture is a Late Copper Age/Early Bronze Age culture of the Southern Bug/Dniester/Ural region (the Pontic steppe), dating to the 36th–23rd centuries BC. The name also appears in English as Pit-Grave Culture or Ochre-Grave Culture. The Catacomb culture, –2200 BC, comprises several related Early Bronze Age cultures occupying what is presently Russia and Ukraine. The Srubna culture was a Late Bronze Age (18th–12th centuries BC) culture. It is a successor to the Yamnaya and the Poltavka culture.\n\nIron and copper smelting appeared around the same time in most parts of Africa. As such, most African civilizations outside of Egypt did not experience a distinct Bronze Age. Evidence for iron smelting appears earlier or at the same time as copper smelting in Nigeria c. 900–800 BC, Rwanda and Burundi c. 700–500 BC and Tanzania c. 300 BC.\n\nThere is a longstanding debate about whether the development of both copper and iron metallurgy were independently developed in sub-Saharan Africa or were introduced from the outside across the Sahara Desert from North Africa or from the Indian Ocean. Evidence for theories of independent development and for outside introduction are scarce and subject to active scholarly debate. Scholars have suggested that both the relative dearth of archeological research in sub-Saharan Africa as well as long standing prejudices have limited or biased our understanding of pre-historic metallurgy on the continent. One scholar characterized the state of historical knowledge as such: “To say that the history of metallurgy in sub-Saharan Africa is complicated is perhaps an understatement.”\n\nThe Bronze Age in Nubia, started as early as 2300 BC. Copper smelting was introduced by Egyptians to the Nubian city of Meroë, in modern-day Sudan, around 2600 BC. A furnace for bronze casting has been found in Kerma that is dated to 2300–1900 BC.\n\nCopper smelting took place in West Africa prior to the appearance of iron smelting in the region. Evidence for copper smelting furnaces was found near Agadez, Niger that has been dated as early as 2200 BC. However, evidence for copper production in this region before 1000 BC is debated. Evidence of copper mining and smelting has been founded at Akjoujt, Mauretania that suggests small scale production to 400 BC.\n\nThe Moche civilization of South America independently discovered and developed bronze smelting. Bronze technology was developed further by the Incas and used widely both for utilitarian objects and sculpture. A later appearance of limited bronze smelting in West Mexico (see Metallurgy in pre-Columbian Mesoamerica) suggests either contact of that region with Andean cultures or separate discovery of the technology. The Calchaquí people of Northwest Argentina had bronze technology.\n\nTrade and industry played a major role in the development of the ancient Bronze Age civilizations. With artifacts of the Indus Valley Civilization being found in ancient Mesopotamia and Egypt, it is clear that these civilizations were not only in touch with each other but also trading with each other. Early long-distance trade was limited almost exclusively to luxury goods like spices, textiles and precious metals. Not only did this make cities with ample amounts of these products extremely rich but also led to an inter-mingling of cultures for the first time in history.\n\nTrade routes were not only over land but also over water. The first and most extensive trade routes were over rivers such as the Nile, the Tigris and the Euphrates which led to growth of cities on the banks of these rivers. The domestication of camels at a later time also helped encourage the use of trade routes over land, linking the Indus Valley with the Mediterranean. This further led to towns sprouting up in numbers any and everywhere there was a pit-stop or caravan-to-ship port.\n\n\n\n\n"}
{"id": "4621", "url": "https://en.wikipedia.org/wiki?curid=4621", "title": "BBC News (TV channel)", "text": "BBC News (TV channel)\n\nBBC News (also known as the BBC News Channel) is a British free-to-air television news channel. It was launched as BBC News 24 on 9 November 1997 at 5:30pm as part of the BBC's foray into digital domestic television channels, becoming the first competitor to Sky News, which had been running since 1989. For a time, looped news, sport and weather bulletins were available to view via BBC Red Button.\n\nOn 22 February 2006, the channel was named \"News Channel of the Year\" at the Royal Television Society Television Journalism Awards for the first time in its history. The judges remarked that this was the year that the channel had \"really come into its own.\"\n\nFrom May 2007, viewers in the UK could watch the channel via the BBC News website. In April 2008, the channel was renamed \"BBC News\" as part of a £550,000 rebranding of the BBC's news output, complete with a new studio and presentation. Its sister service, BBC World was also renamed \"BBC World News\" while the national news bulletins became \"BBC News at One\", \"BBC News at Six\" and \"BBC News at Ten\". Across the day the channel averages about twice the audience of Sky News.\n\nThe channel is based at and broadcasts from Broadcasting House in the West End of London. In 2017, it was named the RTS \"News Channel of the Year\"\n\nBBC News 24 was originally available to digital terrestrial, satellite and cable television subscribers. To this day, it and BBC Parliament remain the only BBC \"digital\" channels which are made available to analogue cable subscribers. This coverage was improved in 1998 with the advent of digital television in the United Kingdom allowing satellite and digital terrestrial television viewers to also view the service. Initially it was difficult to obtain a digital satellite or terrestrial receiver without a subscription to Sky or ONdigital respectively, but now the channel forms an important part of the Freeview and Freesat channel packages.\n\nThe BBC had run the international news channel BBC World for two and a half years prior to the launch of BBC News 24 on 9 November 1997. Sky News had had a free hand with domestic news for over eight years (since 5 February 1989) and being owned by News Corporation their papers were used to criticise the BBC for extending its news output.\n\nSky News objected to the breaking of its monopoly, complaining about the costs associated with running a channel that only a minority could view from the licence fee. Sky News claimed that a number of British cable operators had been incentivised to carry News 24 (which, as a licence-fee funded channel was made available to such operators for free) in preference to the commercial Sky News. However, in September 1999 the European Commission ruled against a complaint made by Sky News that the publicly funded channel was unfair and illegal under EU law. The Commission ruled that the licence fee should be considered state aid but that such aid was justified due to the public service remit of the BBC and that it did not exceed actual costs.\n\nThe channel's journalistic output has been overseen by Controller of the channel, Kevin Bakhurst, since 16 December 2005. This was a return to having a dedicated Controller for the channel in the same way as the rest of the BBC's domestic television channels. At launch, Tim Orchard was Controller of News 24 from 1997 until 2000. Editorial decisions were then overseen by Rachel Atwell in her capacity as Deputy Head of television news. Her deputy Mark Popescu became responsible for editorial content in 2004, a role he continued in until the appointment of Bakhurst as Controller in 2005.\n\nA further announcement by Head of television news Peter Horrocks came at the same time as Bakhurst's appointment in which he outlined his plan to provide more funding and resources for the channel and shift the corporation's emphasis regarding news away from the traditional BBC One bulletins and across to the rolling news channel. The introduction of simulcasts of the main bulletins on the channel was to allow the news bulletins to pool resources rather than work against each other at key times in the face of competition particularly from Sky News.\n\nThe BBC Governors' annual report for 2005/2006 reported that average audience figures for fifteen-minute periods had reached 8.6% in multichannel homes, up from 7.8% in 2004/2005. The 2004 report claimed that the channel outperformed Sky News in both weekly and monthly reach in multichannel homes for the January 2004 period, and for the first time in two years moved ahead of Sky News in being perceived as the channel best for news.\n\nOn 21 April 2008, BBC News 24 was renamed \"BBC News\" on the channel itself – but is referred to as the \"BBC News Channel\" on other BBC services. This is part of the creative futures plan, launched in 2006, to bring all BBC News output under the single brand name.\n\nThe BBC News Channel moved from the Studio N8 set, which became home to BBC World News, to what was the home of the national news in Studio N6, allowing the channel to share its set with the \"BBC News at One\" and the \"BBC News at Ten\" – with other bulletins moving to Studio TC7.\n\nThe channel relocated, along with the remaining BBC News services at Television Centre, to the newly refurbished Broadcasting House on 18 March 2013 at 13:00 GMT. Presentation and on-screen graphics were refreshed, with new full HD studios and a live newsroom backdrop. Moving cameras in the newsroom form part of the top of the hour title sequence and are used at the start of weather bulletins.\n\nOn 16 July 2013, the BBC announced that a high-definition (HD) simulcast of BBC News would be launched by early 2014. The channel broadcasts on the BBC's new HD multiplex on Freeview. HD output from BBC News has been simulcast on BBC One HD and BBC Two HD since the move to Broadcasting House in March 2013. The channel launched on 10 December 2013 (at an early date), though will roll-out nationwide up to June 2014 (as will BBC Four HD and CBeebies HD).\n\nEach hour consists of headlines on each quarter-hour, extended at the top of the hour to form the main part of the daily schedule though these are interspaced with other programmes, generally at weekends. This will be often be displaced by rolling news coverage including reports and live interviews. This channel also provides half-hourly weather summaries by forecasters from the BBC Weather centre and the sports news from the BBC Sport centre at MediaCityUK. At 21:25 a global weather forecast is broadcast and 21:55 \"Weather for the Week Ahead\" is broadcast.\n\nThe BBC maintains guidelines for procedures to be taken for breaking news. With domestic news, the correspondent first recorded a \"generic minute\" summary (for use by all stations and channels) and then priority was to report on BBC Radio 5 Live, then on the BBC News channel and any other programmes that are on air. Since 5 Live's move to Manchester, this has been reversed. For foreign news, first a \"generic minute\" is recorded, then reports are to World Service radio, then the reporter talks to any other programmes that are on air.\n\nA key claim made by Lord Lambert in his report had been that the channel was slower to react to breaking news compared with its main rival Sky News. To counteract this, a new feature introduced with the 2003 relaunch was a 'breaking news sting': a globe shown briefly onscreen to direct a viewer's attention to the breaking news.\n\nThe graphics relaunch in January 2007 has since seen the globe sting replaced by a red strapline to highlight the breaking story immediately.\n\nTo complement this, a permanent live news ticker had earlier been introduced in 2006: this had previously been in use only sporadically. News statements are shown as continuously scrolling upper-case text located at the bottom of the screen; some past ambiguities noted have included spelling the plural of MPs as \"MPS\", together with other occasional spelling and grammatical errors. The design of this ticker was slightly altered with the 2007 graphics redesign and from June turned red to indicate breaking news, as \"Newswatch\" reported viewers' confusion. The ticker is removed during trails and weather forecasts.\n\nThe BBC began simulcasting the channel overnight on terrestrial channel BBC One with the launch of the channel, ending the tradition of a closedown but at the same time effectively making the service available to many more viewers. In the early 2000s, BBC Two also started simulcasting the channel, although the weekend morning show \"Weekend 24\" had been simulcast on the channel in the early days. During major breaking news events, the BBC News Channel has been broadcast on BBC One; examples of special broadcasts include the 11 September 2001 attacks, 7 July 2005 London bombings, the capture of Saddam Hussein, and the death of Osama bin Laden.\n\nCoverage of major events has also been simulcast on BBC World News. Currently, overnight viewers receive 25-minute editions of BBC News every hour, and on weekdays 00:00–02:00 receive \"Newsday\", live from Singapore and from London which also includes Asia Business Report and Sport Today between 00:30 and 01:00 and also between 01:30 and 02:00\nFrom 02:00–05:00 (00:00–06:00 on weekends) receive \"BBC World News\". \"The Briefing\" airs between 05:00-06:00 on weekdays.\n\n\"BBC Breakfast\" has been simulcast since launch (in 2000) on BBC One and BBC News, replacing the individual breakfast shows that had run on both channels. Since May 2006, the simulcast runs from 06:00 until 08:30. \"Breakfast\" on BBC One then continues from MediaCityUK until 09:15 with entertainment and features, whilst BBC News goes to BBC Business Live until 09:00 and reverts to its traditional format from 09:00.\n\nThe \"BBC News at Ten\" began simulcasting on the channel on 30 January 2006 as part of the \"Ten O'Clock Newshour\", followed by extended sport and business news updates. The bulletin was joined in being simulcast on 10 April 2006 when the \"BBC News at One\" (with British Sign Language in-vision signing) and \"BBC News at Six\" bulletins were added to the schedule following a similar format to the \"News at Ten\" in terms of content on the channel once each simulcast ends.\n\nDuring the summer, the hour-long programme \"News 24 Sunday\" was broadcast both on BBC One and the BBC News Channel at 09:00, to replace \"The Andrew Marr Show\", which is off air. It was presented by a news presenter, and came from the main News channel studio. The programme was made up mostly of interviews focusing on current affairs, and included a full paper review, a weather summary, and a news update at 09:00, 09:30 and 10:00. \"Sunday Morning Live\" and alternative programming now fill this slot.\n\nFrom 2013, a new programme was created for BBC Two for 11 am – 12 pm weekdays, consisting of 30 minutes domestic and 30 minutes of BBC World News. On Wednesdays, when parliament is sitting the latter is replaced by the Daily Politics for coverage of Prime Ministers Questions. In March 2016 the channel started showing Newsnight at 23:15.\n\n\nPre-recorded programmes include:\n\nPrevious BBC News programming includes \"Head 2 Head\", \"Your News\", \"E24\", \"The Record Europe\", \"STORYFix\" and \"News 24 Tonight\", a weekday evening programme which ran from 2005 to 2008, providing a round up of the day's news.\n\nAs part of budget cuts, major changes to the channel were announced in late 2014/early 2015. This included axing some bulletins and replacing them with \"Victoria Derbyshire\" and \"BBC Business Live\" with Sally Bundock and Ben Thompson in the morning. \"Outside Source with Ros Atkins\" – an \"interactive\" show already broadcast on BBC World News – aired Mondays-Thursday at (During major stories 18:00) and 21:00 and a new edition of \"World News Today\" Friday-Sunday at 21:00 (During major stories 19:00/20:00 Monday-Friday) adding to the 19:00 edition on BBC Four. \"HARDtalk\" was moved to 20:30 in May. The 00:00 edition was replaced on Sundays-Thursday with \"Newsday\" and on Friday-Saturday a standard edition of \"BBC World News\".\n\nBetween 00:00-06:00 (weekdays) UK time, the channel simulcasts with its sister channel, BBC World News, for the first 25 minutes of each hour with world news shown all through the simulcasts.\n\nOn 1 October 2007, BBC World News started broadcasting \"BBC World News America\" and \"World News Today\" at 00:00 and 03:00 GMT respectively. \"World News Today\" was simulcast on the BBC News channel at 03:00 GMT. \"BBC World News America\" used to be aired as a reduced length, time-delayed version at 00:30 GMT, with \"ABC World News Tonight with David Muir\" also being shown at 01:30 every Tuesday-Friday.\n\nFrom 13 June 2011, the weekday editions of BBC News at 01:00, 02:00, 03:00 and 04:00 were replaced with \"Newsday\". The programme acts as a morning news bulletin for the Asia-Pacific region and is broadcast as a double-headed news bulletin with Rico Hizon in Singapore and Babita Sharma in London. \"Asia Business Report\" and \"Sport Today\" are aired at the back of the first three hours of \"Newsday\". But Newsday changed to 23:00–02:00 on BBC News a year later meaning Mike Embley presents Tuesday-Friday \"BBC World News\" 23:00–02:00 with Kasia Madera on Saturdays and Daniela Ritorto 00:00–06:00 Sunday, 02:00–05:00 Friday/Monday.\n\n\"BBC World News\" and \"World Business Report\" air at 05:00. This was previously known as \"The World Today\", However, since November 2017 this has been rebranded as \"The Briefing\" and \"Business Briefing\" on both channels and in lieu of commercials seen on the international broadcasts, the presenters give a brief update on UK news for domestic audiences.\n\nIn June 2015, BBC News began simulcasting \"Outside Source with Ros Atkins\" on Mondays-Thursday at (During major stories 18:00) / at 21:00 and a new edition of \"World News Today\" Friday-Sunday at (during major stories Monday-Friday 19:00) 21:00. Since January 2017, they began simulcasting \"Beyond 100 Days\" (previously '100 Days\" and \"100 Days +) Monday to Thursday at 19:00, presented from London and Washington. During August, \"Beyond 100 Days\" is replaced by another edition of \"World News Today\".\n\nTraditionally, during simulcasts in December, care has been taken to conceal the newsroom Christmas tree for international audiences. From 2015, the 21:00 bulletin has always been an edition of \"World News Today\", replacing \"Outside Source with Ros Atkins\".\n\nSince 5 March 2012, sports bulletins come from the \"BBC Sport Centre\" in MediaCityUK in Salford Quays, where the sports network BBC Radio 5 Live is also based.\n\nHeadlines are usually provided at 15 minutes past the hour with a full bulletin after the bottom-of-the-hour headlines. There are also extended sports bulletins per day, entitled \"Sportsday\" or \"Sport Today\" (when simulcasting with BBC World News) broadcast at 00:45, 01:45, 02:45, 03:45, 13:30, 18:30, 19:30 (weekends only), 22:30 (weekdays only). Each bulletin is read by a single sports presenter, with the exception of Saturday \"Sportsday\", which is double headed.\n\nThe channel's sports bulletins (internally known as Sport 24) have always had a separate, dedicated production gallery, which is also responsible for the graphics.\n\nBulletins during BBC Breakfast are presented by Sally Nugent or Mike Bushell, with the latter also appearing on other sports bulletins on the channel. the main sports presenters on the channel are Olly Foster, Katie Gornall, Katherine Downes, Damian Johnson, Andrew Lindsay and Jenny Culshaw.\n\nUntil March 2012 bulletins came from the News Channel studio at the quarter to the hour. Presenters for bulletins on the channel have included: Reshmin Choudhury, Amanda Davies, Sean Fletcher, Olly Foster, Matt Gooderick, Lizzie Greenwood-Hughes, Celina Hinchcliffe, Rachael Hodges, Damian Johnson, Adnan Nawaz and Olympic gold medallist turned journalist Matthew Pinsent.\n\nBefore BBC News moved to Broadcasting House, an hourly business update was included during the weekday schedule from the BBC Business Unit. There were two shifts, from 08:30–14:00 and 14:00–23:00, presented by Penny Haslam, Maryam Moshiri, Ben Thompson, Adam Parsons, Susannah Streeter, Joe Lynam, Sara Coburn or Sally Eden. News Channel updates were usually broadcast at 40 minutes past the hour between 08:00 and 23:00. The 21:40 round-up was often earlier and the 22:40 bulletin is an extended round-up of the day's business news. Until May 2009, the business updates on the BBC News Channel were broadcast from one of the London Stock Exchange's studios in central London. From then until March 2013 the bulletins were provided from the channel's studio at BBC Television Centre. The business updates were axed in March 2013 as part of the BBC's Delivering Quality First plan. But after complaints returned in November 2013.\n\nStock market updates now only appear during the quarter-to-the-hour headlines. Rachel Horne is the main presenter from 13:30–18:00 with Vishala Sri-Pathma, Alice Baxter, Jamie Robertson, Aaron Heslehurst and Sally Bundock. There is normally an extended bulletin at 16:45 when the main business stories of the day are discussed on \"Afternoon Live.\" Bundock and Thompson present \"Business Live\" on weekdays at 08:30. Declan Curry presented \"Your Money\", a weekly round-up on a Saturday morning.\n\nRico Hizon or Sharanjit Leyl regularly present the main business stories during the early hours of the morning from Singapore during the BBC's \"Asia Business Report\", which is simulcast from BBC World News. Alice Baxter and Sally Bundock present \"World Business Report\".\n\n\n\nSally Bundock, Alice Baxter and Ben Thompson present \"Business Live\" and \"World Business Report\". Ros Atkins presents 'Outside Source'. Philippa Thomas, Alpa Patel, Karin Giannone or Kasia Madera present \"World News Today\" on Weekdays on BBC Four and weekends on the channel. Rico Hizon and Sharanjit Leyl (Reporting from Singapore), Babita Sharma and Madera are the main overnight presenters on the channel, appearing on \"Newsday\" and generic BBC News bulletins. These programmes are simulcast with BBC World News and either BBC One or BBC Two. Madera, Ben Bland and Mike Embley regularly present 02:00–05:00 weekdays and 01:00-06:00 weekends. Bundock or David Eades present \"The Briefing\" and \"Business Briefing\" on weekday mornings on the channel and BBC One.\n\nThe simulcasting of the main national news bulletins has led to the presenters of those bulletins appearing on the channel and offer relief on the news channel including Huw Edwards, Victoria Derbyshire, Fiona Bruce, George Alagiah, Sophie Raworth, Kate Silverton and Mishal Husain. The main \"Breakfast\" presenters have also appeared on the channel since it was first launched as a simulcast programme in 2000, with the current presenters being Dan Walker, Louise Minchin, Charlie Stayt and Naga Munchetty.\n\nThomas presents the BBC World News programme Reporters on the channel, while Gavin Esler presents \"Dateline London\". Stephen Sackur appears on \"HARDtalk\", which is aired weeknights and at weekends, while Zeinab Badawi, Carrie Gracie and Sarah Montague provide cover for him. Spencer Kelly presents the technology news programme \"Click\". \"Newsnight\" host Evan Davis presents \"The Bottom Line\". Lee McKenzie presents \"Inside F1\" on Grand Prix weekend's. Tanya Beckett presents \"Talking Business\" and \"Witness\". Ade Adepitan, Rajan Datar, Christa Larwood, Henry Golding and Carmen Robert present \"The Travel Show\"\n\nDuring a major news event one or more of the main news presenters may be sent to present live for the channel from the scene of the story, where they will conduct interviews with the people involved, question correspondents, introduce related reports and also give general information on the story, much as a reporter sent to cover a story would. The presenters often have expertise in the story they are sent to cover, for example channel presenters and former reporters Ben Brown and Clive Myrie were dispatched to Cairo and Tripoli during the Middle East uprisings.\n\nThe channel was criticised at launch for its style of presentation, with accusations of it being less authoritative than the BBC One news bulletins, with presenters appearing on-screen without jackets. Jenny Abramsky had originally planned to have a television version of the informal news radio channel BBC Radio 5 Live, or a TV version of Radio 4 News FM both of which she had run. The bright design of the set was also blamed for this – one insider reportedly described it as a \"car crash in a shower\" – and was subject to the network relaunch on 25 October 1999. The channel swapped studios with sister channel BBC World, moving to studio N8 within the newsroom, where it remained until 2008. New music and title sequences accompanied this set change, following the look of newly relaunched BBC One bulletins.\n\nGraphics and titles were developed by the Lambie-Nairn design agency and were gradually rolled out across the whole of BBC News, including a similar design for regional news starting with \"Newsroom South East\" and the three 'BBC Nations' – Scotland, Wales and Northern Ireland. The similarity of main BBC News output was intended to increase the credibility of the channel as well as aiding cross-channel promotion.\n\nA graphics relaunch in January 2007 saw the channel updated, with redesigned headline straplines, a redesigned 'digital on-screen graphic' and repositioned clock. The clock was originally placed to the left hand side of the channel name though following complaints that this could only be viewed in widescreen, it was moved to the right in February 2007. Bulletins on BBC World News and BBC One also introduced similar graphics and title sequences on the same day.\n\nIn 2008, the graphics were again relaunched, using the style introduced in 2007 and a new colour scheme.\n\nThe Lambert Report into the channel's performance in 2002 called upon News 24 to develop a better brand of its own, to allow viewers to differentiate between itself and similar channels such as Sky News. As a direct result of this, a brand new style across all presentation for the channel launched on 8 December 2003 at 09:00. Philip Hayton and Anna Jones were the first two presenters on the set, the relaunch of which had been put back a week due to previous power disruptions at Television Centre where the channel was based. The new designs also featured a dynamic set of titles for the channel; the globe would begin spinning from where the main story was taking place, while the headline scrolled around in a ribbon; this was occasionally replaced by the BBC News logo. The titles concluded with a red globe surrounded by a red stylised clamshell and BBC News ribbons forming above the BBC News logo.\n\nBulletins on BBC One moved into a new set in January 2003 although retained the previous ivory Lambie-Nairn titles until February 2004. News 24 updated the title colours slightly to match those of BBC One bulletins in time for the 50th anniversary of BBC television news on 5 July 2004.\n\nAn important part of the channel's presentation since launch has been the top of the hour countdown sequence, since there is no presentation system with continuity announcers so the countdown provides a link to the beginning of the next hour. A similar musical device is used on BBC Radio 5 Live, and mirrors the pips on BBC Radio 4.\n\nPrevious styles have included a series of fictional flags set to music between 1997 and 1999 before the major relaunch, incorporating the new contemporary music composed by David Lowe, and graphics developed by Lambie-Nairn. Various images, originally ivory numbers fully animated against a deep red background, were designed to fit the pace of the channel, and the music soon gained notoriety, and was often satirised and parodied in popular culture, perhaps most famously by comic Bill Bailey who likened the theme music to an \"apocalyptic rave\". Images of life around the UK were added in replacement later with the same music, together with footage of the newsroom and exterior of Television Centre. The 2003 relaunch saw a small change to this style with less of a metropolitan feel to the footage.\n\nA new sequence was introduced on 28 March 2005, designed and created by Red Bee Media and directed by Mark Chaudoir. The full version ran for 60 seconds, though only around 30 seconds were usually shown on air. The music was revised completely but the biggest change came in the footage used – reflecting the methods and nature of newsgathering, while a strong emphasis was placed on the BBC logo itself. Satellite dishes are shown transmitting and receiving red \"data streams\". In production of the countdown sequence, Clive Norman filmed images around the United Kingdom, Richard Jopson in the United States, while BBC News cameramen filmed images from Iraq, Beijing (Tiananmen Square), Bund of Shanghai, Africa, as well as areas affected by the 2004 Asian tsunami and others.\n\nThe sequence has since seen several remixes to the music and a change in visuals to focus more on the well-known journalists, with less footage of camera crews and production teams. Changes have also seen the channel logo included during the sequences and at the end, as well as the fonts used for the time. The conclusion of the countdown was altered in 2008 to feature the new presentation style, rather than a data stream moving in towards the camera. Also in 2008, the graphic for the countdown changed, resembling BBC One Rhythm and Movement Idents, due to the logo being in a red square in inferior-left corner.\n\nTo coincide with the move of BBC News to Broadcasting House, on 18 March 2013 the countdown was updated again along with several other presentation elements. Three of the most striking features of the new countdown include music performed by the BBC Concert Orchestra, a redesign of the \"data streams\" and the ending of the sequence no longer fading to the BBC News globe and logo, but instead stopping with a time-lapse shot outside the corporation's headquarters. The countdown was also extended back to 90 seconds, of which approximately 86 were seen before the first hour from Broadcasting House.\n\nA full three-minute version of the countdown music was made available on BBC News Online and David Lowe's own website after a remix on 16 May 2006.\n\nAn international version of the countdown was launched on BBC World News on 5 September 2005 featuring more international content and similar music. Various changes have been made to the music and visuals since then, with presentation following the style of BBC News. The visuals in the sequence were updated on 10 May 2010. In June 2011, further imagery was added relating to recent events, including the conflict in Libya and views of outside 10 Downing Street. In January 2013, as part of the relocation of BBC News to Broadcasting House in Central London, BBC World News received a new countdown in the same style as the BBC News Channel's updated countdown, with some minor differences.\n\n\n"}
{"id": "4622", "url": "https://en.wikipedia.org/wiki?curid=4622", "title": "Bill Oddie", "text": "Bill Oddie\n\nWilliam Edgar Oddie, (born 7 July 1941) is an English writer, composer, musician, comedian, artist, birder, conservationist, television presenter and actor. He became famous as one of The Goodies.\n\nA birder since his childhood in Quinton, Birmingham, Oddie has established a reputation as a naturalist, conservationist, and television presenter on wildlife issues. Some of his books are illustrated with his own paintings and drawings. His wildlife programmes for the BBC include: \"Springwatch/Autumnwatch\", \"How to Watch Wildlife\", \"Wild In Your Garden\", \"Birding with Bill Oddie\", \"Britain Goes Wild with Bill Oddie\" and \"Bill Oddie Goes Wild\".\n\nOddie was born in Rochdale but moved to Birmingham at a young age; his father was assistant chief accountant at the Midlands Electricity Board. His mother was diagnosed with schizophrenia and, during most of his youth, lived in a hospital. He was educated at Lapal Primary School, Halesowen Grammar School (now The Earls High School, Halesowen) and King Edward's School, Birmingham, an all-boys direct grant school (since 1976, an independent school), where he captained the school's rugby union team. He then studied English Literature at Pembroke College, Cambridge.\n\nWhilst at Cambridge University Oddie appeared in several Footlights Club productions. One of these, a revue called \"A Clump of Plinths\", was so successful at the Edinburgh Festival Fringe that it was renamed \"Cambridge Circus\" and transferred to the West End in London, then New Zealand and Broadway in September 1964. Meanwhile, still at Cambridge, Oddie wrote scripts for and appeared briefly in TV's \"That Was The Week That Was\".\n\nHe appeared in Bernard Braden's television series \"On The Braden Beat\" in 1964. Subsequently, he was a key member of the performers in the BBC radio series \"I'm Sorry, I'll Read That Again\", where many of his musical compositions were featured. Some were released on the album \"Distinctly Oddie\" (Polydor, 1967). He was one of the first performers to parody a rock song, arranging the traditional Yorkshire folk song \"On Ilkla Moor Baht'at\" in the style of Joe Cocker's hit rendition of the Beatles' \"With a Little Help from My Friends\" (released on John Peel's Dandelion Records in 1970 and featured in Peel's special box of most-treasured singles), and singing \"Andy Pandy\" in the style of a brassy soul number such as Wilson Pickett or Geno Washington might perform. In many shows he would do short impressions of Hughie Green.\n\nOn television Oddie was co-writer and performer in the comedy series \"Twice a Fortnight\" with Graeme Garden, Terry Jones, Michael Palin and Jonathan Lynn. Later, he was co-writer and performer in the comedy series \"Broaden Your Mind\" with Tim Brooke-Taylor and Graeme Garden, for which Oddie became a cast member for the second series.\n\nOddie, Brooke-Taylor and Garden then co-wrote and appeared in their television comedy series \"The Goodies\". The Goodies also released records, including \"Father Christmas Do Not Touch Me\"/\"The In-Betweenies\", \"Funky Gibbon\", and \"Black Pudding Bertha\", which were hit singles in 1974–75. They reformed, briefly, in 2005, for a successful 13-date tour of Australia.\n\nOddie, Brooke-Taylor and Garden voiced characters on the 1983 animated children's programme \"Bananaman\".\n\nIn the Amnesty International show \"A Poke in the Eye (With a Sharp Stick)\", Oddie, Brooke-Taylor and Garden sang their hit song \"Funky Gibbon\". They also appeared on \"Top of the Pops\" with the song. Together with Garden (who is a qualified doctor), Oddie co-wrote many episodes of the television comedy series \"Doctor in the House\", including most of the first season and all of the second season. He has occasionally appeared on the BBC Radio 4 panel game \"I'm Sorry I Haven't a Clue\", on which Garden and Brooke-Taylor are regular panellists. In 1982 Garden and Oddie wrote, but did not perform in, a six-part science fiction sitcom called \"Astronauts\" for Central and ITV. The show was set in an international space station in the near future.\n\nOddie's first published work was an article about the birdlife of Birmingham's Bartley Reservoir in the West Midland Bird Club's 1962 Annual Report (he is first credited in the 1956 report, in which reports of his bird observations are tagged with his initials \"WEO\"). He has since written a number of books about birds and birdwatching, as well as articles for many specialist publications including \"British Birds\", \"Birdwatching Magazine\" and \"Birdwatch\".\n\nHe discussed bird song recordings with Derek Jones in an August 1973 BBC Radio 4 programme called \"Sounds Natural\".\n\nIn the autumn of 1976 Oddie was involved in the successful identification of Britain's first ever record of Pallas's reed bunting on Fair Isle, Shetland.\n\nOne of Oddie's first forays in the world of television natural history was as a guest on \"Animal Magic\" in December 1977. Another early natural history radio appearance was in October, as the guest on Radio 4's \"Through My Window\", discussing the birds of Hampstead Heath.\n\nOn 30 July 1985, he was the subject of a 50-minute \"Nature Watch Special: Bill Oddie – Bird Watcher\", in which he was interviewed by Julian Pettifer at places where he had spent time birding, including Bartley Reservoir, the Christopher Cadbury Wetland Reserve at Upton Warren, RSPB Titchwell Marsh and Blakeney Point.\n\nOddie has since hosted a number of successful nature programmes for the BBC, many produced by Stephen Moss, including:\n\n\n\nOn its first evening of broadcast in 2004, \"Britain Goes Wild\" set a record for its timeslot of 8 pm on BBC Two of 3.4 million viewers, one million more than the Channel 4 programme showing at that time. \"Britain Goes Wild\", renamed \"Springwatch\" the following year, became a wildlife broadcasting phenomenon, attracting up to 5 million viewers. \n\nHe became president of the West Midland Bird Club in 1999, having been Vice-President since 1991, and is a former member of the council of the RSPB. Oddie is also a President of the League Against Cruel Sports and a vice-president of the British Trust for Conservation Volunteers. He practised as a bird ringer, but allowed his licence to lapse.\n\nIn 2003 Oddie set up a half-marathon to raise money for various wildlife charities in his birth-town of Rochdale. Celebrities who have participated in the event include Ray Mears, Catherine Jenkins and Hugh Fearnley-Whittingstall.\n\nIn 2011, Oddie featured as an investigator in \"Snares Uncovered: killers in the countryside\". The film carried out an exposé of snaring in Scotland and was commissioned by animal protection charity OneKind. During the investigation, Oddie discovered over 70 snare traps and several stink pits.\n\nOddie wrote original music at Cambridge University for the Footlights and later wrote comic songs for \"I'm Sorry, I'll Read That Again\". He also wrote a number of comic songs for The Goodies, most of them performed by Oddie.\n\nIn the 1960s and early 1970s, Oddie released a number of singles and at least one album. One of the former, issued in 1970 on John Peel's Dandelion Records label (Catalogue No: 4786), was \"On Ilkla Moor Baht 'at\", performed in the style of Joe Cocker's \"With a Little Help from my Friends\". The B-side, \"Harry Krishna\", featured the Hare Krishna chant, substituting the names of contemporary famous people called Harry, including Harry Secombe, Harry Worth, Harry Lauder, and Harry Corbett, as well as puns such as \"Harry [Hurry] along now\", \"Harrystotle [Aristotle]\" and ending with \"Harry-ly [I really] must go now\". Both tracks appear on the compilation CD \"Life Too, Has Surface Noise: The Complete Dandelion Records Singles Collection 1969–1972\" (2007).\n\nHe played the drums and saxophone and appeared as Cousin Kevin in a production of The Who's rock opera \"Tommy\" at the Rainbow Theatre, Finsbury Park, London, on 9 December 1972. He has also contributed vocals to a Rick Wakeman album, \"Criminal Record\".\n\nOddie took part in the English National Opera production of the Gilbert and Sullivan comic opera \"The Mikado\", in which he appeared in the role of the \"Lord High Executioner\", taking over the role from Eric Idle. During the early 1990s, Oddie was a DJ for London-based jazz radio station 102.2 Jazz FM.\n\nIn 2007 Oddie appeared on the BBC series \"Play It Again\". In the episode he attempts to realise his dream of becoming a rock guitarist. Initially teacher Bridget Mermikides tries to teach him using traditional methods but he rebels: instead he turns to old friends Albert Lee, Dave Davies (of The Kinks) and Mark Knopfler for advice and strikes out on his own. He succeeds in the target of playing lead guitar for his daughter Rosie's band at her 21st birthday party, and even manages to impress his erstwhile teacher.\n\nIn November 2010, he agreed, along with fellow members of The Goodies, to re-release their 1970s hit \"The Funky Gibbon\" to raise funds for the International Primate Protection League's Save the Gibbon appeal.\n\nOddie appeared as the hapless window cleaner in the Eric Sykes' comedy story \"The Plank\" in 1967. He also presented the live children's Saturday morning entertainment show \"Saturday Banana\" (ITV/Southern Television) during the late 1970s. In the late 1980s he was a presenter of the BBC TV show \"Fax\" (a show about 'facts').\n\nIn 1981 he appeared as a Telethon celebrity in New Zealand, hosted by TV1. He voices Asterix in the UK dub of the 1989 animated film \"Asterix and the Big Fight\" (an animated adaptation of the books \"Asterix and the Big Fight\" and \"Asterix and the Soothsayer\", novelized as \"Operation Getafix\").\n\nIn the 1990s he became better known as a presenter of birdwatching, and later wildlife-related, programmes such as \"Springwatch\". Although he remains almost unknown to US audiences, in 1992 he was a guest star in the US comedy television series \"Married... with Children\" for a 3-part episode set in England.\n\nIn 1997–98 he appeared on the Channel 4 archaeological programme \"Time Team\", as the team excavated a Roman villa site in Turkdean, Gloucestershire.\n\nHe was the compère of a daytime BBC gameshow \"History Hunt\" (in 2003); and has appeared in the \"Doctor Who\" audio drama \"Doctor Who and the Pirates\". In 2004, he appeared in the BBC show \"Who Do You Think You Are?\", in which he looked into his ancestry – he was visibly moved by its revelations. His story, in fact, was that long-running series' very first episode. In 2005, he took part in \"Rolf on Art – the big event at Trafalgar Square\" and in September that year was also a celebrity guest along with Lynda Bellingham on the ITV1 programme \"Who Wants to be a Millionaire\". He also gave out opinions in 100 greatest cartoons on Channel 4 that year, talking about cartoon incidents such as the Asses of Fire skit in .\n\nIn 2006 Oddie appeared in the BBC show \"Never Mind The Buzzcocks\", and also appeared on the topical quiz show \"8 out of 10 Cats\". He was also the voice behind many B&Q adverts throughout 2006/2007. On 25 May 2007, Oddie made a cameo appearance on Ronni Ancona's new comedy sketch show, \"Ronni Ancona & Co\".\n\nAlso in 2007, three artists each painted a portrait of Oddie, as part of the BBC programme \"Star Portraits with Rolf Harris\". one of the artists, Mark Roscoe, later revealed a dislike of Oddie, claiming to have included hidden insults in his work.\n\nHe hosted the genealogy-based series \"My Famous Family\", broadcast on UKTV History in 2007. In 2008, Oddie was a guest on Jamie Oliver's television special \"Jamie's Fowl Dinners\", talking about free-range chickens.\n\nHe also appeared on \"Would I Lie To You?\" in 2011 where he revealed that he was saved from drowning by Freddy from popular children's series \"Rainbow\" and \"Rod, Jane and Freddy\" while on holiday in the Seychelles.\nIn February 2015, Oddie appeared in \"The Keith Lemon Sketch Show\" as the narrator of the sketch \"Ed Sheeran Watch\".\n\nHe appeared as a contestant on a celebrity edition of \"Fifteen to One\" in August 2015.\n\nOddie undertook an Australian tour during June 2013 in all of the mainland states capital cities – Brisbane, Sydney, Melbourne, Adelaide and Perth – in a series of one-off shows, \"\"An Oldie but a Goodie\"\". A video message from Tim Brooke-Taylor and Graeme Garden was shown during the performances. Oddie made personal appearances on both \"The Project\" and \"Adam Hills Tonight\" TV shows during the tour; he also filmed a guest-programming spot for the ABC-TV's all-night music video show \"Rage\".\n\nIn 1967 Oddie married Jean Hart, and from this marriage he has two daughters, Bonnie Oddie and Kate Hardie, an actress, as well as three grandchildren, Lyle, Ella, and Gracie.\n\nIn 1983 he married Laura Beaumont-Giles, with whom he has worked on a variety of projects for children, including film scripts, drama and comedy series, puppet shows and books. They have a daughter, Rosie, born in October 1985, and live in Hampstead, North London. Rosie Oddie is a musician, also using the name Rosie Bones.\n\nOddie has suffered from depression for most of his life and was diagnosed with clinical depression in 2001. On 11 March 2009 it was reported that he had been admitted to Capio Nightingale psychiatric hospital in Marylebone, to deal with his depression. His then agent David Foster said: \"Bill gets these bouts every two or three years where he gets down for about two weeks and recovers. He sometimes goes into hospital or takes a break or has a change of scenery to recharge his batteries.\" In January 2010 Oddie spoke to the media, revealing that he had in fact had two separate stays in different hospitals, only being discharged \"in time for Christmas\". He said that he was dealing with depression and bipolar disorder, describing the period as \"probably the worst 12 months of my life\". Oddie stated that he was planning to meet with BBC executives to discuss his return to television work.\n\nHis illness meant that Oddie did not appear in the 2009 and 2010 series of \"Springwatch\", although he made a guest appearance in the penultimate episode of the latter. He subsequently claimed he was dismissed from \"Springwatch\" and that this had caused the depressive illness.\n\nOddie presented the BBC Radio 4 Appeal programme on 10 August 2014 on behalf of the charity Bipolar UK. He revealed that as a consequence of his bipolar disorder he had attempted suicide during one of his depressive episodes. On the UK TV programme \"Who Do You Think You Are?\" he attributed his depression and bipolar disorder as an adult to his minimal and painful relationship with his mother.\n\nOddie supports the Green Party. In October 2014, on the BBC's \"Sunday Morning Live\", he stated that he wanted a limit on the number of children that British families can have, saying that he was \"very often ashamed\" to be British, whom he called \"a terrible race\".\n\nIn 2001, Oddie became the third person to decline to appear on \"This Is Your Life\". He changed his mind a few hours later and agreed to appear on the show. On 16 October 2003, Oddie was made an OBE for his service to Wildlife Conservation in a ceremony at Buckingham Palace. He played down the event, choosing to wear a camouflage shirt and crumpled jacket to receive his medal. In June 2004, Oddie and Johnny Morris were jointly profiled in the first of a three part BBC Two series, \"The Way We Went Wild\", about television wildlife presenters. In May 2005, he received the British Naturalists' Association's Peter Scott Memorial Award, from BNA president David Bellamy, \"in recognition of his great contribution to our understanding of natural history and conservation.\" He is a recipient of the RSPB Medal.\n\nOn 30 June 2009, he was proposed for inclusion in the Birmingham Walk of Stars, with the public invited to vote.\n\nBill Oddie also co-wrote the Springwatch & Autumnwatch book with Kate Humble and Simon King.\n\nCo-written with the other members of The Goodies:\n\nCo-written with Laura Beaumont:\n\n\nIn the fictional world of comedy character Alan Partridge, Oddie is an unseen presence in Alan's life.\n\nHe has also been referenced, often humorously, by the hosts of \"Top Gear\". Jeremy Clarkson even used a mask with Oddie's face to escape speed cameras while racing the Nissan GT-R against the Bullet train in Japan in Episode 4 of \"Top Gear\"s 11th series. James May also raced in Finland against an Oddie lookalike who won the race.\n\n\n"}
{"id": "4626", "url": "https://en.wikipedia.org/wiki?curid=4626", "title": "Broadway (Manhattan)", "text": "Broadway (Manhattan)\n\nBroadway is a road in the U.S. state of New York. Broadway runs from State Street at Bowling Green for through the borough of Manhattan and through the Bronx, exiting north from the city to run an additional through the municipalities of Yonkers, Hastings-On-Hudson, Dobbs Ferry, Irvington, and Tarrytown, and terminating north of Sleepy Hollow in Westchester County.\n\nIt is the oldest north–south main thoroughfare in New York City, dating to the first New Amsterdam settlement, although most of it did not bear its current name until the late 19th century. The name \"Broadway\" is the English language literal translation of the Dutch name, \"Brede weg\".\n\nBroadway in Manhattan is known widely as the heart of the American theatre industry, and is used as a metonym for it.\n\nBroadway was originally the Wickquasgeck Trail, carved into the brush of Manhattan by its Native American inhabitants. Wickquasgeck means \"birch-bark country\" in the Algonquian language. This trail originally snaked through swamps and rocks along the length of Manhattan Island.\n\nUpon the arrival of the Dutch, the trail soon became the main road through the island from \"Nieuw Amsterdam\" at the southern tip. The Dutch explorer and entrepreneur David Pietersz. de Vries gives the first mention of it in his journal for the year 1642 (\"the Wickquasgeck Road over which the Indians passed daily\"). The Dutch named the road \"\"Breede Weg\"\". Although current street signs are simply labeled as \"Broadway\", in a 1776 map of New York City, Broadway is explicitly labeled \"Broadway Street\". In the mid-eighteenth century, part of Broadway in what is now lower Manhattan was known as \"Great George Street\". An 1897 City Map shows a segment of Broadway as \"Kingsbridge Road\" in the vicinity of what is now the George Washington Bridge.\n\nIn the 18th century, Broadway ended at the town commons north of Wall Street, where traffic continued up the East Side of the island via Eastern Post Road and the West Side via Bloomingdale Road. The western Bloomingdale Road would be widened and paved during the 19th century, and called \"Western Boulevard\" or \"The Boulevard\" north of the Grand Circle, now called Columbus Circle. On February 14, 1899, the name \"Broadway\" was extended to the entire Broadway/Bloomingdale/Boulevard road.\n\nBroadway once was a two-way street for its entire length. The present status, in which it runs one-way southbound south of Columbus Circle (59th Street), came about in several stages. On June 6, 1954, Seventh Avenue became southbound and Eighth Avenue became northbound south of Broadway. None of Broadway became one-way, but the increased southbound traffic between Columbus Circle (Eighth Avenue) and Times Square (Seventh Avenue) caused the city to re-stripe that section of Broadway for four southbound and two northbound lanes. Broadway became one-way from Columbus Circle south to Herald Square (34th Street) on March 10, 1957, in conjunction with Sixth Avenue becoming one-way from Herald Square north to 59th Street and Seventh Avenue becoming one-way from 59th Street south to Times Square (where it crosses Broadway). On June 3, 1962, Broadway became one-way south of Canal Street, with Trinity Place and Church Street carrying northbound traffic. \n\nAnother change was made on November 10, 1963, when Broadway became one-way southbound from Herald Square to Madison Square (23rd Street) and Union Square (14th Street) to Canal Street, and two routes – Sixth Avenue south of Herald Square and Centre Street, Lafayette Street, and Fourth Avenue south of Union Square – became one-way northbound. Finally, at the same time as Madison Avenue became one-way northbound and Fifth Avenue became one-way southbound, Broadway was made one-way southbound between Madison Square (where Fifth Avenue crosses) and Union Square on January 14, 1966, completing its conversion south of Columbus Circle.\n\nIn 2001, a one-block section of Broadway between 72nd Street and 73rd Street at Verdi Square was reconfigured. Its easternmost lanes, which formerly hosted northbound traffic, were turned into a public park when a new subway entrance for the 72nd Street station was built in the exact location of these lanes. Northbound traffic on Broadway is now channeled onto Amsterdam Avenue to 73rd Street, makes a left turn on the three-lane 73rd Street, and then a right turn on Broadway shortly afterward.\n\nIn August 2008, two traffic lanes from 42nd to 35th Streets were taken out of service and converted to public plazas. Additionally, bike lanes were added on Broadway from 42nd Street down to Union Square.\n\nSince May 2009, the portions of Broadway through Duffy Square, Times Square, and Herald Square have been closed entirely to automobile traffic, except for cross traffic on the Streets and Avenues, as part of a traffic and pedestrianization experiment, with the pavement reserved exclusively for walkers, cyclists, and those lounging in temporary seating placed by the city. The city decided that the experiment was successful and decided to make the change permanent in February 2010. Though the anticipated benefits to traffic flow were not as large as hoped, pedestrian injuries dropped dramatically and foot traffic increased in the designated areas; the project was popular with both residents and businesses. The current portions converted into pedestrian plazas are between West 47th Street and West 42nd Street within Times and Duffy Squares, and between West 35th Street and West 33rd Street in the Herald Square area. Additionally, portions of Broadway in the Madison Square and Union Square have been dramatically narrowed, allowing ample pedestrian plazas to exist along the side of the road.\n\nIn May 2013, the NYCDOT decided to redesign Broadway between 35th and 42nd Streets for the second time in five years, owing to poor connections between pedestrian plazas and decreased vehicular traffic. With the new redesign, the bike lane is now on the right side of the street; it was formerly on the left side adjacent to the pedestrian plazas, causing conflicts between pedestrian and bicycle traffic.\n\nIn spring 2017, as part of a capital reconstruction of Worth Square, Broadway between 24th and 25th Street was converted to a \"shared street\" where through vehicles are banned and delivery vehicles are restricted to . Delivery vehicles go northbound from Fifth Avenue to 25th Street for that one block, reversing the direction of traffic and preventing vehicles from going south on Broadway south of 25th Street. The capital project expands on a 2008 initiative where part of the intersection of Broadway and Fifth Avenue was repurposed into a public plaza, simplifying that intersection. As part of the 2017 project, Worth Square was expanded, converting the adjoining block of Broadway into a \"shared street.\"\n\nBroadway runs the length of Manhattan Island, roughly parallel to the North River (the portion of the Hudson River bordering Manhattan), from Bowling Green at the south to Inwood at the northern tip of the island. South of Columbus Circle, it is a one-way southbound street. Since 2009, vehicular traffic has been banned at Times Square between 47th and 42nd Streets, and at Herald Square between 35th and 33rd Streets as part of a pilot program; the right-of-way is intact and reserved for cyclists and pedestrians. From the northern shore of Manhattan, Broadway crosses Spuyten Duyvil Creek via the Broadway Bridge and continues through Marble Hill (a discontinuous portion of the borough of Manhattan) and the Bronx into Westchester County. U.S. 9 continues to be known as Broadway until its junction with NY 117.\n\nThe section of lower Broadway from its origin at Bowling Green to City Hall Park is the historical location for the city's ticker-tape parades, and is sometimes called the \"Canyon of Heroes\" during such events. West of Broadway, as far as Canal Street, was the city's fashionable residential area until circa 1825; landfill has more than tripled the area, and the Hudson River shore now lies far to the west, beyond Tribeca and Battery Park City.\n\nBroadway marks the boundary between Greenwich Village to the west and the East Village to the east, passing Astor Place. It is a short walk from there to New York University near Washington Square Park, which is at the foot of Fifth Avenue. A bend in front of Grace Church allegedly avoids an earlier tavern; from 10th Street it begins its long diagonal course across Manhattan, headed almost due north.\n\nBecause Broadway preceded the grid that the Commissioners' Plan of 1811 imposed on the island, Broadway crosses midtown Manhattan diagonally, intersecting with both the east-west streets and north-south avenues. Broadway's intersections with avenues, marked by \"squares\" (some merely triangular slivers of open space), have induced some interesting architecture, such as the Flatiron Building.\n\nAt Union Square, Broadway crosses 14th Street, merges with Fourth Avenue, and continues its diagonal uptown course from the Square's northwest corner; Union Square is the only location wherein the physical section of Broadway is discontinuous in Manhattan (other portions of Broadway in Manhattan are pedestrian-only plazas). At Madison Square, the location of the Flatiron Building, Broadway crosses Fifth Avenue at 23rd Street, and is discontinuous to vehicles for a one-block stretch between 24th and 25th Streets. At Greeley Square (West 33rd Street), Broadway crosses Sixth Avenue (Avenue of the Americas), and is discontinuous to vehicles. Macy's Herald Square department store, one block north of the vehicular discontinuity, is located on the northwest corner of Broadway and West 34th Street and southwest corner of Broadway and West 35th Street; it is one of the largest department stores in the world.\n\nOne famous stretch near Times Square, where Broadway crosses Seventh Avenue in midtown Manhattan, is the home of many Broadway theatres, housing an ever-changing array of commercial, large-scale plays, particularly musicals. This area of Manhattan is often called the Theater District or the Great White Way, a nickname originating in the headline \"Found on the Great White Way\" in the edition of February 3, 1902 of the \"New York Evening Telegram\". The journalistic nickname was inspired by the millions of lights on theater marquees and billboard advertisements that illuminate the area. After becoming the city's de facto red-light district in the 1960s and 1970s (as can be seen in the films \"Taxi Driver\" and \"Midnight Cowboy\"), since the late 1980s Times Square has emerged as a family tourist center, in effect being Disneyfied following the company's purchase and renovation of the New Amsterdam Theatre on 42nd Street in 1993.\n\nUntil June 2007, \"The New York Times\", from which the Square gets its name, was published at offices at 239 West 43rd Street; the paper stopped printing papers there on June 15, 2007.\n\nAt the southwest corner of Central Park, Broadway crosses Eighth Avenue (called Central Park West north of 59th Street) at West 59th Street and Columbus Circle; on the site of the former New York Coliseum convention center is the new shopping center at the foot of the Time Warner Center, headquarters of Time Warner. From Columbus Circle northward, Broadway becomes a wide boulevard to 169th Street; it retains landscaped center islands that separate northbound from southbound traffic. The medians are a vestige of the central mall of \"The Boulevard\" that had become the spine of the Upper West Side, and many of these contain public seating.\n\nBroadway intersects with Columbus Avenue (known as Ninth Avenue south of West 59th Street) at West 65th and 66th Streets where the Juilliard School and Lincoln Center, both well-known performing arts landmarks, as well as the Manhattan New York Temple of The Church of Jesus Christ of Latter-day Saints are located.\n\nBetween West 70th and 73rd Streets, Broadway intersects with Amsterdam Avenue (known as 10th Avenue south of West 59th Street). The wide intersection of the two thoroughfares has historically been the site of numerous traffic accidents and pedestrian casualties, partly due to the long crosswalks. Two small triangular plots of land were created at points where Broadway slices through Amsterdam Avenue. One is a tiny fenced-in patch of shrubbery and plants at West 70th Street called Sherman Square (although it and the surrounding intersection have also been known collectively as Sherman Square), and the other triangle is a lush tree-filled garden bordering Amsterdam Avenue from just above West 72nd Street to West 73rd Street. Named Verdi Square in 1921 for its monument to Italian composer Giuseppe Verdi, which was erected in 1909, this triangular sliver of public space was designated a Scenic Landmark by the Landmarks Preservation Commission in 1974, one of nine city parks that have received the designation. In the 1960s and 1970s, the area surrounding both Verdi Square and Sherman Square was known by local drug users and dealers as \"Needle Park\", and was featured prominently in the gritty 1971 dramatic film \"The Panic in Needle Park\", directed by Jerry Schatzberg and starring Al Pacino in his second onscreen role.\n\nThe original brick and stone shelter leading to the entrance of the 72nd Street subway station, one of the first 28 subway stations in Manhattan, remains located on one of the wide islands in the center of Broadway, on the south side of West 72nd Street. For many years, all traffic on Broadway flowed on either side of this median and its subway entrance, and its uptown lanes went past it along the western edge of triangular Verdi Square. In 2001 and 2002, renovation of the historic 72nd Street station and the addition of a second subway control house and passenger shelter on an adjacent center median just north of 72nd Street, across from the original building, resulted in the creation of a public plaza with stone pavers and extensive seating, connecting the newer building with Verdi Square, and making it necessary to divert northbound traffic to Amsterdam Avenue for one block. While Broadway's southbound lanes at this intersection were unaffected by the new construction, its northbound lanes are no longer contiguous at this intersection. Drivers can either continue along Amsterdam Avenue to head uptown or turn left on West 73rd Street to resume traveling on Broadway.\n\nSeveral notable apartment buildings are in close proximity to this intersection, including The Ansonia, its ornate architecture dominating the cityscape here. After the Ansonia first opened as a hotel, live seals were kept in indoor fountains inside its lobby. Later, it was home to the infamous Plato's Retreat nightclub. Immediately north of Verdi Square is the formidable Apple Bank for Savings building, formerly the Central Savings Bank, which was built in 1926 and designed to resemble the Federal Reserve Bank of New York. Broadway is also home to the Beacon Theatre at West 74th Street, designated a national landmark in 1979 and still in operation as a concert venue after its establishment in 1929 as a vaudeville and music hall, and \"sister\" venue to Radio City Music Hall.\n\nAt its intersection with West 78th Street, Broadway shifts direction and continues directly uptown and aligned approximately with the Commissioners' grid. Past the bend are the historic Apthorp apartment building, built in 1908, and the First Baptist Church in the City of New York, incorporated in New York in 1762, its current building on Broadway erected in 1891. The road heads north and passes historically important apartment houses such as the Belnord, the Astor Court Building, and the Art Nouveau Cornwall.\n\nAt Broadway and 95th Street is Symphony Space, established in 1978 as home to avant-garde and classical music and dance performances in the former Symphony Theatre, which was originally built in 1918 as a premier \"music and motion-picture house\". At 99th Street, Broadway passes between the controversial skyscrapers of the Ariel East and West.\n\nAt 107th Street, Broadway merges with West End Avenue, with the intersection forming Straus Park with its Titanic Memorial by Augustus Lukeman.\n\nBroadway then passes the campus of Columbia University at 116th Street in Morningside Heights, in part on the tract that housed the Bloomingdale Insane Asylum from 1808 until it moved to Westchester County in 1894. Still in Morningside Heights, Broadway passes the park-like campus of Barnard College. Next, the Gothic quadrangle of Union Theological Seminary and the brick buildings of the Jewish Theological Seminary of America with their landscaped interior courtyards face one another across Broadway. On the next block is the Manhattan School of Music.\n\nBroadway then runs past the proposed uptown campus of Columbia University, and the main campus of CUNY–City College near 135th Street; the Gothic buildings of the original City College campus are out of sight, a block to the east. Also to the east are the brownstones of Hamilton Heights. Hamilton Place is a surviving section of Bloomingdale Road, and originally the address of Alexander Hamilton's house, The Grange, which has been moved.\n\nBroadway achieves a verdant, park-like effect, particularly in the spring, when it runs between the uptown Trinity Church Cemetery and the former Trinity Chapel, now the Church of the Intercession near 155th Street.\n\nNewYork–Presbyterian Hospital lies on Broadway near 166th, 167th, and 168th Streets in Washington Heights. The intersection with St. Nicholas Avenue at 167th Street forms Mitchell Square Park. At 178th Street, U.S. 9 becomes concurrent with Broadway.\n\nBroadway crosses the Harlem River on the Broadway Bridge to Marble Hill. Afterward, it then enters the Bronx, where it is the eastern border of Riverdale and the western border of Van Cortlandt Park. At 253rd Street, NY 9A joins with U.S. 9 and Broadway. (NY 9A splits off Broadway at Ashburton Avenue in Yonkers.)\n\nThe northwestern corner of the park marks the city limit and Broadway enters Yonkers, where it is now known as South Broadway. It trends ever westward, closer to the Hudson River, remaining a busy urban commercial street. In downtown Yonkers, it drops close to the river, becomes North Broadway and 9A leaves via Ashburton Avenue. Broadway climbs to the nearby ridgetop runs parallel to the river and the railroad, a few blocks east of both as it passes St. John's Riverside Hospital. The neighborhoods become more residential and the road gently undulates along the ridgetop. In Yonkers, Broadway passes historic Philipse Manor house, which dates back to colonial America.\n\nIt remains Broadway as it leaves Yonkers for Hastings-on-Hudson, where it splits into separate north and south routes for . The trees become taller and the houses, many separated from the road by stone fences, become larger. Another National Historic Landmark, the John William Draper House, was the site of the first astrophotograph of the Moon.\n\nIn the next village, Dobbs Ferry, Broadway has various views of the Hudson River while passing through the residential section. Broadway passes by the Old Croton Aqueduct and nearby the shopping district of the village. After intersecting with Ashford Avenue, Broadway passes Mercy College, then turns left again at the center of town just past South Presbyterian Church, headed for equally comfortable Ardsley-on-Hudson and Irvington. Villa Lewaro, the home of Madam C. J. Walker, the first African-American millionaire, is along the highway here. At the north end of the village of Irvington, a memorial to writer Washington Irving, after whom the village was renamed, marks the turnoff to his home at Sunnyside. Entering into the southern portion of Tarrytown, Broadway passes by historic Lyndhurst mansion, a massive mansion built along the Hudson River built in the early 1800s.\n\nNorth of here, at the Kraft Foods technical center, the Tappan Zee Bridge becomes visible. After crossing under the Thruway and I-87 again, here concurrent with I-287, and then intersecting with the four-lane NY 119, where 119 splits off to the east, Broadway becomes the busy main street of Tarrytown. Christ Episcopal Church, where Irving worshiped, is along the street. Many high quality restaurants and shops are along this main road. This downtown ends at the eastern terminus of NY 448, where Broadway slopes off to the left, downhill, and four signs indicate that Broadway turns left, passing the Old Dutch Church of Sleepy Hollow, another NHL. The road then enters Sleepy Hollow (formerly North Tarrytown), passing the visitors' center for Kykuit, the National Historic Landmark that was (and partially still is) the Rockefeller family's estate. Broadway then passes the historic Sleepy Hollow Cemetery, which includes the resting place of Washington Irving and the setting for The Legend of Sleepy Hollow.\n\nBroadway expands to four lanes at the trumpet intersection with NY 117, where it finally ends and U.S. 9 becomes Albany Post Road (and Highland Avenue) at the northern border of Sleepy Hollow, New York.\n\n\"Canyon of Heroes\" is occasionally used to refer to the section of lower Broadway in the Financial District that is the location of the city's ticker-tape parades.\n\nThe traditional route of the parade is northward from Bowling Green to City Hall Park. Most of the route is lined with tall office buildings along both sides, affording a view of the parade for thousands of office workers who create the snowstorm-like jettison of shredded paper products that characterize the parade.\n\nWhile typical sports championship parades have been showered with some 50 tons of confetti and shredded paper, the V-J Day parade on August 14–15, 1945 – marking the end of World War II – was covered with 5,438 tons of paper, based on estimates provided by the New York City Department of Sanitation.\n\nMore than 200 black granite strips embedded in the sidewalks along the Canyon of Heroes list honorees of past ticker-tape parades.\n\nThe most recent parade up the Canyon of Heroes took place on July 10, 2015 for the United States women's national soccer team in honor of their 2015 FIFA Women's World Cup championship.\n\n\"The Great White Way\" is a nickname for a section of Broadway in Midtown Manhattan, specifically the portion that encompasses the Theater District, between 42nd and 53rd Streets, and encompassing Times Square.\n\nIn 1880, a stretch of Broadway between Union Square and Madison Square was illuminated by Brush arc lamps, making it among the first electrically lighted streets in the United States. By the 1890s, the portion from 23rd Street to 34th Street was so brightly illuminated by electrical advertising signs, that people began calling it \"The Great White Way\". When the theater district moved uptown, the name was transferred to the Times Square area.\n\nThe phrase \"Great White Way\" has been attributed to Shep Friedman, columnist for the \"New York Morning Telegraph\" in 1901, who lifted the term from the title of a book about the Arctic by Albert Paine. The headline \"Found on the Great White Way\" appeared in the February 3, 1902, edition of the \"New York Evening Telegram\".\n\nA portrait of Broadway in the early part of the 20th century and \"The Great White Way\" late at night appeared in \"Artist In Manhattan\" (1940) written by the artist-historian Jerome Myers:\n\nFrom south to north, Broadway at one point or another runs over or under various New York City Subway lines, including the IRT Lexington Avenue Line, the BMT Broadway Line, IRT Broadway–Seventh Avenue Line, and IND Eighth Avenue Line (the IND Sixth Avenue Line is the only north-south trunk line in Manhattan that does not run along Broadway).\n\nEarly street railways on Broadway included the Broadway and Seventh Avenue Railroad's Broadway and University Place Line (1864?) between Union Square (14th Street) and Times Square (42nd Street), the Ninth Avenue Railroad's Ninth and Amsterdam Avenues Line (1884) between 65th Street and 71st Street, the Forty-second Street, Manhattanville and St. Nicholas Avenue Railway's Broadway Branch Line (1885?) between Times Square and 125th Street, and the Kingsbridge Railway's Kingsbridge Line north of 169th Street. The Broadway Surface Railroad's Broadway Line, a cable car line, opened on lower Broadway (below Times Square) in 1893, and soon became the core of the Metropolitan Street Railway, with two cable branches: the Broadway and Lexington Avenue Line and Broadway and Columbus Avenue Line.\n\nThese streetcar lines were replaced with bus routes in the 1930s and 1940s. Before Broadway became one-way, the main bus routes along it were the New York City Omnibus Company's (NYCO) 6 (Broadway below Times Square), 7 (Broadway and Columbus Avenue), and 11 (Ninth and Amsterdam Avenues), and the Surface Transportation Corporation's M100 (Kingsbridge) and M104 (Broadway Branch). Additionally, the Fifth Avenue Coach Company's (FACCo) 4 and 5 used Broadway from 135th Street north to Washington Heights, and their 5 and 6 used Broadway between 57th Street and 72nd Street. With the implementation of one-way traffic, the northbound 6 and 7 were moved to Sixth Avenue.\n\n, Broadway is served by the M4 (ex-FACCo 4), M7 (ex-NYCO 7), M55, M100, and M104. Other routes that use part of Broadway include the M5 (ex-FACCo 5), M10, M20, M60 Select Bus Service, Bx7, Bx9, and Bx20.\n\nBee-Line buses also serves Broadway within Riverdale and Westchester County. Routes 1, 2, 3, 4, 6, 13, and several others run on a portion of Broadway.\n\nBroadway is lined with many famous and otherwise noted and historic buildings, such as:\n\nHistoric buildings on Broadway that are now demolished include:\n\nNotes\nBibliography\n\n"}
{"id": "4628", "url": "https://en.wikipedia.org/wiki?curid=4628", "title": "Bilinear transform", "text": "Bilinear transform\n\nThe bilinear transform (also known as Tustin's method) is used in digital signal processing and discrete-time control theory to transform continuous-time system representations to discrete-time and vice versa.\n\nThe bilinear transform is a special case of a conformal mapping (namely, a Möbius transformation), often used to convert a transfer function formula_1 of a linear, time-invariant (LTI) filter in the continuous-time domain (often called an analog filter) to a transfer function formula_2 of a linear, shift-invariant filter in the discrete-time domain (often called a digital filter although there are analog filters constructed with switched capacitors that are discrete-time filters). It maps positions on the formula_3 axis, formula_4, in the s-plane to the unit circle, formula_5, in the z-plane. Other bilinear transforms can be used to warp the frequency response of any discrete-time linear system (for example to approximate the non-linear frequency resolution of the human auditory system) and are implementable in the discrete domain by replacing a system's unit delays formula_6 with first order all-pass filters.\n\nThe transform preserves stability and maps every point of the frequency response of the continuous-time filter, formula_7 to a corresponding point in the frequency response of the discrete-time filter, formula_8 although to a somewhat different frequency, as shown in the Frequency warping section below. This means that for every feature that one sees in the frequency response of the analog filter, there is a corresponding feature, with identical gain and phase shift, in the frequency response of the digital filter but, perhaps, at a somewhat different frequency. This is barely noticeable at low frequencies but is quite evident at frequencies close to the Nyquist frequency.\n\nThe bilinear transform is a first-order approximation of the natural logarithm function that is an exact mapping of the \"z\"-plane to the \"s\"-plane. When the Laplace transform is performed on a discrete-time signal (with each element of the discrete-time sequence attached to a correspondingly delayed unit impulse), the result is precisely the Z transform of the discrete-time sequence with the substitution of\n\nwhere formula_10 is the numerical integration step size of the trapezoidal rule used in the bilinear transform derivation; or, in other words, the sampling period. The above bilinear approximation can be solved for formula_11 or a similar approximation for formula_12 can be performed.\n\nThe inverse of this mapping (and its first-order bilinear approximation) is\n\nThe bilinear transform essentially uses this first order approximation and substitutes into the continuous-time transfer function, formula_1\n\nThat is\n\nA continuous-time causal filter is stable if the poles of its transfer function fall in the left half of the complex s-plane. A discrete-time causal filter is stable if the poles of its transfer function fall inside the unit circle in the complex z-plane. The bilinear transform maps the left half of the complex s-plane to the interior of the unit circle in the z-plane. Thus, filters designed in the continuous-time domain that are stable are converted to filters in the discrete-time domain that preserve that stability.\n\nLikewise, a continuous-time filter is minimum-phase if the zeros of its transfer function fall in the left half of the complex s-plane. A discrete-time filter is minimum-phase if the zeros of its transfer function fall inside the unit circle in the complex z-plane. Then the same mapping property assures that continuous-time filters that are minimum-phase are converted to discrete-time filters that preserve that property of being minimum-phase.\n\nAs an example take a simple low-pass RC filter. This continuous-time filter has a transfer function\n\nIf we wish to implement this filter as a digital filter, we can apply the bilinear transform by substituting for formula_18 the formula above; after some reworking, we get the following filter representation:\n\nThe coefficients of the denominator are the 'feed-backward' coefficients and the coefficients of the numerator are the 'feed-forward' coefficients used to implement a real-time digital filter.\n\nIt is possible to relate the coefficients of a continuous-time, analog filter with those of a similar discrete-time digital filter created through the bilinear transform process. Transforming a general, second-order continuous-time filter with the given transfer function\n\nusing the bilinear transform (without prewarping any frequency specification) requires the substitution of\n\nwhere\n\nHowever, if the frequency warping compensation as described below is used in the bilinear transform, so that both analog and digital filter gain and phase agree at frequency formula_22, then\n\nThis results in a discrete-time digital biquad filter with coefficients expressed in terms of the coefficients of the original continuous time filter:\n\nNormally the constant term in the denominator must be normalized to 1 before deriving the corresponding difference equation. This results in\n\nThe difference equation (using the Direct Form I) is\n\nTo determine the frequency response of a continuous-time filter, the transfer function formula_27 is evaluated at formula_28 which is on the formula_29 axis. Likewise, to determine the frequency response of a discrete-time filter, the transfer function formula_30 is evaluated at formula_31 which is on the unit circle, formula_32. The bilinear transform maps the formula_29 axis of the \"s\"-plane (of which is the domain of formula_27) to the unit circle of the \"z\"-plane, formula_32 (which is the domain of formula_30), but it is not the same mapping formula_37 which also maps the formula_29 axis to the unit circle. When the actual frequency of formula_39 is input to the discrete-time filter designed by use of the bilinear transform, then it is desired to know at what frequency, formula_40, for the continuous-time filter that this formula_39 is mapped to.\n\nThis shows that every point on the unit circle in the discrete-time filter z-plane, formula_43 is mapped to a point on the formula_44 axis on the continuous-time filter s-plane, formula_45. That is, the discrete-time to continuous-time frequency mapping of the bilinear transform is\n\nand the inverse mapping is\n\nThe discrete-time filter behaves at frequency formula_48 the same way that the continuous-time filter behaves at frequency formula_49. Specifically, the gain and phase shift that the discrete-time filter has at frequency formula_48 is the same gain and phase shift that the continuous-time filter has at frequency formula_51. This means that every feature, every \"bump\" that is visible in the frequency response of the continuous-time filter is also visible in the discrete-time filter, but at a different frequency. For low frequencies (that is, when formula_52 or formula_53), then the features are mapped to a \"slightly\" different frequency; formula_54.\n\nOne can see that the entire continuous frequency range\n\nis mapped onto the fundamental frequency interval\n\nThe continuous-time filter frequency formula_57 corresponds to the discrete-time filter frequency formula_58 and the continuous-time filter frequency formula_59 correspond to the discrete-time filter frequency formula_60\n\nOne can also see that there is a nonlinear relationship between formula_61 and formula_62 This effect of the bilinear transform is called frequency warping. The continuous-time filter can be designed to compensate for this frequency warping by setting formula_46 for every frequency specification that the designer has control over (such as corner frequency or center frequency). This is called pre-warping the filter design.\n\nIt is possible, however, to compensate for the frequency warping by pre-warping a frequency specification formula_64 (usually a resonant frequency or the frequency of the most significant feature of the frequency response) of the continuous-time system. These pre-warped specifications may then be used in the bilinear transform to obtain the desired discrete-time system. When designing a digital filter as an approximation of a continuous time filter, the frequency response (both amplitude and phase) of the digital filter can be made to match the frequency response of the continuous filter at a specified frequency formula_64, as well as matching at DC, if the following transform is substituted into the continuous filter transfer function. This is a modified version of Tustin's transform shown above.\n\nHowever, note that this transform becomes the original transform\n\nas formula_68.\n\nThe main advantage of the warping phenomenon is the absence of aliasing distortion of the frequency response characteristic, such as observed with Impulse invariance.\n\n\n"}
{"id": "4631", "url": "https://en.wikipedia.org/wiki?curid=4631", "title": "Brian Boitano", "text": "Brian Boitano\n\nBrian Anthony Boitano (born October 22, 1963) is an American figure skater from Sunnyvale, California. He is the 1988 Olympic champion, the 1986 and 1988 World Champion, and the 1985–1988 U.S. National Champion. He turned professional following the 1988 season. He returned to competition in 1993 and competed at the 1994 Winter Olympics, where he placed sixth.\n\nBrian Boitano was born in Mountain View, California, and as an adult has lived in San Francisco. Boitano is a graduate of Marian A. Peterson High School in Sunnyvale, California.\n\nBrian Boitano first made his mark on the international scene when he won the bronze medal at the 1978 World Junior Figure Skating Championships, beating future rival Brian Orser for that medal.\n\nIn 1982 Boitano became the first American to land a triple axel. In 1987 he introduced his signature jump, the 'Boitano triple lutz' in which the skater raises his left arm above his head. He attempted a quadruple jump throughout the 1986–87 season and at the 1988 World Figure Skating Championships, but did not cleanly land the jump; he double-footed the landing on two occasions.\n\nBoitano was known primarily as a jumper early in his career and he, along with several other skaters, helped push the technical envelope of men's skating. It was not until his failure to defend his World title in 1987 that he focused specifically on improving his artistry.\n\nBoitano placed second at the 1984 United States Figure Skating Championships, earning himself a trip to the 1984 Winter Olympics. He placed 5th at the Olympics, setting the stage for his success over the next four years.\n\nFollowing the 1984 Olympics, several skaters emerged as likely medal hopes following the retirement of Scott Hamilton.\n\nBoitano won the 1985 United States Figure Skating Championships, the first of his four titles. At the first World Championships of the post-Hamilton era in 1985, Alexander Fadeev won, with Brian Orser finishing 2nd and Boitano 3rd. He had injured tendons in his right ankle a few weeks before the 1986 U.S. Championships but went on to win his second national title. At the 1986 World Championships, Boitano took the title, while Fadeev had a disastrous free skate despite having been in an excellent position to win; Orser finished 2nd once again.\n\nDuring the 1986–87 season, Boitano had introduced two new elements to his programs: the 'Tano triple lutz and a quadruple toe loop, although he never succeeded in landing a clean quadruple jump in competition. The 1987 World Championships were held in Cincinnati, giving defending World champion Boitano a home-field advantage. The outcome of the event would set the tone for the 1988 Olympics. At Worlds, Boitano fell on his quadruple toe loop attempt and placed second.\n\nAfter losing the world title to Orser at home, Boitano and his coach Linda Leaver decided that some changes needed to be made if Boitano was to become the Olympic champion. Boitano had always been good at the technical requirements (\"The first mark\"), but he was weak on the artistic (\"the second mark\"). He was a self-described \"jumping robot.\" In order to help his growth as an artist, he hired choreographer Sandra Bezic to choreograph his programs for the 1987–1988 Olympic season.\n\nBezic choreographed two programs that featured clean lines and accentuated the skating abilities of the 5' 11\" Boitano. The short program was based on Giacomo Meyerbeer's ballet \"Les Patineurs\" in which Boitano plays a cocky young man showing off his tricks, using movements dating back to the 19th century. In one famous moment, Boitano wipes ice shavings, also called snow, off his skate blade and tosses it over his shoulder after landing a triple axel combination. The free skating program was based on the film score, \"Napoleon\", detailing various phases of a soldier's life.\n\nBoitano debuted his new programs at 1987 Skate Canada, held in the Saddledome in Calgary, Alberta, Canada, the same venue in which he would compete against Brian Orser for the Olympic title three months later. Boitano's new programs were received with standing ovations by the audience. Although Orser won the competition, Boitano skated clean, landing seven triple jumps, including a footwork section into a jump. He did however pop his planned 2nd triple axel. Boitano, Leaver, and Bezic were so confident about the strength of Boitano's new programs that they omitted the quadruple toe loop, which if landed, could have put him a shoulder above Orser in technical merit.\n\nThe short program at the 1988 United States Figure Skating Championships proved to be a highlight. Boitano received marks of 6.0 from eight of the nine judges for presentation, the second mark. His free skate was flawed. Due to delays, he did not skate until after midnight. Still, Boitano won the competition, and went into the Olympics as the national champion (U.S.), as did Orser (Canadian).\n\nGoing into the Olympics, Boitano and Brian Orser each had won a World title and each had an excellent, balanced repertoire, with Boitano being known as the slightly better technician and Orser as the better artist. Adding to the rivalry, Boitano and Orser were both performing military-themed programs. Boitano's was to the music of Napoleon.\n\nThe Battle of the Brians at the 1988 Winter Olympics was the highlight of Boitano's amateur career. Boitano and Orser were effectively tied going into the free skating portion of the event and whoever won that portion would win the event. Alexander Fadeev had won the compulsory figures section of the competition with Boitano second and Orser third. In the short program, Orser placed first and Boitano second. The free skating was, at the time, worth 50% of the score, and so Boitano's lead would not be enough to hold him in first place if he lost the free skate.\n\nBoitano skated a clean, technically excellent long program, with eight triple jumps, two Axels, and a triple-triple combination. Orser made one small mistake on a jump and omitted his planned second triple axel. Boitano won the Battle in a 5–4 split. Boitano won the gold medal, wearing skates with American flag appliqués that are now part of the collections of the National Museum of American History at the Smithsonian Institution.\n\nFollowing the Olympics, both Orser and Boitano went to the World Championships, which Boitano won. Boitano turned professional soon after.\n\nFollowing the Olympics, Boitano went on to dominate competitions in the professional ranks, winning 10 straight professional competitions, including 5 consecutive World Professional Championship titles and 4 consecutive wins at the Challenge of Champions. Boitano also appeared in \"Carmen on Ice\", for which he won an Emmy. However, Boitano wanted to return to amateur competition and make another run at the Olympics.\n\nBoitano's lobby proved successful and in June 1993, the International Skating Union (ISU) introduced a clause, commonly known as the \"Boitano rule,\" which allowed professionals to reinstate as \"amateur\" or \"eligible\" skaters. This had been the result of Boitano's active involvement during the early 1990s, which saw professionals being allowed in the Olympic Games in the sports of tennis and basketball. Boitano reinstated as an amateur to compete in the 1994 Winter Olympics in Lillehammer, Norway.\n\nBoitano competed at the 1994 United States Figure Skating Championships, led after the short program, but lost to Scott Davis in the long program in a 6–3 split decision. Boitano was named to the Olympic team. Going into the Olympics as a medal favorite in a strong field, Boitano missed his triple axel combination during the short program for the first time in his career. This mistake proved extremely costly, and knocked Boitano out of medal contention. He skated a good long program and finished 6th.\n\nBoitano returned to the professional ranks afterwards. He was inducted into the World Figure Skating Hall of Fame and the United States Figure Skating Hall of Fame in 1996.\n\nIn December 2013, Boitano was named to the United States delegation to the 2014 Winter Olympics in Sochi, Russia. In conjunction with that appointment, Boitano publicly came out as gay. The Sochi games and Russia have been the targets of criticism and LGBT activism because of a Russian anti-gay \"propaganda\" law passed in June 2013. In January 2014, he told \"Associated Press\" that he had never wanted to come out until the delegation announcement.\n\nA caricature of Boitano as a superhero appears as a semi-recurring character in the cartoon series \"South Park\". The movie \"\" (1999), features a musical number titled \"What Would Brian Boitano Do?\". He was also featured in \"Jesus vs. Santa.\"\n\nOn August 23, 2009, Food Network debuted a new series entitled \"What Would Brian Boitano Make?\", which borrows both its name and opening musical theme from the \"\" song. The show features Boitano preparing meals for his friends. The series was picked up for a ten-episode second season.\n\nHe hosted a series on HGTV, called \"The Brian Boitano Project\", which premiered January 16, 2014, in which he purchased a near derelict ancestral home in Northern Italy, home to many Boitanos. During the series he gives the home in Favale di Malvaro a sympathetic restoration/renovation and shops flea markets with two nieces to find decor and furnishings. Local artisans, carpenters, masons and painters create a gem where he can live part-time and host Boitanos from afar.\n\n\n\n"}
{"id": "4633", "url": "https://en.wikipedia.org/wiki?curid=4633", "title": "List of political scandals in the United Kingdom", "text": "List of political scandals in the United Kingdom\n\nPolitical scandals in the United Kingdom are commonly referred to by the press and commentators as \"'sleaze\".\n\nA number of political scandals in the 1980s and 1990s created the impression of what was described in the British press as \"sleaze\": a perception that the then Conservative government was associated with political corruption and hypocrisy. This was revived in the late 1990s due to accounts of so-called \"sleaze\" by the Labour government.\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "4635", "url": "https://en.wikipedia.org/wiki?curid=4635", "title": "Bombardier Inc.", "text": "Bombardier Inc.\n\nBombardier Inc. () is a multinational aerospace and transportation company based in Montreal, Quebec, Canada. Bombardier started as a maker of snowmobiles, and is now a large manufacturer of regional airliners, business jets, and mass transportation equipment, as well as a provider of financial services.\n\nBombardier was founded by Joseph-Armand Bombardier as \"L'Auto-Neige Bombardier Limitée\" (\"Bombardier Snow Car Limited\") on July 10, 1942, at Valcourt in the Eastern Townships, Quebec. A mechanic who dreamed of building a vehicle that could \"float on snow;\" in 1935, Bombardier designed and produced his first snowmobile in a small Valcourt, Quebec repair shop, following the death of his two-year-old from appendicitis complicated by peritonitis in January 1934, when a blizzard prevented him from reaching hospital in time to save his son.\n\nBombardier's technological breakthrough in the design of bush vehicles came in the mid-1930s when he developed a drive system that revolutionized travel in snow and swampy conditions. In 1937, Bombardier sold 12 snowmobiles, named the B7 and, in 1942, created l'Auto-Neige Bombardier Limitée company.\n\nThe first snowmobiles were large, multipassenger vehicles designed to help people get around during the long winter months. Snowmobiles were used in rural Quebec to take children to school, carry freight, deliver mail, and as ambulances. His invention filled a very particular need in the region and soon business was booming. In 1941, Armand opened a new factory in Valcourt. Then a major setback hit the growing business: the Second World War was well underway and the Canadian government issued wartime rationing regulations. Bombardier customers had to prove that snowmobiles were essential to their livelihood in order to buy one. To keep his business going, Armand shifted his focus and developed vehicles for the military. After the war, Bombardier experienced another setback in his snowmobile business. In 1948, the Quebec government passed a law requiring all highways and local roads to be cleared of snow; the Bombardier company's sales fell by nearly half in one year. Armand Bombardier therefore decided to diversify his business, first by producing tracked snowplows sized specifically for use on municipal sidewalks (replacing horse-drawn vehicles), then by making all-terrain vehicles for the mining, oil, and forestry industries.\nOf note, the machines had removable front skis that could be replaced with front wheels for use on paved or hard surfaces, thus providing greater utility to his large snowmobiles. Production of these machines evolved over time. During 1951, the wooden bodies were replaced with sheet steel and these vehicles were powered by Chrysler flathead six-cylinder engines and 3-speed manual transmissions. In the 1960s, V-8 engines began to appear and during the 1969/1970 production years, the standard round \"porthole\"-style windows were replaced with larger rectangular windows which allowed more interior light and made them feel less claustrophobic. Following these changes came the switchover to more reliable Chrysler Industrial 318 engines with the automatic Loadflite transmissions. Production of these machines continued into the mid-1970s.\n\nBombardier wanted to develop a fast, lightweight snowmobile that could carry one or two people. In the early 1950s, Armand set aside his dream to focus on developing his company's other tracked vehicles, but by the end of the decade, smaller, more efficient engines had been developed and were starting to come onto the market. Bombardier resumed his efforts to build a \"miniature\" snowmobile. He worked alongside his eldest son Germain, who shared his father's mechanical talents. Armand and Germain developed several prototypes of the lightweight snowmobile and finally, the first Bombardier snowmobile went on sale in 1959.\n\nThe Ski-Doo snowmobile was originally called the \"Ski-Dog\" because Bombardier meant it to be a practical vehicle to replace the dogsled for hunters and trappers. By an accident, a painter misinterpreted the name and painted \"Ski-Doo\" on the first prototype. The public soon discovered that speedy vehicles that could zoom over snow were a lot of fun. Suddenly, a new winter sport was born, centred in Quebec. In the first year, Bombardier sold 225 Ski-Doos; four years later, 8,210 were sold. But Armand was reluctant to focus too much on the Ski-Doo and move resources away from his all-terrain vehicles. He vividly remembered his earlier business setbacks that forced him to diversify. Armand slowed down promotion of the Ski-Doo line to prevent it from dominating the other company products, while still allowing him to dominate the snowmobile industry. The snowmobiles produced were of exceptional quality and performance, earning a better reputation than the rival Polaris and Arctic Cat brand of motosleds. In 1971, Bombardier completed the purchase of the Moto-Ski company.\n\nOn February 18, 1964, J. Armand Bombardier died of cancer at age 56. He left behind a thriving business, but also one that had been focused on one person. Armand dominated his company, overseeing all areas of operation. He controlled the small research department, making all the drawings himself. By the time of his death, sales of the company had reached C$20 million, which is the equivalent of C$160 million in 2004 dollars. The younger generation took over, led by Armand's sons and sons-in-law. The young team reorganized and decentralized the company, adopting modern business tactics. The company adopted the latest technological innovation—the computer—to handle inventory, accounts, and billing. Distribution networks were improved and increased, and an incentive program was developed for sales staff.\n\nIn 1967, L'Auto-Neige Bombardier Limitée was renamed \"Bombardier Limited\" and on January 23, 1969, the company went public, listing on the Montreal and Toronto stock exchanges.\n\nIn October 2016, Bombardier Inc. announced that, by the end of 2018, they will slash up to 7,500 jobs or more than 10 percent of 70,900 employees from 2015. About a half of job cuts will be done in railway technology unit.\n\nIn November 2018, Bombardier Inc. announced they were cutting 5,000 jobs and discontinuing their turbo-prop passenger aircraft production over the next 12 to 18 months.\n\nIn 1986, Bombardier acquired Canadair after the Canadian government-owned aircraft manufacturing company recorded the largest corporate loss in Canadian history. Shortly thereafter, de Havilland Canada, Short Brothers and Learjet operations were absorbed by the aerospace arm, which now accounts for over half of company revenue. Bombardier's most popular aircraft currently include its Q400, CRJ100/200/440, and CRJ700/900/1000 lines of regional airliners. In late September, the Company announced that Indian airline SpiceJet had ordered 25 of the Q400 planes with an option for an additional 25 units. The total sale for 50 would be valued at US$1.7 billion, minus discounts.\n\nBombardier also manufactures the Global Express and the Challenger business jet. Learjet continues to operate as a subsidiary of Bombardier, manufacturing jets under the Learjet marque. The slogan was changed in 2012 from \"We Move People\" to \"Evolution of Mobility.\"\n\nAfter some delay in its development of the Bombardier C Series, the CS100 and CS300 now compete with the smaller aircraft in the Airbus A320 family and the Boeing 737 family. On June 29, 2016, Bombardier delivered the first C Series CS100 aircraft to Swiss International Air Lines, which were the launch customer for the new aircraft. Subsequently, both Air Canada and Delta Air Lines placed firm orders for the CSeries. The CS300 is the latest plane offered by Bombardier with up to 160 seats.\n\nIn May 2017, Bombardier and the state-owned Chinese air company Comac began holding talks about an investment into Bombardier's passenger jet business.\n\nIn late September 2017, the U.S. Department of Commerce proposed a 219% tariff on Bombardier CSeries aircraft to be imported into the country. This was a preliminary ruling on a complaint by Boeing that Bombardier was selling the CS100 to Delta Air Lines at unduly low prices, due to subsidies from the governments of Canada and Quebec subsidies; this allegedly produced an unfair competitive advantage. Boeing's complaint stated that the CS100 was being sold at US$19.6 million each, below the US$33.2 million production cost. A final decision on the tariff will be made by the U.S. by spring 2018. Bombardier said it will be disputing the \"absurd\" ruling. The governments of Canada and the UK also promised their support, threatening to stop ordering Boeing aircraft since the company was putting aerospace jobs at risk.\n\nOn October 16, 2017, the Airbus Group bought a 50.01% majority stake in the CSeries Aircraft. Airbus will create a second CSeries assembly line at their A320 assembly facility in Mobile, Alabama, to avoid the duties imposed by the U.S. Department of Commerce. The deal contains a provision which allows Airbus to eventually buy out the remaining stake in the aircraft held by both Bombardier and the Québec government.\n\nDuring the 1970s, Bombardier began to enter the railway passenger car business with domestic orders for commuter and subway systems, winning its first order for mass transit rolling stock in 1974 for the Société de transport de Montréal (STM) (Montreal transport authority) to build MR-73 metro trains for the Montreal Metro. The core of Bombardier Transportation was formed with the purchase of Montreal Locomotive Works (MLW) in 1975 (sold to General Electric in 1988). In a 1985 corporate reorganization, Bombardier removed itself from manufacturing locomotives and concentrated on producing passenger train rolling stock, aircraft and recreational products. In the late 1980s Bombardier Transportation gained manufacturing capacity in the US and Europe, acquiring a 45% share in BN Constructions Ferroviaires et Métalliques (whose principal site was in Brugge (Bruges), Belgium) in 1986, buying the assets of US railcar manufacturers Budd and Pullman-Standard in 1987, and acquiring of ANF-Industries (whose principal site was in Crespin, France, near the Belgian border) in 1989. A series of acquisitions in the UK, Germany, Switzerland, Canada and Mexico further increased Bombardier Transportation's operations. \n\nIn 2001, Bombardier acquired Adtranz (DaimlerChrysler Rail Systems), a manufacturer of trains which were widely used throughout Germany and Great Britain. Bombardier was one of the companies that took over British Rail's Research and Development facilities after privatisation (the remainder largely being absorbed into AEA Technology and Alstom).\n\nWith the acquisition of Adtranz from DaimlerChrysler, Bombardier Transportation emerged as one of the largest manufacturers of railway rolling stock in the world. \n\nBombardier Capital (BC) was the Bombardier division in charge of financial services. From 1973, when it was based in Colchester, Vermont, it offered financial services such as lending, leasing, and asset-management throughout the Americas. In 2001, BC restricted its loan activity to existing customers. The company, which began transitioning some services to Jacksonville, Florida, in 1997, ceased taking on new consumer loans in 2001, focusing instead on loans to retailers and gradually downsizing. In November 2004, Bombardier's credit evaluation was downgraded by Moody's from \"moderate credit risk\" (Baa3) to \"questionable credit quality\" (Ba2), a below investment grade rating which impacted Bombardier Capital, although the company's transportation division was unaffected. In 2005, Bombardier sold the Inventory Finance Division of BC to GE Commercial Finance.\n\nBombardier used to be a major Canadian defence contractor. With the latest restructuring, the company sold off nearly all of its military-related work in Canada. Military Aviation Services was sold to SPAR Aerospace and land-based defence products made by Urban Transportation Development Corporation ceased operations as Bombardier moved away from non-aviation defence products.\n\nOn 27 August 2003, Bombardier, Inc. announced the sale of its BRP (Recreational Products) unit to a group of investors: Bain Capital (50%), Bombardier Family (35%) and Caisse de dépôt et placement du Québec (15%) for $875 million.\nAs part of the deal, BRP retained rights to the sprocket logo, which it subsequently modified. Its snowcats and snowmobiles dated back to the origins of the company; current brands are Ski-Doo and Lynx. Bombardier Recreational Products has also become well known for its Sea-Doo personal watercraft division which also features jet-powered sport boats. Bombardier also makes all-terrain vehicles (ATVs). In 2006, the Bombardier ATV was rebranded as Can-Am. Can-Am was the name of the line of dirt bikes it produced in the 1980s which used high-tech engines featuring Rotax Automatic Variable Exhaust (RAVE) valving to create peak power at a wider range of RPMs. The bikes were shelved but technology tweaks re-emerged in the company's Ski-Doo snowmobiles (beginning with the 1989 model year Ski-Doo Mach 1). Many of today's snowmobiles produced by the company feature proprietary engineering by BRP's Rotax brand engine production plant located in Austria. BRP's Can-Am product is among the high tech recreational vehicles which include the Can-Am Spyder, a three-wheel roadster with a rear-drive wheel and featuring a vehicle stability system (VSS), anti-lock braking system (ABS) and other safety and electronic vehicle control enhancements as certified by the National Highway Traffic Safety Administration (NHTSA).\n\nIn the late 1970s in Ireland, Córas Iompair Éireann (now Bus Éireann and Dublin Bus) commissioned a range of single and double decker buses to be designed and produced. The prototypes were devised in Germany and production was carried out in Shannon, Co. Clare, Ireland. A total of 51 express coaches (KE type) and 366 double deck buses (KD) were assembled at this facility between 1980 and 1983. They remained in service until 1997 and 2000 respectively. Some surviving examples are now exhibits at the National Transport Museum of Ireland in Howth, Co. Dublin.\n\nThe Bombardier Museum is a large modern museum in Valcourt, Quebec dedicated to the life of Joseph-Armand Bombardier, the snowmobile, and the industry he helped create. Opened in 1971, with substantial renovations in 1990, the museum is professionally curated and features a wide array of Ski-Doos, other industrial designs, and a selection of related books, booklets and other items of interest to enthusiasts.\n\nAlso of note at the museum is the original garage \"factory\" that was the genesis of the Bombardier organization. The garage was carefully removed from its original location in Valcourt and moved to its present site at the museum, which is located blocks away from the present-day Bombardier Recreational Products factory.\n\n"}
{"id": "4636", "url": "https://en.wikipedia.org/wiki?curid=4636", "title": "Break key", "text": "Break key\n\nThe Break key of a computer keyboard refers to breaking a telegraph circuit and originated with 19th century practice. In modern usage, the key has no well-defined purpose, but while this is the case, it can be used by software for miscellaneous tasks, such as to switch between multiple login sessions, to terminate a program, or to interrupt a modem connection.\n\nBecause the break function is usually combined with the pause function on one key since the introduction of the IBM Model M 101-key keyboard in 1985, the Break key is also called the Pause key. It can be used to pause some computer games.\n\nA standard telegraph circuit connects all the keys, sounders and batteries in a single series loop. Thus the sounders actuate only when both keys are down (closed, also known as \"marking\" — after the ink marks made on paper tape by early printing telegraphs). So the receiving operator has to hold their key down or close a built-in shorting switch in order to let the other operator send. As a consequence, the receiving operator could interrupt the sending operator by opening their key, breaking the circuit and forcing it into a \"spacing\" condition. Both sounders stop responding to the sender's keying, alerting the sender. (A physical break in the telegraph line would have the same effect.)\n\nThe teleprinter operated in a very similar fashion except that the sending station kept the loop closed (logic 1, or \"marking\") even during short pauses between characters. Holding down a special \"break\" key opened the loop, forcing it into a continuous logic 0, or \"spacing\", condition. When this occurred, the teleprinter mechanisms continually actuated without printing anything, as the all-0s character is the non-printing \"NUL\" in both Baudot and ASCII. The resulting noise got the sending operator's attention.\n\nThis practice carried over to teleprinter use on time-sharing computers. A continuous spacing (logical 0) condition violates the rule that every valid character has to end with one or more logic 1 (marking) \"stop\" bits. The computer (specifically the UART) recognized this as a special \"break\" condition and generated an interrupt that typically stopped a running program or forced the operating system to prompt for a login. Although asynchronous serial telegraphy is now rare, the key once used with terminal emulators can still be used by software for similar purposes.\n\nOn the Sinclair ZX80 and ZX81 computers, the Break is accessed by pressing Space. On the Sinclair ZX Spectrum it is accessed by . The Spectrum+ and later computers have a dedicated key. It does not trigger an interrupt but will halt any running BASIC program, or terminate the loading or saving of data to cassette tape. An interrupted BASIC program can usually be resumed with the codice_1 command. The Sinclair QL computer, without a key, maps the function to .\n\nOn a BBC Micro computer, the key generates a hardware reset which would normally cause a warm restart of the computer. A cold restart is triggered by pressing . If a filing system is installed, will cause the computer to search for and load or run a file called codice_2 on the filing system's default device (e.g. floppy disk 0, network user BOOT). The latter two behaviours were inherited by the successor to Acorn MOS, RISC OS. These behaviours could be changed or exchanged in software, and were often used in rudimentary anti-piracy techniques.\n\nOn many modern PCs, interrupts screen output by BIOS until another key is pressed. This is effective during boot in text mode and in a DOS box in Windows safe mode with 50 lines. On early keyboards without a key (before the introduction of 101/102-key keyboards) the Pause function was assigned to , and the Break function to ; these key-combinations still work with most programs, even on modern PCs with modern keyboards. Pressing the dedicated key on 101/102-key keyboards sends the same scancodes as pressing , then , then releasing them in the reverse order would do; additionally, an E1 prefix is sent, which enables 101/102-key-aware software to discern the two situations, while older software usually just ignores the prefix. The key is different from all other keys in that it sends no scancodes at all on release; therefore it is not possible for any software to determine whether this key is being held down.\n\nOn modern keyboards, the key is usually labeled \"Pause\" with \"Break\" below, sometimes separated by a line: formula_1, or \"Pause\" on the top of the keycap and \"Break\" on the front. In most Windows environments, the key combination brings up the system properties.\n\nCompact and notebook keyboards often do not have a dedicated key.\n\nThese may use the following substitutes for :\n\nSubstitutes for :\n\nApple keyboards do not have the Pause/Break key, as Mac OS X does not use it. The key may be substituted by .\n\nFor some Dell laptops without a Break key press the ALT+Space bar and select \"Interrupt\". \n\nWhile both and combination are commonly implemented as a way of breaking the execution of a console application, they are also used for similar effect in integrated development environments. Although these two are often considered interchangeable, compilers and execution environments usually assign different signals to these. Additionally, in some kernels (e.g. miscellaneous DOS variants) is detected only at the time OS tries reading from a keyboard buffer and only if it's the only key sequence in the buffer, while is often translated instantly (e.g. by INT 1Bh under DOS). Because of this, is usually a more effective choice under these operating systems; sensitivity for these two combinations can be enhanced by the codice_3 CONFIG.SYS statement.\n\n"}
{"id": "4640", "url": "https://en.wikipedia.org/wiki?curid=4640", "title": "Bogie", "text": "Bogie\n\nA bogie ( ) (in some senses called a truck in North American English) is a chassis or framework that carries a wheelset, attached to a vehicle—a modular subassembly of wheels and axles. Bogies take various forms in various modes of transport. A bogie may remain normally attached (as on many railway carriages [cars] and semi-trailers) or be quickly detachable (as the dolly in a road train or in railway bogie exchange); it may contain a suspension within it (as most rail and trucking bogies do), or be solid and in turn be suspended (as most bogies of tracked vehicles are); it may be mounted on a swivel, as traditionally on a railway carriage or locomotive, additionally jointed and sprung (as in the landing gear of an airliner), or held in place by other means (centreless bogies).\n\nWhile \"bogie\" is the preferred spelling and first-listed variant in various dictionaries, bogey and bogy are also used.\n\nA \"bogie\" in the UK, or a \"railroad truck\", \"wheel truck\", or simply \"truck\" in North America, is a structure underneath a railway vehicle (wagon, coach or locomotive) to which axles (and, hence, wheels) are attached through bearings. In Indian English, \"bogie\" may also refer to an entire railway carriage. In South Africa, the term \"bogie\" is often alternatively used to refer to a freight or goods wagon (shortened from \"bogie wagon\").\n\nThe first standard gauge British railway to build coaches with bogies, instead of rigidly mounted axles, was the Midland Railway in 1874.\n\nBogies serve a number of purposes:\n\nUsually, two bogies are fitted to each carriage, wagon or locomotive, one at each end. Another configuration is often used in articulated vehicles, which places the bogies (often Jacobs bogies) under the connection between the carriages or wagons.\n\nMost bogies have two axles, but some cars designed for heavy loads have more axles per bogie. Heavy-duty cars may have more than two bogies using span bolsters to equalize the load and connect the bogies to the cars.\n\nUsually, the train floor is at a level above the bogies, but the floor of the car may be lower between bogies, such as for a bilevel rail car to increase interior space while staying within height restrictions, or in easy-access, stepless-entry, low-floor trains.\n\nKey components of a bogie include:\n\nThe connections of the bogie with the rail vehicle allow a certain degree of rotational movement around a vertical axis pivot (bolster), with side bearers preventing excessive movement. More modern, bolsterless bogie designs omit these features, instead taking advantage of the sideways movement of the suspension to permit rotational movement.\n\nThe Commonwealth bogie was manufactured by the English Steel Corporation under licence from the Commonwealth Steel Company in Illinois, United States. Fitted with SKF or Timken bearings, it was introduced in the late 1950s for all BR Mark 1 vehicles. It was a heavy, cast-steel design weighing about , with sealed roller bearings on the axle ends, avoiding the need to maintain axle box oil levels.\n\nThe leaf springs were replaced by coil springs (one per wheel) running vertically rather than horizontally. The advanced design gave a better ride quality than the BR1, being rated for .\n\nThe side frame of the bogie was usually of bar construction, with simple horn guides attached, allowing the axle boxes vertical movements between them. The axle boxes had a cast-steel equaliser beam or bar resting on them. The bar had two steel coil springs placed on it and the bogie frame rested on the springs. The effect was to allow the bar to act as a compensating lever between the two axles and to use both springs to soften shocks from either axle. The bogie had a conventional bolster suspension with swing links carrying a spring plank.\n\nThe B4 bogie was introduced in 1963. It was a fabricated steel design versus cast iron and was lighter than the Commonwealth, weighing in at . It also had a speed rating of .\n\nAxle to spring connection was again fitted with roller bearings. However, now two coil springs rather than one were fitted per wheel.\n\nOnly a very small number of Mark 1 stock was fitted with the B4 bogie from new, it being used on the Mark 1 only to replace worn BR1 bogies. The British Rail Mark 2 coach, however, carried the B4 bogies from new. A heavier-duty version, the B5, was standard on Southern Region Mk1-based EMUs from the 1960s onwards. Some Mark 1 catering cars had mixed bogies—a B5 under the kitchen end, and a B4 under the seating end. Some of the B4-fitted Mark 2s, as well as many B4-fitted Mark 1 BGs were allowed to run at with extra maintenance, particularly of the wheel profile, and more frequent inspection.\n\nThe BT10 bogie was introduced on the British Rail Mark 3 coach in the 1970s. Each wheel is separately connected to the bogie by a swing-arm axle.\n\nThere is dual suspension:\n\nMost diesel locomotives and electric locomotives are carried on bogies. Those used in the USA include AAR type A switcher truck, Blomberg B, HT-C truck and Flexicoil.\n\nOn a steam locomotive, the leading and trailing wheels may be mounted on bogies like pony trucks or Bissel bogies. Articulated locomotives (e.g. Fairlie, Garratt or Mallet locomotives) have power bogies similar to those on diesel and electric locomotives.\n\nA rollbock is a specialized type of bogie that is inserted under the wheels of a rail wagon/car, usually to convert for another track gauge. Transporter wagons carry the same concept to the level of a flatcar specialized to take other cars as its load.\n\nIn the case of archbar trucks or diamond frame bogies the side frames are fabricated rather than cast.\n\nTram bogies are much simpler in design because of their axle load, and the tighter curves found on tramways mean tram bogies almost never have more than two axles. Furthermore, some tramways have steeper gradients and vertical, as well as horizontal, curves, which means tram bogies often need to pivot on the horizontal axis, as well.\n\nSome articulated trams have bogies located under articulations, a setup referred to as a Jacobs bogie. Often, low-floor trams are fitted with nonpivoting bogies and many tramway enthusiasts see this as a retrograde step, as it leads to more wear of both track and wheels and also significantly reduces the speed at which a tram can round a curve.\n\nIn the past, many different types of bogie (truck) have been used under tramcars (e.g. Brill, Peckham, maximum traction). A maximum traction truck has one driving axle with large wheels and one nondriving axle with smaller wheels. The bogie pivot is located off-centre, so more than half the weight rests on the driving axle.\n\nThe retractable stadium roof on Toronto's Rogers Centre used modified off-the-shelf train bogies on a circular rail. The system was chosen for its proven reliability.\n\nRubber-tyred metro trains use a specialised version of railway bogies. Special flanged steel wheels are behind the rubber-tired running wheels, with additional horizontal guide wheels in front of and behind the running wheels, as well. The unusually large flanges on the steel wheels guide the bogie through standard railroad switches, and in addition keep the train from derailing in case the tires deflate.\n\nTo overcome breaks of gauge some bogies are being fitted with variable gauge axles (VGA) so that they can operate on two different gauges. These include the SUW 2000 system from ZNTK Poznań.\n\nThe Cleminson system is not a true bogie, but serves a similar purpose. It was based on a patent of 1883 by James Cleminson, and was once popular on narrow-gauge rolling stock, e.g. on the Isle of Man and Manx Northern Railways. The vehicle would have three axles and the outer two could pivot to adapt to curvature of the track. The pivoting was controlled by levers attached to the third (centre) axle, which could slide sideways.\n\nSome tanks and other tracked vehicles have bogies as external suspension components (see armoured fighting vehicle suspension). This type of bogie usually has two or more road wheels and some type of sprung suspension to smooth the ride across rough terrain. Bogie suspensions keep much of their components on the outside of the vehicle, saving internal space. Although vulnerable to antitank fire, they can often be repaired or replaced in the field.\n\nAn articulated bogie is any one of a number of bogie designs that allow railway equipment to safely turn sharp corners, while reducing or eliminating the \"screeching\" normally associated with metal wheels rounding a bend in the rails. There are a number of such designs, and the term is also applied to train sets that incorporate articulation in the vehicle, as opposed to the bogies themselves.\n\nIf one considers a single bogie \"up close\", it resembles a small rail car with axles at either end. The same effect that causes the bogies to rub against the rails at longer radius causes each of the pairs of wheels to rub on the rails and cause the screeching. Articulated bogies add a second pivot point between the two axles to allow them to rotate to the correct angle even in these cases.\n\nIn trucking, a bogie is the subassembly of axles and wheels that supports a semi-trailer, whether permanently attached to the frame (as on a single trailer) or making up the dolly that can be hitched and unhitched as needed when hitching up a second or third semi-trailer (as when pulling doubles or triples).\n\n"}
{"id": "4641", "url": "https://en.wikipedia.org/wiki?curid=4641", "title": "British Steel (1967–1999)", "text": "British Steel (1967–1999)\n\nBritish Steel plc was a major British steel producer. It originated from the nationalised British Steel Corporation (BSC), formed in 1967, which was privatised as a public limited company, British Steel plc, in 1988. It was once a constituent of the FTSE 100 Index. The company merged with Koninklijke Hoogovens to form Corus Group in 1999.\n\nAlasdair M. Blair (1997), Professor of International Relations and Head of the Department of Politics and Public Policy at De Montfort University, has explored the history of British Steel since the Second World War to evaluate the impact of government intervention in a market economy. He suggests that entrepreneurship was lacking in the 1940s; the government could not persuade the industry to upgrade its plants. For generations the industry had followed a piecemeal growth pattern that proved inefficient in the face of world competition. The Labour Party came to power in 1945, committed to socialism. In 1946, it put the first steel development plan into practice with the aim of increasing capacity. It passed the Iron and Steel Act 1949, which meant nationalisation of the industry, as the government bought out the shareholders, and created the Iron and Steel Corporation of Great Britain. American Marshall Plan aid in 1948–50 reinforced modernisation efforts and provided funding for them. However, the nationalisation was reversed by the Conservative government after 1952.\n\nThe industry was again nationalised in 1967 under another Labour government, becoming British Steel Corporation (BSC). But by then, 20 years of political manipulation had left companies, such as British Steel, with serious problems: a complacency with existing equipment, plants operating below full capacity (hence the low efficiency), poor-quality assets, outdated technology, government price controls, higher coal and oil costs, lack of funds for capital improvement, and increasing competition in the world market.\n\nBy the 1970s the Labour government's main goal for the declining industry was to keep employment high. Since British Steel was a major employer in depressed regions, it was decided to keep many mills and facilities operating at a loss. In the 1980s, Conservative Prime Minister Margaret Thatcher re-privatised BSC as British Steel. Under private control, the company dramatically cut its work force and underwent a radical reorganisation and massive capital investment to again become competitive in the world marketplace.\n\nBSC was formed from the assets of former private companies which had been nationalised, largely under the Labour government of Harold Wilson, on 28 July 1967. Wilson's was the second attempt at nationalisation, Clement Attlee's Iron and Steel Corporation of Great Britain having been largely privatised by the Conservative governments of the 1950s. Only one steel company, Richard Thomas and Baldwins, remained in public ownership throughout.\n\nBSC was established under the Iron and Steel Act 1967, which vested in the Corporation the shares of the fourteen major UK-based steel companies then in operation, being:\n\nAt the time of its formation, BSC comprised around ninety percent of the UK's steelmaking capacity; it had around 268,500 employees and around 200 wholly or partly owned subsidiaries based in the United Kingdom, Australia, New Zealand, Canada, Africa, South Asia, and South America.\n\nDorman Long, South Durham and Stewarts and Lloyds had merged as British Steel and Tube Ltd before vesting took place. BSC later arranged an exchange deal with Guest, Keen and Nettlefolds Ltd (GKN), the parent company of GKN Steel, under which BSC acquired Dowlais Ironworks at Merthyr Tydfil and GKN took over BSC's Brymbo Steelworks near Wrexham.\n\nAccording to Blair (1997), British Steel faced serious problems at the time of its formation, including obsolescent plants; plants operating under capacity and thus at low efficiency; outdated technology; price controls that reduced marketing flexibility; soaring coal and oil costs; lack of capital investment funds; and increasing competition on the world market. By the 1970s, the government adopted a policy of keeping employment artificially high in the declining industry. This especially impacted BSC since it was a major employer in a number of depressed regions.\n\nOne of the arguments aired in favour of nationalisation was that it would enable steel production to be rationalised. This involved concentrating investment on major integrated plants, placed near the coast for ease of access by sea, and closing older, smaller plants, especially those that had been located inland for proximity to coal supplies.\n\nFrom the mid-1970s the (now loss-making) British Steel, pursued a strategy of concentrating steelmaking in five areas: South Wales, South Yorkshire, Scunthorpe, Teesside and Scotland. This policy continued following the Conservative victory in the 1979 general election. Other traditional steelmaking areas faced cutbacks. Under the Labour government of James Callaghan, a review by Lord Beswick had led to the reprieve of the so-called 'Beswick plants', for social reasons, but subsequent governments were obliged under EU rules to withdraw subsidies. Major changes resulted across Europe, including in the UK:\n\n\nBritish Steel was privatised in 1988 by the Conservative government of Margaret Thatcher. It merged with the Dutch steel producer \"Koninklijke Hoogovens\" to form Corus Group on 6 October 1999. Corus itself was taken over in March 2007 by the Indian steel operator Tata Steel.\n\n\nIan MacGregor later became famous for his role as Chairman of the National Coal Board during the UK miners' strike (1984–1985). During the strike the \"Battle of Orgreave\" took place at British Steel's coking plant.\n\nIn 1971 British Steel sponsored Sir Chay Blyth in his record-making non-stop circumnavigation against the winds and currents, known as 'The Impossible Voyage'. In 1992 they sponsored the British Steel Challenge, the first of a series of 'wrong way' races for amateur crews.\n\nBritish Steel had agreed a sponsorship deal with Middlesbrough Football Club during the 1994–95 season, with a view to British Steel-sponsored Middlesbrough shirts making their appearance the following season. But the sponsorship deal was terminated before it commenced after it was revealed that British steel only made up a tiny fraction of steel used in construction of the stadium, and that the bulk of the steel had been imported from Germany.\n\n\n\n"}
{"id": "4642", "url": "https://en.wikipedia.org/wiki?curid=4642", "title": "BT Group", "text": "BT Group\n\nBT Group plc (trading as BT and formerly British Telecom) is a British multinational telecommunications holding company headquartered in London, United Kingdom. It has operations in around 180 countries and is the largest provider of fixed-line, broadband and mobile services in the UK, and also provides subscription television and IT services.\n\nBT's origins date back to the founding of the Electric Telegraph Company in 1846 which developed a nationwide communications network. In 1912, the General Post Office, a government department, became the monopoly telecoms supplier in the United Kingdom. The Post Office Act of 1969 led to the GPO becoming a public corporation. British Telecommunications, trading as \"British Telecom\", was formed in 1980, and became independent of the Post Office in 1981. British Telecommunications was privatised in 1984, becoming \"British Telecommunications plc\", with some 50 percent of its shares sold to investors. The Government sold its remaining stake in further share sales in 1991 and 1993. BT is a Royal Warrant holder of the British Royal Family and has a primary listing on the London Stock Exchange, a secondary listing on the New York Stock Exchange, and is a constituent of the FTSE 100 Index.\n\nBT controls a number of large subsidiaries. BT Global Services division supplies telecoms services to corporate and government customers worldwide, and its BT Consumer division supplies telephony, broadband, and subscription television services in Great Britain to around 18 million customers. In January 2016, BT acquired EE for £12.5 billion.\n\nA number of privately owned telegraph companies operated in Britain from 1846 onwards. Among them were \nThe Telegraph Act 1868 passed the control of all these to the newly formed GPO (General Post Office)'s Postal Telegraphs Department.\n\nWith the invention of the telephone by Alexander Graham Bell in 1876 the GPO began to provide telephone services from some of its telegraph exchanges. In 1882 the Postmaster-General, Henry Fawcett started to issue licences to operate a telephone service to private businesses and the telephone system grew under the GPO in some areas and private ownership in others. The GPO's main competitor, the National Telephone Company, emerged in this market by absorbing other private telephone companies, prior to its absorption into the GPO in 1912.\n\nThe trunk network was unified under GPO control in 1896 and the local distribution network in 1912. A few municipally owned services remained outside of GPO control. These were Kingston upon Hull, Portsmouth and Guernsey. Hull still retains an independent operator, Kingston Communications, though it is no longer municipally controlled.\n\nIn 1969 the GPO, a government department, became the Post Office, a nationalised industry separate from government. Post Office Telecommunications was one of the divisions.\n\nThe \"British Telecom\" brand was introduced in 1980. On 1 October 1981, this became the official name of Post Office Telecommunications, which became a state-owned corporation independent of the Post Office under the provisions of the British Telecommunications Act 1981. In 1982 BT's monopoly on telecommunications was broken with the granting of a licence to Mercury Communications.\n\nOn 19 July 1982, the Government announced its intention to sell shares in British Telecom to the public. On 1 April 1984, British Telecommunications was incorporated as a public limited company (plc) in anticipation of the passing of the Telecommunications Bill. This Bill received Royal Assent on 12 April, and the transfer to British Telecommunications plc from British Telecom as a statutory corporation of its business, its property, its rights and liabilities took place on 6 August 1984.\n\nInitially all shares in the new plc were owned by the Government. In November 1984, 50.2% of the new company was offered for sale to the public and employees. Shares were listed in London, New York, and Toronto and the first day of trading on was 3 December 1984. The Government sold half its remaining interest in December 1991 and the other half in July 1993. In July 1997, the new Labour Government relinquished its Special Share (\"Golden Share\"), retained at the time of the flotation, which had effectively given it the power to block a takeover of the company, and to appoint two non-executive directors to the Board.\nThe company changed its trading name to \"BT\" on 2 April 1991. In 1996 Peter Bonfield was appointed CEO and Chairman of the Executive Committee, promising a \"rollercoaster ride\".\n\nIn the 1990s, BT entered the Irish telecommunications market through a joint venture with the Electricity Supply Board, the Irish state owned power provider. This venture, entitled Ocean, found its main success through the launch of Ireland's first subscription-free dial-up ISP, oceanfree.net. As a telecoms company it found much less success, mainly targeting corporate customers. BT acquired 100% of this venture in 1999.\n\nIn June 1994 BT and MCI Communications launched Concert Communications Services which was a $1 billion joint venture between the two companies. Its aim was to build a network which would provide easy global connectivity to multinational corporations.\n\nThis alliance progressed further on 3 November 1996 when the two companies announced that they had agreed to a merger, creating a global telecommunications company called Concert plc. The proposal gained approval from the European Commission, the US Department of Justice, and the US Federal Communications Commission and looked set to proceed.\n\nHowever, in light of pressure from investors reacting to the slide in BT's share price on the London Stock Exchange, BT reduced its bid price for MCI, releasing MCI from its exclusivity clause and allowing it to speak to other interested parties. On 1 October 1997, Worldcom made a rival bid for MCI which was followed by a counter-bid from GTE. Because Worldcom used its stock to leverage its purchase, as opposed to cash (used by BT), it was able to outbid BT. MCI accepted the Worldcom bid and BT pulled out of the deal with a severance fee of $465 million.\n\nBT sold its stake in MCI to Worldcom in 1998 for £4,159 million, on which it made a pre-tax profit of £1,133 million. As part of the deal, BT also bought out from MCI its 24.9% interest in Concert Communications, thereby making Concert a wholly owned part of BT.\n\nThe reaction to the failure of the deal in the City of London was critical of then Chairman Iain Vallance and CEO Peter Bonfield, and the lack of confidence from the failed merger led to their removal.\n\nAs BT now owned Concert, and still wanted access to the North American market, it needed a new partner. An AT&T/BT option had been mooted in the past, but stopped on regulatory grounds due to their individual virtual monopolies in their home markets. By 1996, this had receded to the point where a deal was possible. However, the former monopolies clashed in management and culture – and the alliance never really worked from the start. Also, during the proposed MCI merger position, BT/MCI had placed a series of nominated customers inside Concert to overcome regulatory issues, leaving Concert with a sales force. On merger with AT&T, it was reversion to delivery of a series of Global products, and two competing owners – which robbed Concert of revenues and left its management disillusioned.\n\nAt its height, the Concert managed network directly reached more than 800 cities in 52 countries, and interlinked to about 240 other networks to extend access to 1,300 cities in 130 countries. Although Concert continued signing customers, its rate of revenue growth slowed, so that in 1999 David Dorman was made CEO with a brief to revive it.\n\nIn late 2000 the BT and AT&T boards fell-out – partly due to each partner's excess debt, and the resulting board room clear-outs – partly due to Concert's $800 million annual losses. AT&T recognized that Concert was a threat to its ambitions if left intact, and so negotiated a deal where Concert was split in two in 2001: North America and Eastern Asia went to AT&T, the rest of the world and $400M to BT. BT's remaining Concert assets were merged into its BT Ignite, later BT Global Services group.\n\nIn 2000, BT acquired Esat Telecom Group plc, and all its subsidiary companies, and Ireland On Line. It also purchased Telenor's minority shareholding in Esat Digifone. The Esat Telecom Group was split in two with the landline and internet operations were combining with Ocean to became part of BT Ignite. Esat Group was renamed Esat BT in July 2002, and eventually BT Ireland in April 2005. Esat Digifone became part of BT Wireless, before being spun off into a separate independent company mmo2 plc (now Telefónica Europe). EsatBT installed the first DSL lines in Ireland, to try and compete heavily with former state telecoms company Eircom and operate one exchange, in Limerick. It is also the second largest fixed line telecommunications company in Ireland behind the former monopoly operator, Eircom.\n\nBy 2001, BT had a debt of £30 billion, much of which was acquired during the bidding round for the 3rd generation mobile telephony (commonly known as 3G) licences. It had also failed in its series of proposed global mergers, and the funds flowing from its then virtual monopoly of the UK market place had been largely removed. It was also headed by two executives who had little support from the London Stock Exchange, particularly in light of a 60% drop in share price in sixteen months.\n\nPhilip Hampton joined as CFO, and in April 2001 Sir Iain Vallance was replaced as Chairman by recognised turn around expert Sir Christopher Bland. The company then began to sell off or sell and lease back a large part of its assets.\n\nIn May 2001 BT carried out corporate Europe's largest ever rights issue, allowing it to raise £5.9 billion. A few days before, it sold stakes in Japan Telecom, in mobile operator J-Phone Communications, and in Airtel of India to Vodafone.\n\nIn June 2001 BT's directory business was sold as Yell Group to a combination of private equity firms Apax Partners and Hicks, Muse, Tate & Furst for £2.1 billion.\n\nA demerger followed in November 2001, when the former mobile telecommunications business of BT, BT Cellnet, was hived off as a separate business named \"mmO2\". This included BT owned or operated networks in other countries, including BT Cellnet (UK), Esat Digifone (Ireland), and Viag Interkom (Germany). All networks now owned or operated by mmO2 (except Manx Telecom) were renamed as O2. The de-merger was accomplished via a share-swap, all British Telecommunications plc shareholders received one mmO2 plc and one BT Group plc (of which British Telecommunications is now a wholly owned subsidiary) share for each share they owned. British Telecommunications plc was de-listed on 16 November, and the two new companies started trading on 19 November.\n\nAt the end of the series of sales, in October 2001 Sir Peter Bonfield resigned, and was replaced by former Lucent CEO Ben Verwaayen.\nDuring Bonfield's tenure the share price went from £4 to £15, and back again to £5. Bonfield's salary to 31 March 2001 was a basic of £780,000 (increasing to £820,000) plus a £481,000 bonus and £50,000 of other benefits including pension. He also received a deferred bonus, payable in shares three years' later, of £481,000, and additional bonuses of £3.3 million.\n\nmmO2 plc was replaced by O2 plc in a further share-swap in 2005, and subsequently bought in an agreed takeover by Telefónica for £18 billion and delisted. In 2004, BT launched Consult 21, a consultation organisation that was to aid BT 21CN in the eventual conversion to digital telephony.\n\nIn 2004, BT was awarded the contract to deliver and manage N3, a secure and fast broadband network for the NHS National Programme for IT (NPfIT) program, on behalf of the English National Health Service (NHS).\n\nIn 2005 BT made a number of acquisitions. In February 2005, BT acquired Infonet (now re-branded BT Infonet), a large telecoms company based in El Segundo, California, giving BT access to new geographies. It also acquired the Italian company Albacom. Then in April 2005, it bought Radianz from Reuters (now rebranded as BT Radianz), which expanded BT's coverage and provided BT with more buying power in certain countries.\n\nIn August 2006, BT acquired online electrical retailer Dabs.com for £30.6 million. The BT Home Hub manufactured by Inventel was also launched in June 2006.\n\nIn October 2006, BT confirmed that it would be investing 75% of its total capital spending, put at £10 billion over five years, in its new Internet Protocol (IP) based 21st century network (21CN). Annual savings of £1 billion per annum were expected when the transition to the new network was to have been completed in 2010, with over 50% of its customers to have been transferred by 2008. (For actual progress see BT 21CN). That month the first customers on to 21CN was successfully tested at Adastral Park in Suffolk.\n\nIn January 2007, BT acquired Sheffield-based ISP, PlusNet plc, adding 200,000 customers. BT stated that PlusNet will continue to operate separately out of its Sheffield head-office. On 1 February 2007, BT announced agreed terms to acquire International Network Services Inc. (INS), an international provider of IT consultancy and software.\n\nIn February 2007, Sir Michael Rake succeeded Sir Christopher Bland. In April that year, they acquired COMSAT International, followed in October by the acquisition of Lynx Technology.\n\nBT acquired Wire One Communications in June 2008 and folded the company into \"BT Conferencing\", its existing conferencing unit, as a new video business unit\nIn July 2008, BT acquired the online business directory firm Ufindus for £20 million in order to expand its position in the local information market in GB. On 28 July 2008, BT acquired Ribbit, of Mountain View, California, \"Silicon Valley's First Phone Company\". Ribbit provides Adobe Flash/Flex APIs, allowing web developers to incorporate telephony features into their software as a service (SaaS) applications.\n\nIn the early days of its fibre broadband rollout, BT said it would deliver fibre-to-the-premises (FTTP) to around 25% of the Country, with the rest catered for by the slower fibre-to-the-cabinet (FTTC), which uses copper wiring to deliver the final stretch of the connection. In 2014, with less than 0.7% of the company's fibre network being FTTP, BT dropped the 25% target, saying that it was \"far less relevant today\" because of improvements made to the headline speed of FTTC, which had doubled to 80Mbit/s since its fibre broadband rollout was first announced. To supplement FTTC, BT offered an 'FTTP on Demand' product. In January 2015, BT stopped taking orders for the on-demand product.\n\nOn 1 April 2009, BT Engage IT was created from the merger of two previous BT acquisitions, Lynx Technology and Basilica. Apart from the name change not much else changed in operations for another 12 months. On 14 May 2009, BT said it was cutting up to 15,000 jobs in the coming year after it announced its results for the year to 31 March 2009. Then in July 2009, BT offered workers a long holiday for an up front sum of 25% of their annual wage or a one-off payment of £1000 if they agree to go part-time.\n\nOn 6 April 2011, BT launched the first online not-for-profit fundraising service for UK charities called BT MyDonate as part of its investment to the community. The service will pass on 100% of all donations made through the site to the charity, and unlike other services which take a proportion as commission and charge charities for using their services, BT will only pass on credit/debit card charges for each donation. The service allows people to register to give money to charity or collect fundraising donations. BT developed MyDonate with the support of Cancer Research UK, Changing Faces, KidsOut, NSPCC and Women's Aid.\n\nIn March 2013, BT was allocated 4G spectrum in the UK following an auction and assignment by Ofcom, after paying £201.5m.\n\nOn 1 August 2013, BT launched its first television channels, BT Sport, to compete with rival broadcaster Sky Sports. Plans for the channels' launch came about when it was announced in June 2012 that BT had been awarded a package of broadcast rights for the Premier League from the 2013–14 to 2015–16 season, broadcasting 38 matches from each season. In February 2013, BT acquired ESPN Inc.'s UK and Ireland TV channels, continuing its expansion into sports broadcasting. ESPN America and ESPN Classic were both closed, while ESPN continued to be operated by BT. On 9 November 2013, BT announced it had acquired exclusive rights to the Champions League and Europa League for £897m, from the 2015 season, with some free games remaining including both finals.\n\nOn 1 November 2014, BT created a new central business services (CBS) organisation to provide customer services and improve operational efficiency levels.\n\nOn 24 November 2014, shares in BT rose considerably on the announcement that the company was in talks to buy back O2, while at the same time confirmed it was also in talks to acquire EE. BT subsequently entered into exclusive talks to buy EE for £12.5 billion on 15 December 2014 and confirmed on 5 February 2015, subject to regulatory approval. The deal will combine BT's 10 million retail customers and EE's 24.5 million direct mobile subscribers. Deutsche Telekom will own 12% of BT, while Orange S.A. will own 4%.\n\nIn March 2015, launched a 4G service as BT Mobile BT Group CEO Gavin Patterson announced that BT plans to migrate all of its customers onto the IP network by 2025, switching off the company's ISDN network.\n\nOn 15 January 2016, BT received final unconditional approval by the Competition and Markets Authority to acquire EE. The deal was officially completed on 29 January 2016 with Deutsche Telekom now owning 12% of BT, while Orange S.A. own 4%.\n\nOn 1 February 2016, BT announced a new organisational structure that will take effect from April 2016 following the successful acquisition of EE. The EE brand, network and high street stores will be retained and will become a second consumer division, operating alongside BT Consumer. It will serve customers with mobile services, broadband and TV and will continue to deliver the Emergency Services Network contract which was awarded to EE in late 2015. There will be a new BT Business and Public Sector division that will have around £5bn of revenues and will serve small and large businesses as well as the public sector in the UK and Ireland. It will comprise the existing BT Business division along with EE's business division and those parts of BT Global Services that are UK focused. There will also be another new division; BT Wholesale and Ventures that will comprise the existing BT Wholesale division along with EE's MVNO business as well as some specialist businesses such as Fleet, Payphones and Directories. Gerry McQuade, currently Chief Sales and Marketing Officer, Business at EE, will be its CEO.\n\nOn 8 June 2017, BT appointed KPMG as its new auditor to replace PwC in the wake of the fraud scandal in Italy that triggered a major profit warning earlier this year. In last April, KPMG fired six US employees over a scandal that calls into question efforts to ensure that public company accounts are being properly scrutinised.\n\nOn 8 July 2017, \"The Daily Telegraph\" reported that BT \"has called in consultants from McKinsey to conduct a review of its businesses in the hope of saving hundreds of millions of pounds per year. The work, dubbed 'Project Novator', is understood to include a potential merger of BT's struggling global services corporate networking and IT unit with its business and public sector division\".\n\nOn 28 July 2017, BT announced organisational changes to \"simplify its operating model, strengthen accountabilities and accelerate its transformation\" and involves bringing together its BT Consumer and EE divisions into a new unified BT Consumer division that will operate across three brands – BT, EE and Plusnet. It will take effect from 1 April 2018.\n\nOn 18 April 2018, BT announced further organisational changes following unification of its BT Consumer and EE divisions, and involves bringing together its BT Business and Public Sector and BT Wholesale and Ventures divisions into a new unified division known as \"BT Enterprise\". It will also include BT's Ventures business which \"acts as an incubator for potential new growth areas of the company\" and will report as a single unit from 1 October 2018.\n\nBT Group is a holding company; the majority of its businesses and assets are held by its wholly owned subsidiary British Telecommunications plc. BT's businesses are operated under special government regulation by the British telecoms regulator Ofcom (formerly Oftel). BT has been found to have significant market power in some markets following market reviews by Ofcom. In these markets, BT is required to comply with additional obligations such as meeting reasonable requests to supply services and not to discriminate.\n\nBT runs the telephone exchanges, trunk network and local loop connections for the vast majority of British fixed-line telephones. Currently BT is responsible for approximately 28 million telephone lines in GB. Apart from KCOM Group, which serves Kingston upon Hull, BT is the only UK telecoms operator to have a \"Universal service Obligation,\" (USO) which means it must provide a fixed telephone line to any address in the UK. It is also obliged to provide public call boxes.\n\nAs well as continuing to provide service in those traditional areas in which BT has an obligation to provide services or is closely regulated, BT has expanded into more profitable products and services where there is less regulation. These are principally, broadband internet service and bespoke solutions in telecommunications and information technology.\n\nAs BT operates in around 180 countries, it owns and leases a range of buildings and facilities in the UK and around the world. In 2001, it sold some of its UK property portfolio for £2.38 billion to Telereal Trillium in a 30-year leaseback. The deal included 6,700 properties and contributed towards alleviating its debt at the time, with the main advantage being flexibility as it allows BT to vacate property over time, so as to adapt to changing operational requirements.\n\nBT Group's world headquarters and registered office is the BT Centre, a 10-storey office building at 81 Newgate Street in the City of London, opposite St. Paul's tube station.\n\nSome of its UK buildings and stations are:\n\nBT remains one of the largest owners of telecommunications towers in the UK and were a major node in its microwave network. Its BT Tower in London is notable for numerous reasons such as being the tallest building in the UK from its construction in the 1960s until the early 1980s, its revolving restaurant at the top known as 'Top of the Tower' in operation through the late 1960s and 1970s, and remains one of the UK's most important communications nerve centres, the heart of a vast broadcasting and communications network. It carries approximately 95% of the UK's TV content, including live broadcasts and 99% of all live football games as well as pioneering the first international HD, 3D and 4K television transmissions. It serves media production and distribution customers around the world and as part of the Things Connected Network launched in London, it became the highest building in the world to host an Internet of things (IoT) base station in September 2016. Some of its towers are:\nSome of its other UK facilities are:\nBT Group is organised into the following divisions:\n\n\n\nBT's current board of directors as of November 2018:\nBT's current executive committee as of March 2018:\nBT has the second largest defined benefit pension plan of any UK public company.The trustees valued the scheme at £36.7 billion at the end of 2010; an actuarial valuation valued the deficit of the scheme at £9.043 billion as of 31 December 2008.\nFollowing a change in the regulations governing inflation index linking, the deficit was estimated at £5.2 billion in November 2010.\n\nBT sponsored Scotland's domestic rugby union championship and cup competitions between 1999 and 2006.\n\nOn 31 July 2012, it was announced that BT agreed a three-year sponsorship deal with Ulster Rugby and sees BT become the Official Communications Partner. BT's logo will appear on the Ulster Rugby shirt sleeve for all friendlies, Heineken Cup and RaboDirect Pro12 matches as well as a significant brand presence at their home ground; Ravenhill Stadium.\n\nOn 29 July 2013, it was announced that BT had partnered up with Scottish Rugby Union in a four-year sponsorship deal with its two professional clubs; Edinburgh Rugby and Glasgow Warriors that will commence from August 2013. The deal involves BT Sport becoming the new shirt sponsor for both clubs as well as being promoted with BT Group at their respective home grounds; Scotstoun Stadium and Murrayfield Stadium.\n\nOn 28 May 2014, it was announced that BT agreed a £20 million four-year sponsorship deal with Scottish Rugby Union which includes BT securing the naming rights for Murrayfield Stadium which becomes BT Murrayfield Stadium, become sponsor of the Scotland sevens team, become principal and exclusive sponsor of Scotland's domestic league and cup competitions from next season, taking over the role from The Royal Bank of Scotland Group (RBS), and become sponsor of Scottish Rugby's four new academies that aims to drive forward standards for young players who have aspirations to play professionally.\n\nOn 14 April 2015, it was announced that as part of BT's current £20 million four-year sponsorship deal with Scottish Rugby Union that was announced in May 2014, BT has completed its sponsorship portfolio following an additional investment of £3.6 million for the 3 years remaining of its sponsorship deal, to become the new shirt sponsor for the Scotland national teams.\n\nOn 27 January 2016, it was announced that BT, alongside YouTube will be the new joint headline sponsors in a three-year deal with Edinburgh International Television Festival. The two companies will \"share prominence across all branding of the 41st TV Festival, including the famous MacTaggart Lecture and will work closely with the festival organisers in their bid to reflect new trends in a rapidly transforming industry, from new ways of distributing content to technical innovations such as Virtual Reality\".\n\nBT is the founding and principal partner of the Wayne Rooney Foundation, which was established to improve the lives of children and young people. The Foundation will run events \"to raise vital funds to support the work of key organisations dedicated to supporting disadvantaged and vulnerable children and young people\". These organisations are four chosen charities which are, Manchester United Foundation, NSPCC, Claire House Children's Hospice and Alder Hey Children's Hospital. The first of these events was Wayne's testimonial match in August 2016 between Manchester United F.C. and Everton F.C. which raised £1.2 million. The match was screened live through BT Sport with BT MyDonate being the official fundraising platform for the testimonial, with both online and text options for donations promoted during the match.\n\nOn 26 May 2017, it was announced that BT is to sponsor the 2017 British Urban Film Festival (BUFF) and sees BT host every event of the film festival, including the Awards at the BT Tower. BT will also broadcast the awards ceremony on BT.com and will have the opportunity to screen films acquired from the festival on its BT TV store platform.\n\nOn 6 September 2017, it was announced that BT had extended its current £20 million four-year sponsorship deal with Scottish Rugby Union that was announced in May 2014, for a further three years beginning from June 2018. The new deal sees BT retain the naming rights to BT Murrayfield Stadium, alongside its role as principal partner of the Scotland national team and Scotland 7s. BT's logo will continue to be displayed on the front of Scotland rugby shirts across the world, in the Six Nations Championship, as well as the summer and autumn test matches. BT will also continue to be promoted at Edinburgh Rugby and Scotstoun Stadium in Glasgow.\n\nBT's financial results have been as follows:\n\nIn 2004 the BT Group signed the world's largest renewable energy deal with npower and British Gas, and now all of their exchanges, satellite networks and offices are powered by renewable energy. BT is a member of the Corporate Leaders Group on Climate Change. They signed a letter urging the government to do more to tackle this problem. Janet Blake, head of global corporate social responsibility at BT, says that she would like to see incentives that find ways of rewarding those companies that focus on climate change by making investments in green business models.\n\nBT has made it clear that it has an ambitious plan to reduce carbon dioxide emissions. Its strategy includes steps to reduce the company's carbon footprint as well as those of customers, suppliers and employees. BT has pledged to achieve an 80% reduction by the year 2016, which will require further efficiency improvements.\n\nIn 2001, BT discovered it owned a patent () which it believed gave it patent rights on the use of hyperlink technology on the World Wide Web. The corresponding UK patent had already expired, but the US patent was valid until 2006. On 11 February 2002, BT began a court case relating to its claims in a US federal court against the Internet service provider Prodigy Communications Corporation. In the case \"British Telecommunications plc v. Prodigy\", the United States District Court for the Southern District of New York ruled on 22 August 2002 that the BT patent was not applicable to web technology and granted Prodigy's request for summary judgment of non-infringement.\n\nIn early 2008 it was announced that BT had entered into a contract (along with Virgin Media and TalkTalk) with the spyware company Phorm (responsible under their 121Media guise for the Apropos rootkit) to intercept and analyse their users' click-stream data and sell the anonymised aggregate information as part of Phorm's OIX advertising service. The practice, known as \"behavioural targeting\" and condemned by critics as \"data pimping\", came under intense fire from various internet communities and other interested-parties who believe that the interception of data without the consent of users and web site owners is illegal under UK law (RIPA). At a more fundamental level, many have argued that the ISPs and Phorm have no right to sell a commodity (a user's data, and the copyrighted content of web sites) to which they have no claim of ownership. In response to questions about Phorm and the interception of data by the Webwise system Sir Tim Berners-Lee, credited as the creator of the World Wide Web protocol, indicated his disapproval of the concept and is quoted as saying of his data and web history:\n\nBeginning in 2010 the UK intelligence community investigated Huawei, the Chinese supplier of BT's new fibre infrastructure with increasing urgency after the United States, Canada and Australia prevented the company from operating in their countries. Although BT had notified the UK government in 2003 of Huawei's interest in their £10bn network upgrade contract, they did not raise the security implications as BT failed to explain that the Chinese company would have unfettered access to critical infrastructure. On 16 December 2012 the prime minister David Cameron was supplied with an in-depth report indicating that the intelligence services had very grave doubts regarding Huawei, and that UK governmental, military, and civilian privacy may have been under serious threat.\n\nOn 7 June 2013, British lawmakers concluded that BT should not have allowed Huawei access to the UK's communications network without ministerial oversight, saying they were 'deeply shocked' that BT did not inform government that they were allowing Huawei and ZTE, both with ties to the Chinese military, unfettered access to critical national systems. Furthermore, ministers discovered that the agency with the responsibility to ensure Chinese equipment and code was threat-free was entirely staffed by Huawei employees. Subsequently, parliamentarians confirmed that in case of an attack on the UK there was nothing that could be done to stop Chinese infiltration.\n\nBy 2016 Huawei had put measures in place to ensure the integrity of UK national security. Specifically their UK work is now overseen by a board that includes directors from GCHQ, the Cabinet Office and the Home Office.\n\nZTE, another Chinese company that supplies extensive network equipment and subscriber hardware used with BT 'Infinity', was also under scrutiny by parliament's intelligence and security committee after the US, Canada, Australia and the European Union declared the company a security risk.\n\nIn September 2012, BT entered into a $23 million deal with the US military to provide a key communications cable connecting RAF Croughton, a US military base on UK soil, with Camp Lemonnier, a large US base in Djibouti. Camp Lemonnier is used as a base for American drone attacks in Yemen and Somalia, and has been described by \"The Economist\" as \"the most important base for drone operations outside the war zone of Afghanistan.\"\n\nHuman rights groups including Reprieve and Amnesty International have criticised the use of armed drones outside declared war zones. Evidence produced by The Bureau of Investigative Journalism and Stanford University's International Human Rights & Conflict Resolution Clinic suggest that drone strikes have caused substantial civilian casualties, and may be illegal under international law.\n\nIn 2013, BT was the subject of a complaint by Reprieve to the Department of Business, Innovation and Skills under the OECD Guidelines for Multinational Enterprises, following their refusal to explain whether or not their infrastructure was used to facilitate drone strikes. The subsequent refusal of this complaint was appealed in May 2014, on the basis that the UK National Contact Point's decision did not follow the OECD Guidelines. The issue of bias was also raised, due to the appointment of Lord Ian Livingston as government minister for the department which was processing the complaint: Livingston had occupied a senior position at BT when the cable between RAF Croughton and Camp Lemonnier was originally built.\n\n\n"}
{"id": "4644", "url": "https://en.wikipedia.org/wiki?curid=4644", "title": "Balmoral Castle", "text": "Balmoral Castle\n\nBalmoral Castle () is a large estate house in Royal Deeside, Aberdeenshire, Scotland, near the village of Crathie, west of Ballater and east of Braemar.\n\nBalmoral has been one of the residences of the British royal family since 1852, when the estate and its original castle were purchased privately by Prince Albert, the husband of Queen Victoria. It remains the private property of the royal family and is not part of the Crown Estate.\n\nSoon after the estate was purchased by the royal family, the existing house was found to be too small and the current Balmoral Castle was commissioned. The architect was William Smith of Aberdeen, although his designs were amended by Prince Albert.\n\nThe castle is an example of Scottish baronial architecture, and is classified by Historic Scotland as a category A listed building. The new castle was completed in 1856 and the old castle demolished shortly thereafter.\n\nThe Balmoral Estate has been added to by successive members of the royal family, and now covers an area of approximately . It is a working estate, including grouse moors, forestry, and farmland, as well as managed herds of deer, Highland cattle, and ponies.\n\nKing Robert II of Scotland (1316–1390) had a hunting lodge in the area. Historical records also indicate that a house at Balmoral was built by Sir William Drummond in 1390. The estate is recorded in 1451 as \"Bouchmorale\", and later was tenanted by Alexander Gordon, second son of the 1st Earl of Huntly. A tower house was built on the estate by the Gordons. \n\nIn 1662, the estate passed to Charles Farquharson of Inverey, brother of John Farquharson, the \"Black Colonel\". The Farquharsons were Jacobite sympathisers, and James Farquharson of Balmoral was involved in both the 1715 and 1745 rebellions. He was wounded at the Battle of Falkirk in 1746. The Farquharson estates were forfeit, and passed to the Farquharsons of Auchendryne. In 1798, James Duff, 2nd Earl Fife, acquired Balmoral and leased the castle. Sir Robert Gordon, a younger brother of the 4th Earl of Aberdeen, acquired the lease in 1830. He made major alterations to the original castle at Balmoral, including baronial-style extensions that were designed by John Smith of Aberdeen.\n\nQueen Victoria and Prince Albert first visited Scotland in 1842, five years after her accession to the throne and two years after their marriage. During this first visit they stayed at Edinburgh, and at Taymouth Castle in Perthshire, the home of the Marquess of Breadalbane. They returned in 1844 to stay at Blair Castle and, in 1847, when they rented Ardverikie by Loch Laggan. During the latter trip they encountered weather that was extremely rainy, which led Sir James Clark, the queen's doctor, to recommend Deeside instead, for its more healthy climate.\n\nSir Robert Gordon died in 1847 and his lease on Balmoral reverted to Lord Aberdeen. In February 1848 an arrangement was made—that Prince Albert would acquire the remaining part of the lease on Balmoral, together with its furniture and staff—without having seen the property first.\n\nThe royal couple arrived for their first visit on 8 September 1848. Victoria found the house \"small but pretty\", and recorded in her diary that: \"All seemed to breathe freedom and peace, and to make one forget the world and its sad turmoils\". The surrounding hilly landscape reminded them of Thuringia, Albert's homeland in Germany.\n\nQuickly, the house was confirmed to be too small and, in 1848, John and William Smith were commissioned to design new offices, cottages, and other ancillary buildings. Improvements to the woodlands, gardens, and estate buildings also were being made, with the assistance of the landscape gardener, James Beattie, and possibly by the painter, James Giles.\n\nMajor additions to the old house were considered in 1849, but by then negotiations were under way to purchase the estate from the trustees of the deceased Earl Fife. After seeing a corrugated iron cottage at the Great Exhibition of 1851, Prince Albert ordered a pre-fabricated iron building for Balmoral from E. T. Bellhouse & Co., to serve as a temporary ballroom and dining room. It was in use by 1 October 1851, and would serve as a ballroom until 1856.\n\nThe sale was completed in June 1852, the price being £32,000, and Prince Albert formally took possession that autumn. The neighbouring estate of Birkhall was bought at the same time, and the lease on Abergeldie Castle secured as well. To mark the occasion, the \"Purchase Cairn\" was erected in the hills overlooking the castle, the first of many.\n\nThe growing family of Victoria and Albert, the need for additional staff, and the quarters required for visiting friends and official visitors such as cabinet members, however, meant that extension of the existing structure would not be sufficient and that a larger house needed to be built. In early 1852, this was commissioned from William Smith. The son of John Smith (who designed the 1830 alterations of the original castle), William Smith was city architect of Aberdeen from 1852. On learning of the commission, William Burn sought an interview with the prince, apparently to complain that Smith previously had plagiarised his work, however, Burn was unsuccessful in depriving Smith of the appointment. William Smith's designs were amended by Prince Albert, who took a close interest in details such as turrets and windows.\n\nConstruction began during summer 1853, on a site some northwest of the original building that was considered to have a better vista. Another reason for consideration was, that whilst construction was ongoing, the family would still be able to use the old house. Queen Victoria laid the foundation stone on 28 September 1853, during her annual autumn visit. By the autumn of 1855, the royal apartments were ready for occupancy, although the tower was still under construction and the servants had to be lodged in the old house. By coincidence, shortly after their arrival at the estate that autumn, news circulated about the fall of Sevastopol, ending the Crimean War, resulting in wild celebrations by royalty and locals alike. While visiting the estate shortly thereafter, Prince Frederick of Prussia asked for the hand of Princess Victoria.\n\nThe new house was completed in 1856, and the old castle subsequently was demolished. By autumn 1857, a new bridge across the Dee, designed by Isambard Kingdom Brunel linking Crathie and Balmoral was finished.\n\nBalmoral Castle is built from granite quarried at Invergelder on the estate, It consists of two main blocks, each arranged around a courtyard. The southwestern block contains the main rooms, while the northeastern contains the service wings. At the southeast is an tall clock tower topped with turrets, one of which has a balustrade similar to a feature at Castle Fraser. Being similar in style to the demolished castle of the 1830s, the architecture of the new house is considered to be somewhat dated for its time when contrasted with the richer forms of Scots Baronial being developed by William Burn and others during the 1850s. As an exercise in Scots Baronial, it sometimes is described as being too ordered, pedantic, and even, Germanic—as a consequence of Prince Albert's influence on the design.\n\nThe purchase of a Scottish estate by Victoria and Albert and their adoption of a Scottish architectural style, however, was very influential for the ongoing revival of Highland culture. They decorated Balmoral with tartans and attended highland games at Braemar. Queen Victoria expressed an affinity for Scotland, even professing herself to be a Jacobite. Added to the work of Sir Walter Scott, this became a major factor in promoting the adoption of Highland culture by Lowland Scots. Historian Michael Lynch comments that \"the Scottishness of Balmoral helped to give the monarchy a truly British dimension for the first time\".\n\nEven before the completion of the new house, the pattern of the life of the royal couple in the Highlands was soon established. Victoria took long walks of up to four hours daily and Albert spent many days hunting deer and game. In 1849, diarist Charles Greville described their life at Balmoral as resembling that of gentry rather than royalty. Victoria began a policy of commissioning artists to record Balmoral, its surroundings, and its staff. Over the years, numerous painters were employed at Balmoral, including Edwin and Charles Landseer, Carl Haag, William Wyld, and William Henry Fisk. The royal couple took great interest in their staff. They established a lending library.\n\nDuring the 1850s, new plantations were established near the house and exotic conifers were planted on the grounds. Prince Albert had an active role in these improvements, overseeing the design of parterres, the diversion of the main road north of the river via a new bridge, and plans for farm buildings. These buildings included a model dairy that he developed during 1861, the year of his death. The dairy was completed by Victoria. Subsequently, she also built several monuments to her husband on the estate. These include a pyramid-shaped cairn built a year after Albert's death, on top of \"Craig Lurachain\". A large statue of Albert with a dog and a gun by William Theed, was inaugurated on 15 October 1867, the twenty-eighth anniversary of their engagement.\n\nFollowing Albert's death, Victoria spent increasing periods at Balmoral, staying for as long as four months a year during early summer and autumn. Few further changes were made to the grounds, with the exception of some alterations to mountain paths, the erection of various cairns and monuments, and the addition of some cottages (\"Karim Cottage\" and \"Baile na Coille\") built for senior staff. It was during this period that Victoria began to depend on her servant, John Brown. He was a local ghillie from Crathie, who became one of her closest companions during her long mourning.\n\nIn 1887, Balmoral Castle was the birthplace of Victoria Eugenie, a granddaughter of Queen Victoria. She was born to Princess Beatrice, the fifth daughter of Victoria and Albert. Victoria Eugenie would become the queen of Spain.\n\nIn September 1896, Victoria welcomed Emperor Nicholas II of Russia and Empress Alexandra to Balmoral. Four years later Victoria made her last visit to the estate, three months before her death on 22 January 1901.\n\nAfter Victoria's death, the royal family continued to use Balmoral during annual autumn visits. George V had substantial improvements made during the 1910s and 1920s, including formal gardens to the south of the castle.\n\nDuring the Second World War, royal visits to Balmoral ceased. In addition, due to the enmity with Germany, \"Danzig Shiel\", a lodge built by Victoria in Ballochbuie was renamed \"Garbh Allt Shiel\" and the \"King of Prussia's Fountain\" was removed from the grounds.\n\nSince the 1950s, Prince Philip has added herbaceous borders and a water garden. During the 1980s new staff buildings were built close to the castle.\n\nThough called a castle, Balmoral's primary function is that of a country house. It is a \"typical and rather ordinary\" country house from the Victorian period. The tower and \"pepper pot turrets\" are characteristic features of the residence's Scottish Baronial style. The seven-storey tower is an architectural feature borrowed from medieval defensive tower houses. The \"pepper pot\" turrets were influenced by the style of 16th-century French châteaux. Other features of the Scottish Baronial style are the crow-stepped gables, dormer windows, and battlemented porte-cochère.\n\nBalmoral is a private property and, unlike the monarch's official residences, is not the property of the Crown. It originally was purchased personally by Prince Albert, rather than the queen, meaning that no revenues from the estate go to Parliament or to the public purse, as would otherwise be the case for property owned outright by the monarch in accord with the Civil List Act 1760. Along with Sandringham House in Norfolk, ownership of Balmoral was inherited by Edward VIII on his accession in 1936. When he abdicated later the same year, however, he retained ownership of them. A financial settlement was devised, under which Balmoral and Sandringham were purchased by Edward's brother and successor to the Crown, George VI.\n\nCurrently, the estate is still owned outright by the monarch, but, by Trustees under Deeds of Nomination and Appointment, it is managed by a trust.\n\nBalmoral Estate is within the Cairngorms National Park and is partly within the Deeside and Lochnagar National Scenic Area. The estate contains a wide variety of landscapes, from the Dee river valley to open mountains. There are seven Munros (hills in Scotland over ) within the estate, the highest being Lochnagar at . This mountain was the setting for a children's story, \"The Old Man of Lochnagar\", told originally by Prince Charles to his younger brothers, Andrew and Edward. The story was published in 1980, with royalties accruing to The Prince's Trust. The estate also incorporates the 7,500-acre Delnadamph Lodge estate, bought by Elizabeth II in 1978. \n\nThe estate extends to Loch Muick in the southeast where an old boat house and the Royal Bothy (hunting lodge) now named \"Glas-allt-Shiel\", built by Victoria, are located.\n\nThe working estate includes grouse moors, forestry, and farmland, as well as managed herds of deer, Highland cattle, and ponies. It also offers access to the public for fishing (paid) and hiking during certain seasons.\n\nApproximately 8,000 acres of the estate are covered by trees, with almost 3,000 acres used for forestry that yields nearly 10,000 tonnes of wood per year. \"Ballochbuie Forest\", one of the largest remaining areas of old Caledonian pine growth in Scotland, consists of approximately 3,000 acres. It is managed with only minimal or no intervention. The principal mammal on the estate is the red deer with a population of 2,000 to 2,500 head.\n\nThe areas of Lochnagar and Ballochbuie were designated in 1998 by the Secretary of State for Scotland as Special Protection Areas (SPA) under the European Union (EU) Birds Directive.\nBird species inhabiting the moorlands include red grouse, black grouse, ptarmigan, and the capercaillie. Ballochbuie also is protected as a Special Area of Conservation by the EU Habitats Directive, as \"one of the largest remaining continuous areas of native Caledonian Forest\". In addition, there are four sites of special scientific interest on the estate.\n\nThe royal family employs approximately 50 full-time and 50–100 part-time staff to maintain the working estate. A malt whisky distillery located on the Balmoral Estate produces the Royal Lochnagar Single Malt whisky.\n\nThere are approximately 150 buildings on the estate, including Birkhall, formerly home to Queen Elizabeth The Queen Mother, and used now by Prince Charles and the Duchess of Cornwall for their summer holidays. Craigowan Lodge is used regularly by the family and friends of the royal family and also has been used while Balmoral Castle was being prepared for a royal visit. Six smaller buildings on the estate are let as holiday cottages.\n\nIn 1931, the castle gardens were opened to the public for the first time and they now are open daily between April and the end of July, after which Queen Elizabeth II arrives for her annual stay. The ballroom is the only room in the castle that may be viewed by the public.\n\nCraigowan Lodge is a seven-bedroom stone house approximately a mile from the main castle in Balmoral. More rustic than the castle, the lodge was often the home of Charles and Diana when they visited. Currently, it is used as quarters for important guests.\n\nIn the obituary of Michael Andreevich Romanoff, the highest-ranking member of the Russian imperial family at the time of his death in 2008, it was noted that his family spent most of World War II at Craigowan Lodge.\n\nThe lodge has been in the news periodically since 2005, because Queen Elizabeth II often spends the first few days of her summer holiday there. During each weekend of the summer the castle is a lucrative source of income from visiting tourists. Sometimes, the Queen arrives at Balmoral before the tourist visiting season is over.\n\nQueen Elizabeth II was in residence at Balmoral at the time of the death of Diana, Princess of Wales in 1997. Her private discussions with then Prime Minister, Tony Blair, were dramatised in the Stephen Frears film, \"The Queen\" (2006). The 1997 film \"Mrs Brown\" also was based on events at Balmoral. In both films, however, substitute locations were used: Blairquhan Castle in \"The Queen\"; and Duns Castle in \"Mrs Brown\".\n\nQueen Elizabeth II's visits to Balmoral Castle were also featured in several episodes of the Netflix series \"The Crown\". Ardverikie House was used as a stand-in for the royal estate for filming purposes.\n\nSince 1987 an illustration of the castle has been featured on the reverse side of £100 notes issued by the Royal Bank of Scotland.\n\n\n"}
{"id": "4647", "url": "https://en.wikipedia.org/wiki?curid=4647", "title": "Breton language", "text": "Breton language\n\nBreton (; or in Morbihan) is a Southwestern Brittonic Celtic language spoken in Brittany.\n\nUntil recently Breton was thought to have been brought from Great Britain to Armorica by migrating Britons during the Early Middle Ages; it is thus classified as an Insular Celtic language, and as such considered not to be closely related to the Continental Celtic Gaulish language which had been spoken in pre-Roman Gaul. Breton is most closely related to Cornish, both being Southwestern Brittonic languages. Welsh and the extinct Cumbric are the more distantly related Western Brittonic languages. Owing to the predominance of French in modern France, Breton phonology has become closer to that of French, and thus has become more distanced from that of its sister languages in Great Britain. Stephen Oppenheimer, in his book \"The Origins of the British\", has put forward evidence suggesting that Breton developed in Brittany and was brought to western Britain in the early bronze age by people seeking copper and especially tin ore for smelting into bronze.\n\nThe other regional language of Brittany, Gallo, is a langue d'oïl. Gallo is a Romance language descended from Latin (unlike the similarly named ancient Celtic language Gaulish), and a close relative of French.\n\nHaving declined from more than 1,000,000 speakers around 1950 to about 200,000 in the first decade of the 21st century, Breton is classified as \"severely endangered\" by the UNESCO Atlas of the World's Languages in Danger. However, the number of children attending bilingual classes has risen 33% between 2006 and 2012 to 14,709.\n\nBreton is spoken in Lower Brittany (), roughly to the west of a line linking Plouha (west of Saint-Brieuc) and La Roche-Bernard (east of Vannes). It comes from a Brittonic language community that once extended from Great Britain to Armorica (present-day Brittany) and had even established a toehold in Galicia (in present-day Spain). Old Breton is attested from the 9th century. It was the language of the upper classes until the 12th century, after which it became the language of commoners in Lower Brittany. The nobility, followed by the bourgeoisie, adopted French. The written language of the Duchy of Brittany was Latin, switching to French in the 15th century. There exists a limited tradition of Breton literature. Some Old Breton vocabulary remains in the present day as philosophical and scientific terms in Modern Breton. The recognized stages of the Breton language are: Old Breton - c.800 to c.1100, Middle Breton - c.1100 to c.1650, Modern Breton - c.1650 to present.\n\nThe French monarchy was not concerned with the minority languages of France spoken by the lower classes, and required the use of French for government business as part of its policy of national unity. During the French Revolution, the government introduced policies favouring French over the regional languages, which it pejoratively referred to as . The revolutionaries assumed that reactionary and monarchist forces preferred regional languages to try to keep the peasant masses underinformed. In 1794, Bertrand Barère submitted his \"report on the \" to the Committee of Public Safety in which he said that \"federalism and superstition speak Breton\".\n\nSince the 19th century, under the Third, Fourth and Fifth Republics, the government has attempted to stamp out minority languages, including Breton, in state schools, in an effort to build a national culture. Teachers humiliated students for using their regional languages, and such practices prevailed until the late 1960s.\n\nIn the early 21st century, due to the political centralization of France, the influence of the media, and the increasing mobility of people, only about 200,000 people can speak Breton, a dramatic decline from more than a million in 1950. The majority of today's speakers are more than 60 years old, and Breton is now classified as an endangered language.\n\nAt the beginning of the 20th century, half of the population of Lower Brittany knew only Breton; the other half were bilingual. By 1950, there were only 100,000 monolingual Bretons, and this rapid decline has continued, with likely no monolingual speakers left today. A statistical survey in 1997 found around 300,000 speakers in Lower Brittany, of whom about 190,000 were aged 60 or older. Few 15- to 19-year-olds spoke Breton.\n\nIn 1925, Professor Roparz Hemon founded the Breton-language review \"Gwalarn.\" During its 19-year run, \"Gwalarn\" tried to raise the language to the level of a great international language. Its publication encouraged the creation of original literature in all genres, and proposed Breton translations of internationally recognized foreign works. In 1946, \"Al Liamm\" replaced \"Gwalarn\". Other Breton-language periodicals have been published, which established a fairly large body of literature for a minority language.\n\nIn 1977, Diwan schools were founded to teach Breton by immersion. They taught a few thousand young people from elementary school to high school. See the education section for more information.\n\nThe \"Asterix\" comic series has been translated into Breton. According to the comic, the Gaulish village where Asterix lives is in the Armorica peninsula, which is now Brittany. Some other popular comics have also been translated into Breton, including \"The Adventures of Tintin\", \"Spirou\", \"Titeuf\", \"Hägar the Horrible\", \"Peanuts\" and \"Yakari\".\n\nSome original media are created in Breton. The sitcom, \"Ken Tuch\", is in Breton. Radio Kerne, broadcasting from Finistère, has exclusively Breton programming. Some movies (\"Lancelot du Lac\", \"Shakespeare in Love\", \"Marion du Faouet\", \"Sezneg\") and TV series (\"Columbo\", \"Perry Mason\") have also been translated and broadcast in Breton. Poets, singers, linguists, and writers who have written in Breton, including Yann-Ber Kalloc'h, Roparz Hemon, Anjela Duval, Xavier de Langlais, Pêr-Jakez Helias, Youenn Gwernig, Glenmor and Alan Stivell are now known internationally.\n\nToday, Breton is the only living Celtic language that is not recognized by a national government as an official or regional language.\n\nThe first Breton dictionary, the \"Catholicon\", was also the first French dictionary. Edited by Jehan Lagadec in 1464, it was a trilingual work containing Breton, French and Latin. Today bilingual dictionaries have been published for Breton and languages including English, Dutch, German, Spanish and Welsh. A new generation is determined to gain international recognition for Breton. The monolingual dictionary, (1995), defines Breton words in Breton. The first edition contained about 10,000 words, and the second edition of 2001 contains 20,000 words.\n\nIn the early 21st century, the (\"Office of the Breton language\") began a campaign to encourage daily use of Breton in the region by both businesses and local communes. Efforts include installing bilingual signs and posters for regional events, as well as encouraging the use of the Spilhennig to let speakers identify each other. The office also started an Internationalization and localization policy asking Google, Firefox and SPIP to develop their interfaces in Breton. In 2004, the Breton Wikipedia started, which now counts more than 65,000 articles. In March 2007, the \"Ofis ar Brezhoneg\" signed a tripartite agreement with Regional Council of Brittany and Microsoft for the consideration of the Breton language in Microsoft products. In October 2014, Facebook added Breton as one of its 121 languages. after three years of talks between the \"Ofis\" and Facebook.\n\nBreton is spoken mainly in Lower Brittany, but also in a more dispersed way in Upper Brittany (where Gallo is spoken alongside Breton and French), and in areas around the world that have Breton emigrants.\n\nThe four traditional dialects of Breton correspond to medieval bishoprics rather than to linguistic divisions. They are (, of the county of Léon), (, of Trégor), (, of ), and (, of Vannes). was spoken up to the beginning of the 20th century in the region of Guérande and Batz-sur-Mer. There are no clear boundaries between the dialects because they form a dialect continuum, varying only slightly from one village to the next. , however, is almost mutually unintelligible with most of the other dialects.\n\nAs noted, only French is an official language of France. Supporters of Breton and other minority languages continue to argue for their recognition, education in public schools and place in public life.\n\nIn July 2008, the legislature amended the French Constitution, adding article 75-1: (the regional languages belong to the heritage of France).\n\nThe European Charter for Regional or Minority Languages, which obliges signatory states to recognize minority and regional languages, was signed by France in 1999 but has not been ratified. On 27 October 2015, the Senate rejected a draft constitutional law ratifying the charter.\n\nRegional and departmental authorities use Breton to a very limited extent, for example in signage. Some bilingual signage has also been installed, such as street name signs in Breton towns. One station of the Rennes metro system has signs in both French and Breton.\n\nUnder the French law known as Toubon, it is illegal for commercial signage to be in Breton alone. Signs must be bilingual or French only. Since commercial signage usually has limited physical space, most businesses have signs only in French.\n\n, the Breton language agency, was set up in 1999 by the Brittany region to promote and develop the daily use of Breton. It created the campaign, to encourage enterprises, organisations and communes to promote the use of Breton, for example by installing bilingual signage or translating their websites into Breton.\n\nIn the late 20th century, the French government considered incorporating the independent Breton-language immersion schools (called ) into the state education system. This action was blocked by the French Constitutional Council based on the 1994 amendment to the Constitution that establishes French as the language of the republic. Therefore, no other language may be used as a language of instruction in state schools. The Toubon Law implemented the amendment, asserting that French is the language of public education.\n\nThe Diwan schools were founded in Brittany in 1977 to teach Breton by immersion. They taught a few thousand young people from elementary school to high school. They have gained fame owing to their high level of results in school exams. Breton-language schools do not receive funding from the national government, though the Brittany Region may fund them.\n\nAnother teaching method is a bilingual approach by (\"Two Languages\") in the State schools, created in 1979. (\"Awakening\") was created in 1990 for bilingual education in the Catholic schools.\n\nIn 2018, 18,337 pupils (about 2.00% of all pupils in Brittany) attended Diwan, Div Yezh and Dihun schools. Their number has increased yearly. Jean-Yves Le Drian, the president of the Regional Council, had a goal of 20,000 pupils by 2010, but is encouraged by their progress.\n\nIn 2007, some 4,500 to 5,000 adults followed a Breton language course (such as evening course, correspondence, or other). The family transmission of Breton in 1999 is estimated to be 3 percent.\n\nGrowth of the percentage of pupils in bilingual education.\nPercentage of pupils in bilingual education per department.\n\nThe 10 communes with the highest percentage of pupils in bilingual primary education, listed with their total population.\nThe 10 communes of historic Brittany with the highest total population, listed with their percentages of pupils in bilingual primary education.\n\nIn addition to bilingual education (including Breton-medium education) the region has introduced the Breton language in primary education, mainly in the department of Finistère. These \"initiation\" sessions are generally one to three hours per week, and consist of songs and games.\n\nSchools in secondary education (\"collèges\" and \"lycées\") offer some courses in Breton. In 2010, nearly 5,000 students in Brittany were reported to be taking this option. Additionally, the University of Rennes 2 has a Breton language department offering courses in the language along with a master's degree in Breton and Celtic Studies.\n\nVowels in Breton may be short or long. All unstressed vowels are short; stressed vowels can be short or long (vowel lengths are not noted in usual orthographies as they are implicit in the phonology of particular dialects, and not all dialects pronounce stressed vowels as long).\n\nAll vowels can also be nasalized, which is noted by appending an 'n' letter after the base vowel, or by adding a combining tilde above the vowel (most commonly and easily done for \"a\" and \"o\" due to the Portuguese letters), or more commonly by non-ambiguously appending an letter after the base vowel (this depends on the orthographic variant).\nDiphthongs are .\n\n\nAs in English as well as the other Celtic languages, a variety of verbal constructions are available to express grammatical aspect, for example: showing a distinction between progressive and habitual actions:\n\nAs in other modern Celtic languages, Breton pronouns are fused into preceding prepositions to produce a sort of \"conjugated\" preposition. Below are some examples in Breton, Cornish, Welsh, Irish, Scottish Gaelic, and Manx, along with English translations.\nNote that in the examples above the Goidelic languages (Irish, Scottish Gaelic and Manx) use the preposition meaning \"at\" to show possession, whereas the Brittonic languages use \"with\". The Goidelic languages, however, do use the preposition \"with\" to express \"belong to\" (Irish , Scottish , Manx , The book belongs to me).\n\nNote also that the above examples of Welsh are the formal written language. The order and preposition may differ slightly in colloquial Welsh (Formal , North Wales , South Wales ).\n\nBreton has four initial consonant mutations: though modern Breton lost the nasal mutation of Welsh, it also has a \"hard\" mutation, in which voiced stops become voiceless, and a \"mixed\" mutation, which is a mixture of hard and soft mutations.\n\nUnlike the other Insular Celtic languages, Breton has a verb-second (V2) constraint in main clauses, so that the finite verb appears in the second position in the sentence. The initial constituent is pragmatically determined, but in a pragmatically neutral context, there are two commonly-used word order patterns: the first places the subject in initial position (as in (1)), followed by an uninflected verb, while the second places the verbal infinitive in initial position (as in (2)), followed by the auxiliary \"ober\" 'to do'. \n\nOther elements, such as the direct object, or an adverbial phrase, can also appear in initial position, but this is usually pragmatically marked, with focus on the initial element. \n\nThe English words and have been borrowed from French, which took them from Breton. However, this is uncertain: for instance, \"menhir\" is \"peulvan\" or \"maen hir\" (\"long stone\"), \"maen sav\" (\"straight stone\") (two words: noun + adjective) in Breton. \"Dolmen\" is a misconstructed word (it should be \"taol-vaen\"). Some studies state that these words were borrowed from Cornish. can be directly translated from Welsh as \"long stone\" (which is exactly what a or is). The Cornish surnames Mennear, Minear and Manhire all derive from the Cornish \" \" (\"long stone\"), as does Tremenheere \"settlement by the long stone\".\n\nThe French word (\"to jabber in a foreign language\") is derived from Breton ' (\"bread\") and ' (\"wine\"). The French word (\"large seagull\") is derived from Breton ', which shares the same root as English \"gull\" (Welsh ', Cornish \"\").\n\nThe first extant Breton texts, contained in the Leyde manuscript, were written at the end of the 8th century: 50 years prior to the Strasbourg Oaths, considered to be the earliest example of French. Like many medieval orthographies, Old- and Middle Breton orthography was at first not standardised, and the spelling of a particular word varied at authors' discretion. In 1499, however, the \"Catholicon\", was published; as the first dictionary written for both French and Breton, it became a point of reference on how to transcribe the language. The orthography presented in the \"Catholicon\" was largely similar to that of French, in particular with respect to the representation of vowels, as well as the use of both the Latinate digraph —a remnant of the sound change /kʷ/ > /k/ in Latin—and Brittonic or to represent /k/ before front vowels.\n\nAs phonetic and phonological differences between the dialects began to magnify, many regions, particularly the Vannes country, began to devise their own orthographies. Many of these orthographies were more closely related to the French model, albeit with some modifications. Examples of these modifications include the replacement of Old Breton with to denote word-final /x~h/ (an evolution of Old Breton /θ/ in the Vannes dialect) and use of to denote the initial mutation of /k/ (today this mutation is written ). and thus needed another transcription.\n\nIn the 1830s Jean-François Le Gonidec created a modern phonetic system for the language.\n\nDuring the early years of the 20th century, a group of writers known as elaborated and reformed Le Gonidec's system. They made it more suitable as a super-dialectal representation of the dialects of Cornouaille, Leon and Trégor (known as from \"Kernev\", \"Leon\" and \"Treger\" in Breton). This KLT orthography was established in 1911. At the same time writers of the more divergent Vannetais dialect developed a phonetic system also based on that of Le Gonidec.\n\nFollowing proposals made during the 1920s, the KLT and Vannetais orthographies were merged in 1941 to create an orthographic system to represent all four dialects. This (\"wholly unified\") orthography was significant for the inclusion of the \"zh\" digraph, which represents a in Vannetais and corresponds to a in the KLT dialects.\n\nIn 1955 François Falc'hun and the group Emgleo Breiz proposed a new orthography. It was designed to use a set of graphemes closer to the conventions of French. This (\"University Orthography\", known in Breton as ) was given official recognition by the French authorities as the \"official orthography of Breton in French education.\" It was opposed in the region and today is used only by the magazine \"Brud Nevez\" and the publishing house Emgléo Breiz.\n\nBetween 1971 and 1974, a new standard orthography was devised — the or . This system is based on the derivation of the words.\n\nToday the majority of writers continue to use the \"Peurunvan orthography\", and it is the version taught in most Breton-language schools.\n\nDue to the deficient suitableness of those standardised, interdialectal orthography for many dialects (especially the Vannes dialect) they are seen as a threat by some activists, rather than as a helping tool for promoting and spreading the language because it endangers the rich variety of the still living dialects and encourages the usage of a de facto non-existent artificial language.\n\nBreton is written in the Latin script. \"Peurunvan\", the most commonly used orthography, consists of the following letters:\n\nThe circumflex, grave accent, trema and tilde appear on some letters. These diacritics are used in the following way:\n\nSee for an introduction to the Breton alphabet and pronunciation.\n\nBoth orthographies use the above alphabet, although \"é\" is used only in .\n\nDifferences between the two systems are particularly noticeable in word endings. In Peurunvan, final obstruents, which are devoiced in absolute final position and voiced in sandhi before voiced sounds, are represented by a grapheme that indicates a voiceless sound. In OU they are written as voiced but represented as voiceless before suffixes: (big), (bigger).\n\nIn addition, Peurunvan maintains the KLT convention, which distinguishes noun/adjective pairs by nouns written with a final voiced consonant and adjectives with a voiceless one. No distinction is made in pronunciation, e.g. ' \"Breton language\" vs. ' \"Breton (adj)\".\n\nSome examples of words in the different orthographies:\n\nNotes:\n\nVisitors to Brittany may encounter words and phrases (especially on signs and posters) such as the following:\n\n\n\n\n\n\n"}
{"id": "4648", "url": "https://en.wikipedia.org/wiki?curid=4648", "title": "Broch", "text": "Broch\n\nA broch () is an Iron Age drystone hollow-walled structure found in Scotland. Brochs belong to the classification \"complex atlantic roundhouse\" devised by Scottish archaeologists in the 1980s. Their origin is a matter of some controversy.\n\nThe word \"broch\" is derived from Lowland Scots 'brough', meaning (among other things) fort. In the mid-19th century Scottish antiquaries called brochs 'burgs', after Old Norse ', with the same meaning. Place names in Scandinavian Scotland such as Burgawater and Burgan show that Old Norse ' is the older word used for these structures in the north. Brochs are often referred to as \"duns\" in the west. Antiquarians began to use the spelling \"broch\" in the 1870s.\n\nA precise definition for the word has proved elusive. Brochs are the most spectacular of a complex class of roundhouse buildings found throughout Atlantic Scotland. The Shetland Amenity Trust lists about 120 sites in Shetland as candidate brochs, while the Royal Commission on the Ancient and Historical Monuments of Scotland (RCAHMS) identifies a total of 571 candidate broch sites throughout the country. Researcher Euan MacKie has proposed a much smaller total for Scotland of 104.\n\nThe origin of brochs is a subject of continuing research. Sixty years ago most archaeologists believed that brochs, usually regarded as the 'castles' of Iron Age chieftains, were built by immigrants who had been pushed northward after being displaced first by the intrusions of Belgic tribes into what is now southeast England at the end of the second century BC and later by the Roman invasion of southern Britain beginning in AD 43. Yet there is now little doubt that the hollow-walled broch tower was purely an invention in what is now Scotland; even the kinds of pottery found inside them that most resembled south British styles were local hybrid forms. The first of the modern review articles on the subject (MacKie 1965) did not, as is commonly believed, propose that brochs were built by immigrants, but rather that a hybrid culture formed from the blending of a small number of immigrants with the native population of the Hebrides produced them in the first century BC, basing them on earlier, simpler, promontory forts. This view contrasted, for example, with that of Sir W. Lindsay Scott, who argued, following Childe (1935), for a wholesale migration into Atlantic Scotland of people from southwest England.\n\nMacKie's theory has fallen from favour too, mainly because starting in the 1970s there was a general move in archaeology away from 'diffusionist' explanations towards those pointing to exclusively indigenous development. Meanwhile, the increasing number – albeit still pitifully few – of radiocarbon dates for the primary use of brochs (as opposed to their later, secondary use) still suggests that most of the towers were built in the 1st centuries BC and AD. A few may be earlier, notably the one proposed for Old Scatness Broch in Shetland, where a sheep bone dating to 390–200 BC has been reported.\n\nThe other broch claimed to be substantially older than the 1st century BC is Crosskirk in Caithness, but a recent review of the evidence suggests that it cannot plausibly be assigned a date earlier than the 1st centuries BC/AD\n\nThe distribution of brochs is centred on northern Scotland. Caithness, Sutherland and the Northern Isles have the densest concentrations, but there are a great many examples in the west of Scotland and the Hebrides. Although mainly concentrated in the northern Highlands and the Islands, a few examples occur in the Borders (for example Edin's Hall Broch and Bow Castle Broch); on the west coast of Dumfries and Galloway; and near Stirling. In a c.1560 sketch there appears to be a broch by the river next to Annan Castle in Dumfries and Galloway. This small group of southern brochs has never been satisfactorily explained.\n\nThe original interpretation of brochs, favoured by nineteenth century antiquarians, was that they were defensive structures, places of refuge for the community and their livestock. They were sometimes regarded as the work of Danes or Picts. From the 1930s to the 1960s, archaeologists such as V. Gordon Childe and later John Hamilton regarded them as castles where local landowners held sway over a subject population.\n\nThe castle theory fell from favour among Scottish archaeologists in the 1980s, due to a lack of supporting archaeological evidence. These archaeologists suggested defensibility was never a major concern in the siting of a broch, and argued that they may have been the \"stately homes\" of their time, objects of prestige and very visible demonstrations of superiority for important families (Armit 2003). Once again, however, there is a lack of archaeological proof for this reconstruction, and the sheer number of brochs, sometimes in places with a lack of good land, makes it problematic.\n\nBrochs' close groupings and profusion in many areas may indeed suggest that they had a primarily defensive or even offensive function. Some of them were sited beside precipitous cliffs and were protected by large ramparts, artificial or natural: a good example is at Burland near Gulberwick in Shetland, on a clifftop and cut off from the mainland by huge ditches. Often they are at key strategic points. In Shetland they sometimes cluster on each side of narrow stretches of water: the broch of Mousa, for instance, is directly opposite another at Burraland in Sandwick. In Orkney there are more than a dozen on the facing shores of Eynhallow Sound, and many at the exits and entrances of the great harbour of Scapa Flow. In Sutherland quite a few are placed along the sides and at the mouths of deep valleys. Writing in 1956 John Stewart suggested that brochs were forts put up by a military society to scan and protect the countryside and seas.\n\nFinally, some archaeologists consider broch sites individually, doubting that there ever was a single common purpose for which every broch was constructed. There are differences between the various areas in which brochs are found, with regard to position, dimensions and likely status. For example, the broch \"villages\" which occur at a few places in Orkney have no parallel in the Western Isles.\n\nGenerally, brochs have a single entrance with bar-holes, door-checks and lintels. There are mural cells and there is a scarcement (ledge), perhaps for timber-framed lean-to dwellings lining the inner face of the wall. Also there is a spiral staircase winding upwards between the inner and outer wall and connecting the galleries. Brochs vary from 5 to 15 metres (16–50 ft) in internal diameter, with 3 metre (10 ft) thick walls. On average, the walls only survive to a few metres in height. There are five extant examples of towers with significantly higher walls: Dun Carloway on Lewis, Dun Telve and Dun Troddan in Glenelg, Mousa in Shetland and Dun Dornaigil in Sutherland, all of whose walls exceed 6.5 m (21 ft) in height.\n\nMousa's walls are the best preserved and are still 13 m tall; it is not clear how many brochs originally stood this high. A frequent characteristic is that the walls are galleried: with an open space between, the outer and inner wall skins are separate but tied together with linking stone slabs; these linking slabs may in some cases have served as steps to higher floors. It is normal for there to be a cell breaking off from the passage beside the door; this is known as the guard cell. It has been found in some Shetland brochs that guard cells in entrance passageways are close to large door-check stones. Although there was much argument in the past, it is now generally accepted among archaeologists that brochs were roofed, perhaps with a conical timber framed roof covered with a locally sourced thatch. The evidence for this assertion is still fairly scanty, although excavations at Dun Bharabhat, Lewis, may support it. The main difficulty with this interpretation continues to be the potential source of structural timber, though bog and driftwood may have been plentiful sources.\n\nOn the islands of Orkney and Shetland there are very few cells at ground floor. Most brochs have scarcements (ledges) which may have allowed the construction of a very sturdy wooden first floor (first spotted by the antiquary George Low in Shetland in 1774), and excavations at Loch na Berie on the Isle of Lewis show signs of a further, second floor (e.g. stairs on the first floor, which head upwards). Some brochs such as Dun Dornaigil and Culswick in Shetland have unusual triangular lintels above the entrance door.\n\nAs in the case of Old Scatness in Shetland (near Jarlshof and Burroughston on Shapinsay), brochs were sometimes located close to arable land and a source of water (some have wells or natural springs rising within their central space). Sometimes, on the other hand, they were sited in wilderness areas (e.g. Levenwick and Culswick in Shetland, Castle Cole in Sutherland). Brochs are often built beside the sea (Carn Liath, Sutherland); sometimes they are on islands in lochs (e.g. Clickimin in Shetland).\n\nAbout 20 Orcadian broch sites include small settlements of stone buildings surrounding the main tower. Examples include Howe, near Stromness, Gurness Broch in the north west of Mainland, Orkney, Midhowe on Rousay and Lingro near Kirkwall (destroyed in the 1980s). There are \"broch village\" sites in Caithness, but elsewhere they are unknown.\n\nMost brochs are unexcavated. Those that have been properly examined show that they continued to be in use for many centuries, with the interiors often modified and changed, and that they underwent many phases of habitation and abandonment. The end of the broch period seems to have come around AD 200–300.\nMousa, Old Scatness and Jarlshof: The Crucible of Iron Age Shetland is a combination of three broch sites in Shetland that are on the United Kingdom \"Tentative List\" of possible nominations for the UNESCO World Heritage Programme list of sites of outstanding cultural or natural importance to the common heritage of humankind. \nThis list, published in July 2010, includes sites that may be nominated for inscription over the next 5–10 years.\n\n\n\n\n"}
{"id": "4649", "url": "https://en.wikipedia.org/wiki?curid=4649", "title": "Billy Crystal", "text": "Billy Crystal\n\nWilliam Edward Crystal (born March 14, 1948) is an American actor, comedian, writer, producer, director, and television host. He gained prominence in the 1970s for playing Jodie Dallas on the ABC sitcom \"Soap\" and became a Hollywood film star during the late 1980s and 1990s, appearing in the critical and box office successes \"The Princess Bride\" (1987), \"Throw Momma from the Train\" (1987), \"When Harry Met Sally...\" (1989), \"City Slickers\" (1991), \"Mr. Saturday Night\" (1992) and \"Analyze This\" (1999), and providing the voice of Mike Wazowski in the \"Monsters, Inc.\" films starting in 2001.\n\nHe has hosted the Academy Awards nine times, beginning in 1990 and most recently in 2012.\n\nCrystal was born at Doctors Hospital on the Upper East Side of Manhattan, and initially raised in The Bronx. As a toddler, he moved with his family to 549 East Park Avenue in Long Beach, New York, on Long Island. He and his older brothers Joel and Richard, nicknamed Rip, were the sons of Helen (née Gabler), a housewife, and Jack Crystal, who owned and operated the Commodore Music Store, founded by Helen's father, Julius Gabler. Jack was also a jazz promoter, a producer, and an executive for an affiliated jazz record label, Commodore Records, founded by Helen's brother, musician and songwriter Milt Gabler. Crystal is Jewish (his family emigrated from Austria and Russia), and he grew up attending Temple Emanu-El (Long Beach, New York) where he was \"Bar Mitzvahed\". The three young brothers would entertain by reprising comedy routines from the likes of Bob Newhart, Rich Little and Sid Caesar records their father would bring home. Jazz artists such as Arvell Shaw, Pee Wee Russell, Eddie Condon, and Billie Holiday were often guests in the home. With the decline of Dixieland jazz and the rise of discount record stores, in 1963 Crystal's father lost his business and died later that year at the age of 54 after suffering a heart attack while bowling. His mother, Helen Crystal, died in 2001.\n\nAfter graduation from Long Beach High School in 1965, Crystal attended Marshall University in Huntington, West Virginia, on a baseball scholarship, having learned the game from his father, who pitched for St. John's University. Crystal never played baseball at Marshall because the program was suspended during his first year. He did not return to Marshall as a sophomore, instead deciding to stay in New York to be close to his future wife. He attended Nassau Community College with Janice and later transferred to New York University, where he was a film and television directing major. He graduated from NYU in 1970 with a BFA from its School of Fine Arts, not yet named for the Tisch family. One of his instructors was Martin Scorsese, while Oliver Stone and Christopher Guest were among his classmates.\n\nCrystal returned to New York City. For four years he was part of a comedy trio with two friends. They played colleges and coffee houses and Crystal worked as a substitute teacher on Long Island. He later became a solo act and performed regularly at \"The Improv\" and \"Catch a Rising Star\". In 1976, Crystal appeared on an episode of \"All in the Family\". He was on the dais for The Dean Martin Celebrity Roast of Muhammad Ali on February 19, 1976, where he did impressions of both Ali and sportscaster Howard Cosell. He was scheduled to appear on the first episode of \"NBC Saturday Night\" on October 11, 1975 (The show was later renamed \"Saturday Night Live\" on March 26, 1977), but his sketch was cut. He did perform on episode 17 of that first season, doing a monologue of an old jazz man capped by the line \"Can you dig it? I knew that you could.\" Host Ron Nessen introduced him as \"Bill Crystal\". Crystal was a guest on the first and the last episode of \"The Tonight Show with Jay Leno,\" which concluded February 6, 2014, after 22 seasons on the air. Crystal also made game show appearances such as \"The Hollywood Squares,\" \"All Star Secrets\" and \"The $20,000 Pyramid.\" To this day, he holds the Pyramid franchise's record for getting his contestant partner to the top of the pyramid in winner's circle in the fastest time: 26 seconds.\nCrystal's earliest prominent role was as Jodie Dallas on \"Soap,\" one of the first unambiguously gay characters in the cast of an American television series. He continued in the role during the series's entire 1977–1981 run.\n\nIn 1982, Billy Crystal hosted his own variety show, \"The Billy Crystal Comedy Hour\" on NBC. When Crystal arrived to shoot the fifth episode, he learned it had been canceled after only the first two aired. After hosting \"Saturday Night Live\" twice, on March 17, 1984 and the show's ninth season finale on May 5, he joined the regular cast for the 1984-85 season. His most famous recurring sketch was his parody of Fernando Lamas, a smarmy talk-show host whose catchphrase, \"You look... mahvelous!,\" became a media sensation. Crystal subsequently released an album of his stand-up material titled \"Mahvelous!\" in 1985, as well as the single \"You Look Marvelous\", which peaked at No. 58 on the \"Billboard\" Hot 100 in the US, and No. 17 in Canada. Also in the 1980s, Crystal starred in an episode of Shelley Duvall's \"Faerie Tale Theatre\" as the smartest of the three little pigs.\n\nIn 1996, Crystal was the guest star of the third episode of \"Muppets Tonight\" and hosted three Grammy Awards Telecasts: the 29th Grammys; the 30th Grammys; and the 31st Grammys.\n\nIn 2015, Crystal co-starred alongside Josh Gad on the FX comedy series \"The Comedians\", which ran for just one season before being canceled.\n\nCrystal's first film role was in Joan Rivers' 1978 film \"Rabbit Test\", the story of the \"world's first pregnant man.\"\n\nCrystal appeared briefly in the Rob Reiner \"rockumentary\" \"This Is Spinal Tap\" (1984) as Morty The Mime, a waiter dressed as a mime at one of Spinal Tap's parties. He shared the scene with a then-unknown, non-speaking Dana Carvey, stating famously that \"Mime is money.\" He later starred in the action comedy \"Running Scared\" (1986) and was directed by Reiner again in \"The Princess Bride\" (1987), in a comedic supporting role as \"Miracle Max\". Reiner got Crystal to accept the part by saying, \"How would you like to play Mel Brooks?\" Reiner also allowed Crystal to ad-lib, and his parting shot, \"Have fun storming the castle!\" is a frequently-quoted line.\n\nReiner directed Crystal for a third time in the romantic comedy \"When Harry Met Sally...\" (1989), in which Crystal starred alongside Meg Ryan and for which he was nominated for a Golden Globe. The film has since become an iconic classic for the genre and is Crystal's most celebrated film. Crystal then starred in the award-winning buddy comedy \"City Slickers\" (1991), which proved very successful both commercially and critically and for which Crystal was nominated for his second Golden Globe. The film was followed by a sequel, which was less successful. In 1992, he narrated \"Dr. Seuss Video Classics: Horton Hatches the Egg\".\n\nFollowing the significant success of these films, Crystal wrote, directed, and starred in \"Mr. Saturday Night\" (1992) and \"Forget Paris\" (1995). In the former, Crystal played a serious role in aging makeup, as an egotistical comedian who reflects back on his career, although the character was from his \"SNL\" days. Though some of his subsequent films were not as well received as his earlier hits, Crystal had another success alongside Robert De Niro in Harold Ramis' mobster comedy \"Analyze This\" (1999). More recent performances include roles in \"America's Sweethearts\" (2001), the sequel \"Analyze That\" (2002), and \"Parental Guidance\" (2012).\n\nHe directed the made-for-television movie \"61*\" (2001) based on Roger Maris's and Mickey Mantle's race to break Babe Ruth's single-season home run record in 1961. This earned Crystal an Emmy nomination for Outstanding Directing for a Miniseries, Movie or a Special.\n\nCrystal was originally asked to voice Buzz Lightyear in \"Toy Story\" (1995) but turned it down, a decision he later regretted due to the popularity of the series. Crystal later went on to provide the voice of Mike Wazowski in the blockbuster Pixar film \"Monsters, Inc.\" (2001), and reprised his voice role in the prequel, \"Monsters University\", which was released in June 2013. Crystal also provided the voice of Calcifer in the English version of Hayao Miyazaki's \"Howl's Moving Castle\" (2004).\n\nCrystal hosted the Academy Awards broadcast in 1990–1993, 1997, 1998, 2000, 2004 and 2012. His hosting was critically praised, resulting in two Emmy wins for hosting and writing the 63rd Academy Awards and an Emmy win for writing the 64th Academy Awards. He returned as the host for the 2012 Oscar ceremony, after Eddie Murphy resigned from hosting. His nine times as the M.C. is second only to Bob Hope's 19 in most ceremonies hosted. At the 83rd Academy Awards ceremony in 2011, he appeared as a presenter for a digitally inserted Bob Hope and before doing so was given a standing ovation. Film critic Roger Ebert said when Crystal came onstage about two hours into the show, he got the first laughs of the broadcast. Crystal's hosting gigs have regularly included an introductory video segment in which he comedically inserts himself into scenes of that year's nominees in addition to a song following his opening monologue.\n\nCrystal won the 2005 Tony Award for Best Special Theatrical Event for \"700 Sundays\", a two-act, one-man play, which he conceived and wrote about his parents and his childhood growing up on Long Island. He toured throughout the US with the show in 2006 and then Australia in 2007.\n\nFollowing the initial success of the play, Crystal wrote the book \"700 Sundays\" for Warner Books, which was published on October 31, 2005. In conjunction with the book and the play that also paid tribute to his uncle, Milt Gabler, Crystal produced two CD compilations: \"Billy Crystal Presents: The Milt Gabler Story\", which featured his uncle's most influential recordings from Billie Holiday's \"Strange Fruit\" to \"Rock Around the Clock\" by Bill Haley & His Comets; and \"Billy Remembers Billie\" featuring Crystal's favorite Holiday recordings.\n\nIn the fall of 2013, he brought the show back to Broadway for a two-month run at the Imperial Theatre. HBO filmed the January 3–4, 2014 performances for a special, which debuted on their network on April 19, 2014.\n\nIn 1986, Crystal started hosting \"Comic Relief\" on HBO with Robin Williams and Whoopi Goldberg. Founded by Bob Zmuda, Comic Relief raises money for homeless people in the United States.\n\nOn September 6, 2005, on \"The Tonight Show with Jay Leno\", Crystal and Jay Leno were the first celebrities to sign a Harley-Davidson motorcycle to be auctioned off for Gulf Coast relief.\n\nCrystal has participated in the Simon Wiesenthal Center Museum of Tolerance in Los Angeles. Crystal's personal history is featured in the “Finding Our Families, Finding Ourselves” exhibit in the genealogy wing of the museum.\n\nOn March 12, 2008, Crystal signed a one-day minor league contract to play with the New York Yankees, and was invited to the team's major league spring training. He wore uniform number 60 in honor of his upcoming 60th birthday. On March 13, in a spring training game against the Pittsburgh Pirates, Crystal led off as the designated hitter. He managed to make contact, fouling a fastball up the first base line, but was eventually struck out by Pirates pitcher Paul Maholm on six pitches and was later replaced in the batting order by Johnny Damon. He was released on March 14, his 60th birthday.\n\nCrystal's boyhood idol was Yankee Hall of Fame legend Mickey Mantle who had signed a program for him when Crystal attended a game where Mantle had hit a home run. Years later on \"The Dinah Shore Show\", in one of his first television appearances, Crystal met Mantle in person and had Mantle re-sign the same program. Crystal would be good friends with Mickey Mantle until Mantle's death in 1995. He and Bob Costas together wrote the eulogy Costas read at Mantle's funeral, and George Steinbrenner then invited Crystal to emcee the unveiling of Mantle's monument at Yankee Stadium. In his 2013 memoir \"Still Foolin' 'Em\", Crystal writes that after the ceremony, near the Yankee clubhouse, he was punched in the stomach by Joe DiMaggio, who was angry at Crystal for not having introduced him to the crowd as the \"Greatest living player\".\n\nCrystal also was well known for his impressions of Yankee Hall of Famer turned broadcaster Phil Rizzuto. Rizzuto, known for his quirks calling games, did not travel to Anaheim, California in 1996 to call the game for WPIX. Instead, Crystal joined the broadcasters in the booth and pretended to be Rizzuto for a few minutes during the August 31 game.\n\nAlthough a lifelong Yankee fan, he is a part-owner of the Arizona Diamondbacks, even earning a World Series ring in 2001 when the Diamondbacks beat his beloved Yankees.\n\nIn \"City Slickers\", Crystal wears a New York Mets baseball cap. In the 1986 film \"Running Scared\", his character is an avid Chicago Cubs fan, wearing a Cubs' jersey in several scenes. In the 2012 film \"Parental Guidance\", his character is the announcer for the Fresno Grizzlies, a Minor League Baseball team, and aspires to announce for their Major League affiliate, the San Francisco Giants.\n\nCrystal appeared in Ken Burns's 1994 documentary \"Baseball\", telling personal stories about his life-long love of baseball, including meeting Casey Stengel as a child and Ted Williams as an adult.\n\nCrystal is also a longtime Los Angeles Clippers fan.\n\nCrystal and his wife Janice (née Goldfinger) married in June 1970, have two daughters, actress Jennifer and producer Lindsay, and are grandparents.\nThey reside in the Los Angeles neighborhood of Pacific Palisades, California.\n\n\n"}
{"id": "4650", "url": "https://en.wikipedia.org/wiki?curid=4650", "title": "Black hole", "text": "Black hole\n\nA black hole is a region of spacetime exhibiting such strong gravitational effects that nothing—not even particles and electromagnetic radiation such as light—can escape from inside it. The theory of general relativity predicts that a sufficiently compact mass can deform spacetime to form a black hole. The boundary of the region from which no escape is possible is called the event horizon. Although the event horizon has an enormous effect on the fate and circumstances of an object crossing it, no locally detectable features appear to be observed. In many ways a black hole acts like an ideal black body, as it reflects no light. Moreover, quantum field theory in curved spacetime predicts that event horizons emit Hawking radiation, with the same spectrum as a black body of a temperature inversely proportional to its mass. This temperature is on the order of billionths of a kelvin for black holes of stellar mass, making it essentially impossible to observe.\n\nObjects whose gravitational fields are too strong for light to escape were first considered in the 18th century by John Michell and Pierre-Simon Laplace. The first modern solution of general relativity that would characterize a black hole was found by Karl Schwarzschild in 1916, although its interpretation as a region of space from which nothing can escape was first published by David Finkelstein in 1958. Black holes were long considered a mathematical curiosity; it was during the 1960s that theoretical work showed they were a generic prediction of general relativity. The discovery of neutron stars in the late 1960s sparked interest in gravitationally collapsed compact objects as a possible astrophysical reality.\n\nBlack holes of stellar mass are expected to form when very massive stars collapse at the end of their life cycle. After a black hole has formed, it can continue to grow by absorbing mass from its surroundings. By absorbing other stars and merging with other black holes, supermassive black holes of millions of solar masses () may form. There is general consensus that supermassive black holes exist in the centers of most galaxies.\n\nDespite its invisible interior, the presence of a black hole can be inferred through its interaction with other matter and with electromagnetic radiation such as visible light. Matter that falls onto a black hole can form an external accretion disk heated by friction, forming some of the brightest objects in the universe. If there are other stars orbiting a black hole, their orbits can be used to determine the black hole's mass and location. Such observations can be used to exclude possible alternatives such as neutron stars. In this way, astronomers have identified numerous stellar black hole candidates in binary systems, and established that the radio source known as Sagittarius A*, at the core of the Milky Way galaxy, contains a supermassive black hole of about 4.3 million solar masses.\n\nOn 11 February 2016, the LIGO collaboration announced the first direct detection of gravitational waves, which also represented the first observation of a black hole merger. , eleven gravitational wave events have been observed that originated from ten merging black holes (along with one binary neutron star merger).\n\nThe idea of a body so massive that even light could not escape was briefly proposed by astronomical pioneer and English clergyman John Michell in a letter published in November 1784. Michell's simplistic calculations assumed that such a body might have the same density as the Sun, and concluded that such a body would form when a star's diameter exceeds the Sun's by a factor of 500, and the surface escape velocity exceeds the usual speed of light. Michell correctly noted that such supermassive but non-radiating bodies might be detectable through their gravitational effects on nearby visible bodies. Scholars of the time were initially excited by the proposal that giant but invisible stars might be hiding in plain view, but enthusiasm dampened when the wavelike nature of light became apparent in the early nineteenth century. If light were a wave rather than a \"corpuscle\", it became unclear what, if any, influence gravity would have on escaping light waves. Modern relativity discredits Michell's notion of a light ray shooting directly from the surface of a supermassive star, being slowed down by the star's gravity, stopping, and then free-falling back to the star's surface.\n\nIn 1915, Albert Einstein developed his theory of general relativity, having earlier shown that gravity does influence light's motion. Only a few months later, Karl Schwarzschild found a solution to the Einstein field equations, which describes the gravitational field of a point mass and a spherical mass. A few months after Schwarzschild, Johannes Droste, a student of Hendrik Lorentz, independently gave the same solution for the point mass and wrote more extensively about its properties. This solution had a peculiar behaviour at what is now called the Schwarzschild radius, where it became singular, meaning that some of the terms in the Einstein equations became infinite. The nature of this surface was not quite understood at the time. In 1924, Arthur Eddington showed that the singularity disappeared after a change of coordinates (see Eddington–Finkelstein coordinates), although it took until 1933 for Georges Lemaître to realize that this meant the singularity at the Schwarzschild radius was a non-physical coordinate singularity. Arthur Eddington did however comment on the possibility of a star with mass compressed to the Schwarzschild radius in a 1926 book, noting that Einstein's theory allows us to rule out overly large densities for visible stars like Betelgeuse because \"a star of 250 million km radius could not possibly have so high a density as the sun. Firstly, the force of gravitation would be so great that light would be unable to escape from it, the rays falling back to the star like a stone to the earth. Secondly, the red shift of the spectral lines would be so great that the spectrum would be shifted out of existence. Thirdly, the mass would produce so much curvature of the space-time metric that space would close up around the star, leaving us outside (i.e., nowhere).\"\n\nIn 1931, Subrahmanyan Chandrasekhar calculated, using special relativity, that a non-rotating body of electron-degenerate matter above a certain limiting mass (now called the Chandrasekhar limit at ) has no stable solutions. His arguments were opposed by many of his contemporaries like Eddington and Lev Landau, who argued that some yet unknown mechanism would stop the collapse. They were partly correct: a white dwarf slightly more massive than the Chandrasekhar limit will collapse into a neutron star, which is itself stable. But in 1939, Robert Oppenheimer and others predicted that neutron stars above another limit (the Tolman–Oppenheimer–Volkoff limit) would collapse further for the reasons presented by Chandrasekhar, and concluded that no law of physics was likely to intervene and stop at least some stars from collapsing to black holes. Their original calculations, based on the Pauli exclusion principle, gave it as ; subsequent consideration of strong force-mediated neutron-neutron repulsion raised the estimate to approximately to . Observations of the neutron star merger GW170817, which is thought to have generated a black hole shortly afterward, have refined the TOV limit estimate to ~.\n\nOppenheimer and his co-authors interpreted the singularity at the boundary of the Schwarzschild radius as indicating that this was the boundary of a bubble in which time stopped. This is a valid point of view for external observers, but not for infalling observers. Because of this property, the collapsed stars were called \"frozen stars\", because an outside observer would see the surface of the star frozen in time at the instant where its collapse takes it to the Schwarzschild radius.\n\nIn 1958, David Finkelstein identified the Schwarzschild surface as an event horizon, \"a perfect unidirectional membrane: causal influences can cross it in only one direction\". This did not strictly contradict Oppenheimer's results, but extended them to include the point of view of infalling observers. Finkelstein's solution extended the Schwarzschild solution for the future of observers falling into a black hole. A complete extension had already been found by Martin Kruskal, who was urged to publish it.\n\nThese results came at the beginning of the golden age of general relativity, which was marked by general relativity and black holes becoming mainstream subjects of research. This process was helped by the discovery of pulsars in 1967, which, by 1969, were shown to be rapidly rotating neutron stars. Until that time, neutron stars, like black holes, were regarded as just theoretical curiosities; but the discovery of pulsars showed their physical relevance and spurred a further interest in all types of compact objects that might be formed by gravitational collapse.\n\nIn this period more general black hole solutions were found. In 1963, Roy Kerr found the exact solution for a rotating black hole. Two years later, Ezra Newman found the axisymmetric solution for a black hole that is both rotating and electrically charged. Through the work of Werner Israel, Brandon Carter, and David Robinson the no-hair theorem emerged, stating that a stationary black hole solution is completely described by the three parameters of the Kerr–Newman metric: mass, angular momentum, and electric charge.\n\nAt first, it was suspected that the strange features of the black hole solutions were pathological artifacts from the symmetry conditions imposed, and that the singularities would not appear in generic situations. This view was held in particular by Vladimir Belinsky, Isaak Khalatnikov, and Evgeny Lifshitz, who tried to prove that no singularities appear in generic solutions. However, in the late 1960s Roger Penrose and Stephen Hawking used global techniques to prove that singularities appear generically.\n\nWork by James Bardeen, Jacob Bekenstein, Carter, and Hawking in the early 1970s led to the formulation of black hole thermodynamics. These laws describe the behaviour of a black hole in close analogy to the laws of thermodynamics by relating mass to energy, area to entropy, and surface gravity to temperature. The analogy was completed when Hawking, in 1974, showed that quantum field theory predicts that black holes should radiate like a black body with a temperature proportional to the surface gravity of the black hole.\n\nJohn Michell used the term \"dark star\", and in the early 20th century, physicists used the term \"gravitationally collapsed object\". Science writer Marcia Bartusiak traces the term \"black hole\" to physicist Robert H. Dicke, who in the early 1960s reportedly compared the phenomenon to the Black Hole of Calcutta, notorious as a prison where people entered but never left alive.\n\nThe term \"black hole\" was used in print by Life magazine and Science News magazine in 1963, and by science journalist Ann Ewing in her article Black Holes' in Space\", dated 18 January 1964, which was a report on a meeting of the American Association for the Advancement of Science held in Cleveland, Ohio.\n\nIn December 1967, a student reportedly suggested the phrase \"black hole\" at a lecture by John Wheeler; Wheeler adopted the term for its brevity and \"advertising value\", and it quickly caught on, leading some to credit Wheeler with coining the phrase.\n\nThe no-hair conjecture postulates that, once it achieves a stable condition after formation, a black hole has only three independent physical properties: mass, charge, and angular momentum; the black hole is otherwise featureless. If the conjecture is true, any two black holes that share the same values for these properties, or parameters, are indistinguishable from one another. The degree to which the conjecture is true for real black holes under the laws of modern physics, is currently an unsolved problem.\n\nThese properties are special because they are visible from outside a black hole. For example, a charged black hole repels other like charges just like any other charged object. Similarly, the total mass inside a sphere containing a black hole can be found by using the gravitational analog of Gauss's law, the ADM mass, far away from the black hole. Likewise, the angular momentum can be measured from far away using frame dragging by the gravitomagnetic field.\n\nWhen an object falls into a black hole, any information about the shape of the object or distribution of charge on it is evenly distributed along the horizon of the black hole, and is lost to outside observers. The behavior of the horizon in this situation is a dissipative system that is closely analogous to that of a conductive stretchy membrane with friction and electrical resistance—the membrane paradigm. This is different from other field theories such as electromagnetism, which do not have any friction or resistivity at the microscopic level, because they are time-reversible. Because a black hole eventually achieves a stable state with only three parameters, there is no way to avoid losing information about the initial conditions: the gravitational and electric fields of a black hole give very little information about what went in. The information that is lost includes every quantity that cannot be measured far away from the black hole horizon, including approximately conserved quantum numbers such as the total baryon number and lepton number. This behavior is so puzzling that it has been called the black hole information loss paradox.\n\nThe simplest static black holes have mass but neither electric charge nor angular momentum. These black holes are often referred to as Schwarzschild black holes after Karl Schwarzschild who discovered this solution in 1916. According to Birkhoff's theorem, it is the only vacuum solution that is spherically symmetric. This means that there is no observable difference between the gravitational field of such a black hole and that of any other spherical object of the same mass. The popular notion of a black hole \"sucking in everything\" in its surroundings is therefore only correct near a black hole's horizon; far away, the external gravitational field is identical to that of any other body of the same mass.\n\nSolutions describing more general black holes also exist. Non-rotating charged black holes are described by the Reissner–Nordström metric, while the Kerr metric describes a non-charged rotating black hole. The most general stationary black hole solution known is the Kerr–Newman metric, which describes a black hole with both charge and angular momentum.\n\nWhile the mass of a black hole can take any positive value, the charge and angular momentum are constrained by the mass. In Planck units, the total electric charge \"Q\" and the total angular momentum \"J\" are expected to satisfy\n\nfor a black hole of mass \"M\". Black holes with the minimum possible mass satisfying this inequality are called extremal. Solutions of Einstein's equations that violate this inequality exist, but they do not possess an event horizon. These solutions have so-called naked singularities that can be observed from the outside, and hence are deemed \"unphysical\". The cosmic censorship hypothesis rules out the formation of such singularities, when they are created through the gravitational collapse of realistic matter. This is supported by numerical simulations.\n\nDue to the relatively large strength of the electromagnetic force, black holes forming from the collapse of stars are expected to retain the nearly neutral charge of the star. Rotation, however, is expected to be a universal feature of compact astrophysical objects. The black-hole candidate binary X-ray source GRS 1915+105 appears to have an angular momentum near the maximum allowed value. That uncharged limit is\n\nallowing definition of a dimensionless spin parameter such that\n\nBlack holes are commonly classified according to their mass, independent of angular momentum, \"J\". The size of a black hole, as determined by the radius of the event horizon, or Schwarzschild radius, is roughly proportional to the mass, \"M\", through\nwhere \"r\" is the Schwarzschild radius and \"M\" is the mass of the Sun. For a black hole with nonzero spin and/or electric charge, the radius is smaller, until an extremal black hole could have an event horizon close to\n\nThe defining feature of a black hole is the appearance of an event horizon—a boundary in spacetime through which matter and light can only pass inward towards the mass of the black hole. Nothing, not even light, can escape from inside the event horizon. The event horizon is referred to as such because if an event occurs within the boundary, information from that event cannot reach an outside observer, making it impossible to determine if such an event occurred.\n\nAs predicted by general relativity, the presence of a mass deforms spacetime in such a way that the paths taken by particles bend towards the mass. At the event horizon of a black hole, this deformation becomes so strong that there are no paths that lead away from the black hole.\n\nTo a distant observer, clocks near a black hole would appear to tick more slowly than those further away from the black hole. Due to this effect, known as gravitational time dilation, an object falling into a black hole appears to slow as it approaches the event horizon, taking an infinite time to reach it. At the same time, all processes on this object slow down, from the view point of a fixed outside observer, causing any light emitted by the object to appear redder and dimmer, an effect known as gravitational redshift. Eventually, the falling object fades away until it can no longer be seen. Typically this process happens very rapidly with an object disappearing from view within less than a second.\n\nOn the other hand, indestructible observers falling into a black hole do not notice any of these effects as they cross the event horizon. According to their own clocks, which appear to them to tick normally, they cross the event horizon after a finite time without noting any singular behaviour; in classical general relativity, it is impossible to determine the location of the event horizon from local observations, due to Einstein's equivalence principle.\n\nThe shape of the event horizon of a black hole is always approximately spherical. For non-rotating (static) black holes the geometry of the event horizon is precisely spherical, while for rotating black holes the event horizon is oblate.\n\nAt the center of a black hole, as described by general relativity, lies a gravitational singularity, a region where the spacetime curvature becomes infinite. For a non-rotating black hole, this region takes the shape of a single point and for a rotating black hole, it is smeared out to form a ring singularity that lies in the plane of rotation. In both cases, the singular region has zero volume. It can also be shown that the singular region contains all the mass of the black hole solution. The singular region can thus be thought of as having infinite density.\n\nObservers falling into a Schwarzschild black hole (\"i.e.\", non-rotating and not charged) cannot avoid being carried into the singularity, once they cross the event horizon. They can prolong the experience by accelerating away to slow their descent, but only up to a limit. When they reach the singularity, they are crushed to infinite density and their mass is added to the total of the black hole. Before that happens, they will have been torn apart by the growing tidal forces in a process sometimes referred to as spaghettification or the \"noodle effect\".\n\nIn the case of a charged (Reissner–Nordström) or rotating (Kerr) black hole, it is possible to avoid the singularity. Extending these solutions as far as possible reveals the hypothetical possibility of exiting the black hole into a different spacetime with the black hole acting as a wormhole. The possibility of traveling to another universe is, however, only theoretical since any perturbation would destroy this possibility. It also appears to be possible to follow closed timelike curves (returning to one's own past) around the Kerr singularity, which lead to problems with causality like the grandfather paradox. It is expected that none of these peculiar effects would survive in a proper quantum treatment of rotating and charged black holes.\n\nThe appearance of singularities in general relativity is commonly perceived as signaling the breakdown of the theory. This breakdown, however, is expected; it occurs in a situation where quantum effects should describe these actions, due to the extremely high density and therefore particle interactions. To date, it has not been possible to combine quantum and gravitational effects into a single theory, although there exist attempts to formulate such a theory of quantum gravity. It is generally expected that such a theory will not feature any singularities.\n\nThe photon sphere is a spherical boundary of zero thickness in which photons that move on tangents to that sphere would be trapped in a circular orbit about the black hole. For non-rotating black holes, the photon sphere has a radius 1.5 times the Schwarzschild radius. Their orbits would be dynamically unstable, hence any small perturbation, such as a particle of infalling matter, would cause an instability that would grow over time, either setting the photon on an outward trajectory causing it to escape the black hole, or on an inward spiral where it would eventually cross the event horizon.\n\nWhile light can still escape from the photon sphere, any light that crosses the photon sphere on an inbound trajectory will be captured by the black hole. Hence any light that reaches an outside observer from the photon sphere must have been emitted by objects between the photon sphere and the event horizon.\n\nRotating black holes are surrounded by a region of spacetime in which it is impossible to stand still, called the ergosphere. This is the result of a process known as frame-dragging; general relativity predicts that any rotating mass will tend to slightly \"drag\" along the spacetime immediately surrounding it. Any object near the rotating mass will tend to start moving in the direction of rotation. For a rotating black hole, this effect is so strong near the event horizon that an object would have to move faster than the speed of light in the opposite direction to just stand still.\n\nThe ergosphere of a black hole is a volume whose inner boundary is the black hole's oblate spheroid event horizon and a pumpkin-shaped outer boundary, which coincides with the event horizon at the poles but noticeably wider around the equator. The outer boundary is sometimes called the \"ergosurface\".\n\nObjects and radiation can escape normally from the ergosphere. Through the Penrose process, objects can emerge from the ergosphere with more energy than they entered. This energy is taken from the rotational energy of the black hole causing the latter to slow.\n\nIn Newtonian gravity, test particles can stably orbit at arbitrary distances from a central object. In general relativity, however, there exists an innermost stable circular orbit (often called the ISCO), inside of which, any infinitesimal perturbations to a circular orbit will lead to inspiral into the black hole. The location of the ISCO depends on the spin of the black hole, in the case of a Schwarzschild black hole (spin zero) is:\n\nand decreases with increasing black hole spin for particles orbiting in the same direction as the spin.\n\nGiven the bizarre character of black holes, it was long questioned whether such objects could actually exist in nature or whether they were merely pathological solutions to Einstein's equations. Einstein himself wrongly thought that black holes would not form, because he held that the angular momentum of collapsing particles would stabilize their motion at some radius. This led the general relativity community to dismiss all results to the contrary for many years. However, a minority of relativists continued to contend that black holes were physical objects, and by the end of the 1960s, they had persuaded the majority of researchers in the field that there is no obstacle to the formation of an event horizon.\n\nPenrose proved that once an event horizon forms, general relativity without quantum mechanics requires that a singularity will form within. Shortly afterwards, Hawking showed that many cosmological solutions that describe the Big Bang have singularities without scalar fields or other exotic matter (see \"Penrose–Hawking singularity theorems\"). The Kerr solution, the no-hair theorem, and the laws of black hole thermodynamics showed that the physical properties of black holes were simple and comprehensible, making them respectable subjects for research. Conventional black holes are formed by gravitational collapse of heavy objects such as stars, but they can also in theory be formed by other processes.\n\nGravitational collapse occurs when an object's internal pressure is insufficient to resist the object's own gravity. For stars this usually occurs either because a star has too little \"fuel\" left to maintain its temperature through stellar nucleosynthesis, or because a star that would have been stable receives extra matter in a way that does not raise its core temperature. In either case the star's temperature is no longer high enough to prevent it from collapsing under its own weight.\nThe collapse may be stopped by the degeneracy pressure of the star's constituents, allowing the condensation of matter into an exotic denser state. The result is one of the various types of compact star. Which type forms depends on the mass of the remnant of the original star left after the outer layers have been blown away. Such explosions and pulsations lead to planetary nebula. This mass can be substantially less than the original star. Remnants exceeding are produced by stars that were over before the collapse.\n\nIf the mass of the remnant exceeds about (the Tolman–Oppenheimer–Volkoff limit), either because the original star was very heavy or because the remnant collected additional mass through accretion of matter, even the degeneracy pressure of neutrons is insufficient to stop the collapse. No known mechanism (except possibly quark degeneracy pressure, see quark star) is powerful enough to stop the implosion and the object will inevitably collapse to form a black hole.\n\nThe gravitational collapse of heavy stars is assumed to be responsible for the formation of stellar mass black holes. Star formation in the early universe may have resulted in very massive stars, which upon their collapse would have produced black holes of up to . These black holes could be the seeds of the supermassive black holes found in the centers of most galaxies. It has further been suggested that supermassive black holes with typical masses of ~ could have formed from the direct collapse of gas clouds in the young universe. Some candidates for such objects have been found in observations of the young universe.\n\nWhile most of the energy released during gravitational collapse is emitted very quickly, an outside observer does not actually see the end of this process. Even though the collapse takes a finite amount of time from the reference frame of infalling matter, a distant observer would see the infalling material slow and halt just above the event horizon, due to gravitational time dilation. Light from the collapsing material takes longer and longer to reach the observer, with the light emitted just before the event horizon forms delayed an infinite amount of time. Thus the external observer never sees the formation of the event horizon; instead, the collapsing material seems to become dimmer and increasingly red-shifted, eventually fading away.\n\nGravitational collapse requires great density. In the current epoch of the universe these high densities are only found in stars, but in the early universe shortly after the Big Bang densities were much greater, possibly allowing for the creation of black holes. High density alone is not enough to allow black hole formation since a uniform mass distribution will not allow the mass to bunch up. In order for primordial black holes to have formed in such a dense medium, there must have been initial density perturbations that could then grow under their own gravity. Different models for the early universe vary widely in their predictions of the scale of these fluctuations. Various models predict the creation of primordial black holes ranging in size from a Planck mass to hundreds of thousands of solar masses.\n\nDespite the early universe being extremely dense—far denser than is usually required to form a black hole—it did not re-collapse into a black hole during the Big Bang. Models for gravitational collapse of objects of relatively constant size, such as stars, do not necessarily apply in the same way to rapidly expanding space such as the Big Bang.\n\nGravitational collapse is not the only process that could create black holes. In principle, black holes could be formed in high-energy collisions that achieve sufficient density. As of 2002, no such events have been detected, either directly or indirectly as a deficiency of the mass balance in particle accelerator experiments. This suggests that there must be a lower limit for the mass of black holes. Theoretically, this boundary is expected to lie around the Planck mass (\"m\"= ≈ ≈ ), where quantum effects are expected to invalidate the predictions of general relativity. This would put the creation of black holes firmly out of reach of any high-energy process occurring on or near the Earth. However, certain developments in quantum gravity suggest that the Planck mass could be much lower: some braneworld scenarios for example put the boundary as low as . This would make it conceivable for micro black holes to be created in the high-energy collisions that occur when cosmic rays hit the Earth's atmosphere, or possibly in the Large Hadron Collider at CERN. These theories are very speculative, and the creation of black holes in these processes is deemed unlikely by many specialists. Even if micro black holes could be formed, it is expected that they would evaporate in about 10 seconds, posing no threat to the Earth.\n\nOnce a black hole has formed, it can continue to grow by absorbing additional matter. Any black hole will continually absorb gas and interstellar dust from its surroundings. This is the primary process through which supermassive black holes seem to have grown. A similar process has been suggested for the formation of intermediate-mass black holes found in globular clusters. Black holes can also merge with other objects such as stars or even other black holes. This is thought to have been important, especially in the early growth of supermassive black holes, which could have formed from the aggregation of many smaller objects. The process has also been proposed as the origin of some intermediate-mass black holes.\n\nIn 1974, Hawking predicted that black holes are not entirely black but emit small amounts of thermal radiation at a temperature ℏ \"c\"/(8 π \"G\" \"M\" \"k\"); this effect has become known as Hawking radiation. By applying quantum field theory to a static black hole background, he determined that a black hole should emit particles that display a perfect black body spectrum. Since Hawking's publication, many others have verified the result through various approaches. If Hawking's theory of black hole radiation is correct, then black holes are expected to shrink and evaporate over time as they lose mass by the emission of photons and other particles. The temperature of this thermal spectrum (Hawking temperature) is proportional to the surface gravity of the black hole, which, for a Schwarzschild black hole, is inversely proportional to the mass. Hence, large black holes emit less radiation than small black holes.\n\nA stellar black hole of has a Hawking temperature of 62 nanokelvins. This is far less than the 2.7 K temperature of the cosmic microwave background radiation. Stellar-mass or larger black holes receive more mass from the cosmic microwave background than they emit through Hawking radiation and thus will grow instead of shrink. To have a Hawking temperature larger than 2.7 K (and be able to evaporate), a black hole would need a mass less than the Moon. Such a black hole would have a diameter of less than a tenth of a millimeter.\n\nIf a black hole is very small, the radiation effects are expected to become very strong. Even a black hole that is heavy compared to a human would evaporate in an instant. A black hole with the mass of a car would have a diameter of about 10 m and take a nanosecond to evaporate, during which time it would briefly have a luminosity of more than 200 times that of the Sun. Lower-mass black holes are expected to evaporate even faster; for example, a black hole of mass 1 TeV/\"c\" would take less than 10 seconds to evaporate completely. For such a small black hole, quantum gravitation effects are expected to play an important role and could hypothetically make such a small black hole stable, although current developments in quantum gravity do not indicate so.\n\nThe Hawking radiation for an astrophysical black hole is predicted to be very weak and would thus be exceedingly difficult to detect from Earth. A possible exception, however, is the burst of gamma rays emitted in the last stage of the evaporation of primordial black holes. Searches for such flashes have proven unsuccessful and provide stringent limits on the possibility of existence of low mass primordial black holes. NASA's Fermi Gamma-ray Space Telescope launched in 2008 will continue the search for these flashes.\n\nIf black holes evaporate via Hawking radiation, a solar mass black hole will evaporate (beginning once the temperature of the cosmic microwave background drops below that of the black hole) over 10 years. A supermassive black hole with a mass of 10 (100 billion) will evaporate in around 2×10 years. Some monster black holes in the universe are predicted to continue to grow up to perhaps 10 during the collapse of superclusters of galaxies. Even these would evaporate over a timescale of up to 10 years.\n\nBy their very nature, black holes do not directly emit any electromagnetic radiation other than the hypothetical Hawking radiation, so astrophysicists searching for black holes must generally rely on indirect observations. For example, a black hole's existence can sometimes be inferred by observing its gravitational interactions with its surroundings.\n\nThe Event Horizon Telescope (EHT), however, run by MIT's Haystack Observatory, is an attempt to directly observe the immediate environment of the event horizon of Sagittarius A*, the black hole at the centre of the Milky Way, and to produce a silhouetted image of it. The first such image may appear as early as 2018. In 2015, the EHT managed to detect magnetic fields just outside the event horizon of Sagittarius A*, and even discern some of their properties. The existence of magnetic fields had been predicted by theoretical studies of black holes.\n\nOn 14 September 2015 the LIGO gravitational wave observatory made the first-ever successful direct observation of gravitational waves. The signal was consistent with theoretical predictions for the gravitational waves produced by the merger of two black holes: one with about 36 solar masses, and the other around 29 solar masses. This observation provides the most concrete evidence for the existence of black holes to date. For instance, the gravitational wave signal suggests that the separation of the two objects prior to the merger was just 350 km (or roughly 4 times the Schwarzschild radius corresponding to the inferred masses). The objects must therefore have been extremely compact, leaving black holes as the most plausible interpretation.\n\nMore importantly, the signal observed by LIGO also included the start of the post-merger ringdown, the signal produced as the newly formed compact object settles down to a stationary state. Arguably, the ringdown is the most direct way of observing a black hole. From the LIGO signal it is possible to extract the frequency and damping time of the dominant mode of the ringdown. From these it is possible to infer the mass and angular momentum of the final object, which match independent predictions from numerical simulations of the merger. The frequency and decay time of the dominant mode are determined by the geometry of the photon sphere. Hence, observation of this mode confirms the presence of a photon sphere, however it cannot exclude possible exotic alternatives to black holes that are compact enough to have a photon sphere.\n\nThe observation also provides the first observational evidence for the existence of stellar-mass black hole binaries. Furthermore, it is the first observational evidence of stellar-mass black holes weighing 25 solar masses or more.\n\nOn 15 June 2016, a second detection of a gravitational wave event from colliding black holes was announced, and other gravitational wave events have since been observed.\n\nThe proper motions of stars near the center of our own Milky Way provide strong observational evidence that these stars are orbiting a supermassive black hole. Since 1995, astronomers have tracked the motions of 90 stars orbiting an invisible object coincident with the radio source Sagittarius A*. By fitting their motions to Keplerian orbits, the astronomers were able to infer, in 1998, that a 2.6 million object must be contained in a volume with a radius of 0.02 light-years to cause the motions of those stars. Since then, one of the stars—called S2—has completed a full orbit. From the orbital data, astronomers were able to refine the calculations of the mass to 4.3 million and a radius of less than 0.002 light years for the object causing the orbital motion of those stars. The upper limit on the object's size is still too large to test whether it is smaller than its Schwarzschild radius; nevertheless, these observations strongly suggest that the central object is a supermassive black hole as there are no other plausible scenarios for confining so much invisible mass into such a small volume. Additionally, there is some observational evidence that this object might possess an event horizon, a feature unique to black holes.\n\nDue to conservation of angular momentum, gas falling into the gravitational well created by a massive object will typically form a disc-like structure around the object. Artists' impressions such as the accompanying representation of a black hole with corona commonly depict the black hole as if it were a flat-space body hiding the part of the disc just behind it, but in reality gravitational lensing would greatly distort the image of the accretion disk.\nWithin such a disc, friction would cause angular momentum to be transported outward, allowing matter to fall further inward, thus releasing potential energy and increasing the temperature of the gas.\nWhen the accreting object is a neutron star or a black hole, the gas in the inner accretion disc orbits at very high speeds because of its proximity to the compact object. The resulting friction is so significant that it heats the inner disc to temperatures at which it emits vast amounts of electromagnetic radiation (mainly X-rays). These bright X-ray sources may be detected by telescopes. This process of accretion is one of the most efficient energy-producing processes known; up to 40% of the rest mass of the accreted material can be emitted as radiation. (In nuclear fusion only about 0.7% of the rest mass will be emitted as energy.) In many cases, accretion discs are accompanied by relativistic jets that are emitted along the poles, which carry away much of the energy. The mechanism for the creation of these jets is currently not well understood, in part due to insufficient data.\n\nAs such, many of the universe's more energetic phenomena have been attributed to the accretion of matter on black holes. In particular, active galactic nuclei and quasars are believed to be the accretion discs of supermassive black holes. Similarly, X-ray binaries are generally accepted to be binary star systems in which one of the two stars is a compact object accreting matter from its companion. It has also been suggested that some ultraluminous X-ray sources may be the accretion disks of intermediate-mass black holes.\n\nIn November 2011 the first direct observation of a quasar accretion disk around a supermassive black hole was reported.\n\nX-ray binaries are binary star systems that emit a majority of their radiation in the X-ray part of the spectrum. These X-ray emissions are generally thought to result when one of the stars (compact object) accretes matter from another (regular) star. The presence of an ordinary star in such a system provides an opportunity for studying the central object and to determine if it might be a black hole.\n\nIf such a system emits signals that can be directly traced back to the compact object, it cannot be a black hole. The absence of such a signal does, however, not exclude the possibility that the compact object is a neutron star. By studying the companion star it is often possible to obtain the orbital parameters of the system and to obtain an estimate for the mass of the compact object. If this is much larger than the Tolman–Oppenheimer–Volkoff limit (that is, the maximum mass a neutron star can have before it collapses) then the object cannot be a neutron star and is generally expected to be a black hole.\n\nThe first strong candidate for a black hole, Cygnus X-1, was discovered in this way by Charles Thomas Bolton, Louise Webster and Paul Murdin in 1972. Some doubt, however, remained due to the uncertainties that result from the companion star being much heavier than the candidate black hole. Currently, better candidates for black holes are found in a class of X-ray binaries called soft X-ray transients. In this class of system, the companion star is of relatively low mass allowing for more accurate estimates of the black hole mass. Moreover, these systems are actively emit X-rays for only several months once every 10–50 years. During the period of low X-ray emission (called quiescence), the accretion disc is extremely faint allowing detailed observation of the companion star during this period. One of the best such candidates is V404 Cygni.\n\nThe faintness of the accretion disc of an X-ray binary during quiescence is suspected to be caused by the flow of mass entering a mode called an advection-dominated accretion flow (ADAF). In this mode, almost all the energy generated by friction in the disc is swept along with the flow instead of radiated away. If this model is correct, then it forms strong qualitative evidence for the presence of an event horizon, since if the object at the center of the disc had a solid surface, it would emit large amounts of radiation as the highly energetic gas hits the surface, an effect that is observed for neutron stars in a similar state.\n\nThe X-ray emissions from accretion disks sometimes flicker at certain frequencies. These signals are called quasi-periodic oscillations and are thought to be caused by material moving along the inner edge of the accretion disk (the innermost stable circular orbit). As such their frequency is linked to the mass of the compact object. They can thus be used as an alternative way to determine the mass of candidate black holes.\n\nAstronomers use the term \"active galaxy\" to describe galaxies with unusual characteristics, such as unusual spectral line emission and very strong radio emission. Theoretical and observational studies have shown that the activity in these active galactic nuclei (AGN) may be explained by the presence of supermassive black holes, which can be millions of times more massive than stellar ones. The models of these AGN consist of a central black hole that may be millions or billions of times more massive than the Sun; a disk of gas and dust called an accretion disk; and two jets perpendicular to the accretion disk.\nAlthough supermassive black holes are expected to be found in most AGN, only some galaxies' nuclei have been more carefully studied in attempts to both identify and measure the actual masses of the central supermassive black hole candidates. Some of the most notable galaxies with supermassive black hole candidates include the Andromeda Galaxy, M32, M87, NGC 3115, NGC 3377, NGC 4258, NGC 4889, NGC 1277, OJ 287, APM 08279+5255 and the Sombrero Galaxy.\n\nIt is now widely accepted that the center of nearly every galaxy, not just active ones, contains a supermassive black hole. The close observational correlation between the mass of this hole and the velocity dispersion of the host galaxy's bulge, known as the M-sigma relation, strongly suggests a connection between the formation of the black hole and the galaxy itself.\nAnother way that the black hole nature of an object may be tested in the future is through observation of effects caused by a strong gravitational field in their vicinity. One such effect is gravitational lensing: The deformation of spacetime around a massive object causes light rays to be deflected much as light passing through an optic lens. Observations have been made of weak gravitational lensing, in which light rays are deflected by only a few arcseconds. However, it has never been directly observed for a black hole. One possibility for observing gravitational lensing by a black hole would be to observe stars in orbit around the black hole. There are several candidates for such an observation in orbit around Sagittarius A*.\n\nThe evidence for stellar black holes strongly relies on the existence of an upper limit for the mass of a neutron star. The size of this limit heavily depends on the assumptions made about the properties of dense matter. New exotic phases of matter could push up this bound. A phase of free quarks at high density might allow the existence of dense quark stars, and some supersymmetric models predict the existence of Q stars. Some extensions of the standard model posit the existence of preons as fundamental building blocks of quarks and leptons, which could hypothetically form preon stars. These hypothetical models could potentially explain a number of observations of stellar black hole candidates. However, it can be shown from arguments in general relativity that any such object will have a maximum mass.\n\nSince the average density of a black hole inside its Schwarzschild radius is inversely proportional to the square of its mass, supermassive black holes are much less dense than stellar black holes (the average density of a black hole is comparable to that of water). Consequently, the physics of matter forming a supermassive black hole is much better understood and the possible alternative explanations for supermassive black hole observations are much more mundane. For example, a supermassive black hole could be modelled by a large cluster of very dark objects. However, such alternatives are typically not stable enough to explain the supermassive black hole candidates.\n\nThe evidence for the existence of stellar and supermassive black holes implies that in order for black holes to not form, general relativity must fail as a theory of gravity, perhaps due to the onset of quantum mechanical corrections. A much anticipated feature of a theory of quantum gravity is that it will not feature singularities or event horizons and thus black holes would not be real artifacts. For example, in the fuzzball model based on string theory, the individual states of a black hole solution do not generally have an event horizon or singularity, but for a classical/semi-classical observer the statistical average of such states appears just as an ordinary black hole as deduced from general relativity.\n\nA few theoretical objects have been conjectured to match observations of astronomical black hole candidates identically or near-identically, but which function via a different mechanism. These include the gravastar, the black star (semiclassical gravity), and the dark-energy star.\n\nIn 1971, Hawking showed under general conditions that the total area of the event horizons of any collection of classical black holes can never decrease, even if they collide and merge. This result, now known as the second law of black hole mechanics, is remarkably similar to the second law of thermodynamics, which states that the total entropy of a system can never decrease. As with classical objects at absolute zero temperature, it was assumed that black holes had zero entropy. If this were the case, the second law of thermodynamics would be violated by entropy-laden matter entering a black hole, resulting in a decrease of the total entropy of the universe. Therefore, Bekenstein proposed that a black hole should have an entropy, and that it should be proportional to its horizon area.\n\nThe link with the laws of thermodynamics was further strengthened by Hawking's discovery that quantum field theory predicts that a black hole radiates blackbody radiation at a constant temperature. This seemingly causes a violation of the second law of black hole mechanics, since the radiation will carry away energy from the black hole causing it to shrink. The radiation, however also carries away entropy, and it can be proven under general assumptions that the sum of the entropy of the matter surrounding a black hole and one quarter of the area of the horizon as measured in Planck units is in fact always increasing. This allows the formulation of the first law of black hole mechanics as an analogue of the first law of thermodynamics, with the mass acting as energy, the surface gravity as temperature and the area as entropy.\n\nOne puzzling feature is that the entropy of a black hole scales with its area rather than with its volume, since entropy is normally an extensive quantity that scales linearly with the volume of the system. This odd property led Gerard 't Hooft and Leonard Susskind to propose the holographic principle, which suggests that anything that happens in a volume of spacetime can be described by data on the boundary of that volume.\n\nAlthough general relativity can be used to perform a semi-classical calculation of black hole entropy, this situation is theoretically unsatisfying. In statistical mechanics, entropy is understood as counting the number of microscopic configurations of a system that have the same macroscopic qualities (such as mass, charge, pressure, etc.). Without a satisfactory theory of quantum gravity, one cannot perform such a computation for black holes. Some progress has been made in various approaches to quantum gravity. In 1995, Andrew Strominger and Cumrun Vafa showed that counting the microstates of a specific supersymmetric black hole in string theory reproduced the Bekenstein–Hawking entropy. Since then, similar results have been reported for different black holes both in string theory and in other approaches to quantum gravity like loop quantum gravity.\n\nBecause a black hole has only a few internal parameters, most of the information about the matter that went into forming the black hole is lost. Regardless of the type of matter which goes into a black hole, it appears that only information concerning the total mass, charge, and angular momentum are conserved. As long as black holes were thought to persist forever this information loss is not that problematic, as the information can be thought of as existing inside the black hole, inaccessible from the outside, but represented on the event horizon in accordance with the holograpic principle. However, black holes slowly evaporate by emitting Hawking radiation. This radiation does not appear to carry any additional information about the matter that formed the black hole, meaning that this information appears to be gone forever.\n\nThe question whether information is truly lost in black holes (the black hole information paradox) has divided the theoretical physics community (see Thorne–Hawking–Preskill bet). In quantum mechanics, loss of information corresponds to the violation of vital property called unitarity, which has to do with the conservation of probability. It has been argued that loss of unitarity would also imply violation of conservation of energy. Over recent years evidence has been building that indeed information and unitarity are preserved in a full quantum gravitational treatment of the problem.\n\nAccording to quantum field theory in curved spacetime, a single emission of Hawking radiation involves two mutually entangled particles. The outgoing particle escapes and is emitted as a quantum of Hawking radiation; the infalling particle is swallowed by the black hole. Assume a black hole formed a finite time in the past and will fully evaporate away in some finite time in the future. Then, it will only emit a finite amount of information encoded within its Hawking radiation. Assume that at time formula_7, more than half of the information had already been emitted. According to widely accepted research by physicists like Don Page and Leonard Susskind, an outgoing particle emitted at time formula_7 must be entangled with all the Hawking radiation the black hole has previously emitted. This creates a paradox: a principle called \"monogamy of entanglement\" requires that, like any quantum system, the outgoing particle cannot be fully entangled with two independent systems at the same time; yet here the outgoing particle appears to be entangled with both the infalling particle and, independently, with past Hawking radiation.\n\nIn order to resolve the paradox, physicists may eventually be forced to give up one of three time-tested theories: Einstein's equivalence principle, unitarity, or existing quantum field theory. One possible solution, which violates the equivalence principle, is that a \"firewall\" destroys incoming particles at the event horizon.<ref name=\"sciam/Confound\"> Originally published in Quanta, December 21, 2012.</ref> A 2016 analysis of LIGO data shows tentative signs of echoes caused by a fuzzy event horizon; such echoes may be possible in firewall or fuzzball theories but should not occur in classical general relativity. Over the next two years, additional LIGO data should establish whether the echoes were just random noise, or whether they are instead evidence of a violation of classical general relativity.\n\n"}
{"id": "4651", "url": "https://en.wikipedia.org/wiki?curid=4651", "title": "Beta decay", "text": "Beta decay\n\nIn nuclear physics, beta decay (\"β\"-decay) is a type of radioactive decay in which a beta ray (fast energetic electron or positron) is emitted from an atomic nucleus. For example, beta decay of a neutron transforms it into a proton by the emission of an electron accompanied by an antineutrino, or conversely a proton is converted into a neutron by the emission of a positron (positron emission) with a neutrino, thus changing the nuclide type. Neither the beta particle nor its associated (anti-)neutrino exist within the nucleus prior to beta decay, but are created in the decay process. By this process, unstable atoms obtain a more stable ratio of protons to neutrons. The probability of a nuclide decaying due to beta and other forms of decay is determined by its nuclear binding energy. The binding energies of all existing nuclides form what is called the nuclear band or valley of stability. For either electron or positron emission to be energetically possible, the energy release (see below) or Q value must be positive.\n\nBeta decay is a consequence of the weak force, which is characterized by relatively lengthy decay times. Nucleons are composed of up quarks and down quarks, and the weak force allows a quark to change type by the exchange of a W boson and the creation of an electron/antineutrino or positron/neutrino pair. For example, a neutron, composed of two down quarks and an up quark, decays to a proton composed of a down quark and two up quarks. Decay times for many nuclides that are subject to beta decay can be thousands of years.\n\nElectron capture is sometimes included as a type of beta decay, because the basic nuclear process, mediated by the weak force, is the same. In electron capture, an inner atomic electron is captured by a proton in the nucleus, transforming it into a neutron, and an electron neutrino is released.\n\nThe two types of beta decay are known as \"beta minus\" and \"beta plus\". In beta minus (β) decay, a neutron is converted to a proton, and the process creates an electron and an electron antineutrino; while in beta plus (β) decay, a proton is converted to a neutron and the process creates a positron and an electron neutrino. β decay is also known as positron emission.\n\nBeta decay conserves a quantum number known as the lepton number, or the number of electrons and their associated neutrinos (other leptons are the muon and tau particles). These particles have lepton number +1, while their antiparticles have lepton number −1. Since a proton or neutron has lepton number zero, β decay (a positron, or antielectron) must be accompanied with an electron neutrino, while β decay (an electron) must be accompanied by an electron antineutrino.\n\nAn example of electron emission (β decay) is the decay of carbon-14 into nitrogen-14 with a half-life of about 5,730 years:\n\nOr for example the decay of hydrogen-3 (tritium) into helium-3 which is stable:\n\nIn this form of decay, the original element becomes a new chemical element in a process known as nuclear transmutation. This new element has an unchanged mass number , but an atomic number that is increased by one. As in all nuclear decays, the decaying element (in this case ) is known as the \"parent nuclide\" while the resulting element (in this case ) is known as the \"daughter nuclide\".\n\nAn example of positron emission (β decay) is the decay of magnesium-23 into sodium-23 with a half-life of about 11.3 s:\nβ decay also results in nuclear transmutation, with the resulting element having an atomic number that is decreased by one.\nThe beta spectrum, or distribution of energy values for the beta particles, is continuous. The total energy of the decay process is divided between the electron, the antineutrino, and the recoiling nuclide. In the figure to the right, an example of an electron with 0.40 MeV energy from the beta decay of Bi is shown. In this example, the total decay energy is 1.16 MeV, so the antineutrino has the remaining energy: 1.16-0.40=0.76 MeV. An electron at the far right of the curve would have the maximum possible kinetic energy, leaving the energy of the neutrino to be only its small rest mass.\n\nRadioactivity was discovered in 1896 by Henri Becquerel in uranium, and subsequently observed by Marie and Pierre Curie in thorium and in the new elements polonium and radium. In 1899, Ernest Rutherford separated radioactive emissions into two types: alpha and beta (now beta minus), based on penetration of objects and ability to cause ionization. Alpha rays could be stopped by thin sheets of paper or aluminium, whereas beta rays could penetrate several millimetres of aluminium. In 1900, Paul Villard identified a still more penetrating type of radiation, which Rutherford identified as a fundamentally new type in 1903 and termed gamma rays. Alpha, beta, and gamma are the first three letters of the Greek alphabet.\n\nIn 1900, Becquerel measured the mass-to-charge ratio () for beta particles by the method of J.J. Thomson used to study cathode rays and identify the electron. He found that for a beta particle is the same as for Thomson's electron, and therefore suggested that the beta particle is in fact an electron.\n\nIn 1901, Rutherford and Frederick Soddy showed that alpha and beta radioactivity involves the transmutation of atoms into atoms of other chemical elements. In 1913, after the products of more radioactive decays were known, Soddy and Kazimierz Fajans independently proposed their radioactive displacement law, which states that beta (i.e., ) emission from one element produces another element one place to the right in the periodic table, while alpha emission produces an element two places to the left.\n\nThe study of beta decay provided the first physical evidence for the existence of the neutrino. In both alpha and gamma decay, the resulting particle has a narrow energy distribution, since the particle carries the energy from the difference between the initial and final nuclear states. However, the kinetic energy distribution, or spectrum, of beta particles measured by Lise Meitner and Otto Hahn in 1911 and by Jean Danysz in 1913 showed multiple lines on a diffuse background. These measurements offered the first hint that beta particles have a continuous spectrum. In 1914, James Chadwick used a magnetic spectrometer with one of Hans Geiger's new counters to make more accurate measurements which showed that the spectrum was continuous. The distribution of beta particle energies was in apparent contradiction to the law of conservation of energy. If beta decay were simply electron emission as assumed at the time, then the energy of the emitted electron should have a particular, well-defined value. For beta decay, however, the observed broad distribution of energies suggested that energy is lost in the beta decay process. This spectrum was puzzling for many years.\n\nA second problem is related to the conservation of angular momentum. Molecular band spectra showed that the nuclear spin of nitrogen-14 is 1 (i.e. equal to the reduced Planck constant) and more generally that the spin is integral for nuclei of even mass number and half-integral for nuclei of odd mass number. This was later explained by the proton-neutron model of the nucleus. Beta decay leaves the mass number unchanged, so the change of nuclear spin must be an integer. However, the electron spin is 1/2, hence angular momentum would not be conserved if beta decay were simply electron emission.\n\nFrom 1920–1927, Charles Drummond Ellis (along with Chadwick and colleagues) further established that the beta decay spectrum is continuous. In 1933, Ellis and Nevill Mott obtained strong evidence that the beta spectrum has an effective upper bound in energy. Niels Bohr had suggested that the beta spectrum could be explained if conservation of energy was true only in a statistical sense, thus this principle might be violated in any given decay. However, the upper bound in beta energies determined by Ellis and Mott ruled out that notion. Now, the problem of how to account for the variability of energy in known beta decay products, as well as for conservation of momentum and angular momentum in the process, became acute.\n\nIn a famous letter written in 1930, Wolfgang Pauli attempted to resolve the beta-particle energy conundrum by suggesting that, in addition to electrons and protons, atomic nuclei also contained an extremely light neutral particle, which he called the neutron. He suggested that this \"neutron\" was also emitted during beta decay (thus accounting for the known missing energy, momentum, and angular momentum), but it had simply not yet been observed. In 1931, Enrico Fermi renamed Pauli's \"neutron\" the \"neutrino\" (roughly 'little neutral one' in Italian). In 1934, Fermi published his landmark theory for beta decay, where he applied the principles of quantum mechanics to matter particles, supposing that they can be created and annihilated, just as the light quanta in atomic transitions. Thus, according to Fermi, neutrinos are created in the beta-decay process, rather than contained in the nucleus; the same happens to electrons. The neutrino interaction with matter was so weak that detecting it proved a severe experimental challenge. Further indirect evidence of the existence of the neutrino was obtained by observing the recoil of nuclei that emitted such a particle after absorbing an electron. Neutrinos were finally detected directly in 1956 by Clyde Cowan and Frederick Reines in the Cowan–Reines neutrino experiment. The properties of neutrinos were (with a few minor modifications) as predicted by Pauli and Fermi.\n\nIn 1934, Frédéric and Irène Joliot-Curie bombarded aluminium with alpha particles to effect the nuclear reaction  +  →  + , and observed that the product isotope emits a positron identical to those found in cosmic rays (discovered by Carl David Anderson in 1932). This was the first example of  decay (positron emission), which they termed artificial radioactivity since is a short-lived nuclide which does not exist in nature. In recognition of their discovery the couple were awarded the Nobel Prize in Chemistry in 1935.\n\nThe theory of electron capture was first discussed by Gian-Carlo Wick in a 1934 paper, and then developed by Hideki Yukawa and others. K-electron capture was first observed in 1937 by Luis Alvarez, in the nuclide V. Alvarez went on to study electron capture in Ga and other nuclides.\n\nIn 1956, Tsung-Dao Lee and Chen Ning Yang noticed that there was no evidence that parity was conserved in weak interactions, and so they postulated that this symmetry may not be preserved by the weak force. They sketched the design for an experiment for testing conservation of parity in the laboratory. Later that year, Chien-Shiung Wu and coworkers conducted the Wu experiment showing an asymmetrical beta decay of cobalt-60 at cold temperatures that proved that parity is not conserved in beta decay. This surprising result overturned long-held assumptions about parity and the weak force. In recognition of their theoretical work, Lee and Yang were awarded the Nobel Prize for Physics in 1957.\n\nIn  decay, the weak interaction converts an atomic nucleus into a nucleus with atomic number increased by one, while emitting an electron () and an electron antineutrino ().  decay generally occurs in neutron-rich nuclei. The generic equation is:\nwhere and are the mass number and atomic number of the decaying nucleus, and X and X' are the initial and final elements, respectively.\n\nAnother example is when the free neutron () decays by  decay into a proton ():\n\nAt the fundamental level (as depicted in the Feynman diagram on the right), this is caused by the conversion of the negatively charged (− e) down quark to the positively charged (+ e) up quark by emission of a boson; the boson subsequently decays into an electron and an electron antineutrino:\n\nIn  decay, or \"positron emission\", the weak interaction converts an atomic nucleus into a nucleus with atomic number decreased by one, while emitting a positron () and an electron neutrino ().  decay generally occurs in proton-rich nuclei. The generic equation is:\nThis may be considered as the decay of a proton inside the nucleus to a neutron\n\nHowever,  decay cannot occur in an isolated proton because it requires energy due to the mass of the neutron being greater than the mass of the proton.  decay can only happen inside nuclei when the daughter nucleus has a greater binding energy (and therefore a lower total energy) than the mother nucleus. The difference between these energies goes into the reaction of converting a proton into a neutron, a positron and a neutrino and into the kinetic energy of these particles. This process is opposite to negative beta decay, in that the weak interaction converts a proton into a neutron by converting an up quark into a down quark resulting in the emission of a or the absorption of a .\n\nIn all cases where  decay (positron emission) of a nucleus is allowed energetically, so too is electron capture allowed. This is a process during which a nucleus captures one of its atomic electrons, resulting in the emission of a neutrino:\n\nAn example of electron capture is one of the decay modes of krypton-81 into bromine-81:\n\nAll emitted neutrinos are of the same energy. In proton-rich nuclei where the energy difference between the initial and final states is less than ,  decay is not energetically possible, and electron capture is the sole decay mode.\n\nIf the captured electron comes from the innermost shell of the atom, the K-shell, which has the highest probability to interact with the nucleus, the process is called K-capture. If it comes from the L-shell, the process is called L-capture, etc.\n\nElectron capture is a competing (simultaneous) decay process for all nuclei that can undergo β decay. The converse, however, is not true: electron capture is the \"only\" type of decay that is allowed in proton-rich nuclides that do not have sufficient energy to emit a positron and neutrino.\n\nIf the proton and neutron are part of an atomic nucleus, the above described decay processes transmute one chemical element into another. For example:\n\nBeta decay does not change the number () of nucleons in the nucleus, but changes only its charge . Thus the set of all nuclides with the same  can be introduced; these \"isobaric\" nuclides may turn into each other via beta decay. For a given there is one that is most stable. It is said to be beta stable, because it presents a local minima of the mass excess: if such a nucleus has numbers, the neighbour nuclei and have higher mass excess and can beta decay into , but not vice versa. For all odd mass numbers , there is only one known beta-stable isobar. For even , there are up to three different beta-stable isobars experimentally known; for example, , , and are all beta-stable. There are about 355 known beta-decay stable nuclides.\n\nUsually unstable nuclides are clearly either \"neutron rich\" or \"proton rich\", with the former undergoing beta decay and the latter undergoing electron capture (or more rarely, due to the higher energy requirements, positron decay). However, in a few cases of odd-proton, odd-neutron radionuclides, it may be energetically favorable for the radionuclide to decay to an even-proton, even-neutron isobar either by undergoing beta-positive or beta-negative decay. An often-cited example is the single isotope (29 protons, 35 neutrons), which illustrates three types of beta decay in competition. Copper-64 has a half-life of about 12.7 hours. This isotope has one unpaired proton and one unpaired neutron, so either the proton or the neutron can decay. This particular nuclide (though not all nuclides in this situation) is almost equally likely to decay through proton decay by positron emission (18%) or electron capture (43%) to , as it is through neutron decay by electron emission (39%) to .\n\nMost naturally occurring nuclides on earth are beta stable. Those that are not have half-lives ranging from under a second to periods of time significantly greater than the age of the universe. One common example of a long-lived isotope is the odd-proton odd-neutron nuclide , which undergoes all three types of beta decay (, and electron capture) with a half-life of .\n\nwhere\n\nBeta decay just changes neutron to proton or, in the case of positive beta decay (electron capture) proton to neutron so the number of individual quarks doesn't change. It is only the baryon flavor that changes, here labelled as the isospin.\n\nUp and down quarks have total isospin formula_4 and isospin projections\n\nAll other quarks have \"I\" = 0.\n\nIn general\n\nso all leptons have assigned a value of +1, antileptons −1, and non-leptonic particles 0. \n\nFor allowed decays, the net orbital angular momentum is zero, hence only spin quantum numbers are considered.\n\nThe electron and antineutrino are fermions, spin-1/2 objects, therefore they may couple to total formula_9 (parallel) or formula_10 (anti-parallel).\n\nFor forbidden decays, orbital angular momentum must also be taken into consideration.\n\nThe value is defined as the total energy released in a given nuclear decay. In beta decay, is therefore also the sum of the kinetic energies of the emitted beta particle, neutrino, and recoiling nucleus. (Because of the large mass of the nucleus compared to that of the beta particle and neutrino, the kinetic energy of the recoiling nucleus can generally be neglected.) Beta particles can therefore be emitted with any kinetic energy ranging from 0 to . A typical is around 1 MeV, but can range from a few keV to a few tens of MeV.\n\nSince the rest mass of the electron is 511 keV, the most energetic beta particles are ultrarelativistic, with speeds very close to the speed of light.\n\nConsider the generic equation for beta decay\nThe value for this decay is\nwhere formula_12 is the mass of the nucleus of the atom, formula_13 is the mass of the electron, and formula_14 is the mass of the electron antineutrino. In other words, the total energy released is the mass energy of the initial nucleus, minus the mass energy of the final nucleus, electron, and antineutrino. The mass of the nucleus is related to the standard atomic mass by\nThat is, the total atomic mass is the mass of the nucleus, plus the mass of the electrons, minus the sum of all \"electron\" binding energies for the atom. This equation is rearranged to find formula_12, and formula_17 is found similarly. Substituting these nuclear masses into the Q-value equation, while neglecting the nearly-zero antineutrino mass and the difference in electron binding energies, which is very small for high- atoms, we have\nThis energy is carried away as kinetic energy by the electron and neutrino.\n\nBecause the reaction will proceed only when the -value is positive, β decay can occur when the mass of atom is greater than the mass of atom .\n\nThe equations for β decay are similar, with the generic equation\ngiving\nHowever, in this equation, the electron masses do not cancel, and we are left with\n\nBecause the reaction will proceed only when the -value is positive, β decay can occur when the mass of atom exceeds that of by at least twice the mass of the electron.\n\nThe analogous calculation for electron capture must take into account the binding energy of the electrons. This is because the atom will be left in an excited state after capturing the electron, and the binding energy of the captured innermost electron is significant. Using the generic equation for electron capture\nwe have\nwhich simplifies to\nwhere is the binding energy of the captured electron.\n\nBecause the binding energy of the electron is much less than the mass of the electron, nuclei that can undergo β decay can always also undergo electron capture, but the reverse is not true.\n\nBeta decay can be considered as a perturbation as described in quantum mechanics, and thus Fermi's Golden Rule can be applied. This leads to an expression for the kinetic energy spectrum of emitted betas as follows:\n\nwhere is the kinetic energy, is a shape function that depends on the forbiddenness of the decay (it is constant for allowed decays), is the Fermi Function (see below) with \"Z\" the charge of the final-state nucleus, is the total energy, is the momentum, and is the Q value of the decay. The kinetic energy of the emitted neutrino is given approximately by minus the kinetic energy of the beta.\n\nAs an example, the beta decay spectrum of Bi (originally called RaE) is shown to the right.\n\nThe Fermi function that appears in the beta spectrum formula accounts for the Coulomb attraction / repulsion between the emitted beta and the final state nucleus. Approximating the associated wavefunctions to be spherically symmetric, the Fermi function can be analytically calculated to be:\n\nwhere (α is the fine-structure constant), (+ for electrons, − for positrons), ( is the radius of the final state nucleus), and Γ is the Gamma function.\n\nFor non-relativistic betas (), this expression can be approximated by:\n\nOther approximations can be found in the literature.\n\nA Kurie plot (also known as a Fermi–Kurie plot) is a graph used in studying beta decay developed by Franz N. D. Kurie, in which the square root of the number of beta particles whose momenta (or energy) lie within a certain narrow range, divided by the Fermi function, is plotted against beta-particle energy. It is a straight line for allowed transitions and some forbidden transitions, in accord with the Fermi beta-decay theory. The energy-axis (x-axis) intercept of a Kurie plot corresponds to the maximum energy imparted to the electron/positron (the decay's -value). With a Kurie plot one can find the limit on the effective mass of a neutrino.\n\nAfter the discovery of parity non-conservation (see History), it was found that, in beta decay, electrons are emitted mostly with negative helicity, i.e., they move, naively speaking, like left-handed screws driven into a material (they have negative longitudinal polarization). Conversely, positrons have mostly positive helicity, i.e., they move like right-handed screws. Neutrinos (emitted in positron decay) have positive helicity, while antineutrinos (emitted in electron decay) have negative helicity.\n\nThe higher the energy of the particles, the higher their polarization.\n\nBeta decays can be classified according to the angular momentum (-value) and total spin (-value) of the emitted radiation. Since total angular momentum must be conserved, including orbital and spin angular momentum, beta decay occurs by a variety of quantum state transitions to various nuclear angular momentum or spin states, known as \"Fermi\" or \"Gamow-Teller\" transitions. When beta decay particles carry no angular momentum (L=0), the decay is referred to as \"allowed\", otherwise it is \"forbidden\".\n\nOther decay modes, which are rare, are known as bound state decay and double beta decay.\n\nA Fermi transition is a beta decay in which the spins of the emitted electron (positron) and anti-neutrino (neutrino) couple to total spin formula_10, leading to an angular momentum change formula_27 between the initial and final states of the nucleus (assuming an allowed transition). In the non-relativistic limit, the nuclear part of the operator for a Fermi transition is given by\n\nwith formula_29 the weak vector coupling constant, formula_30 the isospin raising and lowering operators, and formula_31 running over all protons and neutrons in the nucleus.\n\nA Gamow-Teller transition is a beta decay in which the spins of the emitted electron (positron) and anti-neutrino (neutrino) couple to total spin formula_9, leading to an angular momentum change formula_33 between the initial and final states of the nucleus (assuming an allowed transition).\nIn this case, the nuclear part of the operator is given by\n\nwith formula_35 the weak axial-vector coupling constant, and formula_36 the spin Pauli matrices, which can produce a spin-flip in the decaying nucleon.\n\nWhen , the decay is referred to as \"forbidden\". Nuclear selection rules require high L-values to be accompanied by changes in nuclear spin () and parity (π). The selection rules for the th forbidden transitions are:\n\nwhere or corresponds to no parity change or parity change, respectively. The special case of a transition between isobaric analogue states, where the structure of the final state is very similar to the structure of the initial state, is referred to as \"superallowed\" for beta decay, and proceeds very quickly. The following table lists the Δ and Δπ values for the first few values of :\n\nA very small minority of free neutron decays (about four per million) are so-called \"two-body decays\", in which the proton, electron and antineutrino are produced, but the electron fails to gain the 13.6 eV energy necessary to escape the proton, and therefore simply remains bound to it, as a neutral hydrogen atom. In this type of beta decay, in essence all of the neutron decay energy is carried off by the antineutrino.\n\nFor fully ionized atoms (bare nuclei), it is possible in likewise manner for electrons to fail to escape the atom, and to be emitted from the nucleus into low-lying atomic bound states (orbitals). This cannot occur for neutral atoms with low-lying bound states which are already filled by electrons.\n\nBound-state β decays were predicted by Daudel, Jean, and Lecoin in 1947, and the phenomenon in fully ionized atoms was first observed for Dy in 1992 by Jung et al. of the Darmstadt Heavy-Ion Research group. Although neutral Dy is a stable isotope, the fully ionized Dy undergoes β decay into the K and L shells with a half-life of 47 days.\n\nAnother possibility is that a fully ionized atom undergoes greatly accelerated β decay, as observed for Re by Bosch et al., also at Darmstadt. Neutral Re does undergo β decay with a half-life of 42 × 10 years, but for fully ionized Re this is shortened by a factor of 10 to only 32.9 years. For comparison the variation of decay rates of other nuclear processes due to chemical environment is less than 1%.\n\nSome nuclei can undergo double beta decay (ββ decay) where the charge of the nucleus changes by two units. Double beta decay is difficult to study, as the process has an extremely long half-life. In nuclei for which both β decay and ββ decay are possible, the rarer ββ decay process is effectively impossible to observe. However, in nuclei where β decay is forbidden but ββ decay is allowed, the process can be seen and a half-life measured. Thus, ββ decay is usually studied only for beta stable nuclei. Like single beta decay, double beta decay does not change ; thus, at least one of the nuclides with some given has to be stable with regard to both single and double beta decay.\n\n\"Ordinary\" double beta decay results in the emission of two electrons and two antineutrinos. If neutrinos are Majorana particles (i.e., they are their own antiparticles), then a decay known as neutrinoless double beta decay will occur. Most neutrino physicists believe that neutrinoless double beta decay has never been observed.\n\n\n\n\n"}
{"id": "4652", "url": "https://en.wikipedia.org/wiki?curid=4652", "title": "Blitzkrieg", "text": "Blitzkrieg\n\nBlitzkrieg (German, \"lightning war\") is a method of warfare whereby an attacking force, spearheaded by a dense concentration of armoured and motorised or mechanised infantry formations with close air support, breaks through the opponent's line of defence by short, fast, powerful attacks and then dislocates the defenders, using speed and surprise to encircle them with the help of air superiority. Through the employment of combined arms in manoeuvre warfare, blitzkrieg attempts to unbalance the enemy by making it difficult for it to respond to the continuously changing front, then defeat it in a decisive (battle of annihilation).\n\nDuring the interwar period, aircraft and tank technologies matured and were combined with systematic application of the traditional German tactic of (maneuver warfare), deep penetrations and the bypassing of enemy strong points to encircle and destroy enemy forces in a (cauldron battle). During the Invasion of Poland, Western journalists adopted the term \"blitzkrieg\" to describe this form of armoured warfare. The term had appeared in 1935, in a German military periodical (German Defence), in connection to quick or lightning warfare. German manoeuvre operations were successful in the campaigns of 1939–1941 and by 1940 the term \"blitzkrieg\" was extensively used in Western media. Blitzkrieg operations capitalized on surprise penetrations (e.g., the penetration of the Ardennes forest region), general enemy unreadiness and their inability to match the pace of the German attack. During the Battle of France, the French made attempts to re-form defensive lines along rivers but were frustrated when German forces arrived first and pressed on.\n\nDespite being common in German and English-language journalism during World War II, the word was never used by the Wehrmacht as an official military term, except for propaganda. According to David Reynolds, \"Hitler himself called the term Blitzkrieg 'A completely idiotic word' (ein ganz blödsinniges Wort)\". Some senior officers, including Kurt Student, Franz Halder and Johann Adolf von Kielmansegg, even disputed the idea that it was a military concept. Kielmansegg asserted that what many regarded as blitzkrieg was nothing more than \"ad hoc solutions that simply popped out of the prevailing situation\". Student described it as ideas that \"naturally emerged from the existing circumstances\" as a response to operational challenges. The Wehrmacht never officially adopted it as a concept or doctrine.\n\nIn 2005, the historian Karl-Heinz Frieser summarized blitzkrieg as the result of German commanders using the latest technology in the most beneficial way according to traditional military principles and employing \"the right units in the right place at the right time\". Modern historians now understand blitzkrieg as the combination of the traditional German military principles, methods and doctrines of the 19th century with the military technology of the interwar period. Modern historians use the term casually as a generic description for the style of manoeuvre warfare practised by Germany during the early part of World War II, rather than as an explanation. According to Frieser, in the context of the thinking of Heinz Guderian on mobile combined arms formations, blitzkrieg can be used as a synonym for modern manoeuvre warfare on the operational level.\n\nThe traditional meaning of blitzkrieg is that of German tactical and operational methodology in the first half of the Second World War, that is often hailed as a new method of warfare. The word, meaning \"lightning war\" or \"lightning attack\" in its strategic sense describes a series of quick and decisive short battles to deliver a knockout blow to an enemy state before it could fully mobilize. Tactically, blitzkrieg is a coordinated military effort by tanks, motorized infantry, artillery and aircraft, to create an overwhelming local superiority in combat power, to defeat the opponent and break through its defences. \"Blitzkrieg\" as used by Germany had considerable psychological, or \"terror\" elements, such as the \"Jericho Trompete\", a noise-making siren on the Junkers Ju 87 dive-bomber, to affect the morale of enemy forces. The devices were largely removed when the enemy became used to the noise after the Battle of France in 1940 and instead bombs sometimes had whistles attached. It is also common for historians and writers to include psychological warfare by using Fifth columnists to spread rumours and lies among the civilian population in the theatre of operations.\n\nThe origin of the term \"blitzkrieg\" is obscure. It was never used in the title of a military doctrine or handbook of the German army or air force, and no \"coherent doctrine\" or \"unifying concept of blitzkrieg\" existed. The term seems rarely to have been used in the German military press before 1939 and recent research at the German \"Militärgeschichtliches Forschungsamt\" at Potsdam found it in only two military articles from the 1930s. Both used the term to mean a swift strategic knock-out, rather than a radical new military doctrine or approach to war. The first article (1935) deals primarily with supplies of food and materiel in wartime. The term \"blitzkrieg\" is used with reference to German efforts to win a quick victory in the First World War but is not associated with the use of armoured, mechanised or air forces. It argued that Germany must develop self-sufficiency in food, because it might again prove impossible to deal a swift knock-out to its enemies, leading to a long war. In the second article (1938), launching a swift strategic knock-out is described as an attractive idea for Germany but difficult to achieve on land under modern conditions (especially against systems of fortification like the Maginot Line), unless an exceptionally high degree of surprise could be achieved. The author vaguely suggests that a massive strategic air attack might hold out better prospects but the topic is not explored in detail. A third relatively early use of the term in German occurs in \"Die Deutsche Kriegsstärke\" (German War Strength) by Fritz Sternberg, a Jewish, Marxist, political economist and refugee from the Third Reich, published in 1938 in Paris and in London as \"Germany and a Lightning War\". Sternberg wrote that Germany was not prepared economically for a long war but might win a quick war (\"\"Blitzkrieg\"\"). He did not go into detail about tactics or suggest that the German armed forces had evolved a radically new operational method. His book offers scant clues as to how German lightning victories might be won.\n\nIn English and other languages, the term had been used since the 1920s. The British press used it to describe the German successes in Poland in September 1939, called by Harris \"a piece of journalistic sensationalism – a buzz-word with which to label the spectacular early successes of the Germans in the Second World War\". It was later applied to the bombing of Britain, particularly London, hence \"The Blitz\". The German popular press followed suit nine months later, after the fall of France in 1940; hence although the word had been used in German, it was first popularized by British journalism. Heinz Guderian referred to it as a word coined by the Allies: \"as a result of the successes of our rapid campaigns our enemies ... coined the word \"Blitzkrieg\"\". After the German failure in the Soviet Union in 1941, use of the term began to be frowned upon in the Third Reich, and Hitler then denied ever using the term, saying in a speech in November 1941, \"I have never used the word \"Blitzkrieg\", because it is a very silly word\". In early January 1942, Hitler dismissed it as \"Italian phraseology\".\n\nIn 1914, German strategic thinking derived from the writings of Carl von Clausewitz (June 1, 1780 – November 16, 1831), Helmuth von Moltke the Elder (26 October 1800 – 24 April 1891) and Alfred von Schlieffen (28 February 1833 – 4 January 1913), who advocated manoeuvre, mass and envelopment to create the conditions for a decisive battle (). During the war, generals such as Oskar von Hutier developed tactics to restore manoeuvre on the battlefield. Specialist light infantry (\"Sturmtruppen\", \"storm troops\") were to exploit soft spots, to make gaps for larger infantry units to advance with heavier weapons and exploit the success, leaving isolated strong points to troops following up. Hutier tactics were combined with short hurricane artillery bombardments using massed artillery, devised by Colonel Georg Bruchmüller. Attacks relied on speed and surprise rather than on weight of numbers. Hutier-Bruchmüller tactics met with great success in Operation Michael, the spring offensive of 1918 and restored temporarily the war of movement, once the Allied trench system had been overrun. The German armies pushed on towards Amiens and then Paris, coming within before supply difficulties and Allied reinforcements halted the advance. Historian James Corum criticised the German leadership for failing to understand the technical advances of the First World War, having given tank production the lowest priority and having conducted no studies of the machine gun prior to that war. \n\nGerman operational theories were revised after the First World War. The Treaty of Versailles limited the Reichswehr to a maximum of 100,000 men, making impossible the deployment of mass armies. The German General Staff was abolished by the treaty but continued covertly as the \"Truppenamt\" (Troop Office), disguised as an administrative body. Committees of veteran staff officers were formed within the \"Truppenamt\" to evaluate 57 issues of the war. By the time of the Second World War, their reports had led to doctrinal and training publications, including H. Dv. 487, \"Führung und Gefecht der verbundenen Waffen\" (Command and Battle of the Combined Arms), known as das Fug (1921–23) and \"Truppenführung\" (1933–34), containing standard procedures for combined-arms warfare. The \"Reichswehr\" was influenced by its analysis of pre-war German military thought, in particular infiltration tactics, which at the end of the war had seen some breakthroughs on the Western Front and the manoeuvre warfare which dominated the Eastern Front.\n\nOn the Eastern Front, the war did not bog down into trench warfare; German and Russian armies fought a war of manoeuvre over thousands of miles, which gave the German leadership unique experience not available to the trench-bound western Allies. Studies of operations in the east led to the conclusion that small and coordinated forces possessed more combat power than large, uncoordinated forces. After the war, the \"Reichswehr\" modified Hutier tactics. The commander in chief, Hans von Seeckt, argued that there had been an excessive focus on encirclement and emphasized speed instead. Seeckt inspired a revision of \"Bewegungskrieg\" (maneuver warfare) thinking and its associated \"Auftragstaktik\", in which the commander expressed his goals to subordinates and gave them discretion in how to achieve them; the governing principle was \"the higher the authority, the more general the orders were,\" so it was the responsibility of the lower echelons to fill in the details. Implementation of higher orders remained within limits determined by the training doctrine of an elite officer-corps. Delegation of authority to local commanders increased the tempo of operations, which had great influence on the success of German armies in the early war period. Seeckt, who believed in the Prussian tradition of mobility, developed the German army into a mobile force, advocating technical advances that would lead to a qualitative improvement of its forces and better coordination between motorized infantry, tanks, and planes.\n\nThe British army took lessons from the successful infantry and artillery offensives on the Western Front in late 1918. To obtain the best co-operation between all arms, emphasis was placed on detailed planning, rigid control and adherence to orders. Mechanization of the army was considered a means to avoid mass casualties and indecisive nature of offensives, as part of a combined-arms theory of war. The four editions of \"Field Service Regulations\" published after 1918 held that only combined-arms operations could create enough fire power to enable mobility on a battlefield. This theory of war also emphasized consolidation, recommending caution against overconfidence and ruthless exploitation.\n\nIn the Sinai and Palestine Campaign, operations involved some aspects of what would later be called \"blitzkrieg\". Key elements in the \"blitzkrieg warfare\" at the decisive Battle of Megiddo included concentration, surprise and speed; success depended on attacking only in terrain favoring the movement of large formations around the battlefield and tactical improvements in the British artillery and infantry attack. General Edmund Allenby used infantry to attack the strong Ottoman front line in co-operation with supporting artillery, augmented by the guns of two destroyers. Through constant pressure by infantry and cavalry, two Ottoman armies in the Judean Hills were kept off-balance and virtually encircled during the Battles of Sharon and Nablus (Battle of Megiddo).\n\nThe British methods induced \"strategic paralysis\" among the Ottomans and led to their rapid and complete collapse. In an advance of , captures were estimated to be \"at least prisoners and 260 guns.\" Liddell Hart considered that important aspects of the operation were the extent to which Ottoman commanders were denied intelligence on the British preparations for the attack through British air superiority and air attacks on their headquarters and telephone exchanges, which paralyzed attempts to react to the rapidly deteriorating situation.\n\nNorman Stone detects early \"Blitzkrieg\" operations in offensives by the French generals Charles Mangin and Marie-Eugène Debeney in 1918. However, French doctrine in the interwar years became defence-oriented. Colonel Charles de Gaulle advocated concentration of armour and aeroplanes. His opinions appeared in his book \"Vers l'Armée de Métier\" (Towards the Professional Army, 1933). Like von Seeckt, de Gaulle concluded that France could no longer maintain the huge armies of conscripts and reservists which had fought World War I, and he sought to use tanks, mechanised forces and aircraft to allow a smaller number of highly-trained soldiers to have greater impact in battle. His views little endeared him to the French high command, but are claimed by some to have influenced Heinz Guderian.\n\nIn 1916, General Alexei Brusilov had used surprise and infiltration tactics during the Brusilov Offensive. Later, Marshal Mikhail Tukhachevsky, Georgii Isserson and other members of the Red Army developed a concept of deep battle from the experience of the Polish–Soviet War. These concepts would guide Red Army doctrine throughout World War II. Realising the limitations of infantry and cavalry, Tukhachevsky was an advocate of mechanised formations and the large-scale industrialisation required. Robert Watt (2008) wrote that blitzkrieg holds little in common with Soviet deep battle. In 2002, H. P. Willmott had noted that deep battle contained two important differences: it was a doctrine of total war, not limited operations, and decisive battle was rejected in favour of several large, simultaneous offensives.\n\nThe \"Reichswehr\" and the Red Army began a secret collaboration in the Soviet Union to evade the Treaty of Versailles occupational agent, the Inter-Allied Commission. In 1926, War games and tests were begun at Kazan and Lipetsk. The centres were used to field test aircraft and armoured vehicles up to the battalion level and housed aerial and armoured warfare schools, through which officers were rotated.\n\nAfter becoming Chancellor of Germany (head of government) in 1933, Adolf Hitler ignored the Versailles Treaty provisions. Within the Wehrmacht (established in 1935) the command for motorised armored forces was named the \"Panzerwaffe\" in 1936. The Luftwaffe (the German air force) was officially established in February 1935, and development began on ground-attack aircraft and doctrines. Hitler strongly supported this new strategy. He read Guderian's 1937 book \"Achtung – Panzer!\" and upon observing armoured field exercises at Kummersdorf he remarked, \"That is what I want – and that is what I will have.\"\n\nGuderian summarised combined-arms tactics as the way to get the mobile and motorised armoured divisions to work together and support each other to achieve decisive success. In his 1950 book, \"Panzer Leader\", he wrote:\n\nGuderian believed that developments in technology were required to support the theory; especially, equipping armoured divisions—tanks\nforemost–with wireless communications. Guderian insisted in 1933 to the high command that every tank in the German armoured force must be equipped with a radio. At the start of World War II, only the German army was thus prepared with all tanks \"radio-equipped\". This proved critical in early tank battles where German tank commanders exploited the organizational advantage over the Allies that radio communication gave them. Later all Allied armies would copy this innovation. During the Polish campaign, the performance of armoured troops, under the influence of Guderian's ideas, won over a number of skeptics who had initially expressed doubt about armoured warfare, such as von Rundstedt and Rommel.\n\nAccording to David A.Grossman, by the 12th Battle of Isonzo (October-November 1917), while conducting a light-infantry operation, Rommel had perfected his maneuver-warfare principles, which were the very same ones that were applied during the Blitzkrieg against France in 1940 (and repeated in the Coalition ground offensive against Iraq in the 1991 Gulf War). During the Battle of France and against his staff advisor's advice, Hitler ordered that everything should be completed in a few weeks; fortunately for the Führer, Rommel and Guderian disobeyed the General Staff's orders (particularly General von Kleist) and forged ahead making quicker progress than anyone expected, and on the way, \"inventing the idea of Blitzkrieg.\" It was Rommel who created the new archetype of Blitzkrieg, leading his division far ahead of flanking divisions. MacGregor and Williamson remark that Rommel's version of Blitzkrieg displayed a significantly better understanding of combined-arms warfare than that of Guderian. General Hoth submitted an official report in July 1940 which declared that Rommel had \"explored new paths in the command of Panzer divisions\".\n\n\"Schwerpunktprinzip\" was a heuristic device (conceptual tool or thinking formula) used in the German army since the nineteenth century, to make decisions from tactics to strategy about priority. \"Schwerpunkt\" has been translated as \"centre of gravity\", \"crucial\", \"focal point\" and \"point of main effort\". None of these forms is sufficient to describe the universal importance of the term and the concept of \"Schwerpunktprinzip\". Every unit in the army, from the company to the supreme command, decided on a \"Schwerpunkt\" through \"schwerpunktbildung\", as did the support services, which meant that commanders always knew what was most important and why. The German army was trained to support the \"Schwerpunkt\", even when risks had to be taken elsewhere to support the point of main effort. Through \"Schwerpunktbildung\", the German army could achieve superiority at the \"Schwerpunkt\", whether attacking or defending, to turn local success at the \"Schwerpunkt\" into the progressive disorganisation of the opposing force, creating more opportunities to exploit this advantage, even if numerically and strategically inferior in general. In the 1930s, Guderian summarised this as \"Klotzen, nicht kleckern!\" (\"Kick, don't spatter them!\").\n\nHaving achieved a breakthrough of the enemy's line, units comprising the \"Schwerpunkt\" were not supposed to become decisively engaged with enemy front line units to the right and left of the breakthrough area. Units pouring through the hole were to drive upon set objectives behind the enemy front line. In World War II, German Panzer forces used motorised mobility, to paralyse the opponent's ability to react. Fast-moving mobile forces seized the initiative, exploited weaknesses and acted before opposing forces could respond. Central to this was the decision cycle (tempo). Decision-making required time to gather information, make a decision, give orders to subordinates to implement the decision. Through superior mobility and faster decision-making cycles, mobile forces could act quicker than the forces opposing them. Directive control was a fast and flexible method of command. Rather than receiving an explicit order, a commander would be told of his superior's intent and the role which his unit was to fill in this concept. The method of execution was then a matter for the discretion of the subordinate commander. Staff burden was reduced at the top and spread among tiers of command with knowledge about their situation. Delegation and the encouragement of initiative aided implementation, important decisions could be taken quickly and communicated verbally or with brief written orders. Germans soldiers also used Pervitin, a form of Amphetamine, which was given to drivers, to keep them awake.\n\nThe last part of an offensive operation was the destruction of un-subdued pockets of resistance, which had been enveloped earlier and by-passed by the fast-moving armoured and motorised spearheads. The \"Kesselschlacht\" 'cauldron battle' was a concentric attack on such pockets. It was here that most losses were inflicted upon the enemy, primarily through the mass capture of prisoners and weapons. During Operation Barbarossa, huge encirclements in 1941 produced nearly 3.5 million Soviet prisoners, along with masses of equipment.\n\nClose air support was provided in the form of the dive bomber and medium bomber. They would support the focal point of attack from the air. German successes are closely related to the extent to which the German \"Luftwaffe\" was able to control the air war in early campaigns in Western and Central Europe, and the Soviet Union. However, the \"Luftwaffe\" was a broadly based force with no constricting central doctrine, other than its resources should be used generally to support national strategy. It was flexible and it was able to carry out both operational-tactical, and strategic bombing. Flexibility was the \"Luftwaffe\"s strength in 1939–1941. Paradoxically, from that period onward it became its weakness. While Allied Air Forces were tied to the support of the Army, the \"Luftwaffe\" deployed its resources in a more general, operational way. It switched from air superiority missions, to medium-range interdiction, to strategic strikes, to close support duties depending on the need of the ground forces. In fact, far from it being a specialist panzer spearhead arm, less than 15 percent of the Luftwaffe was intended for close support of the army in 1939.\n\nThe concepts associated with the term \"blitzkrieg\"—deep penetrations by armour, large encirclements, and combined arms attacks—were largely dependent upon terrain and weather conditions. Where the ability for rapid movement across \"tank country\" was not possible, armoured penetrations often were avoided or resulted in failure. Terrain would ideally be flat, firm, unobstructed by natural barriers or fortifications, and interspersed with roads and railways. If it were instead hilly, wooded, marshy, or urban, armour would be vulnerable to infantry in close-quarters combat and unable to break out at full speed. Additionally, units could be halted by mud (thawing along the Eastern Front regularly slowed both sides) or extreme snow. Operation Barbarossa helped confirm that armour effectiveness and the requisite aerial support were dependent on weather and terrain. It should however be noted that the disadvantages of terrain could be nullified if surprise was achieved over the enemy by an attack through areas considered natural obstacles, as occurred during the Battle of France when the German blitzkrieg-style attack went through the Ardennes. Since the French thought the Ardennes unsuitable for massive troop movement, particularly for tanks, they were left with only light defences which were quickly overrun by the \"Wehrmacht\". The Germans quickly advanced through the forest, knocking down the trees the French thought would impede this tactic.\n\nThe influence of air forces over forces on the ground changed significantly over the course of the Second World War. Early German successes were conducted when Allied aircraft could not make a significant impact on the battlefield. In May 1940, there was near parity in numbers of aircraft between the \"Luftwaffe\" and the Allies, but the \"Luftwaffe\" had been developed to support Germany's ground forces, had liaison officers with the mobile formations, and operated a higher number of sorties per aircraft. In addition, German air parity or superiority allowed the unencumbered movement of ground forces, their unhindered assembly into concentrated attack formations, aerial reconnaissance, aerial resupply of fast moving formations and close air support at the point of attack. The Allied air forces had no close air support aircraft, training or doctrine. The Allies flew 434 French and 160 British sorties a day but methods of attacking ground targets had yet to be developed; therefore Allied aircraft caused negligible damage. Against these 600 sorties the \"Luftwaffe\" on average flew 1,500 sorties a day. On May 13, \"Fliegerkorps\" VIII flew 1,000 sorties in support of the crossing of the Meuse. The following day the Allies made repeated attempts to destroy the German pontoon bridges, but German fighter aircraft, ground fire and \"Luftwaffe\" flak batteries with the panzer forces destroyed 56 percent of the attacking Allied aircraft while the bridges remained intact.\n\nAllied air superiority became a significant hindrance to German operations during the later years of the war. By June 1944 the Western Allies had complete control of the air over the battlefield and their fighter-bomber aircraft were very effective at attacking ground forces. On D-Day the Allies flew 14,500 sorties over the battlefield area alone, not including sorties flown over north-western Europe. Against this on 6 June the \"Luftwaffe\" flew some 300 sorties. Though German fighter presence over Normandy increased over the next days and weeks, it never approached the numbers the Allies commanded. Fighter-bomber attacks on German formations made movement during daylight almost impossible. Subsequently, shortages soon developed in food, fuel and ammunition, severely hampering the German defenders. German vehicle crews and even flak units experienced great difficulty moving during daylight. Indeed, the final German offensive operation in the west, Operation Wacht am Rhein, was planned to take place during poor weather to minimize interference by Allied aircraft. Under these conditions it was difficult for German commanders to employ the \"armoured idea\", if at all.\n\nBlitzkrieg is vulnerable to an enemy that is robust enough to weather the shock of the attack and that does not panic at the idea of enemy formations in its rear area. This is especially true if the attacking formation lacks the reserve to keep funnelling forces into the spearhead, or lacks the mobility to provide infantry, artillery and supplies into the attack. If the defender can hold the shoulders of the breach they will have the opportunity to counter-attack into the flank of the attacker, potentially cutting off the van as happened to Kampfgruppe Peiper in the Ardennes.\n\nDuring the Battle of France in 1940, the 4th Armoured Division (Major-General Charles de Gaulle) and elements of the 1st Army Tank Brigade (British Expeditionary Force) made probing attacks on the German flank, pushing into the rear of the advancing armoured columns at times. This may have been a reason for Hitler to call a halt to the German advance. Those attacks combined with Maxime Weygand's Hedgehog tactic would become the major basis for responding to blitzkrieg attacks in the future: deployment in depth, permitting enemy or \"shoulders\" of a penetration was essential to channelling the enemy attack, and artillery, properly employed at the shoulders, could take a heavy toll of attackers. While Allied forces in 1940 lacked the experience to successfully develop these strategies, resulting in France's capitulation with heavy losses, they characterised later Allied operations. At the Battle of Kursk the Red Army employed a combination of defence in great depth, extensive minefields, and tenacious defence of breakthrough shoulders. In this way they depleted German combat power even as German forces advanced. The reverse can be seen in the Russian summer offensive of 1944, Operation Bagration, which resulted in the destruction of Army Group Center. German attempts to weather the storm and fight out of encirclements failed due to the Russian ability to continue to feed armoured units into the attack, maintaining the mobility and strength of the offensive, arriving in force deep in the rear areas, faster than the Germans could regroup.\n\nAlthough effective in quick campaigns against Poland and France, mobile operations could not be sustained by Germany in later years. Strategies based on manoeuvre have the inherent danger of the attacking force overextending its supply lines, and can be defeated by a determined foe who is willing and able to sacrifice territory for time in which to regroup and rearm, as the Soviets did on the Eastern Front (as opposed to, for example, the Dutch who had no territory to sacrifice). Tank and vehicle production was a constant problem for Germany; indeed, late in the war many panzer \"divisions\" had no more than a few dozen tanks. As the end of the war approached, Germany also experienced critical shortages in fuel and ammunition stocks as a result of Anglo-American strategic bombing and blockade. Although production of \"Luftwaffe\" fighter aircraft continued, they would be unable to fly for lack of fuel. What fuel there was went to panzer divisions, and even then they were not able to operate normally. Of those Tiger tanks lost against the United States Army, nearly half of them were abandoned for lack of fuel.\n\nGerman volunteers first used armour in live field conditions during the Spanish Civil War of 1936. Armour commitment consisted of Panzer Battalion 88, a force built around three companies of Panzer I tanks that functioned as a training cadre for Nationalists. The Luftwaffe deployed squadrons of fighters, dive bombers and transport aircraft as the \"Condor Legion\". Guderian said that the tank deployment was \"on too small a scale to allow accurate assessments to be made.\" The true test of his \"armoured idea\" would have to wait for the Second World War. However, the \"Luftwaffe\" also provided volunteers to Spain to test both tactics and aircraft in combat, including the first combat use of the \"Stuka\".\n\nDuring the war, the \"Condor Legion\" undertook the bombing of Guernica which had a tremendous psychological effect on the populations of Europe. The results were exaggerated, and the Western Allies concluded that the \"city-busting\" techniques were now a part of the German way in war. The targets of the German aircraft were actually the rail lines and bridges. But lacking the ability to hit them with accuracy (only three or four Ju 87s saw action in Spain), a method of carpet bombing was chosen resulting in heavy civilian casualties.\n\nDespite the term \"blitzkrieg\" being coined by journalists during the Invasion of Poland of 1939, historians Matthew Cooper and J. P. Harris have written that German operations during it were consistent with traditional methods. The Wehrmacht strategy was more in line with \"Vernichtungsgedanken\" a focus on envelopment to create pockets in broad-front annihilation. Panzer forces were dispersed among the three German concentrations with little emphasis on independent use, being used to create or destroy close pockets of Polish forces and seize operational-depth terrain in support of the largely un-motorized infantry which followed.\n\nWhile early German tanks, Stuka dive-bombers and concentrated forces were used in the Polish campaign, the majority of the battle was conventional infantry and artillery warfare and most Luftwaffe action was independent of the ground campaign. Matthew Cooper wrote that\n\nJohn Ellis wrote that \"...there is considerable justice in Matthew Cooper's assertion that the panzer divisions were not given the kind of \"strategic\" mission that was to characterize authentic armoured blitzkrieg, and were almost always closely subordinated to the various mass infantry armies.\" Steven Zaloga wrote, \"Whilst Western accounts of the September campaign have stressed the shock value of the panzer and Stuka attacks, they have tended to underestimate the punishing effect of German artillery on Polish units. Mobile and available in significant quantity, artillery shattered as many units as any other branch of the Wehrmacht.\"\n\nThe German invasion of France, with subsidiary attacks on Belgium and the Netherlands, consisted of two phases, Operation Yellow (\"Fall Gelb\") and Operation Red (\"Fall Rot\"). Yellow opened with a feint conducted against the Netherlands and Belgium by two armoured corps and paratroopers. Most of the German armoured forces were placed in Panzer Group von Kleist, which attacked through the Ardennes, a lightly defended sector that the French planned to reinforce if need be, before the Germans could bring up heavy and siege artillery. There was no time for such a reinforcement to be sent, for the Germans did not wait for siege artillery but reached the Meuse and achieved a breakthrough at the Battle of Sedan in three days.\n\nThe group raced to the English Channel, reaching the coast at Abbeville and cut off the BEF, the Belgian Army and some of the best-equipped divisions of the French Army in northern France. Armoured and motorised units under Guderian, Rommel and others, advanced far beyond the marching and horse-drawn infantry divisions and far in excess of that with which Hitler and the German high command expected or wished. When the Allies counter-attacked at Arras using the heavily armoured British Matilda I and Matilda II tanks, a brief panic was created in the German High Command. The armoured and motorised forces were halted by Hitler outside the port of Dunkirk, which was being used to evacuate the Allied forces. Hermann Göring promised that the Luftwaffe would complete the destruction of the encircled armies but aerial operations failed to prevent the evacuation of the majority of the Allied troops. In Operation Dynamo some French and British troops escaped.\n\nCase Yellow surprised everyone, overcoming the Allies' 4,000 armoured vehicles, many of which were better than German equivalents in armour and gun-power. The French and British frequently used their tanks in the dispersed role of infantry support rather than concentrating force at the point of attack, to create overwhelming firepower.\nThe French armies were much reduced in strength and the confidence of their commanders shaken. With much of their own armour and heavy equipment lost in Northern France, they lacked the means to fight a mobile war. The Germans followed their initial success with Operation Red, a triple-pronged offensive. The XV Panzer Corps attacked towards Brest, XIV Panzer Corps attacked east of Paris, towards Lyon and the XIX Panzer Corps encircled the Maginot Line. The French were hard pressed to organise any sort of counter-attack and were continually ordered to form new defensive lines and found that German forces had already by-passed them and moved on. An armoured counter-attack organised by Colonel de Gaulle could not be sustained and he had to retreat.\n\nPrior to the German offensive in May, Winston Churchill had said \"Thank God for the French Army\". That same French army collapsed after barely two months of fighting. This was in shocking contrast to the four years of trench warfare they had engaged in during the First World War. The French president of the Ministerial Council, Reynaud, attributed the collapse in a speech on 21 May 1940:\n\nThe Germans had not used paratroop attacks in France and only made one big drop in the Netherlands, to capture three bridges; some small glider-landings were conducted in Belgium to tank bottle-necks on routes of advance before the arrival of the main force (the most renowned being the landing on Fort Eben-Emael in Belgium).\n\nUse of armoured forces was crucial for both sides on the Eastern Front. Operation Barbarossa, the German invasion of the Soviet Union in 1941, involved a number of breakthroughs and encirclements by motorised forces. Its goal according to Führer Directive 21 (18 December 1940) was \"to destroy the Russian forces deployed in the West and to prevent their escape into the wide-open spaces of Russia.\" The Red Army was to be destroyed west of the Dvina and Dnieper rivers, which were about east of the Soviet border, to be followed by a mopping-up operation. The surprise attack resulted in the near annihilation of the Voyenno-Vozdushnye Sily (VVS, Soviet Air Force) by simultaneous attacks on airfields, allowing the Luftwaffe to achieve total air supremacy over all the battlefields within the first week. On the ground, four German panzer groups outflanked and encircled disorganised Red Army units, while the marching infantry completed the encirclements and defeated the trapped forces. In late July, after 2nd Panzer Group (commanded by Guderian) captured the watersheds of the Dvina and Dnieper rivers near Smolensk, the panzers had to defend the encirclement, because the marching infantry divisions were still hundreds of kilometres to the west.\n\nThe Germans conquered large areas of the Soviet Union but their failure to destroy the Red Army before the winter of 1941 was a strategic failure that made German tactical superiority and territorial gains irrelevant. The Red Army had survived enormous losses and regrouped with new formations far to the rear of the front line. During the Battle of Moscow, the Red Army defeated the German Army Group Center and for the first time in the war seized the strategic initiative.\n\nIn the summer of 1942, Germany launched another offensive in the southern USSR against Stalingrad and the Caucasus, the Soviets again lost tremendous amounts of territory, only to counter-attack once more during winter. German gains were ultimately limited by Hitler diverting forces from the attack on Stalingrad and driving towards the Caucasus oilfields simultaneously. The \"Wehrmacht\" became overstretched, although winning operationally, it could not inflict a decisive defeat as the durability of the Soviet Union's manpower, resources, industrial base and aid from the Western Allies began to take effect.\n\nIn July 1943 the \"Wehrmacht\" conducted Operation (Citadel) against a salient at Kursk that was heavily defended by Soviet troops. Soviet defensive tactics were by now hugely improved, particularly in the use of artillery and air support. By April 1943, the Stavka had learned of German intentions through intelligence supplied by front line reconnaissance and Ultra intercepts. In the following months, the Red Army constructed deep defensive belts along the paths of the planned German attack. The Soviets made a concerted effort to disguise their knowledge of German plans and the extent of their own defensive preparations, and the German commanders still hoped to achieve operational surprise when the attack commenced.\n\nThe Germans did not achieve surprise and were not able to outflank or break through into enemy rear areas during the operation. Several historians assert that Operation Citadel was planned and intended to be a blitzkrieg operation. Many of the German participants who wrote about the operation after the war, including Manstein, make no mention of blitzkrieg in their accounts. In 2000, Niklas Zetterling and Anders Frankson characterised only the southern pincer of the German offensive as a \"classical blitzkrieg attack\". Pier Battistelli wrote that the operational planning marked a change in German offensive thinking away from blitzkrieg and that more priority was given to brute force and fire power than to speed and manoeuvre.\n\nIn 1995, David Glantz stated that for the first time, blitzkrieg was defeated in summer and the opposing Soviet forces were able to mount a successful counter-offensive. The Battle of Kursk ended with two Soviet counter-offensives and the revival of deep operations. In the summer of 1944, the Red Army destroyed Army Group Centre in Operation Bagration, using combined-arms tactics for armour, infantry and air power in a coordinated strategic assault, known as deep operations, which led to an advance of in six weeks.\n\nAllied armies began using combined arms formations and deep penetration strategies that Germany had used in the opening years of the war. Many Allied operations in the Western Desert and on the Eastern Front, relied on firepower to establish breakthroughs by fast-moving armoured units. These artillery-based tactics were also decisive in Western Front operations after Operation Overlord and the British Commonwealth and American armies developed flexible and powerful systems for using artillery support. What the Soviets lacked in flexibility, they made up for in number of rocket launchers, guns and mortars. The Germans never achieved the kind of fire concentrations their enemies were capable of by 1944.\n\nAfter the Allied landings at Normandy, the Germans began a counter-offensive to overwhelm the landing force with armoured attacks but these failed for lack of co-ordination and Allied superiority in anti-tank defence and in the air. The most notable attempt to use deep penetration operations in Normandy was Operation Luttich at Mortain, which only hastened the Falaise Pocket and the destruction of German forces in Normandy. The Mortain counter-attack was defeated by the US 12th Army Group with little effect on its own offensive operations.\n\nThe last German offensive on the Western front, the Battle of the Bulge (Operation \"Wacht am Rhein\"), was an offensive launched towards the port of Antwerp in December 1944. Launched in poor weather against a thinly held Allied sector, it achieved surprise and initial success as Allied air power was grounded by cloud cover. Determined defence by US troops in places throughout the Ardennes, the lack of good roads and German supply shortages caused delays. Allied forces deployed to the flanks of the German penetration and as soon as the skies cleared, Allied aircraft returned to the battlefield. Allied counter-attacks soon forced back the Germans, who abandoned much equipment for lack of fuel.\n\nThe origins of blitzkrieg are in some doubt: if it existed, who contributed to it, whether it was part of German war strategy from 1933–1939. There has been a great deal of debate about whether it existed as a coherent military strategy. Many historians now think that blitzkrieg was not a military theory and the campaigns conducted by the Germans from 1939 to circa 1942 (with the exception of Operation Barbarossa) were improvised, rather than being based on a particular military strategy. Blitzkrieg had been called a Revolution in Military Affairs (RMA) but many writers and historians have concluded that the Germans did not invent a new form of warfare but applied new technologies to traditional ideas of \"Bewegungskrieg\" (manoeuvre warfare) to achieve decisive victory.\n\nIn 1965, Captain Robert O'Neill, Professor of the History of War at the University of Oxford produced an example of the popular view. In \"Doctrine and Training in the German Army 1919–1939\", O'Neill wrote\n\nOther historians wrote that blitzkrieg was an operational doctrine of the German armed forces and a strategic concept on which the leadership of the \"Third Reich\" based its strategic and economic planning. Military planners and bureaucrats in the war economy appear rarely, if ever, to have employed the term \"blitzkrieg\" in official documents. That the German army had a \"blitzkrieg doctrine\" was rejected in the late 1970s by Matthew Cooper. The concept of a blitzkrieg \"Luftwaffe\" was challenged by Richard Overy in the late 1970s and by Williamson Murray in the mid-1980s. That the \"Third Reich\" went to war on the basis of \"blitzkrieg economics\" was criticised by Richard Overy in the 1980s and George Raudzens described the contradictory senses in which historians have used the word. The notion of a German blitzkrieg concept or doctrine survives in popular history and many historians still support the thesis.\n\nFrieser wrote that after the failure of the Schlieffen Plan in 1914, the German army concluded that decisive battles were no longer possible in the changed conditions of the twentieth century. Frieser wrote that the Oberkommando der Wehrmacht (OKW), which was created in 1938 had intended to avoid the decisive battle concepts of its predecessors and planned for a long war of exhaustion (\"ermattungskrieg\"). It was only after the improvised plan for the Battle of France in 1940 was unexpectedly successful, that the German General Staff came to believe that \"vernichtungskrieg\" was still feasible. German thinking reverted to the possibility of a quick and decisive war for the Balkan Campaign and Operation Barbarossa.\n\nMost academic historians regard the notion of blitzkrieg as military doctrine to be a myth. Shimon Naveh wrote \"The striking feature of the blitzkrieg concept is the complete absence of a coherent theory which should have served as the general cognitive basis for the actual conduct of operations\". Naveh described it as an \"ad hoc solution\" to operational dangers, thrown together at the last moment. Overy disagreed with the idea that Hitler and the Nazi regime ever intended a blitzkrieg war, because the once popular belief that the Nazi state organised their economy to carry out its grand strategy in short campaigns was false. Hitler had intended for a rapid unlimited war to occur much later than 1939, but the \"Third Reich's\" aggressive foreign policy forced the Nazi state into war before it was ready. Hitler and the \"Wehrmacht's\" planning in the 1930s did not reflect a blitzkrieg method but the opposite. John Harris wrote that the Wehrmacht never used the word, and it did not appear in German army or air force field manuals; the word was coined in September 1939, by a \"Times\" newspaper reporter. Harris also found no evidence that German military thinking developed a blitzkrieg mentality. Karl-Heinz Frieser and Adam Tooze reached similar conclusions to Overy and Naveh, that the notions of blitzkrieg-economy and strategy were myths. Frieser wrote that surviving German economists and General Staff officers denied that Germany went to war with a blitzkrieg strategy. Robert M. Citino argues:\n\nHistorian Victor Davis Hanson states that \"Blitzkrieg\" \"played on the myth of German technological superiority and industrial dominance,\" adding that German successes, particularly that of its Panzer divisions were \"instead predicated on the poor preparation and morale of Germany's enemies.\" Hanson also reports that at a Munich public address in November 1941, Hitler had \"disowned\" the concept of \"Blitzkrieg\" by calling it an \"idiotic word.\" Further, successful \"Blitzkrieg\" operations were predicated on superior numbers, air-support, and were only possible for short periods of time without sufficient supply lines. For all intents and purposes, \"Blitzkrieg\" ended at the Eastern Front once the German forces gave up Stalingrad, after they faced hundreds of new T-34 tanks, when the Luftwaffe became unable to assure air dominance, and following the stalemate at Kursk—to this end, Hanson concludes that German military success was not accompanied by the adequate provisioning of its troops with food and materiel far from the source of supply, which contributed to its ultimate failures. Despite its later disappointments as German troops extended their lines at too great a distance, the very specter or armored \"Blitzkrieg\" forces initially proved victorious against Polish, Dutch, Belgian, and French armies early in the war.\n\nIn the 1960s, Alan Milward developed a theory of blitzkrieg economics, that Germany could not fight a long war and chose to avoid comprehensive rearmament and armed in breadth, to win quick victories. Milward described an economy positioned between a full war economy and a peacetime economy. The purpose of the blitzkrieg economy was to allow the German people to enjoy high living standards in the event of hostilities and avoid the economic hardships of the First World War.\n\nOvery wrote that blitzkrieg as a \"coherent military and economic concept has proven a difficult strategy to defend in light of the evidence\". Milward's theory was contrary to Hitler's and German planners' intentions. The Germans, aware of the errors of the First World War, rejected the concept of organising its economy to fight only a short war. Therefore, focus was given to the development of armament in depth for a long war, instead of armament in breadth for a short war. Hitler claimed that relying on surprise alone was \"criminal\" and that \"we have to prepare for a long war along with surprise attack\". During the winter of 1939–40, Hitler demobilised many troops from the army to return as skilled workers to factories because the war would be decided by production, not a quick \"Panzer operation\".\n\nIn the 1930s, Hitler had ordered rearmament programs that cannot be considered limited. In November 1937 Hitler had indicated that most of the armament projects would be completed by 1943–45. The rearmament of the \"Kriegsmarine\" was to have been completed in 1949 and the \"Luftwaffe\" rearmament program was to have matured in 1942, with a force capable of strategic bombing with heavy bombers. The construction and training of motorised forces and a full mobilisation of the rail networks would not begin until 1943 and 1944 respectively. Hitler needed to avoid war until these projects were complete but his misjudgements in 1939 forced Germany into war before rearmament was complete.\n\nAfter the war, Albert Speer claimed that the German economy achieved greater armaments output, not because of diversions of capacity from civilian to military industry but through streamlining of the economy. Richard Overy pointed out some 23 percent of German output was military by 1939. Between 1937 and 1939, 70 percent of investment capital went into the rubber, synthetic fuel, aircraft and shipbuilding industries. Hermann Göring had consistently stated that the task of the Four Year Plan was to rearm Germany for total war. Hitler's correspondence with his economists also reveals that his intent was to wage war in 1943–1945, when the resources of central Europe had been absorbed into the \"Third Reich\".\n\nLiving standards were not high in the late 1930s. Consumption of consumer goods had fallen from 71 percent in 1928 to 59 percent in 1938. The demands of the war economy reduced the amount of spending in non-military sectors to satisfy the demand for the armed forces. On 9 September, Göring as Head of the \"Reich Defence Council\", called for complete \"employment\" of living and fighting power of the national economy for the duration of the war. Overy presents this as evidence that a \"blitzkrieg economy\" did not exist.\n\nAdam Tooze wrote that the German economy was being prepared for a long war. The expenditure for this war was extensive and put the economy under severe strain. The German leadership were concerned less with how to balance the civilian economy and the needs of civilian consumption but to figure out how to best prepare the economy for total war. Once war had begun, Hitler urged his economic experts to abandon caution and expend all available resources on the war effort but the expansion plans only gradually gained momentum in 1941. Tooze wrote that the huge armament plans in the pre-war period did not indicate any clear-sighted blitzkrieg economy or strategy.\n\nFrieser wrote that the () was not ready for blitzkrieg at the start of the war. A blitzkrieg method called for a young, highly skilled mechanised army. In 1939–40, 45 percent of the army was 40 years old and 50 percent of the soldiers had only a few weeks' training. The German army, contrary to the blitzkrieg legend, was not fully motorised and had only 120,000 vehicles, compared to the 300,000 of the French Army. The British also had an \"enviable\" contingent of motorised forces. Thus, \"the image of the German 'Blitzkrieg' army is a figment of propaganda imagination\". During the First World War the German army used 1.4 million horses for transport and in the Second World War used 2.7 million horses; only ten percent of the army was motorised in 1940.\n\nHalf of the German divisions available in 1940 were combat ready but less well-equipped than the British and French or the Imperial German Army of 1914. In the spring of 1940, the German army was semi-modern, in which a small number of well-equipped and \"elite\" divisions were offset by many second and third rate divisions\". In 2003, John Mosier wrote that while the French soldiers in 1940 were better trained than German soldiers, as were the Americans later and that the German army was the least mechanised of the major armies, its leadership cadres were larger and better and that the high standard of leadership was the main reason for the successes of the German army in World War II, as it had been in World War I.\n\nJames Corum wrote that it was a myth that the \"Luftwaffe\" had a doctrine of terror bombing, in which civilians were attacked to break the will or aid the collapse of an enemy, by the \"Luftwaffe\" in \"Blitzkrieg\" operations. After the bombing of Guernica in 1937 and the Rotterdam Blitz in 1940, it was commonly assumed that terror bombing was a part of \"Luftwaffe\" doctrine. During the interwar period the \"Luftwaffe\" leadership rejected the concept of terror bombing in favour of battlefield support and interdiction operations.\n\nCorum continues: General Walther Wever compiled a doctrine known as \"The Conduct of the Aerial War\". This document, which the \"Luftwaffe\" adopted, rejected Giulio Douhet's theory of terror bombing. Terror bombing was deemed to be \"counter-productive\", increasing rather than destroying the enemy's will to resist. Such bombing campaigns were regarded as diversion from the \"Luftwaffe's\" main operations; destruction of the enemy armed forces. The bombings of Guernica, Rotterdam and Warsaw were tactical missions in support of military operations and were not intended as strategic terror attacks.\n\nJ. P. Harris wrote that most Luftwaffe leaders from Goering through the general staff believed (as did their counterparts in Britain and the United States) that strategic bombing was the chief mission of the air force and that given such a role, the Luftwaffe would win the next war and that\n\nThe Luftwaffe did end up with an air force consisting mainly of relatively short-range aircraft, but this does not prove that the German air force was solely interested in ’tactical’ bombing. It happened because the German aircraft industry lacked the experience to build a long-range bomber fleet quickly, and because Hitler was insistent on the very rapid creation of a numerically large force. It is also significant that Germany's position in the centre of Europe to a large extent obviated the need to make a clear distinction between bombers suitable only for ’tactical’ and those necessary for strategic purposes in the early stages of a likely future war.\n\nBritish theorists John Frederick Charles Fuller and Captain Basil Henry Liddell Hart have often been associated with the development of blitzkrieg, though this is a matter of controversy. In recent years historians have uncovered that Liddell Hart distorted and falsified facts to make it appear as if his ideas were adopted. After the war Liddell Hart imposed his own perceptions, after the event, claiming that the mobile tank warfare practised by the \"Wehrmacht\" was a result of his influence. By manipulation and contrivance, Liddell Hart distorted the actual circumstances of the blitzkrieg formation, and he obscured its origins. Through his indoctrinated idealisation of an ostentatious concept, he reinforced the myth of blitzkrieg. By imposing, retrospectively, his own perceptions of mobile warfare upon the shallow concept of blitzkrieg, he \"created a theoretical imbroglio that has taken 40 years to unravel.\" Blitzkrieg was not an official doctrine and historians in recent times have come to the conclusion that it did not exist as such.\n\nThe early 1950s literature transformed blitzkrieg into a historical military doctrine, which carried the signature of Liddell Hart and Guderian. The main evidence of Liddell Hart's deceit and \"tendentious\" report of history can be found in his letters to Erich von Manstein, Heinz Guderian and the relatives and associates of Erwin Rommel. Liddell Hart, in letters to Guderian, \"imposed his own fabricated version of blitzkrieg on the latter and compelled him to proclaim it as original formula\". Kenneth Macksey found Liddell Hart's original letters to Guderian in the General's papers, requesting that Guderian give him credit for \"impressing him\" with his ideas of armoured warfare. When Liddell Hart was questioned about this in 1968 and the discrepancy between the English and German editions of Guderian's memoirs, \"he gave a conveniently unhelpful though strictly truthful reply. ('There is nothing about the matter in my file of correspondence with Guderian himself except...that I thanked him...for what he said in that additional paragraph'.)\".\n\nDuring World War I, Fuller had been a staff officer attached to the new tank corps. He developed Plan 1919 for massive, independent tank operations, which he claimed were subsequently studied by the German military. It is variously argued that Fuller's wartime plans and post-war writings were an inspiration or that his readership was low and German experiences during the war received more attention. The German view of themselves as the losers of the war, may be linked to the senior and experienced officers' undertaking a thorough review, studying and rewriting of all their Army doctrine and training manuals.\n\nFuller and Liddell Hart were \"outsiders\": Liddell Hart was unable to serve as a soldier after 1916 after being gassed on the Somme and Fuller's abrasive personality resulted in his premature retirement in 1933. Their views had limited impact in the British army; the War Office permitted the formation of an Experimental Mechanized Force on 1 May 1927, composed of tanks, lorried infantry, self-propelled artillery and motorised engineers but the force was disbanded in 1928 on the grounds that it had served its purpose. A new experimental brigade was intended for the next year and became a permanent formation in 1933, during the cuts of the financial years.\n\nIt has been argued that blitzkrieg was not new; the Germans did not invent something called blitzkrieg in the 1920s and 1930s. Rather the German concept of wars of movement and concentrated force were seen in wars of Prussia and the German wars of unification. The first European general to introduce rapid movement, concentrated power and integrated military effort was Swedish King Gustavus Adolphus during the Thirty Years' War. The appearance of the aircraft and tank in the First World War, called an RMA, offered the German military a chance to get back to the traditional war of movement as practised by Moltke the Elder. The so-called \"blitzkrieg campaigns\" of 1939 – circa 1942, were well within that operational context.\n\nAt the outbreak of war, the German army had no radically new theory of war. The operational thinking of the German army had not changed significantly since the First World War or since the late 19th century. J. P. Harris and Robert M. Citino point out that the Germans had always had a marked preference for short, decisive campaigns – but were unable to achieve short-order victories in First World War conditions. The transformation from the stalemate of the First World War into tremendous initial operational and strategic success in the Second, was partly the employment of a relatively small number of mechanised divisions, most importantly the Panzer divisions, and the support of an exceptionally powerful air force.\n\nHeinz Guderian is widely regarded as being highly influential in developing the military methods of warfare used by Germany's tank men at the start of the Second World War. This style of warfare brought manoeuvre back to the fore, and placed an emphasis on the offensive. This style, along with the shockingly rapid collapse in the armies that opposed it, came to be branded as blitzkrieg warfare.\n\nFollowing Germany's military reforms of the 1920s, Heinz Guderian emerged as a strong proponent of mechanised forces. Within the Inspectorate of Transport Troops, Guderian and colleagues performed theoretical and field exercise work. Guderian met with opposition from some in the General Staff, who were distrustful of the new weapons and who continued to view the infantry as the primary weapon of the army. Among them, Guderian claimed, was Chief of the General Staff Ludwig Beck (1935–38), whom he alleged was sceptical that armoured forces could be decisive. This claim has been disputed by later historians. James Corum wrote:\n\nBy Guderian's account he single-handedly created the German tactical and operational methodology. Between 1922 and 1928 Guderian wrote a number of articles concerning military movement. As the ideas of making use of the combustible engine in a protected encasement to bring mobility back to warfare developed in the German army, Guderian was a leading proponent of the formations that would be used for this purpose. He was later asked to write an explanatory book, which was titled \"Achtung Panzer!\" (1937). In it he explained the theories of the tank men and defended them.\n\nGuderian argued that the tank would be the decisive weapon of the next war. \"If the tanks succeed, then victory follows\", he wrote. In an article addressed to critics of tank warfare, he wrote \"until our critics can produce some new and better method of making a successful land attack other than self-massacre, we shall continue to maintain our beliefs that tanks—properly employed, needless to say—are today the best means available for land attack.\" Addressing the faster rate at which defenders could reinforce an area than attackers could penetrate it during the First World War, Guderian wrote that \"since reserve forces will now be motorized, the building up of new defensive fronts is easier than it used to be; the chances of an offensive based on the timetable of artillery and infantry co-operation are, as a result, even slighter today than they were in the last war.\" He continued, \"We believe that by attacking with tanks we can achieve a higher rate of movement than has been hitherto obtainable, and—what is perhaps even more important—that we can keep moving once a breakthrough has been made.\" Guderian additionally required that tactical radios be widely used to facilitate coordination and command by having one installed in all tanks.\n\nGuderian's leadership was supported, fostered and institutionalised by his supporters in the Reichswehr General Staff system, which worked the Army to greater and greater levels of capability through massive and systematic Movement Warfare war games in the 1930s. Guderian's book incorporated the work of theorists such as Ludwig Ritter von Eimannsberger, whose book, \"The Tank War\" (\"Der Kampfwagenkrieg\") (1934) gained a wide audience in the German army. Another German theorist, Ernst Volckheim, wrote a huge amount on tank and combined arms tactics and was influential to German thinking on the use of armoured formations but his work was not acknowledged in Guderian's writings.\n\n\n\n\n\n["}
{"id": "4653", "url": "https://en.wikipedia.org/wiki?curid=4653", "title": "The Beano", "text": "The Beano\n\nThe Beano is the longest running British children's comic magazine, published by DC Thomson. The comic first appeared on 30 July 1938, and was published weekly. In September 2009, \"The Beano\"'s 3,500th issue was published. One of the best selling comics in British popular culture, along with \"The Dandy\", the weekly circulation of \"The Beano\" in April 1950 was 1,974,072. \"The Beano\" is currently edited by John Anderson. Each issue is published on a Wednesday, with the issue date being that of the following Saturday. \"The Beano\" will strike 4000 issues in the summer of 2019.\n\nIts characters include \"Dennis the Menace\", \"Minnie the Minx\", \"The Bash Street Kids\", \"The Numskulls\", \"Roger the Dodger\", \"Billy Whizz\" and \"Tricky Dicky.\" Earlier characters who have been phased out include \"Ball Boy,\" \"Ivy the Terrible\", \"The Three Bears\" and \"Pansy Potter\". Some old characters, like \"Biffo the Bear\", \"Lord Snooty\", \"Baby Face Finlayson\" and \"Little Plum\", have more recently made a return as \"funsize\" quarter-page strips.\n\nThe style of \"Beano\" humour has shifted noticeably over the years, though the longstanding tradition of anarchic humour has remained. For decades strips have appeared to glorify immoral behaviour, e.g. pranking/bullying (\"Dennis the Menace\"), dishonesty (\"Roger the Dodger\") and even robbery (\"Baby Face Finlayson\" and \"The Three Bears\"). Although the readers' sympathies are assumed to be with the miscreants, the latter are very often shown punished for their actions. Recent years have seen a rise in humour involving gross bodily functions, especially flatulence (which would have been taboo in children's comics prior to the 1990s), while depictions of corporal punishment have declined. For example, the literal slipper – \"The Demon Whacker\" (Dennis the Menace's father's instrument of chastisement) – has become the name of the local chief of police (Sergeant Slipper). Dennis is a critic about eating his vegetables and dislikes his parents as they boss him around until he gets his own way.\n\nIn 1921, D. C. Thomson had first entered the field of boys' story papers with \"Adventure\". The success of this paper led to five further publications, \"The Rover\" and \"The Wizard\" in 1922, \"The Vanguard\" in 1924, \"The Skipper\" in 1930 and \"The Hotspur\" in 1933. Although \"The Vanguard\" folded in 1926, the others were a great triumph and became known as \"The Big Five\"; they ended Amalgamated Press's near-monopoly of the British comic industry.\n\nAnother success was the \"Fun Section\" of D. C. Thomson's Scottish weekly newspaper \"The Sunday Post\", which included the two strips \"Oor Wullie\" and \"The Broons\" by lead artist Dudley Watkins, as well as other funnies and various puzzles and adventure stories. This gave R. D. Low, the head of children's publications at D. C. Thomson at the time, the idea to create another Big Five, this time of comics intended for both boys and girls and consisting mainly of 'funnies' and more lighthearted adventure and text stories. The first of these publications, \"The Dandy\", commenced in 1937 and was followed by \"The Beano\" on 26 July 1938. \"The Beano\" comic takes its name from the English word \"beano\", a short form of bean-feast, a term for a festive meal, or loosely \"a good time\". A third paper, \"The Magic Comic\", aimed at a slightly younger audience, followed in July 1939, but ceased publication in early 1941, due to paper rationing. Wartime shortages also prevented the New Big Five project from being completed.\n\nThe first edition of \"The Beano\" was dated 30 July 1938. A facsimile of the first issue's cover was printed on the back of issue No. 2,000. There are only 12 known copies of the first issue in existence, and only five known copies of the second issue (not including facsimiles). A copy of the first issue sold for £12,100 on 16 March 2004, which was at the time thought to be the highest price ever paid for a British comic at an auction. (The current highest price is £20,350, which was paid for the first issue of \"The Dandy\" on 7 September 2004.)\n\nDuring the Second World War, \"The Beano\" and \"The Dandy\" were published on alternating weeks because of paper and ink rationing. D. C. Thomson's other publications also suffered, with the \"Oor Wullie\" and \"The Broons\" annuals falling victim to paper and ink shortages. Paper and ink supplies were fully restored shortly after the end of hostilities and weekly publication of \"The Beano\" and \"The Dandy\" resumed in 1949.\n\nThe 3,000th issue of \"The Beano\" was published in January 2000. \"The Beano\" is now the longest-running weekly comic, since \"The Dandy\" became a fortnightly comic in 2007, and later stopped publlishing in 2013.\n\n\"The Beano\"'s weekly circulation in April 1950 was 1,974,072; it currently sells slightly over 31,000 copies per week.\n\n\"The Beano\" is so popular that it had its own section of the Chessington World of Adventures theme park, \"Beanoland\". This opened in 2000 and survived for a decade before sponsorship was eventually lost. Most of the major Beanoland attractions remain in operation today but have been rethemed as \"Wild Asia\".\n\nOn 19 March 2012 Royal Mail launched a special stamp collection to celebrate Britain's rich comic book history. The collection featured \"The Beano\", \"The Dandy\", \"Eagle\", \"The Topper\", \"Roy of the Rovers\", \"Bunty\", \"Buster\", \"Valiant\", \"Twinkle\" and \"2000 AD\".\n\nThe original editor was George Moonie from 1938 to 1959; followed by Harold Cramond from 1959 to 1984.\n\nEuan Kerr was editor from 1984 until he handed over the reins to Alan Digby in early 2006. Digby had been \"Beano\" Chief Sub Editor when Kerr first became editor, and later edited \"The Beezer\". Kerr has returned to edit \"BeanoMAX\" as of issue 2 (see below). Following the retirement of Kerr, Digby took over as Editor-in-Chief of both titles. Digby retired in 2011, leaving Michael Stirling as the new editor.\n\nThe following editor of \"The Beano\" was Craig Graham, who joined \"The Beano\" once \"The Dandy\" announced its closure. Upon his arrival as editor, he made many changes to \"The Beano\".\n\nThe \"Beano\"'s first major revamp was in the 50th birthday issue of 1988, when the page number was increased, the comic had a wider paper style, and more colour was used throughout. Another occurred in issue 2,674, dated 16 October 1993, when the whole comic was now printed in full colour, along with some new strips such as \"The Numskulls\", which had been moved from \"The Beezer\".\n\nNo major revamps happened from then until 1998, when Dennis's baby sister Bea was born. The logo was rounded and embossed (but later flattened in February 1999), and there were 8 extra pages. Computers were starting to be used for articles and speech bubbles, rather than the usual hand drawn ones.\n\nSince April 2007, \"The Beano\" has had five revamps to help it keep up to date. The first occurred on 7 April 2007. The logo was raised using a heavy black drop shadow, and the body of the lettering and its yellow trim were separated by a subtle 3D groove effect. The website address was looped inside the \"O\". This logo had been used in the Beano Club for one issue in 2006. Two new comic strips were introduced, these being \"The Riot Squad\" and \"Fred's Bed\", reprints from \"Hoot\" and \"The Beezer\" and \"Topper\" respectively. There was a record number of uncredited reprints, with the likes of \"Ivy the Terrible\", \"Calamity James\", \"Les Pretend\" also being reprinted. In certain areas of the UK, such as Lancashire, the price was increased to 99p, while elsewhere it remained as 85p.\n\nThe second happened on 27 October 2007. The logo was still grooved, but was now back to the rounded style which it had from 1999 to 2006. It was quite similar to the original rounded logo from 1998, which was flattened the following year. The number of reprint pages was cut from 4 to 2, but more started to appear after about a month. Two new strips were also added, \"Johnny Bean from Happy Bunny Green\" and \"London B412\". The price increased to 99p across the whole UK.\n\nThe third was the least major revamp. The background was changed from one colour behind the logo and another behind the Dennis strip to one single colour or a pattern, such as red and black stripes. New fonts were being used on the front cover, and the \"Pocket money price\" logo had been changed to a large \"WOW! 99p\" which was usually placed in the top corners. No new strips were added this time, but the amount of reprints went up to 5, sometimes lowering back to 4 per week, and an extra \"Dennis\" strip was added on the inside back two pages.\n\nThe fourth revamp, which happened with the issue dated 18 October 2008, is the most major revamp to date. There was a return of \"Billy the Cat\" inside, as well as a new \"Super School\" strip by Lew Stringer. The price rose to £1.25 per issue. Different characters appear on the 'O' each week in a cleaner and tidier embossed logo. New headline fonts were introduced (CCZoinks); the balloon font was also changed to Cloudsplitter by Blambot. But the main change was the paper style, which had finally changed from newsprint to a glossy paper, much in the style of the inside pages of the then companion papers \"Dandy Xtreme\" and \"BeanoMAX\". The only difference between these paper styles is the front cover, which was thicker on the \"Dandy Xtreme\" and \"BeanoMAX\", but the same as the pages throughout in the weekly \"Beano\".\n\nAs of late 2010, \"The Beano\" is printed by BGP and the comic is now in an A4 format. A mild revision of style accompanies this with balloon font changed to CCTimeSaleLower, an upper and lower case font and a much larger Beano logo on the cover. The font CCZoinks appears to have less prominence with CreativeBlockBold taking centre stage. The Beano Club was closed down in 2010 and its pages changed to Beano VIP with more online presence. The paper is still glossy, but the paper stock gives it a matte feel. At the start of 2011, the Beano VIP pages were dropped from the comic, but the online features remain.\n\nIn the issue dated 12 October 2011, there was another revamp. The comic was expanded to 36 pages, and the paper stock was made smoother. The \"Number 13\" and \"The Germs\" strips returned as reprints. A reader's page was also reintroduced, this time titled the Menace Gallery. After two appearances, this was renamed \"The Treehouse\".\n\nIn the issue dated 28 January 2012, \"The Beano\"'s cover changed. The logo was now more like the logo from 1972-1998, but with \"The\" inside the B much like later versions of the logo. The special \"O\"s that had appeared sometimes in the last year were also kept. The first panel of the Dennis & Gnasher strip also appeared on the cover, like from 1972 to 2008, but the \"This Week In Beanotown\" feature still appeared across the bottom.\n\nIn late 2012, Craig Graham took over as Beano editor and revamped the comic. As a result, two mini-strip pages titled \"Funsize Funnies\" were introduced and featured \"Simply Smiffy\", \"Rasher\", \"Little Plum\", \"Les Pretend\", \"Pup Parade\", \"Baby Face Finlayson\" as well as two new strips \"Gnash Gnews\" and Winston and also introduced artists such as Wilbur Dawbarn (who took over Billy Whizz from Nick Brennan), Lew Stringer (not seen in the Beano since Super School), Alexander Matthews, Paul Palmer and Nigel Auchterlounie. Auchterlounie soon took over writing \"Dennis the Menace and Gnasher\" also which had returned to its pre-2009 style with new characters from the 2009 TV series. In January 2013, \"Biffo the Bear\", \"Pansy Potter\", \"Lord Snooty\" and \"Gnipper\" were added to the Funsize Funnies, introducing Graham Howie to the Beano and being the return of Wayne Thompson. Later that year, two new comic strips were added called \"Big Time Charlie\" and \"Tricky Dicky\" (relaunch of the classic Topper star) and \"Stunt Gran\", \"BamBeanos\", \"BSK CCTV\" joined the Funsize Funnies replacing Gnash Gnews, Pup Parade and Pansy Potter. Puzzle pages frequently appeared in the comic now, with Jamie Smart and Lew Stringer originally drawing the puzzles, and later on other artists such as Steve Beckett and Barrie Appleby.\n\nAs a celebration, in partnership with the CLIC Sargent charity, 2 August 2008 was Gnashional Menace Day, where children were sponsored to behave like Dennis. The anniversary was also celebrated with a 40-page issue (instead of 32 pages; the 60th birthday issue also had extra pages, 48 instead of 24) guest edited by \"Wallace and Gromit\" creator Nick Park, price £1.50 (not 99p) and an issue of Classics from the Comics devoted to the Beano. There is also a special 64-page book available, \"The Beano Special Collectors Edition: 70 Years of Fun\", giving a brief history of the comic. In the Beano's home city of Dundee, a special exhibition was held at the University of Dundee featuring original artwork and other memorabilia loaned from D.C. Thomson - it ran until 20 September 2008. In London the Cartoon Museum showed the exhibition \"Beano and Dandy Birthday Bash!\" from 30 July to 2 November 2008, featuring original artwork from all eight decades of both \"The Beano\" and \"The Dandy\", including work by Dudley D. Watkins, David Law, Leo Baxendale and Ken Reid as well as David Sutherland and many contemporary artists. There were events for children throughout August.\nThere was also a special coffee table book called \"\", published by Waverly Books.\n\nIn the 75th Anniversary Special, \"The Beano\" had yet another revamp introducing celebrities as regular characters. As a result, all of the Funsize Funnies as well as the two new recently added comic strips \"Tricky Dicky\" and \"Big Time Charlie\" plus the reprinted \"Calamity James\" were all dropped. \"Bananaman\" came out of Geering reprints after being in them for over a year with Wayne Thompson reprising the role of artist after drawing him previously in \"The Dandy\" from 2010 to 2012. \"Roger the Dodger\" was taken over by Jamie Smart and \"Ball Boy\" was taken over by Alexander Matthews and completely relaunched. Nigel Auchterlounie also took over as scriptwriter of \"The Bash Street Kids\" and \"Bananaman\", as well as now both writing and drawing \"The Numskulls\" which itself had had a huge relaunch with one-off celebrities replacing the role of Edd starting with Ant and Dec. \n\n12-year-old artist Zoom Rockman also joined \"The Beano\" in this issue, drawing \"Skanky Pigeon\" which appeared monthly. In the issue after the 75th Anniversary Special, fourteen new comic strips joined \"The Beano\" with twelve of these becoming the new Funsize Funnies stories, all of which are parodies of either a celebrity or television show: \"High School Moozical\", \"Neigh-Bours\", \"Celebrity Believe It or Not\", \"I Pity the School\", \"Murs Attacks\", \"Ashley's Banjo\", \"Coronation Bleat\", \"Jose's Back\", \"Simon's Bowel\", \"Guess Who?\", \"Watch-Hog\" and \"Danny Diddly O'Donoghue\" as well as two new one-page stories to replace \"Tricky Dicky\" and \"Big Time Charlie\": \"El Poco Loco\" and \"Teenage Mutant Ninja Turkeys\".\n\nStu Munro also took over as both puzzle page artist (as he did in \"The Dandy\") and \"The Dandy's Madvertisements\" were brought back with Stu Munro once again drawing them. Since the 75th Anniversary Special revamp, \"The Beano\" has now gained Andy Fanton, Stephen Waller, Dean Rankine, Garry Davies and Rick Eades all from \"The Dandy\" and the only original Beano artists that remain in the comic are David Sutherland, Laura Howell and Nigel Parkinson since Barrie Appleby, Barry Glennard, Hunt Emerson and Dave Eastbury all appear to have gone.\n\nA number of strips in the comic have run for a very long time. The top five longest running Beano comic strips are, in descending order, \"Dennis the Menace\", \"Minnie the Minx\", \"Bash Street Kids\", \"Roger the Dodger\", and then the last holder of the title before \"Dennis\", \"Lord Snooty\".\n\"Dennis the Menace\"'s famous red and black jersey had formed the colours of a few of the \"Beano\" characters' clothes (\"Minnie the Minx\" has the same, although the placement of the stripes is a bit different; \"Ball Boy\"&apos;s was a vertical red and black; \"Roger the Dodger\" has a chessboard design top, and Danny (from the \"Bash Street Kids\") has a similar cap), but they have changed for \"Minnie\" and \"Ball Boy\" (\"Minnie\" at one point had a red and yellow top and \"Ball Boy\"&apos;s strip is now black and blue).\n\nThere are frequent fictional crossovers between \"Beano\" characters, with most of the characters living in the fictional \"Beanotown\". Many of the comic strips in \"The Dandy\" are drawn by the same artists, and crossovers between the two comic magazines also occur occasionally. Quite often, one magazine will make a tongue-in-cheek jibe at the other (e.g., a character meeting an elderly lady, and stating that she's \"older than the jokes in \"The Dandy\"\"). In the strips, it is expressed that the two towns are rivals with each other and before \"The Dandy\" did a drastic format change they had an embassy in \"Beanotown\" which many of the town's citizens attempted to overrun, but failed (the embassy had no existence in \"The Beano\"). This rivalry inspired the spin-off computer game \"Beanotown Racing\", in which various characters from both comics could be raced around points in \"Beanotown\", including the Embassy. The game was given a large amount of advance publicity in the comics, with storylines often revolving how the characters each acquired his/her vehicle.\n\nOccasionally there are longer than usual strips, for example, a strip of sixteen pages rather than the usual two pages. These longer strips include \"The Bash Street Kids\" Adventures written and drawn by Kev F Sutherland which since 2004 have featured parodies of famous comic strip images, including \"Amazing Fantasy\"'s first \"Spider-Man\" cover, Action Comics' first \"Superman\" cover, and most recently the cover of \"X-Men\" No. 100.\n\nDuring the 1980s, \"The Beano\" ran a 'Readers' Request' feature where readers could request for a particular comic strip to feature in the Beano. This led to the return of dropped characters, including \"Little Plum\", \"Baby Face Finlayson\" and \"The McTickles\", but also led to the introduction of new strips such as \"Little Monkey\".\n\nReader polls started to appear in the 1990s, allowing the readers to rate the strips in the comic. These polls have been quite influential, as they indicate which strips the readers like best, and strips that have performed poorly in these polls were usually dropped.\n\nOn a number of occasions, the Beano has allowed its readers to vote for which new strips they want to appear in the comic. This usually consists of three new comic strips being run for a number of weeks and the readers can vote on which strips they prefer and the one that receives the most votes stays in the Beano. Readers have been able to cast their votes via telephone, or more recently via the Beano website.\n\nThe first such vote occurred in 1995 with \"Vic Volcano\" emerging as the winner. In the 1997 competition, two new strips were added permanently, with \"Tim Traveller\" winning and \"Crazy for Daisy\" the runner-up. By the early 2000s, these competitions were named Comic Idol (in reference to \"Pop Idol\"). In the 2004 competition, the margin between winner \"Joe Jitsu\" and runner-up \"Colin the Vet\" was 1%, so both strips were added to the comic.\n\nThe most recent incarnation in 2010 featured three new strips, \"Meebo and Zuky\", \"Home Invasion\", and \"Uh oh Si Co!\". \"Meebo and Zuky\" won, with \"Home Invasion\" finishing as runner-up, though only \"Meebo and Zuky\" were added to the comic. In 2011, the Dandy did a similar competition where readers voted for their favourite out of four strips, entitled \"Strictly Come Laughing\" (a reference to \"Strictly Come Dancing\").\n\nSince 1982 the comic, along with \"The Dandy\", has also run \"Comic Library\" titles. Released monthly, these titles are a feature length (usually about 64-page) adventure, featuring a character from the comic itself. They are available in A5 size only. In 1998, these were replaced by the \"Fun Size Beano\". Fun Size Comics were discontinued in late 2010.\n\nThe comic also ran A4-sized \"Beano Specials\" in 1987 with full coloured pages, which later were replaced by \"Beano Superstars\" which ran for 121 issues from 1992-2002. These were similar to the Comic Library series. Some of the last issues were printed versions of episodes from the 1996-1998 \"Dennis and Gnasher\" animated TV series. A \"Beano Poster Comic\" series was also printed in the early 1990s.\n\nThe Beano Specials returned in 2003, and were now published seasonally. The issues were numbered, and the first one was a Dennis and Friends special, the last a Christmas reprint special. These were replaced by BeanoMAX in early 2007.\n\nOn 15 February 2007, the first issue of a monthly comic entitled BeanoMAX was published. The sister comic features many of the same characters, however the stories in BeanoMAX are written in a longer format meant for 10- to 13-year-olds. The first issue was a Comic Relief special featuring assorted celebrity guests. This Magazine has since re-branded various times since 2013, and is currently known as EPIC Magazine.\n\n\"Plug\" was a comic based on the eponymous character from \"The Bash Street Kids\" that began with issue dated 24 September 1977, and is notable for being the first comic to make use of rotogravure printing. The magazine similar in style to I.P.C's \"Krazy\" which had started the previous year. It contained uncharacteristically outlandish material for D C. Thomson, as well as later including celebrity appearances in the comic.\n\nThe comic revealed Plug's full name to be Percival Proudfoot Plugsley and also gave him a pet monkey by the name of Chumkee. Plug's strip was mostly drawn by Vic Neill but other artists, including Dave Gudgeon drew some later strips. Other strips included \"Antchester United\", \"Violent Elizabeth\", \"Eebagoom\", \"Hugh's Zoo\" and \"D'ye Ken John Squeal and his Hopeless Hounds\".\n\nThe venture was unsuccessful, in part because the comic cost 9p, with the \"Beano\" at the time only costing 4p and most of its rivals priced similarly. It merged with \"The Beezer\" on 24 February 1979.\n\nThe brand new \"Dennis and Gnasher\" was launched separately from \"The Beano\" in September 2009.\n\n\"Dennis and Gnasher\" got their own TV series on CBBC from 7 September 2009 to accompany the comic's new look. This was their second, having also had one in 1996, which ran for two series on CBBC, \"The Children's Channel\", and \"Fox Kids\". It also marked the debut of this Dennis in the US, as \"The Beano\" is not distributed in the US and the title is taken by the \"newspaper comic strip\"- the series aired from 10 October 2010 to 10 December 2013 on what was then known as \"The Hub\" (now renamed \"Discovery Family\").\n\nOn 8 June 2016, it was announced via a press release that the Beano would now form a studio under their name. The studio would be use to bring their characters to life via other forms of media, such as television, film and live performances, to allow their properties to be distributed around the world for all audiences. Soon after the announcement of the studio's formation, news was released about a new television series based upon the companies famous \"Dennis the Menace\" property, which unlike its previous versions, would be done in CGI rather than the classic 2D style drawing. The studio would also revamp the website, \"beano.com\".\n\n\n"}
{"id": "4654", "url": "https://en.wikipedia.org/wiki?curid=4654", "title": "Bee", "text": "Bee\n\nBees are flying insects closely related to wasps and ants, known for their role in pollination and, in the case of the best-known bee species, the western honey bee, for producing honey and beeswax. Bees are a monophyletic lineage within the superfamily Apoidea and are presently considered a clade, called Anthophila. There are nearly 20,000 known species of bees in seven recognized biological families. They are found on every continent except Antarctica, in every habitat on the planet that contains insect-pollinated flowering plants.\n\nSome species including honey bees, bumblebees, and stingless bees live socially in colonies. Bees are adapted for feeding on nectar and pollen, the former primarily as an energy source and the latter primarily for protein and other nutrients. Most pollen is used as food for larvae. Bee pollination is important both ecologically and commercially; the decline in wild bees has increased the value of pollination by commercially managed hives of honey bees.\n\nBees range in size from tiny stingless bee species whose workers are less than long, to \"Megachile pluto\", the largest species of leafcutter bee, whose females can attain a length of . The most common bees in the Northern Hemisphere are the Halictidae, or sweat bees, but they are small and often mistaken for wasps or flies. Vertebrate predators of bees include birds such as bee-eaters; insect predators include beewolves and dragonflies.\n\nHuman beekeeping or apiculture has been practised for millennia, since at least the times of Ancient Egypt and Ancient Greece. Apart from honey and pollination, honey bees produce beeswax, royal jelly and propolis. Bees have appeared in mythology and folklore, through all phases of art and literature, from ancient times to the present day, though primarily focused in the Northern Hemisphere, where beekeeping is far more common.\n\nThe ancestors of bees were wasps in the family Crabronidae, which were predators of other insects. The switch from insect prey to pollen may have resulted from the consumption of prey insects which were flower visitors and were partially covered with pollen when they were fed to the wasp larvae. This same evolutionary scenario may have occurred within the vespoid wasps, where the pollen wasps evolved from predatory ancestors. Until recently, the oldest non-compression bee fossil had been found in New Jersey amber, \"Cretotrigona prisca\" of Cretaceous age, a corbiculate bee. A bee fossil from the early Cretaceous (~100 mya), \"Melittosphex burmensis\", is considered \"\"an extinct lineage of pollen-collecting Apoidea sister to the modern bees\"\". Derived features of its morphology (apomorphies) place it clearly within the bees, but it retains two unmodified ancestral traits (plesiomorphies) of the legs (two mid-tibial spurs, and a slender hind basitarsus), showing its transitional status. By the Eocene (~45 mya) there was already considerable diversity among eusocial bee lineages.\n\nThe highly eusocial corbiculate Apidae appeared roughly 87 Mya, and the Allodapini (within the Apidae) around 53 Mya.\nThe Colletidae appear as fossils only from the late Oligocene (~25 Mya) to early Miocene.\nThe Melittidae are known from \"Palaeomacropis eocenicus\" in the Early Eocene.\nThe Megachilidae are known from trace fossils (characteristic leaf cuttings) from the Middle Eocene.\nThe Andrenidae are known from the Eocene-Oligocene boundary, around 34 Mya, of the Florissant shale.\nThe Halictidae first appear in the Early Eocene with species found in amber. The Stenotritidae are known from fossil brood cells of Pleistocene age.\n\nThe earliest animal-pollinated flowers were shallow, cup-shaped blooms pollinated by insects such as beetles, so the syndrome of insect pollination was well established before the first appearance of bees. The novelty is that bees are specialized as pollination agents, with behavioral and physical modifications that specifically enhance pollination, and are the most efficient pollinating insects. In a process of coevolution, flowers developed floral rewards such as nectar and longer tubes, and bees developed longer tongues to extract the nectar. Bees also developed structures known as scopal hairs and pollen baskets to collect and carry pollen. The location and type differ among and between groups of bees. Most bees have scopal hairs located on their hind legs or on the underside of their abdomens, some bees in the family Apidae possess pollen baskets on their hind legs while very few species lack these entirely and instead collect pollen in their crops. This drove the adaptive radiation of the angiosperms, and, in turn, the bees themselves. Bees have not only coevolved with flowers but it is believed that some bees have coevolved with mites. Some bees provide tufts of hairs called acarinaria that appear to provide lodgings for mites; in return, it is believed that the mites eat fungi that attack pollen, so the relationship in this case may be mutualistc.\n\nThis phylogenetic tree is based on Debevic \"et al\", 2012, which used molecular phylogeny to demonstrate that the bees (Anthophila) arose from deep within the Crabronidae, which is therefore paraphyletic. The placement of the Heterogynaidae is uncertain. The small subfamily Mellininae was not included in their analysis.\n\nThis cladogram of the bee families is based on Hedtke et al., 2013, which places the former families Dasypodaidae and Meganomiidae as subfamilies inside the Melittidae.\nEnglish names, where available, are given in parentheses.\n\nBees are generally easy to recognize. They differ from closely related groups such as wasps by having branched or plume-like setae (hairs), combs on the forelimbs for cleaning their antennae, small anatomical differences in the limb structure and the venation of the hind wings, and in females, by having the seventh dorsal abdominal plate divided into two half-plates.\n\nBehaviourally, one of the most obvious characteristics of bees is that they collect pollen to provide provisions for their young, and have the necessary adaptations to do this. However, certain wasp species such as pollen wasps have similar behaviours, and a few species of bee scavenge from carcases to feed their offspring. The world's largest species of bee is thought to be the Indonesian resin bee \"Megachile pluto\", whose females can attain a length of . The smallest species may be dwarf stingless bees in the tribe Meliponini whose workers are less than in length.\nA bee has a pair of large compound eyes which cover much of the surface of the head. Between and above these are three small simple eyes (ocelli) which provide information for the bee on light intensity. The antennae usually have thirteen segments in males and twelve in females and are geniculate, having an elbow joint part way along. They house large numbers of sense organs that can detect touch (mechanoreceptors), smell and taste, and small, hairlike mechanoreceptors that can detect air movement so as to \"hear\" sounds. The mouthparts are adapted for both chewing and sucking by having both a pair of mandibles and a long proboscis for sucking up nectar.\n\nThe thorax has three segments, each with a pair of robust legs, and a pair of membranous wings on the hind two segments. The front legs of corbiculate bees bear combs for cleaning the antennae, and in many species the hind legs bear pollen baskets, flattened sections with incurving hairs to secure the collected pollen. The wings are synchronised in flight and the somewhat smaller hind wings connect to the forewings by a row of hooks along their margin which connect to a groove in the forewing. The abdomen has nine segments, the hindermost three being modified into the sting.\n\nAccording to inclusive fitness theory, organisms can gain fitness not just through increasing their own reproductive output, but also that of close relatives. In evolutionary terms, individuals should help relatives when \"Cost < Relatedness * Benefit\". The requirements for eusociality are more easily fulfilled by haplodiploid species such as bees because of their unusual relatedness structure.\nIn haplodiploid species, females develop from fertilized eggs and males from unfertilized eggs. Because a male is haploid (has only one copy of each gene), his daughters (which are diploid, with two copies of each gene) share 100% of his genes and 50% of their mother's. Therefore, they share 75% of their genes with each other. This mechanism of sex determination gives rise to what W. D. Hamilton termed \"supersisters\", more closely related to their sisters than they would be to their own offspring. Workers often do not reproduce, but they can pass on more of their genes by helping to raise their sisters (as queens) than they would by having their own offspring (each of which would only have 50% of their genes), assuming they would produce similar numbers. This unusual situation has been proposed as an explanation of the multiple independent evolutions of eusociality (arising at least nine separate times) within the Hymenoptera.\nHowever, some eusocial species such as termites are not haplodiploid. Conversely, all bees are haplodiploid but not all are eusocial, and among eusocial species many queens mate with multiple males, creating half-sisters that share only 25% of their genes. Haplodiploidy is thus neither necessary nor sufficient for eusociality. But, monogamy (queens mating singly) is the ancestral state for all eusocial species so far investigated, so it is likely that haplodiploidy contributed to the evolution of eusociality in bees.\n\nBees may be solitary or may live in various types of communities. Eusociality appears to have originated from at least three independent origins in halictid bees. The most advanced of these are species with eusocial colonies; these are characterised by having cooperative brood care and a division of labour into reproductive and non-reproductive adults, plus overlapping generations. This division of labour creates specialized groups within eusocial societies which are called castes. In some species, groups of cohabiting females may be sisters, and if there is a division of labour within the group, they are considered semisocial. The group is called eusocial if, in addition, the group consists of a mother (the queen) and her daughters (workers). When the castes are purely behavioural alternatives, with no morphological differentiation other than size, the system is considered primitively eusocial, as in many paper wasps; when the castes are morphologically discrete, the system is considered highly eusocial.\n\nThe true honey bees (genus \"Apis\", of which there are seven currently-recognized species) are highly eusocial, and are among the best known of all insects. Their colonies are established by swarms, consisting of a queen and several hundred workers. There are 29 subspecies of one of these species, \"Apis mellifera\", native to Europe, the Middle East, and Africa. Africanized bees are a hybrid strain of \"A. mellifera\" that escaped from experiments involving crossing European and African subspecies; they are extremely defensive.\n\nStingless bees are also highly eusocial. They practise mass provisioning, with complex nest architecture and perennial colonies also established via swarming.\n\nMany bumblebees are eusocial, similar to the eusocial Vespidae such as hornets in that the queen initiates a nest on her own rather than by swarming. Bumblebee colonies typically have from 50 to 200 bees at peak population, which occurs in mid to late summer. Nest architecture is simple, limited by the size of the pre-existing nest cavity, and colonies rarely last more than a year. In 2011, the International Union for Conservation of Nature set up the Bumblebee Specialist Group to review the threat status of all bumblebee species worldwide using the IUCN Red List criteria.\n\nThere are many more species of primitively eusocial than highly eusocial bees, but they have been studied less often. Most are in the family Halictidae, or \"sweat bees\". Colonies are typically small, with a dozen or fewer workers, on average. Queens and workers differ only in size, if at all. Most species have a single season colony cycle, even in the tropics, and only mated females hibernate. A few species have long active seasons and attain colony sizes in the hundreds, such as \"Halictus hesperus\". Some species are eusocial in parts of their range and solitary in others, or have a mix of eusocial and solitary nests in the same population. The orchid bees (Apidae) include some primitively eusocial species with similar biology. Some allodapine bees (Apidae) form primitively eusocial colonies, with progressive provisioning: a larva's food is supplied gradually as it develops, as is the case in honey bees and some bumblebees.\n\nMost other bees, including familiar insects such as carpenter bees, leafcutter bees and mason bees are solitary in the sense that every female is fertile, and typically inhabits a nest she constructs herself. There is no division of labor so these nests lack queens and \"worker\" bees for these species. Solitary bees typically produce neither honey nor beeswax.\n\nSolitary bees are important pollinators; they gather pollen to provision their nests with food for their brood. Often it is mixed with nectar to form a paste-like consistency. Some solitary bees have advanced types of pollen-carrying structures on their bodies. A very few species of solitary bees are being cultured for commercial pollination. Most of these species belong to a distinct set of genera which are commonly known by their nesting behavior or preferences, namely: carpenter bees, sweat bees, mason bees, plasterer bees, squash bees, dwarf carpenter bees, leafcutter bees, alkali bees and digger bees.\n\nMost solitary bees nest in the ground in a variety of soil textures and conditions while others create nests in hollow reeds or twigs, holes in wood. The female typically creates a compartment (a \"cell\") with an egg and some provisions for the resulting larva, then seals it off. A nest may consist of numerous cells. When the nest is in wood, usually the last (those closer to the entrance) contain eggs that will become males. The adult does not provide care for the brood once the egg is laid, and usually dies after making one or more nests. The males typically emerge first and are ready for mating when the females emerge. Solitary bees are either stingless or very unlikely to sting (only in self-defense, if ever).\n\nWhile solitary, females each make individual nests. Some species, such as the European mason bee \"Hoplitis anthocopoides\", and the Dawson's Burrowing bee, \"Amegilla dawsoni,\" are gregarious, preferring to make nests near others of the same species, and giving the appearance of being social. Large groups of solitary bee nests are called \"aggregations\", to distinguish them from colonies. In some species, multiple females share a common nest, but each makes and provisions her own cells independently. This type of group is called \"communal\" and is not uncommon. The primary advantage appears to be that a nest entrance is easier to defend from predators and parasites when there are multiple females using that same entrance on a regular basis.\n\nThe life cycle of a bee, be it a solitary or social species, involves the laying of an egg, the development through several moults of a legless larva, a pupation stage during which the insect undergoes complete metamorphosis, followed by the emergence of a winged adult. Most solitary bees and bumble bees in temperate climates overwinter as adults or pupae and emerge in spring when increasing numbers of flowering plants come into bloom. The males usually emerge first and search for females with which to mate. The sex of a bee is determined by whether or not the egg is fertilised; after mating, a female stores the sperm, and determines which sex is required at the time each individual egg is laid, fertilised eggs producing female offspring and unfertilised eggs, males. Tropical bees may have several generations in a year and no diapause stage.\nThe egg is generally oblong, slightly curved and tapering at one end. In the case of solitary bees, each one is laid in a cell with a supply of mixed pollen and nectar next to it. This may be rolled into a pellet or placed in a pile and is known as mass provisioning. In social species of bee there is progressive provisioning with the larva being fed regularly while it grows. The nest varies from a hole in the ground or in wood, in solitary bees, to a substantial structure with wax combs in bumblebees and honey bees.\n\nThe larvae are generally whitish grubs, roughly oval and bluntly-pointed at both ends. They have fifteen segments and spiracles in each segment for breathing. They have no legs but are able to move within the confines of the cell, helped by tubercles on their sides. They have short horns on the head, jaws for chewing their food and an appendage on either side of the mouth tipped with a bristle. There is a gland under the mouth that secretes a viscous liquid which solidifies into the silk they use to produce their cocoons. The pupa can be seen through the semi-transparent cocoon and over the course of a few days, the insect undergoes metamorphosis into the form of the adult bee. When ready to emerge, it splits its skin dorsally and climbs out of the exuviae as a winged adult and breaks out of the cell.\n\nIn Antoine Magnan's 1934 book \"Le vol des insectes\", he wrote that he and André Sainte-Laguë had applied the equations of air resistance to insects and found that their flight could not be explained by fixed-wing calculations, but that \"One shouldn't be surprised that the results of the calculations don't square with reality\". This has led to a common misconception that bees \"violate aerodynamic theory\", but in fact it merely confirms that bees do not engage in fixed-wing flight, and that their flight is explained by other mechanics, such as those used by helicopters. In 1996 it was shown that vortices created by many insects' wings helped to provide lift. High-speed cinematography and robotic mock-up of a bee wing showed that lift was generated by \"the unconventional combination of short, choppy wing strokes, a rapid rotation of the wing as it flops over and reverses direction, and a very fast wing-beat frequency\". Wing-beat frequency normally increases as size decreases, but as the bee's wing beat covers such a small arc, it flaps approximately 230 times per second, faster than a fruitfly (200 times per second) which is 80 times smaller.\n\nThe ethologist Karl von Frisch studied navigation in the honey bee. He showed that honey bees communicate by the waggle dance, in which a worker indicates the location of a food source to other workers in the hive. He demonstrated that bees can recognize a desired compass direction in three different ways: by the sun, by the polarization pattern of the blue sky, and by the earth's magnetic field. He showed that the sun is the preferred or main compass; the other mechanisms are used under cloudy skies or inside a dark beehive. Bees navigate using spatial memory with a \"rich, map-like organization\".\n\nMost bees are polylectic (generalist) meaning they collect pollen from a range of flowering plants, however, some are oligoleges (specialists), in that they only gather pollen from one or a few species or genera of closely related plants. Specialist pollinators also include bee species which gather floral oils instead of pollen, and male orchid bees, which gather aromatic compounds from orchids (one of the few cases where male bees are effective pollinators). Bees are able to sense the presence of desirable flowers through ultraviolet patterning on flowers, floral odors, and even electromagnetic fields. Once landed, a bee then uses nectar quality and pollen taste to determine whether to continue visiting similar flowers.\n\nIn rare cases, a plant species may only be effectively pollinated by a single bee species, and some plants are endangered at least in part because their pollinator is also threatened. There is, however, a pronounced tendency for oligolectic bees to be associated with common, widespread plants which are visited by multiple pollinators. There are some forty oligoleges associated with the creosote bush in the arid parts of the United States southwest, for example.\n\nMany bees are aposematically coloured, typically orange and black, warning of their ability to defend themselves with a powerful sting. As such they are models for Batesian mimicry by non-stinging insects such as bee-flies, robber flies and hoverflies, all of which gain a measure of protection by superficially looking and behaving like bees.\n\nBees are themselves Müllerian mimics of other aposematic insects with the same colour scheme, including wasps, lycid and other beetles, and many butterflies and moths (Lepidoptera) which are themselves distasteful, often through acquiring bitter and poisonous chemicals from their plant food. All the Müllerian mimics, including bees, benefit from the reduced risk of predation that results from their easily recognised warning coloration.\n\nBees are also mimicked by plants such as the bee orchid which imitates both the appearance and the scent of a female bee; male bees attempt to mate (pseudocopulation) with the furry lip of the flower, thus pollinating it.\n\nBrood parasites occur in several bee families including the apid subfamily Nomadinae. Females of these bees lack pollen collecting structures (the scopa) and do not construct their own nests. They typically enter the nests of pollen collecting species, and lay their eggs in cells provisioned by the host bee. When the cuckoo bee larva hatches it consumes the host larva's pollen ball, and often the host egg also. The Arctic bee species, \"Bombus hyperboreus,\" in particular are an aggressive species that attack and enslave other bees of the same subgenus. However, unlike many other bee brood parasites, they have pollen baskets and often collect pollen.\n\nIn the south of Africa, hives of African honeybees (\"A. mellifera scutellata\") are being destroyed by parasitic workers of the Cape honeybee, \"A. m. capensis\". These lay diploid eggs (\"thelytoky\"), escaping normal worker policing, leading to the colony's destruction; the parasites can then move to other hives.\n\nThe cuckoo bees in the \"Bombus\" subgenus \"Psithyrus\" are closely related to, and resemble, their hosts in looks and size. This common pattern gave rise to the ecological principle \"Emery's rule\". Others parasitize bees in different families, like \"Townsendiella\", a nomadine apid, two species of which are cleptoparasites of the dasypodaid genus \"Hesperapis\", while the other species in the same genus attacks halictid bees.\n\nFour bee families (Andrenidae, Colletidae, Halictidae, and Apidae) contain some species that are crepuscular. Most are tropical or subtropical, but there are some which live in arid regions at higher latitudes. These bees have greatly enlarged ocelli, which are extremely sensitive to light and dark, though incapable of forming images. Some have refracting superposition compound eyes: these combine the output of many elements of their compound eyes to provide enough light for each retinal photoreceptor. Their ability to fly by night enables them to avoid many predators, and to exploit flowers that produce nectar only or also at night.\n\nVertebrate predators of bees include bee-eaters, shrikes and flycatchers, which make short sallies to catch insects in flight. Swifts and swallows fly almost continually, catching insects as they go. The honey buzzard attacks bees' nests and eats the larvae. The greater honeyguide interacts with humans by guiding them to the nests of wild bees. The humans break open the nests and take the honey and the bird feeds on the larvae and the wax. Among mammals, predators such as the badger dig up bumblebee nests and eat both the larvae and any stored food. North American bears were particularly fond of honey.\n\nSpecialist ambush predators of visitors to flowers include crab spiders, which wait on flowering plants for pollinating insects; predatory bugs, and praying mantises, some of which (the flower mantises of the tropics) wait motionless, aggressive mimics camouflaged as flowers. Beewolves are large wasps that habitually attack bees; the ethologist Niko Tinbergen estimated that a single colony of the beewolf \"Philanthus triangulum\" might kill several thousand honeybees in a day: all the prey he observed were honeybees. Other predatory insects that sometimes catch bees include robber flies and dragonflies. Honey bees are affected by parasites including acarine and \"Varroa\" mites. However, some bees are believed to have a mutualistic relationship with mites.\n\nThree bee maidens with the power of divination and thus speaking truth are described in Homer's \"Hymn to Hermes\", and the food of the gods is \"identified as honey\"; the bee maidens were originally associated with Apollo, and are probably not correctly identified with the Thriae. Honey, according to a Greek myth, was discovered by a nymph called Melissa (\"Bee\"); and honey was offered to the Greek gods from Mycenean times. Bees were associated, too, with the Delphic oracle and the prophetess was sometimes called a bee.\n\nThe image of a community of honey bees has been used from ancient to modern times, in Aristotle and Plato; in Virgil and Seneca; in Erasmus and Shakespeare; Tolstoy, and by political and social theorists such as Bernard Mandeville and Karl Marx as a model for human society. In English folklore, bees would be told of important events in the household, in a custom known as \"Telling the bees\".\n\nSome of the oldest examples of bees in art are rock paintings in Spain which have been dated to 15,000 BC.\n\nW. B. Yeats's poem \"The Lake Isle of Innisfree\" (1888) contains the couplet \"Nine bean rows will I have there, a hive for the honey bee, / And live alone in the bee loud glade.\" At the time he was living in Bedford Park in the West of London. Beatrix Potter's illustrated book \"The Tale of Mrs Tittlemouse\" (1910) features Babbity Bumble and her brood \"(pictured)\". Kit Williams' treasure hunt book \"The Bee on the Comb\" (1984) uses bees and beekeeping as part of its story and puzzle. Sue Monk Kidd's \"The Secret Life of Bees\" (2004), and the 2009 film starring Dakota Fanning, tells the story of a girl who escapes her abusive home and finds her way to live with a family of beekeepers, the Boatwrights.\n\nThe humorous 2007 animated film \"Bee Movie\" used Jerry Seinfeld's first script and was his first work for children; he starred as a bee named Barry B. Benson, alongside Renée Zellweger. Critics found its premise awkward and its delivery tame. Dave Goulson's \"A Sting in the Tale\" (2014) describes his efforts to save bumblebees in Britain, as well as much about their biology. The playwright Laline Paull's fantasy \"The Bees\" (2015) tells the tale of a hive bee named Flora 717 from hatching onwards.\n\nHumans have kept honey bee colonies, commonly in hives, for millennia. Beekeepers collect honey, beeswax, propolis, pollen, and royal jelly from hives; bees are also kept to pollinate crops and to produce bees for sale to other beekeepers.\n\nDepictions of humans collecting honey from wild bees date to 15,000 years ago; efforts to domesticate them are shown in Egyptian art around 4,500 years ago. Simple hives and smoke were used; jars of honey were found in the tombs of pharaohs such as Tutankhamun. From the 18th century, European understanding of the colonies and biology of bees allowed the construction of the moveable comb hive so that honey could be harvested without destroying the colony. Among Classical Era authors, beekeeping with the use of smoke is described in the \"History of Animals\" Book 9. The account mentions that bees die after stinging; that workers remove corpses from the hive, and guard it; castes including workers and non-working drones, but \"kings\" rather than queens; predators including toads and bee-eaters; and the waggle dance, with the \"irresistible suggestion\" of άpοσειονται (aroseiontai, it waggles) and παρακολουθούσιν (parakolouthousin, they watch).\n\nBeekeeping is described in detail by Virgil in his \"Eclogues\"; it is also mentioned in his \"Aeneid\", and in Pliny's \"Natural History\".\n\nBees play an important role in pollinating flowering plants, and are the major type of pollinator in many ecosystems that contain flowering plants. It is estimated that one third of the human food supply depends on pollination by insects, birds and bats, most of which is accomplished by bees, whether wild or domesticated.\n\nContract pollination has overtaken the role of honey production for beekeepers in many countries. From 1972 to 2006, feral honey bees declined dramatically in the US, and they are now almost absent. The number of colonies kept by beekeepers declined slightly, through urbanization, systematic pesticide use, tracheal and \"Varroa\" mites, and the closure of beekeeping businesses. In 2006 and 2007 the rate of attrition increased, and was described as colony collapse disorder. In 2010 invertebrate iridescent virus and the fungus \"Nosema ceranae\" were shown to be in every killed colony, and deadly in combination. Winter losses increased to about 1/3. \"Varroa\" mites were thought to be responsible for about half the losses.\n\nApart from colony collapse disorder, losses outside the US have been attributed to causes including pesticide seed dressings, using neonicotinoids such as Clothianidin, Imidacloprid and Thiamethoxam. From 2013 the European Union restricted some pesticides to stop bee populations from declining further. In 2014 the Intergovernmental Panel on Climate Change report warned that bees faced increased risk of extinction because of global warming. In 2018 the European Union decided to ban field use of all three major neonicotinoids; they remain permitted in veterinary, greenhouse, and vehicle transport usage.\n\nFarmers have focused on alternative solutions to mitigate these problems. By raising native plants, they provide food for native bee pollinators like \"L. vierecki\" and \"L. leucozonium\", leading to less reliance on honey bee populations.\n\nHoney is a natural product produced by bees and stored for their own use, but its sweetness has always appealed to humans. Before domestication of bees was even attempted, humans were raiding their nests for their honey. Smoke was often used to subdue the bees and such activities are depicted in rock paintings in Spain dated to 15,000 BC.\n\nHoney bees are used commercially to produce honey. They also produce some substances used as dietary supplements with possible health benefits, pollen, propolis, and royal jelly, though all of these can also cause allergic reactions.\n\nBees are partly considered edible insects. Indigenous people in many countries eat insects, including the larvae and pupae of bees, mostly stingless species. They also gather larvae, pupae and surrounding cells, known as bee brood, for consumption. In the Indonesian dish \"botok tawon\" from Central and East Java, bee larvae are eaten as a companion to rice, after being mixed with shredded coconut, wrapped in banana leaves, and steamed.\n\nBee brood (pupae and larvae) although low in calcium, has been found to be high in protein and carbohydrate, and a useful source of phosphorus, magnesium, potassium, and trace minerals iron, zinc, copper, and selenium. In addition, while bee brood was high in fat, it contained no fat soluble vitamins (such as A, D, and E) but it was a good source of most of the water-soluble B-vitamins including choline as well as vitamin C. The fat was composed mostly of saturated and monounsaturated fatty acids with 2.0% being polyunsaturated fatty acids.\n\nApitherapy is a branch of alternative medicine that uses honey bee products, including raw honey, royal jelly, pollen, propolis, beeswax and apitoxin (Bee venom). The claim that apitherapy treats cancer, which some proponents of apitherapy make, remains unsupported by evidence-based medicine.\n\nThe painful stings of bees are mostly associated with the poison gland and the Dufour's gland which are abdominal exocrine glands containing various chemicals. In \"Lasioglossum leucozonium\", the Dufour's Gland mostly contains octadecanolide as well as some eicosanolide. There is also evidence of n-triscosane, n-heptacosane, and 22-docosanolide. However, the secretions of these glands could also be used for nest construction.\n\n\n"}
{"id": "4660", "url": "https://en.wikipedia.org/wiki?curid=4660", "title": "Basques", "text": "Basques\n\nThe Basques ( or ; ; ; ) are an indigenous ethnic group characterised by the Basque language, a common culture and shared ancestry to the ancient Vascones and Aquitanians. Basques are indigenous to and primarily inhabit an area traditionally known as the Basque Country (), a region that is located around the western end of the Pyrenees on the coast of the Bay of Biscay and straddles parts of north-central Spain and south-western France.\n\nThe English word \"Basque\" may be pronounced or and derives from the French \"Basque\" (), which is derived from Gascon \"Basco\" (pronounced ), cognate with Spanish \"Vasco \"(pronounced ). These, in turn, come from Latin \"Vasco\" (pronounced ), plural \"Vascones\" (see History section below). The Latin labial-velar approximant /w/ generally evolved into the bilabials /b/ and /β̞/ in Gascon and Spanish, probably under the influence of Basque and Aquitanian, a language related to old Basque and spoken in Gascony in Antiquity (similarly the Latin /w/ evolved into /v/ in French, Italian and other languages).\n\nSeveral coins from the 2nd and 1st centuries BC found in the Basque Country bear the inscription \"barscunes\". The place where they were minted is not certain, but is thought to be somewhere near Pamplona, in the heartland of the area that historians believe was inhabited by the \"Vascones\". Some scholars have suggested a Celtic etymology based on \"bhar-s-\", meaning \"summit\", \"point\" or \"leaves\", according to which \"barscunes\" may have meant \"the mountain people\", \"the tall ones\" or \"the proud ones\", while others have posited a relationship to a proto-Indo-European root \"*bar-\" meaning \"border\", \"frontier\", \"march\".\n\nIn Basque, people call themselves the \"euskaldunak\", singular \"euskaldun\", formed from \"euskal-\" (i.e. \"Basque (language)\") and \"-dun\" (i.e. \"one who has\"); \"euskaldun\" literally means a Basque speaker. Not all Basques are Basque-speakers. Therefore, the neologism \"euskotar\", plural \"euskotarrak\", was coined in the 19th century to mean a culturally Basque person, whether Basque-speaking or not. Alfonso Irigoyen posits that the word \"euskara\" is derived from an ancient Basque verb \"enautsi\" \"to say\" (cf. modern Basque \"esan\") and the suffix \"-(k)ara\" (\"way (of doing something)\"). Thus \"euskara\" would literally mean \"way of saying\", \"way of speaking\". One item of evidence in favour of this hypothesis is found in the Spanish book \"Compendio Historial\", written in 1571 by the Basque writer Esteban de Garibay. He records the name of the Basque language as \"enusquera\". It may, however, be a writing mistake.\n\nIn the 19th century, the Basque nationalist activist Sabino Arana posited an original root \"euzko\" which, he thought, came from \"eguzkiko\" (\"of the sun\", related to the assumption of an original solar religion). On the basis of this putative root, Arana proposed the name Euzkadi for an independent Basque nation, composed of seven Basque historical territories. Arana's neologism \"Euzkadi\" (in the regularized spelling Euskadi) is still widely used in both Basque and Spanish, since it is now the official name of the Autonomous Community of the Basque Country.\n\nSince the Basque language is unrelated to Indo-European, it has long been thought to represent the people or culture that occupied Europe before the spread of Indo-European languages there. A comprehensive analysis of Basque genetic patterns has shown that Basque genetic uniqueness predates the arrival of agriculture in the Iberian Peninsula, about 7,000 years ago. It is thought that Basques are a remnant of the early inhabitants of Western Europe, specifically those of the Franco-Cantabrian region. Basque tribes were mentioned in Roman times by Strabo and Pliny, including the Vascones, the Aquitani, and others. There is enough evidence to support the hypothesis that at that time and later they spoke old varieties of the Basque language (see: Aquitanian language).\n\nIn the Early Middle Ages the territory between the Ebro and Garonne rivers was known as Vasconia, a vaguely defined ethnic area and political entity struggling to fend off pressure from the Iberian Visigothic kingdom and Arab rule to the south, as well as the Frankish push from the north. By the turn of the first millennium, the territory of Vasconia had fragmented into different feudal regions, such as Soule and Labourd, while south of the Pyrenees the Castile, Pamplona and the Pyrenean counties of Aragon, Sobrarbe, Ribagorza (later Kingdom of Aragon), and Pallars emerged as the main regional entities with Basque population in the 9th and 10th centuries.\n\nThe Kingdom of Pamplona, a central Basque realm, later known as Navarre, underwent a process of feudalization and was subject to the influence of its much larger Aragonese, Castilian and French neighbours. Castile deprived Navarre of its coastline by conquering key western territories (1199–1201), leaving the kingdom landlocked. The Basques were ravaged by the War of the Bands, bitter partisan wars between local ruling families. Weakened by the Navarrese civil war, the bulk of the realm eventually fell before the onslaught of the Spanish armies (1512–1524). However, the Navarrese territory north of the Pyrenees remained beyond the reach of an increasingly powerful Spain. Lower Navarre became a province of France in 1620.\n\nNevertheless, the Basques enjoyed a great deal of self-government until the French Revolution (1790) and the Carlist Wars (1839, 1876), when the Basques supported heir apparent Carlos V and his descendants. On either side of the Pyrenees, the Basques lost their native institutions and laws held during the \"Ancien régime\". Since then, despite the current limited self-governing status of the Basque Autonomous Community and Navarre as settled by the Spanish Constitution, many Basques have attempted higher degrees of self-empowerment (see Basque nationalism), sometimes by acts of violence. Labourd, Lower Navarre, and Soule were integrated into the French department system (starting 1790), with Basque efforts to establish a region-specific political-administrative entity failing to take off to date. However, in January 2017, a single agglomaration community was established for the Basque Country in France.\n\nThe Basque region is divided into at least three administrative units, namely the Basque Autonomous Community and Navarre in Spain, and the arrondissement of Bayonne and the cantons of Mauléon-Licharre and Tardets-Sorholus in the \"département\" of Pyrénées Atlantiques, France.\n\nThe autonomous community (a concept established in the Spanish Constitution of 1978) known as \"Euskal Autonomia Erkidegoa\" or EAE in Basque and as \"Comunidad Autónoma Vasca\" or CAV in Spanish (in English: \"Basque Autonomous Community\" or BAC), is made up of the three Spanish provinces of Álava, Biscay and Gipuzkoa. The corresponding Basque names of these territories are \"Araba\", \"Bizkaia\" and \"Gipuzkoa\", and their Spanish names are \"Álava\", \"Vizcaya\" and \"Guipúzcoa\".\n\nThe BAC only includes three of the seven provinces of the currently called historical territories. It is sometimes referred to simply as \"the Basque Country\" (or \"Euskadi\") by writers and public agencies only considering those three western provinces, but also on occasions merely as a convenient abbreviation when this does not lead to confusion in the context. Others reject this usage as inaccurate and are careful to specify the BAC (or an equivalent expression such as \"the three provinces\", up to 1978 referred to as \"Provincias Vascongadas\" in Spanish) when referring to this entity or region. Likewise, terms such as \"the Basque Government\" for \"the government of the BAC\" are commonly though not universally employed. In particular in common usage the French term \"Pays Basque\" (\"Basque Country\"), in the absence of further qualification, refers either to the whole Basque Country (\"Euskal Herria\" in Basque), or not infrequently to the northern (or \"French\") Basque Country specifically.\n\nUnder Spain's present constitution, Navarre (\"Nafarroa\" in present-day Basque, \"Navarra\" historically in Spanish) constitutes a separate entity, called in present-day Basque \"Nafarroako Foru Erkidegoa\", in Spanish \"Comunidad Foral de Navarra\" (the autonomous community of Navarre). The government of this autonomous community is the Government of Navarre. Note that in historical contexts Navarre may refer to a wider area, and that the present-day northern Basque province of Lower Navarre may also be referred to as (part of) \"Nafarroa\", while the term \"High Navarre\" (\"Nafarroa Garaia\" in Basque, \"Alta Navarra\" in Spanish) is also encountered as a way of referring to the territory of the present-day autonomous community.\n\nThere are three other historic provinces parts of the Basque Country: Labourd, Lower Navarre and Soule (\"Lapurdi, Nafarroa Beherea\" and \"Zuberoa\" in Basque; \"Labourd, Basse-Navarre\" and \"Soule\" in French), devoid of official status within France's present-day political and administrative territorial organization, and only minor political support to the Basque nationalists. A large number of regional and local nationalist and non-nationalist representatives have waged a campaign for years advocating for the creation of a separate Basque département, while these demands have gone unheard by the French administration.\n\nThere are 2,123,000 people living in the Basque Autonomous Community (279,000 in Alava, 1,160,000 in Biscay and 684,000 in Gipuzkoa). The most important cities in this region, which serve as the provinces' administrative centers, are Bilbao (in Biscay), San Sebastián (in Gipuzkoa) and Vitoria-Gasteiz (in Álava). The official languages are Basque and Spanish. Knowledge of Spanish is compulsory under the Spanish constitution (article no. 3), and knowledge and usage of Basque is a right under the Statute of Autonomy (article no. 6), so only knowledge of Spanish is virtually universal. Knowledge of Basque, after declining for many years during Franco's dictatorship owing to official persecution, is again on the rise due to favorable official language policies and popular support. Currently about 33 percent of the population in the Basque Autonomous Community speaks Basque.\n\nNavarre has a population of 601,000; its administrative capital and main city, also regarded by many nationalist Basques as the Basques' historical capital, is Pamplona (\"Iruñea\" in modern Basque). Only Spanish is an official language of Navarre, and the Basque language is only co-official in the province's northern region, where most Basque-speaking Navarrese are concentrated.\n\nAbout a quarter of a million people live in the French Basque Country. Nowadays Basque-speakers refer to this region as \"Iparralde\" (Basque for North), and to the Spanish provinces as \"Hegoalde\" (South). Much of this population lives in or near the Bayonne-Anglet-Biarritz (BAB) urban belt on the coast (in Basque these are \"Baiona\", \"Angelu\" and \"Miarritze\"). The Basque language, which was traditionally spoken by most of the region's population outside the BAB urban zone, is today rapidly losing ground to French. The French Basque Country's lack of self-government within the French state is coupled with the absence of official status for the Basque language in the region. Attempts to introduce bilingualism in local administration have so far met direct refusal from French officials.\n\nLarge numbers of Basques have left the Basque Country to settle in the rest of Spain, France or other parts of the world in different historical periods, often for economic or political reasons. Historically the Basques abroad were often employed in shepherding and ranching and by maritime fisheries and merchants. Millions of Basque descendants (see Basque American and Basque Canadian) live in North America (the United States; Canada, mainly in the provinces of New Brunswick and Quebec), Latin America (in all 23 countries), South Africa, and Australia.\n\nMiguel de Unamuno said: \"There are at least two things that clearly can be attributed to Basques: the Society of Jesus and the Republic of Chile.\" Chilean historian Luis Thayer Ojeda estimated that 48 percent of immigrants to Chile in the 17th and 18th centuries were Basque. Estimates range between 2.5 - 5 million Basque descendants live in Chile; the Basque have been a major if not the strongest influence in the country's cultural and economic development.\n\nBasque place names are to be found, such as Nueva Vizcaya (now Chihuahua and Durango, Mexico), Biscayne Bay (Guatemala), and Aguereberry Point (United States). Nueva Vizcaya was the first province in the north of the Viceroyalty of New Spain (Mexico) to be explored and settled by the Spanish. It consisted mostly of the area which is today the states of Chihuahua and Durango.\n\nIn Mexico most Basques are concentrated in the cities of Monterrey, Saltillo, Reynosa, Camargo, and the states of Jalisco, Durango, Nuevo León, Tamaulipas, and Coahuila. The Basques were important in the mining industry; many were ranchers and vaqueros (cowboys), and the rest opened small shops in major cities such as Mexico City, Guadalajara and Puebla. In Guatemala, most Basques have been concentrated in Sacatepequez Department, Antigua Guatemala, Jalapa for six generations now, while some have migrated to Guatemala City.\n\nIn Colombia, Basques settled mainly in Antioquia and the Coffee Axis. It is estimated that nearly 2,500,000 persons from all Antioquia (40% of this department) have Basque ancestry, as well, in the 19th century about 10% of Colombia's total population were Basque descendants. Antioquia has one of the biggest concentrations of Basques descendants around the world. In 1955, Joaquín Ospina said: \"Is there something more similar to the Basque people than the \"\"antioqueños\"\". Also, writer Arturo Escobar Uribe said in his book \"\"Mitos de Antioquia\"\" (Myths of Antioquia) (1950): \"Antioquia, which in its clean ascendance predominates the peninsular farmer of the Basque provinces, inherited the virtues of its ancestors... Despite the predominance of the white race, its extension in the mountains... has projected over Colombia's map the prototype of its race; in Medellín with the industrial paisa, entrepreneur, strong and steady... in its towns, the adventurer, arrogant, world-explorer... Its myths, which are an evidence of their deep credulity and an indubitable proof of their Iberian ancestor, are the sequel of the conqueror's blood which runs through their veins...\". Bambuco, a Colombian folk music, has Basque roots.\n\nThe largest of several important Basque communities in the United States is in the area around Boise, Idaho, home to the Basque Museum and Cultural Center, host to an annual Basque festival, as well as a festival for the Basque diaspora every five years. Reno, Nevada, where the Center for Basque Studies and the Basque Studies Library are located at the University of Nevada, is another significant nucleus of Basque population. Elko, Nevada sponsors an annual Basque festival that celebrates the dance, cuisine and cultures of the Basque peoples of Spanish, French and Mexican nationalities who have arrived in Nevada since the late 19th century.\n\nTexas has a large percentage of Hispanics descended from Basques who participated in the conquest of New Spain. Many of the original Tejanos had Basque blood, including those who fought in the Battle of the Alamo alongside many of the other Texans. Along the Mexican/Texan border, many Basque surnames can be found. The largest concentration of Basques who settled on Mexico's north-eastern \"frontera\", including the states of Chihuahua, Durango, Coahuila, Nuevo León, and Tamaulipas, also settled along Texas' Rio Grande River from South Texas to West Texas. Many of the historic \"hidalgos\", or noble families from this area, had gained their titles and land grants from Spain and Mexico; they still value their land. Some of North America's largest ranches, which were founded under these colonial land grants, can be found in this region.\n\nCalifornia has a major concentration of Basques, most notably in the San Joaquin Valley between Stockton, Fresno and Bakersfield. The city of Bakersfield has a large Basque community and the city has several Basque restaurants, including Noriega's which won the 2011 James Beard Foundation America's Classic Award. There is a history of Basque culture in Chino, California. In Chino, two annual Basque festivals celebrate the dance, cuisine, and culture of the peoples. The surrounding area of San Bernardino County has many Basque descendants as residents. They are mostly descendants of settlers from Spain and Mexico. These Basques in California are grouped in the group known as \"Californios\".\n\nBasques of European Spanish-French and Latin American nationalities also settled throughout the western U.S. in states like Louisiana, New Mexico, Arizona, Utah, Colorado, Wyoming, Montana, Oregon, and Washington.\n\nThe identifying language of the Basques is called Basque or \"Euskara\", spoken today by 25%-30% of the region's population. An idea of the central place of the cultural terms in Basque nationalist politicians is given by the fact that, in Basque, Basques identify themselves by the term \"euskaldun\" and their country as \"Euskal Herria\", literally \"Basque speaker\" and \"Country of the Basque Language\" respectively. The language has been made a political issue by official Spanish and French policies restricting its use either historically or currently; however, this has not stopped the teaching, speaking, writing, and cultivating of this increasingly vibrant minority language. This sense of Basque identity tied to the local language does not exist in isolation. It is juxtaposed with an equally strong sense of national identity tied with the use of the Spanish and French languages among other Basques. As with many European states, a regional identity, be it linguistically derived or otherwise, is not mutually exclusive with the broader national one. For example, Basque rugby union player for France, Imanol Harinordoquy, has said about his national identity:I am French and Basque. There is no conflict, I am proud of both. . . . I have friends who are involved in the political side of things but that is not for me. My only interest is the culture, the Euskera language, the people, our history and ways.\n\nAs a result of state language promotion, school policies, the effects of mass media and migration, today virtually all Basques (except for some children below school age) speak the official language of their state (Spanish or French). There are extremely few Basque monolingual speakers: essentially all Basque speakers are bilingual on both sides of the border. Spanish or French is typically the first language of citizens from other regions (who often feel no need to learn Basque), and Spanish or French is also the first language of many Basques, all of which maintains the dominance of the state tongues of both France and Spain. Recent Basque Government policies aim to change this pattern, as they are viewed as potential threats against mainstream usage of the minority tongue.\n\nThe Basque language is thought to be a genetic language isolate in contrast with other European languages, almost all of which belong to the broad Indo-European language family. Another peculiarity of Basque is that it has been spoken continuously \"in situ\", in and around its present territorial location, for longer than other modern European languages, which were all introduced in historic or prehistoric times through population migrations or other processes of cultural transmission.\n\nHowever, popular stereotypes characterizing Basque as \"the oldest language in Europe\" and \"unique among the world's languages\" may be misunderstood and lead to erroneous assumptions. Over the centuries, Basque has remained in continuous contact with neighboring western European languages with which it has come to share numerous lexical properties and typological features; it is therefore misleading to exaggerate the \"outlandish\" character of Basque. Basque is also a modern language, and is established as a written and printed one used in present-day forms of publication and communication, as well as a language spoken and used in a very wide range of social and cultural contexts, styles, and registers.\n\nBasques have a close attachment to their home (\"etxe(a)\" 'house, home'), especially when this consists of the traditional self-sufficient, family-run farm or \"baserri(a)\". Home in this context is synonymous with family roots. Some Basque surnames were adapted from old \"baserri\" or habitation names. They typically related to a geographical orientation or other locally meaningful identifying features. Such surnames provide even those Basques whose families may have left the land generations ago with an important link to their rural family origins: \"Bengoetxea\" \"the house of further down\", \"Goikoetxea\" \"the house above\", \"Landaburu\" \"top of the field\", \"Errekondo\" \"next to the stream\", \"Elizalde\" \"by the church\", \"Mendizabal\" \"wide hill\", \"Usetxe\" \"house of birds\" \"Ibarretxe\" \"house in the valley\", \"Etxeberria\" \"the new house\", and so on.\n\nIn contrast to surrounding regions, ancient Basque inheritance patterns, recognised in the \"fueros,\" favoured survival of the unity of inherited land holdings. In a kind of primogeniture, these usually were inherited by either the eldest male or female. As in other cultures, the fate of other family members depended on the assets of a family: wealthy Basque families tended to provide for all children in some way, while less-affluent may have had only one asset to provide to one child. However, this heir often provided for the rest of the family (unlike in England, with strict primogeniture, where the eldest son inherited everything and often did not provide for others). Even though they were provided for in some way, younger siblings had to make much of their living by other means. Before the advent of industrialisation, this system resulted in the emigration of many rural Basques to Spain, France or the Americas. Harsh by modern standards, this custom resulted in a great many enterprising figures of Basque origin who went into the world to earn their way, from Spanish conquistadors such as Lope de Aguirre and Francisco Vásquez de Coronado, to explorers, missionaries and saints of the Catholic Church, such as Francis Xavier.\n\nA widespread belief that Basque society was originally matriarchal is at odds with the current, clearly patrilineal kinship system and inheritance structures. Some scholars and commentators have attempted to reconcile these points by assuming that patrilineal kinship represents an innovation. In any case, the social position of women in both traditional and modern Basque society is somewhat better than in neighbouring cultures, and women have a substantial influence in decisions about the domestic economy. In the past, some women participated in collective magical ceremonies. They were key participants in a rich folklore, today largely forgotten.\n\nBasque cuisine is at the heart of Basque culture, influenced by the neighboring communities and the excellent produce from the sea and the land. A 20th-century feature of Basque culture is the phenomenon of gastronomical societies (called \"txoko\" in Basque), food clubs where men gather to cook and enjoy their own food. Until recently, women were allowed entry only one day in the year. Cider houses (Sagardotegiak) are popular restaurants in Gipuzkoa open for a few months while the cider is in season.\n\nAt the end of the 20th century, despite ETA violence (ended in 2010) and the crisis of heavy industries, the Basque economic condition recovered remarkably. They emerged from the Franco regime with a revitalized language and culture. The Basque language expanded geographically led by large increases in the major urban centers of Pamplona, Bilbao, and Bayonne, where only a few decades ago the Basque language had all but disappeared. Nowadays, the number of Basque speakers is maintaining its level or increasing slightly.\n\nTraditionally Basques have been mostly Roman Catholics. In the 19th century and well into the 20th, Basques as a group remained notably devout and churchgoing. In recent years church attendance has fallen off, as in most of Western Europe. The region has been a source of missionaries like Francis Xavier and Michel Garicoïts. Ignatius Loyola, founder of the Society of Jesus, was a Basque. California Franciscan Fermín Lasuén was born in Vitoria. Lasuén was the successor to Franciscan Padre Junípero Serra and founded 9 of the 21 extant California Missions along the coast.\n\nA sprout of Protestantism in the continental Basque Country produced the first translation of the new Testament into Basque by Joanes Leizarraga. Queen Jeanne III of Navarre, a devout Huguenot, commissioned the translation of the New Testament into Basque and Béarnese for the benefit of her subjects. By the time Henry III of Navarre converted to Roman Catholicism in order to become king of France, Protestantism virtually disappeared from the Basque community.\n\nBayonne held a Jewish community composed mainly of Sephardi Jews fleeing from the Spanish and Portuguese Inquisitions. There were also important Jewish and Muslim communities in Navarre before the Castilian invasion of 1512-21.\n\nNowadays, according to one single opinion poll, only slightly more than 50% of Basques profess some kind of belief in God, while the rest are either agnostic or atheist. The number of religious skeptics increases noticeably for the younger generations, while the older ones are more religious.\nRoman Catholicism is, by far, the largest religion in Basque Country. In 2012, the proportion of Basques that identify themselves as Roman Catholic was 58.6%, while it is one of the most secularized communities of Spain: 24.6% were non-religious and 12.3% of Basques were atheist.\n\nChristianisation of the Basque Country has been the topic of some discussion. There are broadly speaking two views. According to one, Christianity arrived in the Basque Country during the 4th and 5th centuries but according to the other, it did not take place until the 12th and 13th centuries. The main issue lies in the different interpretations of what is considered Christianisation. Early traces of Christianity can be found in the major urban areas from the 4th century onwards, a bishopric from 589 in Pamplona and three hermit cave concentrations (two in Álava, one in Navarre) were in use from the 6th century onwards. In this sense, Christianity arrived \"early\".\n\nPre-Christian belief seems to have focused on a goddess called Mari. A number of place-names contain her name and would suggest these places were related to worship of her such as \"Anbotoko Mari\" who appears to have been related to the weather. According to one tradition, she travelled every seven years between a cave on Mount Anboto and one on another mountain (the stories vary); the weather would be wet when she was in Anboto, dry when she was in Aloña, or Supelegor, or Gorbea. One of her names, \"Mari Urraca\" possibly ties her to an historical Navarrese princess of the 11th and 12th century, with other legends giving her a brother or cousin who was a Roman Catholic priest. So far the discussions about whether the name Mari is original and just happened to coincide closely with the Christian name María or if Mari is an early Basque attempt to give a Christian veneer to pagan worship have remained speculative. At any rate, Mari (Andramari) is one of the oldest worshipped Christian icons in Basque territories.\n\nMari's consort is Sugaar. This chthonic couple seem to bear the superior ethical power and also the power of creation and destruction. It's said that when they gathered in the high caves of the sacred peaks, they engendered the storms. These meetings typically happened on Friday nights, the day of historical akelarre or coven. Mari was said to reside in Mount Anboto; periodically she crossed the skies as a bright light to reach her other home at mount Txindoki.\n\nLegends also speak of many and abundant genies, like \"jentilak\" (equivalent to giants), \"lamiak\" (equivalent to nymphs), \"mairuak\" (builders of the cromlechs or stone circles, literally Moors), \"iratxoak\" (imps), \"sorginak\" (witches, priestess of Mari), and so on. Basajaun is a Basque version of the Woodwose. This character is probably an anthropomorphism of the bear. There is a trickster named \"San Martin Txiki\" (\"St Martin the Lesser\").\n\nIt has been shown that some of these stories have entered Basque culture in recent centuries or as part of Roman \"superstition\". It is unclear whether neolithic stone structures called dolmens have a religious significance or were built to house animals or resting shepherds. Some of the dolmens and cromlechs are burial sites serving as well as border markers.\n\nThe \"jentilak\" ('Giants'), on the other hand, are a legendary people which explains the disappearance of a people of Stone Age culture that used to live in the high lands and with no knowledge of the iron. Many legends about them tell that they were bigger and taller, with a great force, but were displaced by the \"ferrons\", or workers of ironworks foundries, until their total fade-out. They were pagans, but one of them, Olentzero, accepted Christianity and became a sort of Basque Santa Claus. They gave name to several toponyms, as \"Jentilbaratza\".\nHistorically, Basque society can be described as being somewhat at odds with Roman and later European societal norms.\n\nStrabo's account of the north of Spain in his \"Geographica\" (written between approximately 20 BC and 20 AD) makes a mention of \"a sort of woman-rule—not at all a mark of civilization\" (Hadington 1992), a first mention of the—for the period—unusual position of women. \"Women could inherit and control property as well as officiate in churches. Combined with the issue of lingering pagan beliefs, this enraged the leaders of the Spanish Inquisition, perhaps leading to one of the largest witch hunts in the Basque town of Logroño in 1610\".\n\nThis preference for female dominance existed well into the 20th century:\n...matrilineal inheritance laws, and agricultural work performed by women continued in Basque country until the early twentieth century. For more than a century, scholars have widely discussed the high status of Basque women in law codes, as well as their positions as judges, inheritors, and arbitrators through ante-Roman, medieval, and modern times. The system of laws governing succession in the French Basque region reflected total equality between the sexes. Up until the eve of the French Revolution, the Basque woman was truly ‘the mistress of the house', hereditary guardian, and head of the lineage.\n\nAlthough the kingdom of Navarre did adopt feudalism, most Basques also possessed unusual social institutions different from those of the rest of feudal Europe. Some aspects of this include the elizate tradition where local house-owners met in front of the church to elect a representative to send to the \"juntas\" and \"Juntas Generales\" (such as the \"Juntas Generales de Vizcaya\" or \"Guipúzcoa\") which administered much larger areas. Another example was the fact that in the medieval period most land was owned by the farmers, not the Church or a king.\n\nThe great family of ball games has its unique offspring among Basque ball games, known generically as pilota (Spanish: \"pelota\"). Some variants have been exported to the United States and Macau under the name of Jai Alai.\n\nThere are several sports derived by Basques from everyday chores. Heavy workers were challenged and bets placed upon them. Examples are:\n\nThe encierro (bull run) in Pamplona's fiestas \"Sanfermines\" started as a transport of bulls to the ring. These encierros, as well as other bull and bullock related activities are not exclusive to Pamplona but are traditional in many towns and villages of the Basque country.\n\nThere are several clubs within the Basque Country, such as Athletic Bilbao, Real Sociedad, Deportivo Alavés, SD Eibar and, as Navarre club, the CA Osasuna (the only club in La Liga that has a Basque name — \"osasuna\" means \"health\"). In the 2016-2017 season these five clubs played together in La Liga, the first instance where five Basque clubs have reached that level at the same time. Athletic's recruitment policy has meant the club refuses to sign any non-Basque players. Real Sociedad also previously employed such a policy.\n\nRugby union is a popular sport among French Basques, with major clubs Biarritz Olympique and Aviron Bayonnais traditional powerhouses in the premier division of French Rugby (the Top 14). Biarritz regularly play Heineken Cup matches, especially knockout matches, at Estadio Anoeta in San Sebastian. Games between the Basque clubs and Catalan club USA Perpignan are always hard fought.\n\nCycling is popular and the Euskaltel-Euskadi professional cycling team, partly sponsored by the Basque Government participated in the UCI World Tour division until 2014. Known for their orange tops and hill-climbing ability, their fans were famous for lining the famous Pyrenean climbs in the Tour de France, in support of their compatriots.\n\nEach April the week-long Tour of the Basque Country showcases the beautiful rolling Basque countryside. Miguel Indurain, born in Villava is one of the most celebrated cyclists in the world having won 5 consecutive Tours de France.\n\nWhile there is no independent Basque state, Spain's autonomous community of the Basque Country, made up of the provinces of Álava (Araba), Biscay (Bizkaia) and Gipuzkoa, is primarily a historical consequence and an answer to the wide autonomy claim of its population.\n\nNavarre has a separate statute of autonomy, a contentious arrangement designed during Spanish transition to democracy (the \"Amejoramiento\", an 'upgrade' of its previous status during dictatorship). It refers back to the kingdom status of Navarre (up to 1841) and their traditional institutional and legal framework (charters). Basque, the original and main language of Navarre up to the late 18th century, has kept family transmission especially in the northern part of Navarre and central areas to a lesser extent, designated as Basque speaking or mixed area in Navarrese law. Questions of political, linguistic and cultural allegiance and identity are highly complex in Navarre. Politically some Basque nationalists would like to integrate with the Basque Autonomous Community.\n\nThe French Basque Country today does not exist as a formal political entity and is officially simply part of the French department of Pyrénées Atlantiques, centered in Béarn. In recent years the number of mayors of the region supporting the creation of a separate Basque department has grown to 63.87%. So far, their attempts have been unsuccessful.\n\nBoth the Spanish and French governments have, at times, suppressed Basque linguistic and cultural identity. The French Republics, the epitome of the nation-state, have a long history of attempting the complete cultural absorption of cultural minority groups. Spain has, at most points in its history, granted some degree of linguistic, cultural, and even political autonomy to its Basques, but under the regime of Francisco Franco, the Spanish government reversed the advances of Basque nationalism, as it had fought in the opposite side of the Spanish Civil War: cultural activity in Basque was limited to folkloric issues and the Roman Catholic Church.\n\nToday, the Southern Basque Country within Spain enjoys an extensive cultural and political autonomy. The majority of schools under the jurisdiction of the Basque education system use Basque as the primary medium of teaching. However, the situation is more delicate in the Northern Basque Country within France, where Basque is not officially recognized, and where lack of autonomy and monolingual public schooling in French exert great pressure on the Basque language.\n\nIn Navarre, Basque has been declared an endangered language, since the anti-Basque and conservative government of Navarrese People's Union opposes the symbols of Basque culture, highlighting a Spanish identity for Navarre.\n\nBasque is also spoken by immigrants in the major cities of Spain and France, in Australia, in many parts of Latin America, and in the United States, especially in Nevada, Idaho, and California.\n\nSince its articulation by Sabino Arana in the late 19th century, the more radical currents of Basque nationalism have demanded the right of self-determination and even independence. Within the Basque country, this element of Basque politics is often in balance with the conception of the Basque Country as just another part of the Spanish state, a view more commonly espoused on the right of the political spectrum. In contrast, the desire for greater autonomy or independence is particularly common among leftist Basque nationalists. The right of self-determination was asserted by the Basque Parliament in 2002 and 2006.\nSince self-determination is not recognized in the Spanish Constitution of 1978, a wide majority of Basques abstained (55%) and some even voted against it (23.5%) in the ratification referendum of December 6 of that year. However, it was approved by clear majority overall in Spanish (87%). The autonomous regime for the Basque Country was approved in a 1979 referendum but the autonomy of Navarre (\"Amejoramiento del Fuero\": \"improvement of the charter\") was never subject to a referendum but only approved by the Navarrese Cortes (parliament).\n\nAs with their language, the Basques are clearly a distinct cultural group in their region. They regard themselves as culturally and especially linguistically distinct from their surrounding neighbours. Some Basques identify themselves as Basques only whereas others identify themselves both as Basque and Spanish. Many Basques regard the designation as a \"cultural minority\" as incomplete, favouring instead the definition as a nation, the commonly accepted designation for the Basque people up to the rise of the nation-states and the definition imposed by the 1812 Spanish Constitution.\n\nIn modern times, as a European people living in a highly industrialized area, cultural differences from the rest of Europe are inevitably blurred, although a conscious cultural identity as a people or nation remains very strong, as does an identification with their homeland, even among many Basques who have emigrated to other parts of Spain or France, or to other parts of the world.\n\nThe strongest distinction between the Basques and their traditional neighbours is linguistic. Surrounded by Romance-language speakers, the Basques traditionally spoke (and many still speak) a language that was not only non-Romance but non-Indo-European. The prevailing belief amongst Basques, and forming part of their national identity, is that their language has continuity with the people who were in this region since not only pre-Roman and pre-Celtic times, but since the Stone Age.\n\nIn 1920, H. G. Wells referred to the Mediterranean race as the \"Iberian race\". He regarded it as a fourth subrace of the Caucasian race, along with the \"Aryan\", \"Semitic\", and \"Hamitic\" subraces. He stated that the main ethnic group that most purely represented the racial stock of the Iberian race was the Basques, and that the Basques were the descendants of the Cro-Magnons. In 1994, in his book \"The History and Geography of Human Genes\", population geneticist L. Luca Cavalli-Sforza stated that \"there is support from many sides\" for the hypothesis that the Basques are the descendants of the original Cro-Magnons.\n\nEven before the development of modern genetics based on DNA sequencing, Basques were already noted for distinctive genetic patterns, such as possessing the highest global apportion of the Rh- blood type (35% phenotypically, 60% genetically). Additionally, the Basque population has virtually no B blood type, nor the related AB type. They have a high rate of O blood group but this is probably due to isolation.\n\nAlthough they are genetically distinctive in some ways, the Basques are still very typically European in terms of their Y-DNA and mtDNA sequences, and in terms of some other genetic loci. These same sequences are widespread throughout the western half of Europe, especially along the western fringe of the continent.\n\nThe distinctiveness noted by studies of 'classical' genetic markers (such as blood groups) and the apparently \"pre-Indo-European\" nature of the Basque language has resulted in a popular and long-held view that Basques are \"living fossils\" of the earliest modern humans who colonized Europe. However, studies of the Y-chromosome found that on their direct male lineages, the vast majority of modern Basques have a common ancestry with other Western Europeans, namely a marked predominance of Haplogroup R1b.\n\nInitially Haplogroup R1b was theorised to be that a Palaeolithic marker, introduced when Europe was repopulated after the Last Glacial Maximum, about 25,000 years ago. As such, Basque populations were used as proxy representatives for the \"Palaeolithic component\" in admixture studies that tried to quantify the extent of Neolithic diffusions. Such studies concluded that the main components in the European genomes appear to derive from ancestors whose features were similar to those of modern Basques and people of the Near East (or Western Asia), with average values greater than 35% for both these parental populations, regardless of whether molecular information is taken into account or not. The smallest degree of both Basque and Near Eastern admixture is found in Finland, whereas the highest values are, respectively, 70% \"Basque\" in Spain and roughly 60% \"Near Eastern\" in the Balkans. This theory encountered inconsistencies even prior to most recent chronological re-evaluations. That R1b should be a Palaeolithic marker was an \"ad hoc\" assumption suggested by Semino \"et al.\" (2000) and propagated by subsequent scholars without further analysis. Higher resolution STR analysis of R1b lineages from other western European populations (e.g. Italy or Britain (Wales)) show that their populations appear to derive from the Basque ones.\n\nMore recent studies instead propose that R1b spread through Europe from southwest Asia in the Neolithic period or later, between 4,000 and 8,000 years ago.\n\nAutosomal genetic studies have confirmed that Basques share:\n\nSeveral ancient DNA samples have been recovered and amplified from Palaeolithic sites in the Basque region. The collection of mtDNA haplogroups sampled there differed significantly compared to their modern frequencies. The authors concluded that there is \"discontinuity\" between ancient locals and modern Basques.\n\nThus, while Basques harbour some very archaic lineages (such as mtDNA Hg U8a), they are not of \"undiluted Palaeolithic ancestry\", nor are they ancestral to large parts of western Europe. Rather, their genetic distinctiveness is a result of centuries of low population size, genetic drift and endogamy.\n\nIn 2015, a new scientific study of Basque DNA was published which seems to indicate that Basques are descendants of Neolithic farmers who mixed with local Mesolithic hunters before becoming genetically isolated from the rest of Europe for millennia. Mattias Jakobsson from Uppsala University in Sweden analysed genetic material from eight Stone Age human skeletons found in El Portalón Cavern in Atapuerca, northern Spain. These individuals lived between 3,500 and 5,500 years ago, after the transition to farming in southwest Europe. The results show that these early Iberian farmers are the closest ancestors to present-day Basques.\n\nThe findings were published in \"Proceedings of the National Academy of Sciences\" of the United States. According to the study, the \"results show that the Basques trace their ancestry to early farming groups from Iberia, which contradicts previous views of them being a remnant population that trace their ancestry to Mesolithic hunter-gatherer groups.\" These early Neolithic farmer ancestors of the Basques, however, additionally mixed with local southwestern hunter-gatherers, and \"the proportion of hunter gatherer-related admixture into early farmers also increased over the course of two millennia.\" This admixed group was also found to be ancestral to other modern-day Iberian peoples, but while the Basques remained relatively isolated for millennia after this time, later migrations into Iberia led to distinct and additional admixture in all other Iberian groups.\n\nAmong the most notable Basque people are Juan Sebastián Elcano (led the first successful expedition to circumnavigate the globe after Ferdinand Magellan died mid-journey); Sancho III of Navarre; and Ignatius of Loyola and Francis Xavier, founders of the Society of Jesus. Don Diego María de Gardoqui y Arriquibar (1735–1798) was Spain's first Ambassador to the United States. Miguel de Unamuno was a noted novelist and philosopher of the late 19th and the 20th century.\n\n\n\n"}
{"id": "4661", "url": "https://en.wikipedia.org/wiki?curid=4661", "title": "Blot", "text": "Blot\n\nBlot may refer to:\n\n\n\n"}
{"id": "4662", "url": "https://en.wikipedia.org/wiki?curid=4662", "title": "Bookkeeping", "text": "Bookkeeping\n\nBookkeeping is the recording of financial transactions, and is part of the process of accounting in business. Transactions include purchases, sales, receipts, and payments by an individual person or an organization/corporation. There are several standard methods of bookkeeping, including the single-entry and double-entry bookkeeping systems. While these may be viewed as \"real\" bookkeeping, any process for recording financial transactions is a bookkeeping process.\n\nBookkeeping is the work of a bookkeeper (or book-keeper), who records the day-to-day financial transactions of a business. They usually write the \"daybooks\" (which contain records of sales, purchases, receipts, and payments), and document each financial transaction, whether cash or credit, into the correct daybook—that is, petty cash book, suppliers ledger, customer ledger, etc.—and the general ledger. Thereafter, an accountant can create financial reports from the information recorded by the bookkeeper.\n\nBookkeeping refers mainly to the record-keeping aspects of financial accounting, and involves preparing source documents for all transactions, operations, and other events of a business.\n\nThe bookkeeper brings the books to the trial balance stage: an accountant may prepare the income statement and balance sheet using the trial balance and ledgers prepared by the bookkeeper.\n\nThe origin of book-keeping is lost in obscurity, but recent researches indicate that methods of keeping accounts have existed from the remotest times of human life in cities. Babylonian records written with styli on small slabs of clay have been found dating to 2600 BCE. \nThe term \"waste book\" was used in colonial America, referring to the documenting of daily transactions of receipts and expenditures. Records were made in chronological order, and for temporary use only. Daily records were then transferred to a daybook or account ledger to balance the accounts and to create a permanent journal; then the waste book could be discarded, hence the name.\n\nThe bookkeeping process primarily records the \"financial effects\" of transactions. An important difference between a manual and an electronic accounting system is the former's latency between the recording of a financial transaction and its posting in the relevant account. This delay, which is absent in electronic accounting systems due to nearly instantaneous posting to relevant accounts, is characteristic of manual systems, and gave rise to the primary books of accounts—cash book, purchase book, sales book, etc.—for immediately documenting a financial transaction.\n\nIn the normal course of business, a document is produced each time a transaction occurs. Sales and purchases usually have invoices or receipts. Deposit slips are produced when lodgements (deposits) are made to a bank account. Checks (spelled \"cheques\" in the UK and several other countries) are written to pay money out of the account. Bookkeeping first involves recording the details of all of these \"source documents\" into multi-column \"journals\" (also known as \"books of first entry\" or \"daybooks\"). For example, all credit sales are recorded in the sales journal; all cash payments are recorded in the cash payments journal. Each column in a journal normally corresponds to an account. In the single entry system, each transaction is recorded only once. Most individuals who balance their check-book each month are using such a system, and most personal-finance software follows this approach.\n\nAfter a certain period, typically a month, each column in each journal is totalled to give a summary for that period. Using the rules of double-entry, these journal summaries are then transferred to their respective accounts in the ledger, or \"account book\". For example, the entries in the Sales Journal are taken and a debit entry is made in each customer's account (showing that the customer now owes us money), and a credit entry might be made in the account for \"Sale of class 2 widgets\" (showing that this activity has generated revenue for us). This process of transferring summaries or individual transactions to the ledger is called \"posting\". Once the posting process is complete, accounts kept using the \"T\" format undergo \"balancing\", which is simply a process to arrive at the balance of the account.\n\nAs a partial check that the posting process was done correctly, a working document called an \"unadjusted trial balance\" is created. In its simplest form, this is a three-column list. Column One contains the names of those accounts in the ledger which have a non-zero balance. If an account has a \"debit\" balance, the balance amount is copied into Column Two (the \"debit column\"); if an account has a \"credit\" balance, the amount is copied into Column Three (the \"credit column\"). The debit column is then totalled, and then the credit column is totalled. The two totals must agree—which is not by chance—because under the double-entry rules, whenever there is a posting, the debits of the posting equal the credits of the posting. If the two totals do not agree, an error has been made, either in the journals or during the posting process. The error must be located and rectified, and the totals of the debit column and the credit column recalculated to check for agreement before any further processing can take place.\n\nOnce the accounts balance, the accountant makes a number of adjustments and changes the balance amounts of some of the accounts. These adjustments must still obey the double-entry rule: for example, the \"inventory\" account and asset account might be changed to bring them into line with the actual numbers counted during a stocktake. At the same time, the \"expense\" account associated with usage of inventory is adjusted by an equal and opposite amount. Other adjustments such as posting depreciation and prepayments are also done at this time. This results in a listing called the \"adjusted trial balance\". It is the accounts in this list, and their corresponding debit or credit balances, that are used to prepare the financial statements.\n\nFinally financial statements are drawn from the trial balance, which may include:\n\nTwo bookkeeping methods in most common use today are the single-entry bookkeeping system and the double-entry bookkeeping system. Single-entry bookkeeping is adequate for many small businesses; it uses only income and expense accounts recorded primarily in a revenue and expense journal. In the double-entry system, at least two accounting entries are required to properly document each financial transaction. These entries may be recorded to asset, liability, equity, expense, or revenue accounts.\n\nThe primary bookkeeping record in single-entry bookkeeping is the \"cash book\", which is similar to a checking account register (in UK: cheque account, current account), except all entries are allocated among several categories of income and expense accounts. Separate account records are maintained for petty cash, accounts payable and receivable, and other relevant transactions such as inventory and travel expenses. To save time and avoid the errors of manual calculations, single-entry bookkeeping can be done today with do-it-yourself bookkeeping software.\n\nA \"double-entry bookkeeping system\" is a set of rules for recording financial information in a financial accounting system in which every transaction or event changes at least two different nominal ledger accounts.\n\nA \"daybook\" is a descriptive and chronological (diary-like) record of day-to-day financial transactions; it is also called a \"book of original entry\". The daybook's details must be transcribed formally into journals to enable posting to ledgers. Daybooks include:\n\n\nA \"petty cash\" book is a record of small-value purchases before they are later transferred to the ledger and final accounts; it is maintained by a petty or junior cashier. This type of cash book usually uses the imprest system: a certain amount of money is provided to the petty cashier by the senior cashier. This money is to cater for minor expenditures (hospitality, minor stationery, casual postage, and so on) and is reimbursed periodically on satisfactory explanation of how it was spent.\n\n\"Journals\" are recorded in the general journal daybook. A journal is a formal and chronological record of financial transactions before their values are accounted for in the general ledger as debits and credits. A company can maintain one journal for all transactions, or keep several journals based on similar activity (e.g., sales, cash receipts, revenue, etc.), making transactions easier to summarize and reference later. For every debit journal entry recorded, there must be an equivalent credit journal entry to maintain a balanced accounting equation.\n\nA \"ledger\" is a record of accounts.The ledger is a permanent summary of all amounts entered in supporting Journals which list individual transactions by date. These accounts are recorded separately, showing their beginning/ending balance. A journal lists financial transactions in chronological order, without showing their balance but showing how much is going to be charged in each account. A ledger takes each financial transaction from the journal and records it into the corresponding account for every transaction listed. The ledger also sums up the total of every account, which is transferred into the balance sheet and the income statement. There are three different kinds of ledgers that deal with book-keeping:\n\n\nA chart of accounts is a list of the accounts codes that can be identified with numeric, alphabetical, or alphanumeric codes allowing the account to be located in the general ledger. The equity section of the chart of accounts is based on the fact that the legal structure of the entity is of a particular legal type. Possibilities include \"sole trader\", \"partnership\", \"trust\", and \"company\".\n\nComputerized bookkeeping removes many of the paper \"books\" that are used to record the financial transactions of a business entity; instead, relational databases are used today, but typically, these still enforce the norms of bookkeeping methodology including the single-entry and double-entry bookkeeping systems. CPAs supervise the internal controls for computerized bookkeeping systems, which serve to minimize errors in documenting the numerous activities a business entity may initiate or complete over an accounting period.\n\nBookkeeper (or bookkeepers, bookkeeping etc.) is the only common English word which contains three consecutive double letters.\n\n"}
{"id": "4664", "url": "https://en.wikipedia.org/wiki?curid=4664", "title": "Bézier curve", "text": "Bézier curve\n\nA Bézier curve (pronounced in French) is a parametric curve used in computer graphics and related fields. The curve, which is related to the Bernstein polynomial, is named after Pierre Bézier, who used it in the 1960s for designing curves for the bodywork of Renault cars. Other uses include the design of computer fonts and animation. Bézier curves can be combined to form a Bézier spline, or generalized to higher dimensions to form Bézier surfaces. The Bézier triangle is a special case of the latter.\n\nIn vector graphics, Bézier curves are used to model smooth curves that can be scaled indefinitely. \"Paths\", as they are commonly referred to in image manipulation programs, are combinations of linked Bézier curves. Paths are not bound by the limits of rasterized images and are intuitive to modify.\n\nBézier curves are also used in the time domain, particularly in animation, user interface design and smoothing cursor trajectory in eye gaze controlled interfaces. For example, a Bézier curve can be used to specify the velocity over time of an object such as an icon moving from A to B, rather than simply moving at a fixed number of pixels per step. When animators or interface designers talk about the \"physics\" or \"feel\" of an operation, they may be referring to the particular Bézier curve used to control the velocity over time of the move in question.\n\nThis also applies to robotics where the motion of a welding arm, for example, should be smooth to avoid unnecessary wear.\n\nThe mathematical basis for Bézier curves—the Bernstein polynomial—had been known since 1912, but the polynomials were not applied to graphics until some 50 years later,\nwhen they were widely publicised by the French engineer Pierre Bézier, who used them to design automobile bodies at Renault. The study of these curves was however first developed in 1959 by mathematician Paul de Casteljau using de Casteljau's algorithm, a numerically stable method to evaluate Bézier curves at Citroën, another French automaker.\n\nBézier curves are widely used in computer graphics to model smooth curves. As the curve is completely contained in the convex hull of its control points, the points can be graphically displayed and used to manipulate the curve intuitively. Affine transformations such as translation and rotation can be applied on the curve by applying the respective transform on the control points of the curve.\n\nQuadratic and cubic Bézier curves are most common. Higher degree curves are more computationally expensive to evaluate. When more complex shapes are needed, low order Bézier curves are patched together, producing a composite Bézier curve. A composite Bézier curve is commonly referred to as a \"path\" in vector graphics languages (like PostScript), vector graphics standards (like SVG) and vector graphics programs (like Artline, Timeworks Publisher, Adobe Illustrator, CorelDraw and Inkscape). To guarantee smoothness (\"C\" continuity), the control point at which two curves meet must be on the line between the two control points on either side.\n\nThe simplest method for scan converting (rasterizing) a Bézier curve is to evaluate it at many closely spaced points and scan convert the approximating sequence of line segments. However, this does not guarantee that the rasterized output looks sufficiently smooth, because the points may be spaced too far apart. Conversely it may generate too many points in areas where the curve is close to linear. A common adaptive method is recursive subdivision, in which a curve's control points are checked to see if the curve approximates a straight line to within a small tolerance. If not, the curve is subdivided parametrically into two segments, 0 ≤ \"t\" ≤ 0.5 and 0.5 ≤ \"t\" ≤ 1, and the same procedure is applied recursively to each half. There are also forward differencing methods, but great care must be taken to analyse error propagation.\n\nAnalytical methods where a Bézier is intersected with each scan line involve finding roots of cubic polynomials (for cubic Béziers) and dealing with multiple roots, so they are not often used in practice.\n\nIn animation applications, such as Adobe Flash and Synfig, Bézier curves are used to outline, for example, movement. Users outline the wanted path in Bézier curves, and the application creates the needed frames for the object to move along the path.\n\nFor 3D animation Bézier curves are often used to define 3D paths as well as 2D curves for keyframe interpolation.. Bézier curves are now very frequently used to control the animation easing in CSS and JavaScript.\n\nTrueType fonts use composite Bézier curves composed of quadratic Bézier curves. Other languages and imaging tools (such as PostScript, Asymptote, Metafont, and SVG) use composite Béziers composed of cubic Bézier curves for drawing curved shapes. OpenType fonts can use either kind, depending on the flavor of the font.\n\nThe internal rendering of all Bézier curves in font or vector graphics renderers will split them recursively up to the point where the curve is flat enough to be drawn as a series of linear or circular segments. The exact splitting algorithm is implementation dependent, only the flatness criteria must be respected to reach the necessary precision and to avoid non-monotonic local changes of curvature. The \"smooth curve\" feature of charts in Microsoft Excel also uses this algorithm.\n\nBecause arcs of circles and ellipses cannot be exactly represented by Bézier curves, they are first approximated by Bézier curves, which are in turn approximated by arcs of circles. This is inefficient as there exists also approximations of all Bézier curves using arcs of circles or ellipses, which can be rendered incrementally with arbitrary precision. Another approach, used by modern hardware graphics adapters with accelerated geometry, can convert exactly all Bézier and conic curves (or surfaces) into NURBS, that can be rendered incrementally without first splitting the curve recursively to reach the necessary flatness condition. This approach also allows preserving the curve definition under all linear or perspective 2D and 3D transforms and projections.\n\nFont engines, like FreeType, draw the font's curves (and lines) on a pixellated surface using a process known as font rasterization.\n\nA Bézier curve is defined by a set of \"control points\" P through P, where \"n\" is called its order (\"n\" = 1 for linear, 2 for quadratic, etc.). The first and last control points are always the end points of the curve; however, the intermediate control points (if any) generally do not lie on the curve. The sums in the following sections are to be understood as affine combinations, the coefficients sum to 1.\n\nGiven distinct points P and P, a linear Bézier curve is simply a straight line between those two points. The curve is given by\n\nand is equivalent to linear interpolation.\n\nA quadratic Bézier curve is the path traced by the function B(\"t\"), given points P, P, and P,\n\nwhich can be interpreted as the linear interpolant of corresponding points on the linear Bézier curves from P to P and from P to P respectively. Rearranging the preceding equation yields:\n\nThis can be written in a way that highlights the symmetry with respect to P:\n\nWhich immediately gives the derivative of the Bézier curve with respect to \"t\":\n\nfrom which it can be concluded that the tangents to the curve at P and P intersect at P. As \"t\" increases from 0 to 1, the curve departs from P in the direction of P, then bends to arrive at P from the direction of P.\n\nThe second derivative of the Bézier curve with respect to \"t\" is\n\nFour points P, P, P and P in the plane or in higher-dimensional space define a cubic Bézier curve.\nThe curve starts at P going toward P and arrives at P coming from the direction of P. Usually, it will not pass through P or P; these points are only there to provide directional information. The distance between P and P determines \"how far\" and \"how fast\" the curve moves towards P before turning towards P.\n\nWriting B(\"t\") for the quadratic Bézier curve defined by points P, P, and P, the cubic Bézier curve can be defined as an affine combination of two quadratic Bézier curves:\n\nThe explicit form of the curve is:\n\nFor some choices of P and P the curve may intersect itself, or contain a cusp.\n\nAny series of any 4 distinct points can be converted to a cubic Bézier curve that goes through all 4 points in order.\nGiven the starting and ending point of some cubic Bézier curve, and the points along the curve corresponding to \"t\" = 1/3 and \"t\" = 2/3, the control points for the original Bézier curve can be recovered.\n\nThe derivative of the cubic Bézier curve with respect to \"t\" is\n\nThe second derivative of the Bézier curve with respect to \"t\" is\n\nBézier curves can be defined for any degree \"n.\"\n\nA recursive definition for the Bézier curve of degree \"n\" expresses it as a point-to-point linear combination (linear interpolation) of a pair of corresponding points in two Bézier curves of degree \"n\" − 1.\n\nLet formula_11 denote the Bézier curve determined by any selection of points P, P, ..., P. Then to start,\n\nThis recursion is elucidated in the animations below.\n\nThe formula can be expressed explicitly as follows:\n\nwhere formula_15 are the binomial coefficients.\n\nFor example, for \"n\" = 5:\n\nSome terminology is associated with these parametric curves. We have\n\nwhere the polynomials\n\nare known as Bernstein basis polynomials of degree \"n\".\n\nNote that \"t\" = 1, (1 − \"t\") = 1, and that the binomial coefficient, formula_15, also expressed as formula_20 or formula_21, is:\n\nThe points P are called \"control points\" for the Bézier curve. The polygon formed by connecting the Bézier points with lines, starting with P and finishing with P, is called the \"Bézier polygon\" (or \"control polygon\"). The convex hull of the Bézier polygon contains the Bézier curve.\n\nSometimes it is desirable to express the Bézier curve as a polynomial instead of a sum of less straightforward Bernstein polynomials. Application of the binomial theorem to the definition of the curve followed by some rearrangement will yield:\n\nwhere\n\nThis could be practical if formula_25 can be computed prior to many evaluations of formula_26; however one should use caution as high order curves may lack numeric stability (de Casteljau's algorithm should be used if this occurs). Note that the empty product is 1.\n\n\nA quadratic Bézier curve is also a segment of a parabola. As a parabola is a conic section, some sources refer to quadratic Béziers as \"conic arcs\". With reference to the figure on the right, the important features of the parabola can be derived as follows:\n\n\nThe derivative for a curve of order \"n\" is\n\nThe \"t\" in the function for a linear Bézier curve can be thought of as describing how far B(\"t\") is from P to P. For example, when \"t=0.25\", B(\"t\") is one quarter of the way from point P to P. As \"t\" varies from 0 to 1, B(\"t\") describes a straight line from P to P.\n\nFor quadratic Bézier curves one can construct intermediate points Q and Q such that as \"t\" varies from 0 to 1:\n\nFor higher-order curves one needs correspondingly more intermediate points. For cubic curves one can construct intermediate points Q, Q, and Q that describe linear Bézier curves, and points R & R that describe quadratic Bézier curves:\n\nFor fourth-order curves one can construct intermediate points Q, Q, Q & Q that describe linear Bézier curves, points R, R & R that describe quadratic Bézier curves, and points S & S that describe cubic Bézier curves:\n\nFor fifth-order curves, one can construct similar intermediate points.\n\nThese representations rest on the process used in De Casteljau's algorithm to calculate Bézier curves.\n\nThe curve at a fixed offset from a given Bézier curve, called an offset or parallel curve in mathematics (lying \"parallel\" to the original curve, like the offset between rails in a railroad track), cannot be exactly formed by a Bézier curve (except in some trivial cases). In general, the two-sided offset curve of a cubic Bézier is a 10th-order algebraic curve and more generally for a Bézier of degree \"n\" the two-sided offset curve is an algebraic curve of degree 4\"n\"-2. However, there are heuristic methods that usually give an adequate approximation for practical purposes.\n\nIn the field of vector graphics, painting two symmetrically distanced offset curves is called \"stroking\" (the Bézier curve or in general a path of several Bézier segments). The conversion from offset curves to filled Bézier contours is of practical importance in converting fonts defined in METAFONT, which allows stroking of Bézier curves, to the more widely used PostScript type 1 fonts, which only allow (for efficiency purposes) the mathematically simpler operation of filling a contour defined by (non-self-intersecting) Bézier curves.\n\nA Bézier curve of degree \"n\" can be converted into a Bézier curve of degree \"n\" + 1 \"with the same shape\". This is useful if software supports Bézier curves only of specific degree. For example, systems that can only work with cubic Bézier curves can implicitly work with quadratic curves by using their equivalent cubic representation.\n\nTo do degree elevation, we use the equality formula_31 Each component formula_32 is multiplied by (1 − \"t\") and \"t\", thus increasing a degree by one, without changing the value. Here is the example of increasing degree from 2 to 3.\n\nFor arbitrary \"n\" we use equalities\n\nTherefore:\n\nintroducing arbitrary formula_36 and formula_37.\n\nTherefore, new control points are \n\nThe concept of Degree Elevation can be repeated on a control polygon R to get a sequence of control polygons R,R,R, and so on. After \"r\" degree elevations, the polygon R has the vertices P,P,P...,P given by \n\nIt can also be shown that for the underlying Bézier curve \"B\",\n\nThe rational Bézier curve adds adjustable weights to provide closer approximations to arbitrary shapes. The numerator is a weighted Bernstein-form Bézier curve and the denominator is a weighted sum of Bernstein polynomials. Rational Bézier curves can, among other uses, be used to represent segments of conic sections exactly, including circular arcs.\n\nGiven \"n\" + 1 control points P, the rational Bézier curve can be described by:\nor simply\n\n\n\n\n"}
{"id": "4665", "url": "https://en.wikipedia.org/wiki?curid=4665", "title": "Banach algebra", "text": "Banach algebra\n\nIn mathematics, especially functional analysis, a Banach algebra, named after Stefan Banach, is an associative algebra \"A\" over the real or complex numbers (or over a non-Archimedean complete normed field) that at the same time is also a Banach space, i.e. a normed space and complete in the metric induced by the norm. The norm is required to satisfy\n\nThis ensures that the multiplication operation is continuous.\n\nA Banach algebra is called \"unital\" if it has an identity element for the multiplication whose norm is 1, and \"commutative\" if its multiplication is commutative.\nAny Banach algebra formula_2 (whether it has an identity element or not) can be embedded isometrically into a unital Banach algebra formula_3 so as to form a closed ideal of formula_3. Often one assumes \"a priori\" that the algebra under consideration is unital: for one can develop much of the theory by considering formula_3 and then applying the outcome in the original algebra. However, this is not the case all the time. For example, one cannot define all the trigonometric functions in a Banach algebra without identity.\n\nThe theory of real Banach algebras can be very different from the theory of complex Banach algebras. For example, the spectrum of an element of a nontrivial complex Banach algebra can never be empty, whereas in a real Banach algebra it could be empty for some elements.\n\nBanach algebras can also be defined over fields of p-adic numbers. This is part of p-adic analysis.\n\nThe prototypical example of a Banach algebra is formula_6, the space of (complex-valued) continuous functions on a locally compact (Hausdorff) space that vanish at infinity. formula_6 is unital if and only if \"X\" is compact. The complex conjugation being an involution, formula_6 is in fact a C*-algebra. More generally, every C*-algebra is a Banach algebra.\n\n\nThe algebra of the quaternions formula_9 is not a complex Banach algebra (for any norm on formula_9), for if formula_11 is a complex Banach algebra that is also a division algebra, then formula_12 (Gelfand–Mazur theorem), since if formula_13 is a point in the non-empty spectrum formula_14 of formula_15, formula_16 is not invertible, hence formula_17 since formula_11 is a division algebra, whence formula_19 (which also proves the Gelfand–Mazur theorem).\n\nSeveral elementary functions which are defined via power series may be defined in any unital Banach algebra; examples include the exponential function and the trigonometric functions, and more generally any entire function. (In particular, the exponential map can be used to define abstract index groups.) The formula for the geometric series remains valid in general unital Banach algebras. The binomial theorem also holds for two commuting elements of a Banach algebra.\n\nThe set of invertible elements in any unital Banach algebra is an open set, and the inversion operation on this set is continuous, (and hence is a homeomorphism) so that it forms a topological group under multiplication.\n\nIf a Banach algebra has unit 1, then 1 cannot be a commutator; i.e., formula_20  for any \"x\", \"y\" ∈ \"A\". This is because \"xy\" and \"yx\" have the same spectrum except possibly \"0\".\n\nThe various algebras of functions given in the examples above have very different properties from standard examples of algebras such as the reals. For example:\n\n\nUnital Banach algebras over the complex field provide a general setting to develop spectral theory. The \"spectrum\" of an element \"x\" ∈ \"A\", denoted by formula_21, consists of all those complex scalars \"λ\" such that \"x\" − \"λ\"1 is not invertible in \"A\". The spectrum of any element \"x\" is a closed subset of the closed disc in C with radius ||\"x\"|| and center 0, and thus is compact. Moreover, the spectrum formula_21 of an element \"x\" is non-empty and satisfies the spectral radius formula:\n\nGiven \"x\" ∈ \"A\", the holomorphic functional calculus allows to define \"ƒ\"(\"x\") ∈ \"A\" for any function \"ƒ\" holomorphic in a neighborhood of formula_24 Furthermore, the spectral mapping theorem holds:\n\nWhen the Banach algebra \"A\" is the algebra L(\"X\") of bounded linear operators on a complex Banach space \"X\"  (e.g., the algebra of square matrices), the notion of the spectrum in \"A\" coincides with the usual one in the operator theory. For \"ƒ\" ∈ \"C\"(\"X\") (with a compact Hausdorff space \"X\"), one sees that:\n\nThe norm of a normal element \"x\" of a C*-algebra coincides with its spectral radius. This generalizes an analogous fact for normal operators.\n\nLet \"A\"  be a complex unital Banach algebra in which every non-zero element \"x\" is invertible (a division algebra). For every \"a\" ∈ \"A\", there is \"λ\" ∈ C such that\n\"a\" − \"λ1 is not invertible (because the spectrum of \"a\" is not empty) hence \"a\" = \"λ1 : this algebra \"A\" is naturally isomorphic to C (the complex case of the Gelfand–Mazur theorem).\n\nLet \"A\"  be a unital \"commutative\" Banach algebra over C. Since \"A\" is then a commutative ring with unit, every non-invertible element of \"A\" belongs to some maximal ideal of \"A\". Since a maximal ideal formula_27 in \"A\" is closed, formula_28 is a Banach algebra that is a field, and it follows from the Gelfand–Mazur theorem that there is a bijection between the set of all maximal ideals of \"A\" and the set Δ(\"A\") of all nonzero homomorphisms from \"A\"  to C. The set Δ(\"A\") is called the \"structure space\" or \"character space\" of \"A\", and its members \"characters.\"\n\nA character χ is a linear functional on \"A\" which is at the same time multiplicative, χ(\"ab\") = χ(\"a\") χ(\"b\"), and satisfies \"χ\"(1) = 1. Every character is automatically continuous from \"A\"  to C, since the kernel of a character is a maximal ideal, which is closed. Moreover, the norm (\"i.e.\", operator norm) of a character is one. Equipped with the topology of pointwise convergence on \"A\" (\"i.e.\", the topology induced by the weak-* topology of \"A\"), the character space, Δ(\"A\"), is a Hausdorff compact space.\n\nFor any \"x\" ∈ \"A\",\n\nwhere formula_30 is the Gelfand representation of \"x\" defined as follows: formula_30 is the continuous function from Δ(\"A\") to C given by formula_32  The spectrum of formula_33 in the formula above, is the spectrum as element of the algebra \"C\"(Δ(\"A\")) of complex continuous functions on the compact space Δ(\"A\"). Explicitly,\n\nAs an algebra, a unital commutative Banach algebra is semisimple (i.e., its Jacobson radical is zero) if and only if its Gelfand representation has trivial kernel. An important example of such an algebra is a commutative C*-algebra. In fact, when \"A\" is a commutative unital C*-algebra, the Gelfand representation is then an isometric *-isomorphism between \"A\" and \"C\"(Δ(\"A\")) .\n\n\n"}
{"id": "4667", "url": "https://en.wikipedia.org/wiki?curid=4667", "title": "Boris Pasternak", "text": "Boris Pasternak\n\nBoris Leonidovich Pasternak () (29 January 189030 May 1960) was a Russian poet, novelist, and literary translator. In his native Russian, Pasternak's first book of poems, \"My Sister, Life\" (1917), is one of the most influential collections ever published in the Russian language. Pasternak's translations of stage plays by Goethe, Schiller, Calderón de la Barca and Shakespeare remain very popular with Russian audiences. \n\nAs a novelist, Pasternak is also known as the author of \"Doctor Zhivago\" (1957), a novel which takes place between the Russian Revolution of 1905 and the Second World War. \"Doctor Zhivago\" was rejected for publication in the USSR. Pasternak was awarded the Nobel Prize for Literature in 1958, an event which enraged the Communist Party of the Soviet Union, which forced him to decline the prize, though his descendants were later to accept it in his name in 1988. Doctor Zhivago has been part of the main Russian school curriculum since 2003.\n\nPasternak was born in Moscow on 10 February, into a wealthy assimilated Jewish family. His father was the Post-Impressionist painter, Leonid Pasternak, professor at the Moscow School of Painting, Sculpture, and Architecture. His mother was Rosa Kaufman, a concert pianist and the daughter of Odessa industrialist Isadore Kaufman and his wife. Pasternak had a younger brother Alex and sisters Lydia and Josephine. The family claimed to be descended on the paternal line from Isaac Abrabanel, the famous 15th-century Sephardic Jewish treasurer of Portugal.\n\nFrom 1904 to 1907 Boris Pasternak was the cloister-mate of Peter Minchakievich (1890–1963) in Holy Dormition Pochayiv Lavra, located in West Ukraine. Minchakievich came from an Orthodox Ukrainian family and Pasternak came from a Jewish family. Some confusion has arisen as to Pasternak attending a military academy in his boyhood years. The uniforms of their monastery Cadet Corp were only similar to those of The Czar Alexander the Third Military Academy, as Pasternak and Minchakievich never attended any military academy. Most schools used a distinctive military looking uniform particular to them as was the custom of the time in Eastern Europe and Russia. Boyhood friends, they parted in 1908, friendly but with different politics, never to see each other again. Pasternak went to the Moscow Conservatory to study music (later Germany to study philosophy), and Minchakievich went to L'viv University (L'vov, L'wow) to study history and philosophy. The good dimension of the character Strelnikov in Dr. Zhivago is based upon Peter Minchakievich. Several of Pasternak's characters are composites. After World War One and the Revolution, fighting for the Provisional or Republican government under Kerensky, and then escaping a Communist jail and execution, Minchakievich trekked across Siberia in 1917 and became an American citizen. Pasternak stayed in Russia.\n\nIn a 1959 letter to Jacqueline de Proyart, Pasternak recalled,\n\nShortly after his birth, Pasternak's parents had joined the Tolstoyan Movement. Novelist Leo Tolstoy was a close family friend, as Pasternak recalled, \"my father illustrated his books, went to see him, revered him, and ...the whole house was imbued with his spirit.\"\nIn a 1956 essay, Pasternak recalled his father's feverish work creating illustrations for Tolstoy's novel \"Resurrection\". The novel was serialized in the journal \"Niva\" by the publisher Fyodor Marx, based in St Petersburg. The sketches were drawn from observations in such places as courtrooms, prisons and on trains, in a spirit of realism. To ensure that the sketches met the journal deadline, train conductors were enlisted to personally collect the illustrations. Pasternak wrote,\n\nAccording to Max Hayward, \"In November 1910, when Tolstoy fled from his home and died in the stationmaster's house at Astapovo, Leonid Pasternak was informed by telegram and he went there immediately, taking his son Boris with him, and made a drawing of Tolstoy on his deathbed.\"\n\nRegular visitors to the Pasternak's home also included Sergei Rachmaninoff, Alexander Scriabin, Lev Shestov, Rainer Maria Rilke. Pasternak aspired first to be a musician. Inspired by Scriabin, Pasternak briefly was a student at the Moscow Conservatory. In 1910 he abruptly left for the German University of Marburg, where he studied under Neo-Kantian philosophers Hermann Cohen, Nicolai Hartmann and Paul Natorp.\n\nIn 1910 Pasternak was reunited with his cousin, Olga Freidenberg (1890–1955). They had shared the same nursery but had been separated when the Freidenberg family moved to Saint Petersburg. They fell in love immediately but were never lovers. The romance however is made clear from their letters, Pasternak writing:‘You do not know how my tormenting feeling grew and grew until it became obvious to me and to others. As you walked beside me with complete detachment, I could not express it to you. It was a rare sort of closeness, as if we two, you and I, were in love with something that was utterly indifferent to both of us, something that remained aloof from us by virtue of its extraordinary inability to adapt to the other side of life.'The cousins' initial passion developed into a lifelong close friendship. From 1910 Pasternak and Freidenberg exchanged frequent letters, and their correspondence lasted over 40 years until 1954. The cousins last met in 1936. \n\nPasternak fell in love with Ida Wissotzkaya, a girl from a notable Moscow Jewish , whose company Wissotzky Tea was the largest tea company in the world. Pasternak had tutored her in the final class of high school. He helped her prepare for finals. They met in Marburg during the summer of 1912 when Boris' father, Leonid Pasternak, painted her portrait.\n\nAlthough Professor Cohen encouraged him to remain in Germany and to pursue a Philosophy doctorate, Pasternak decided against it. He returned to Moscow upon the outbreak of World War I. His first book of poems was published later that year. In the aftermath, Pasternak proposed marriage to Ida. However, the Wissotzky family was disturbed by Pasternak's poor prospects and persuaded Ida to refuse him. She turned him down and he told of his love and rejection in the poem \"Marburg\" (1917):\n\n<poem>I quivered. I flared up, and then was extinguished.\nI shook. I had made a proposal—but late,\nToo late. I was scared, and she had refused me.\nI pity her tears, am more blessed than a saint.</poem>\n\nAnother failed love affair in 1917 inspired the poems in his first book, \"My Sister, Life\". His early verse cleverly dissimulates his preoccupation with Immanuel Kant's philosophy. Its fabric includes striking alliterations, wild rhythmic combinations, day-to-day vocabulary, and hidden allusions to his favourite poets such as Rilke, Lermontov, Pushkin and German-language Romantic poets.\nDuring World War I, Pasternak taught and worked at a chemical factory in Vsevolodovo-Vilve near Perm, which undoubtedly provided him with material for \"Dr. Zhivago\" many years later. Unlike the rest of his family and many of his closest friends, Pasternak chose not to leave Russia after the October Revolution of 1917. According to Max Hayward,\n\nWhen it finally was published in 1921, Pasternak's \"My Sister, Life\" revolutionised Russian poetry. It made Pasternak the model for younger poets, and decisively changed the poetry of Osip Mandelshtam, Marina Tsvetayeva and others.\n\nFollowing \"My Sister, Life\", Pasternak produced some hermetic pieces of uneven quality, including his masterpiece, the lyric cycle \"Rupture\" (1921). Both Pro-Soviet writers and their White emigre equivalents applauded Pasternak's poetry as pure, unbridled inspiration.\n\nIn the late 1920s, he also participated in the much celebrated tripartite correspondence with Rilke and Tsvetayeva. As the 1920s wore on, however, Pasternak increasingly felt that his colourful style was at odds with a less educated readership. He attempted to make his poetry more comprehensible by reworking his earlier pieces and starting two lengthy poems on the Russian Revolution of 1905. He also turned to prose and wrote several autobiographical stories, notably \"The Childhood of Luvers\" and \"Safe Conduct\".\nIn 1922 Pasternak married Evgeniya Lurye (Евгения Лурье), a student at the Art Institute. The following year they had a son, Evgenii.\n\nEvidence of Pasternak's support of still-revolutionary members of the leadership of the Communist Party as late as 1926 is indicated by his worshipful poem \"In Memory of Reissner\" presumably written upon the shockingly premature death from typhus of legendary Bolshevik leader Larisa Reisner at age 30 in February of that year.\n\nBy 1927, Pasternak's close friends Vladimir Mayakovsky and Nikolai Aseyev were advocating the complete subordination of the arts to the needs of the Communist Party of the Soviet Union. In a letter to his sister Josephine, Pasternak wrote of his intentions to, \"break off relations,\" with both of them. Although he expressed that it would be deeply painful, Pasternak explained that it could not be prevented. He explained,\n\nBy 1932, Pasternak had strikingly reshaped his style to make it more understandable to the general public and printed the new collection of poems, aptly titled \"The Second Birth\". Although its Caucasian pieces were as brilliant as the earlier efforts, the book alienated the core of Pasternak's refined audience abroad, which was largely composed of anti-communist emigres.\n\nIn 1932 Pasternak fell in love with Zinaida Neuhaus, the wife of the Russian pianist Heinrich Neuhaus. They both got divorces and married two years later.\n\nHe continued to change his poetry, simplifying his style and language through the years, as expressed in his next book, \"Early Trains\" (1943).\n\nIn April 1934 Osip Mandelstam recited his \"Stalin Epigram\" to Pasternak. After listening, Pasternak told Mandelstam: \"I didn't hear this, you didn't recite it to me, because, you know, very strange and terrible things are happening now: they've begun to pick people up. I'm afraid the walls have ears and perhaps even these benches on the boulevard here may be able to listen and tell tales. So let's make out that I heard nothing.\"\n\nOn the night of 14 May 1934, Mandelstam was arrested at his home based on a warrant signed by NKVD boss Genrikh Yagoda. Devastated, Pasternak went immediately to the offices of \"Izvestia\" and begged Nikolai Bukharin to intercede on Mandelstam's behalf.\n\nSoon after his meeting with Bukharin, the telephone rang in Pasternak's Moscow apartment. A voice from The Kremlin said, \"Comrade Stalin wishes to speak with you.\" According to Ivinskaya, Pasternak was struck dumb. \"He was totally unprepared for such a conversation. But then he heard \"his\" voice, the voice of Stalin, coming over the line. The Leader addressed him in a rather bluff uncouth fashion, using the familiar \"thou\" form: 'Tell me, what are they saying in your literary circles about the arrest of Mandelstam?'\" Flustered, Pasternak denied that there was any discussion or that there were any literary circles left in Soviet Russia. Stalin went on to ask him for his own opinion of Mandelstam. In an \"eager fumbling manner\" Pasternak explained that he and Mandelstam each had a completely different philosophy about poetry. Stalin finally said, in a mocking tone of voice: \"I see, you just aren't able to stick up for a comrade,\" and put down the receiver.\n\nAccording to Pasternak, during the 1937 show trial of General Iona Yakir and Marshal Mikhail Tukhachevsky, the Union of Soviet Writers requested all members to add their names to a statement supporting the death penalty for the defendants. They demanded Pasternak's signature as well, but he refused to give it. Vladimir Stavski, the chairman of the Union, was terrified that he would be punished for Pasternak's dissent. The leadership of the Union travelled to Pasternak's dacha at Peredelkino and severely threatened the writer, who refused to sign the statement and returned to his dacha. Hearing this, Zinaida Pasternak, who was pregnant, was terribly upset, accusing him of risking the destruction of their family. Pasternak went to bed. He and Zinaida expected to be arrested that evening. They later learned that an NKVD agent was hiding in the bushes outside their window and wrote down every word they said to each other.\n\nSoon after, Pasternak appealed directly to Stalin. He wrote about his family's strong Tolstoyan convictions, which he still held dear. He declared that his own life was at the Leader's disposal. He said that he could not stand as a self-appointed judge of life and death. Pasternak was certain that he would be instantly arrested, but he was not. Stalin is said to have crossed Pasternak's name off an execution list during the Great Purge. According to Pasternak, Stalin declared, \"Do not touch this cloud dweller\" (or, in another version, \"Leave that holy fool alone!\")\n\nAlthough Pasternak was never arrested by the Soviet secret police, his close friend Titsian Tabidze fell victim to the Great Purge. In an autobiographical essay published in the 1950s, Pasternak described the execution of Tabidze and the suicides of Marina Tsvetaeva and Paolo Iashvili as the greatest heartbreaks of his entire life.\n\nIvinskaya wrote, \"I believe that between Stalin and Pasternak there was an incredible, silent duel.\"\n\nWhen the Luftwaffe began bombing Moscow, Pasternak immediately began to serve as a fire warden on the roof of the writer's building on Lavrushinski Street. According to Ivinskaya, he repeatedly helped to dispose of German bombs which fell on it.\n\nIn 1943, Pasternak was finally granted permission to visit the soldiers at the front. He bore it well, considering the hardships of the journey (he had a weak leg from an old injury), and he wanted to go to the most dangerous places. He read his poetry and talked extensively with the active and injured troops.\n\nWith the end of the war in 1945, the Soviet people expected to see the end of the devastation of Nazism, and hoped for the end of Stalin's Purges. But sealed trains began carrying large numbers of prisoners to the Soviet Gulags. Some were Nazi collaborators who had fought under General Andrey Vlasov, but most were ordinary Soviet officers and men. Pasternak watched as ex-POWs were directly transferred from Nazi Germany to Soviet concentration camps. White emigres who had returned due to pledges of amnesty were also sent directly to the Gulag, as were Jews from the Anti-Fascist Committee and other organizations. Many thousands of innocent people were incarcerated in connection with the Leningrad Affair and the so-called Doctor's Plot, while whole ethnic groups were deported to Siberia.\n\nPasternak later said, \"If, in a bad dream, we had seen all the horrors in store for us after the war, we should not have been sorry to see Stalin fall, together with Hitler. Then, an end to the war in favour of our allies, civilized countries with democratic traditions, would have meant a hundred times less suffering for our people than that which Stalin again inflicted on it after his victory.\"\n\nIn October 1946, the twice married Pasternak met Olga Ivinskaya, a 34 year old single mother employed by \"Novy Mir\". Deeply moved by her resemblance to his first love Ida Vysotskaya, Pasternak gave Ivinskaya several volumes of his poetry and literary translations. Although Pasternak never left his wife Zinaida, he started an extramarital relationship with Ivinskaya that would last for the remainder of Pasternak's life. Ivinskaya later recalled, \"He phoned almost every day and, instinctively fearing to meet or talk with him, yet dying of happiness, I would stammer out that I was \"busy today.\" But almost every afternoon, toward the end of working hours, he came in person to the office and often walked with me through the streets, boulevards, and squares all the way home to Potapov Street. 'Shall I make you a present of this square?' he would ask.\"\n\nShe gave him the phone number of her neighbour Olga Volkova who resided below. In the evenings, Pasternak would phone and Volkova would signal by Olga banging on the water pipe which connected their apartments.\n\nWhen they first met, Pasternak was translating the verse of the Hungarian national poet, Sándor Petőfi. Pasternak gave his lover a book of Petőfi with the inscription, \"Petőfi served as a code in May and June 1947, and my close translations of his lyrics are an expression, adapted to the requirements of the text, of my feelings and thoughts for you and about you. In memory of it all, B.P., 13 May 1948.\"\n\nPasternak later noted on a photograph of himself, \"Petőfi is magnificent with his descriptive lyrics and picture of nature, but you are better still. I worked on him a good deal in 1947 and 1948, when I first came to know you. Thank you for your help. I was translating both of you.\" Ivinskaya would later describe the Petőfi translations as, \"a first declaration of love.\"\n\nAccording to Ivinskaya, Zinaida Pasternak was infuriated by her husband's infidelity. Once, when his younger son Leonid fell seriously ill, Zinaida extracted a promise from her husband, as they stood by the boy's sickbed, that he would end his affair with Ivinskaya. Pasternak asked Luisa Popova, a mutual friend, to tell Ivinskaya about his promise. Popova told him that he must do it himself. Soon after, Ivinskaya happened to be ill at Popova's apartment, when suddenly Zinaida Pasternak arrived and confronted her.\n\nIvinskaya later recalled,\n\nIn 1948, Pasternak advised Ivinskaya to resign her job at \"Novy Mir\", which was becoming extremely difficult due to their relationship. In the aftermath, Pasternak began to instruct her in translating poetry. In time, they began to refer to her apartment on Potapov Street as, \"Our Shop.\"\n\nOn the evening of 6 October 1949, Ivinskaya was arrested at her apartment by the KGB. Ivinskaya relates in her memoirs that, when the agents burst into her apartment, she was at her typewriter working on translations of the Korean poet Won Tu-Son. Her apartment was ransacked and all items connected with Pasternak were piled up in her presence. Ivinskaya was taken to the Lubyanka Prison and repeatedly interrogated, where she refused to say anything incriminating about Pasternak. At the time, she was pregnant with Pasternak's child and had a miscarriage early in her ten-year sentence in the GULAG.\n\nUpon learning of his mistress' arrest, Pasternak telephoned Liuisa Popova and asked her to come at once to Gogol Boulevard. She found him sitting on a bench near the Palace of Soviets Metro Station. Weeping, Pasternak told her, \"Everything is finished now. They've taken her away from me and I'll never see her again. It's like death, even worse.\"\n\nAccording to Ivinskaya, \"After this, in conversation with people he scarcely knew, he always referred to Stalin as a 'murderer.' Talking with people in the offices of literary periodicals, he often asked: 'When will there be an end to this freedom for lackeys who happily walk over corpses to further their own interests?' He spent a good deal of time with Akhmatova—who in those years was given a very wide berth by most of the people who knew her. He worked intensively on the second part of \"Doctor Zhivago\".\"\n\nIn a 1958 letter to a friend in West Germany, Pasternak wrote, \"She was put in jail on my account, as the person considered by the secret police to be closest to me, and they hoped that by means of a gruelling interrogation and threats they could extract enough evidence from her to put me on trial. I owe my life, and the fact that they did not touch me in those years, to her heroism and endurance.\"\n\nPasternak's translation of the of \"Faust\" led him to be attacked in the August 1950 edition of \"Novy Mir\". The critic accused Pasternak of distorting Goethe's \"progressive\" meanings to support \"the reactionary theory of 'pure art'\", as well as introducing aesthetic and individualist values. In a subsequent letter to the daughter of Marina Tsvetaeva, Pasternak explained that the attack was motivated by the fact that the supernatural elements of the play, which \"Novy Mir\" considered, \"irrational,\" had been translated as Goethe had written them. Pasternak further declared that, despite the attacks on his translation, his contract for the had not been revoked.\n\nWhen Stalin died of a stroke on 5 March 1953, Olga Ivinskaya was still imprisoned in the Gulag, and Pasternak was in Moscow. Across the nation, there were waves of panic, confusion, and public displays of grief. Pasternak wrote, \"Men who are not free... always idealize their bondage.\"\n\nAfter her release, Pasternak's relationship with Ivinskaya picked up where it had left off. Soon after he confided in her, \"For so long we were ruled over by a madman and a murderer, and now by a fool and a pig. The madman had his occasional flights of fancy, he had an intuitive feeling for certain things, despite his wild obscurantism. Now we are ruled over by mediocrities.\" During this period, Pasternak delighted in reading a clandestine copy of George Orwell's \"Animal Farm\" in English. In conversation with Ivinskaya, Pasternak explained that the pig dictator Napoleon, in the novel, \"vividly reminded\" him of Soviet Premier Nikita Khrushchev.\n\nAlthough it contains passages written in the 1910s and 1920s, \"Doctor Zhivago\" was not completed until 1956. Pasternak submitted the novel to Novy Mir, which refused publication due to its rejection of socialist realism. The author, like his protagonist Yuri Zhivago, showed more concern for the welfare of individual characters than for the \"progress\" of society. Censors also regarded some passages as anti-Soviet, especially the novel's criticisms of Stalinism, Collectivisation, the Great Purge, and the Gulag.\n\nPasternak's fortunes were soon to change, however. In March 1956, the Italian Communist Party sent a journalist, Sergio D'Angelo, to work in the Soviet Union, and his status as a journalist as well as his membership in the Italian Communist Party allowed him to have access to various aspects of the cultural life in Moscow at the time. A Milan publisher, the communist Giangiacomo Feltrinelli, had also given him a commission to find new works of Soviet literature that would be appealing to Western audiences, and upon learning of \"Doctor Zhivago\"'s existence, D'Angelo travelled immediately to Peredelkino and offered to submit Pasternak's novel to Feltrinelli's company for publication. At first Pasternak was stunned. Then he brought the manuscript from his study and told D'Angelo with a laugh, \"You are hereby invited to watch me face the firing squad.\"\n\nAccording to Lazar Fleishman, Pasternak was aware that he was taking a huge risk. No Soviet author had attempted to deal with Western publishers since the 1920s, when such behavior led the Soviet State to declare war on Boris Pilnyak and Evgeny Zamyatin. Pasternak, however, believed that Feltrinelli's Communist affiliation would not only guarantee publication, but might even force the Soviet State to publish the novel in Russia.\n\nIn a rare moment of agreement, both Olga Ivinskaya and Zinaida Pasternak were horrified by the submission of \"Doctor Zhivago\" to a Western publishing house. Pasternak, however, refused to change his mind and informed an emissary from Feltrinelli that he was prepared to undergo any sacrifice in order to see \"Doctor Zhivago\" published.\n\nIn 1957, Feltrinelli announced that the novel would be published by his company. Despite repeated demands from visiting Soviet emissaries, Feltrinelli refused to cancel or delay publication. According to Ivinskaya, \"He did not believe that we would ever publish the manuscript here and felt he had no right to withhold a masterpiece from the world – this would be an even greater crime.\" The Soviet government forced Pasternak to cable the publisher to withdraw the manuscript, but he sent separate, secret letters advising Feltrinelli to ignore the telegrams.\n\nHelped considerably by the Soviet campaign against the novel (as well as by the U.S. Central Intelligence Agency's secret purchase of hundreds of copies of the book as it came off the presses around the world – see \"Nobel Prize\" section below), \"Doctor Zhivago\" became an instant sensation throughout the non-Communist world upon its release in November 1957. In the State of Israel, however, Pasternak's novel was sharply criticized for its assimilationist views towards the Jewish people. When informed of this, Pasternak responded, \"No matter. I am above race...\" According to Lazar Fleishman, Pasternak had written the disputed passages prior to Israeli independence. At the time, Pasternak had also been regularly attending Russian Orthodox Divine Liturgy. Therefore, he believed that Soviet Jews converting to Christianity was preferable to assimilating into atheism and Stalinism.\n\nThe first English translation of \"Doctor Zhivago\" was hastily produced by Max Hayward and Manya Harari in order to coincide with overwhelming public demand. It was released in August 1958, and remained the only edition available for more than fifty years. Between 1958 and 1959, the English language edition spent 26 weeks at the top of \"The New York Times\"' bestseller list.\n\nIvinskaya's daughter Irina circulated typed copies of the novel in Samizdat. Although no Soviet critics had read the banned novel, \"Doctor Zhivago\" was pilloried in the State-owned press. Similar attacks led to a humorous Russian saying, \"I haven't read Pasternak, but I condemn him\".\n\nDuring the aftermath of the Second World War, Pasternak had composed a series of poems on Gospel themes. According to Ivinskaya, Pasternak had regarded Stalin as a, \"giant of the pre-Christian era.\" Therefore, Pasternak's Christian-themed poems were, \"a form of protest.\"\n\nOn 9 September 1958, the \"Literary Gazette\" critic Viktor Pertsov retaliated by denouncing, \"the decadent religious poetry of Pasternak, which reeks of mothballs from the Symbolist suitcase of 1908–10 manufacture.\" Furthermore, the author received much hate mail from Communists both at home and abroad. According to Ivinskaya, Pasternak continued to receive such letters for the remainder of his life.\n\nIn a letter written to his sister Josephine, however, Pasternak recalled the words of his friend Ekaterina Krashennikova upon reading \"Doctor Zhivago\". She had said, \"Don't forget yourself to the point of believing that it was you who wrote this work. It was the Russian people and their sufferings who created it. Thank God for having expressed it through your pen.\"\n\nAccording to Yevgeni Borisovich Pasternak, \"Rumors that Pasternak was to receive the Nobel Prize started right after the end of World War II. According to the former Nobel Committee head Lars Gyllensten, his nomination was discussed every year from 1946 to 1950, then again in 1957 (it was finally awarded in 1958). Pasternak guessed at this from the growing waves of criticism in USSR. Sometimes he had to justify his European fame: 'According to the Union of Soviet Writers, some literature circles of the West see unusual importance in my work, not matching its modesty and low productivity…'\"\n\nAccording to journalist Ivan Tolstoi, the British MI6 and the American CIA lent a hand to ensure that \"Doctor Zhivago\" was submitted to the Nobel Committee in the original Russian. According to Tolstoi, this was done so that Pasternak could win the Nobel prize and harm the international credibility of the Soviet Union. He repeats and elaborates upon Feltrinelli's claims that the CIA operatives had photographed a manuscript of the novel and secretly printed a small number of books in the Russian language. More recently, Anna Sergeyeva-Klyatis wrote that the first Russian edition of \"Doctor Zhivago\", which was a pirated version with numerous typographical errors and omissions, was actually initiated by the Central Association of Postwar Émigrées, in response to a growing demand among Russian émigrés.\n\nThe issue of whether or not the CIA had a hand in creating the international controversy that led to Pasternak's winning the Nobel Prize was definitively settled on 11 April 2014 when the U.S. Central Intelligence Agency released \"nearly 100 declassified documents\" confirming that it had, in fact, undertaken a massive propaganda campaign to influence the Nobel Prize committee to consider \"Zhivago\" for the award, starting as early as 12 December 1957: \"\"Dr. Zhivago\" should be published in a maximum number of foreign editions, for maximum free world discussion and acclaim and consideration for such honor as the Nobel prize\" [sic] In order to turn Pasternak's novel into an international bestseller worthy of consideration for the Nobel Prize, the CIA purchased thousands of copies of the novel as they came off the presses throughout Europe. When in the summer of 1958 the Dutch publishing house of Mouton brought out an edition of \"Zhivago\", the CIA secretly arranged to \"obtain first thousand copies of the book off the press and of these send 500 copies to the Brussels Fair\" (i.e., the World Fair held that summer in Brussels, Belgium). In its announcement of the declassification of the \"Zhivago\" documents the CIA states that it also published \"thousands\" of copies of \"Zhivago\" and gave them out to Soviet tourists on holiday in Western Europe and had them smuggled into the Soviet Union: \"After working secretly to publish the Russian-language edition in the Netherlands, the CIA moved quickly to ensure that copies of Doctor Zhivago were available for distribution to Soviet visitors at the 1958 Brussels World's Fair. By the end of the Fair, 355 copies of Doctor Zhivago had been surreptitiously handed out, and eventually thousands more were distributed throughout the Communist bloc. [...] Subsequently, the CIA funded the publication of a miniature, lightweight paperback edition of Doctor Zhivago that could be easily mailed or concealed in a jacket pocket. Distribution of the miniature version began in April 1959.\"\n\nMeanwhile, Pasternak wrote to Renate Schweitzer and his sister, Lydia Pasternak Slater. In both letters, the author expressed hope that he would be passed over by the Nobel Committee in favour of Alberto Moravia. Pasternak wrote that he was wracked with torments and anxieties at the thought of placing his loved ones in danger.\n\nOn 23 October 1958, Boris Pasternak was announced as the winner of the Nobel Prize. The citation credited Pasternak's contribution to Russian lyric poetry and for his role in \"continuing the great Russian epic tradition.\" On 25 October, Pasternak sent a telegram to the Swedish Academy: \"Infinitely grateful, touched, proud, surprised, overwhelmed.\" That same day, the Literary Institute in Moscow demanded that all its students sign a petition denouncing Pasternak and his novel. They were further ordered to join a \"spontaneous\" demonstration demanding Pasternak's exile from the Soviet Union. On 26 October, the \"Literary Gazette\" ran an article by David Zaslavski entitled, \"Reactionary Propaganda Uproar over a Literary Weed\".\n\nAccording to Solomon Volkov:\n\nFurthermore, Pasternak was informed that, if he traveled to Stockholm to collect his Nobel Medal, he would be refused re-entry to the Soviet Union. As a result, Pasternak sent a second telegram to the Nobel Committee: \"In view of the meaning given the award by the society in which I live, I must renounce this undeserved distinction which has been conferred on me. Please do not take my voluntary renunciation amiss.\" The Swedish Academy announced: \"This refusal, of course, in no way alters the validity of the award. There remains only for the Academy, however, to announce with regret that the presentation of the Prize cannot take place.\"\n\nAccording to Yevgenii Pasternak, \"I couldn't recognize my father when I saw him that evening. Pale, lifeless face, tired painful eyes, and only speaking about the same thing: 'Now it all doesn’t matter, I declined the Prize.'\"\n\nDespite his decision to decline the award, the Soviet Union of Writers continued to demonise Pasternak in the State-owned press. Furthermore, he was threatened at the very least with formal exile to the West. In response, Pasternak wrote directly to Soviet Premier Nikita Khrushchev,\n\nIn \"The Oak and the Calf\", Alexander Solzhenitsyn sharply criticized Pasternak, both for declining the Nobel Prize and for sending such a letter to Khrushchev. In her own memoirs, Olga Ivinskaya blames herself for pressuring her lover into making both decisions.\n\nAccording to Yevgenii Pasternak, \"She accused herself bitterly for persuading Pasternak to decline the Prize. After all that had happened, open shadowing, friends turning away, Pasternak's suicidal condition at the time, one can... understand her: the memory of Stalin's camps was too fresh, [and] she tried to protect him.\"\n\nOn 31 October 1958, the Union of Soviet Writers held a trial behind closed doors. According to the meeting minutes, Pasternak was denounced as an internal White emigre and a Fascist fifth columnist. Afterwards, the attendees announced that Pasternak had been expelled from the Union. They further signed a petition to the Politburo, demanding that Pasternak be stripped of his Soviet citizenship and exiled to, \"his Capitalist paradise.\" According to Yevgenii Pasternak, however, author Konstantin Paustovsky refused to attend the meeting. Yevgeny Yevtushenko did attend, but walked out in disgust.\n\nAccording to Yevgenii Pasternak, his father would have been exiled had it not been for Indian Prime Minister Jawaharlal Nehru, who telephoned Khrushchev and threatened to find a Committee for Pasternak's protection.\n\nIt is possible that the 1958 Nobel Prize prevented Pasternak's imprisonment due to the Soviet State's fear of international protests. Yevgenii Pasternak believes, however, that the resulting persecution fatally weakened his father's health.\n\nMeanwhile, Bill Mauldin produced a political cartoon which won the 1959 Pulitzer Prize for Editorial Cartooning. The cartoon depicts Pasternak and another GULAG inmate, splitting trees in the snow. The caption reads, \"I won the Nobel Prize for literature. What was your crime?\"\n\nPasternak's post-\"Zhivago\" poetry probes the universal questions of love, immortality, and reconciliation with God. Boris Pasternak wrote his last complete book, \"When the Weather Clears\", in 1959.\n\nAccording to Ivinskaya, Pasternak continued to stick to his daily writing schedule even during the controversy over \"Doctor Zhivago\". He also continued translating the writings of Juliusz Słowacki and Pedro Calderón de la Barca. In his work on Calderon, Pasternak received the discreet support of Nikolai Mikhailovich Liubimov, a senior figure in the Party's literary apparatus. Ivinskaya describes Liubimov as, \"a shrewd and enlightened person who understood very well that all the mudslinging and commotion over the novel would be forgotten, but that there would always be a Pasternak.\" In a letter to his sisters in Oxford, England, Pasternak claimed to have finished translating one of Calderon's plays in less than a week.\n\nDuring the summer of 1959, Pasternak began writing \"The Blind Beauty\", a trilogy of stage plays set before and after Alexander II's abolition of serfdom in Russia. In an interview with Olga Carlisle from \"The Paris Review\", Pasternak enthusiastically described the play's plot and characters. He informed Olga Carlisle that, at the end of \"The Blind Beauty\", he wished to depict \"the birth of an enlightened and affluent middle class, open to occidental influences, progressive, intelligent, artistic\". However, Pasternak fell ill with terminal lung cancer before he could complete the first play of the trilogy.\n\nBoris Pasternak died of lung cancer in his dacha in Peredelkino on the evening of 30 May 1960. He first summoned his sons, and in their presence said, \"Who will suffer most because of my death? Who will suffer most? Only Oliusha will, and I haven't had time to do anything for her. The worst thing is that she will suffer.\" Pasternak's last words were, \"I can't hear very well. And there's a mist in front of my eyes. But it will go away, won't it? Don't forget to open the window tomorrow.\"\n\nShortly before his death, a priest of the Russian Orthodox Church had given Pasternak the last rites. Later, in the strictest secrecy, a Russian Orthodox funeral liturgy, or Panikhida, was offered in the family's dacha.\n\nDespite only a small notice appearing in the \"Literary Gazette\", handwritten notices carrying the date and time of the funeral were posted throughout the Moscow subway system. As a result, thousands of admirers braved Militia and KGB surveillance to attend Pasternak's funeral in Peredelkino.\n\nBefore Pasternak's civil funeral, Olga Ivinskaya had a conversation with Konstantin Paustovsky. According to Ivinskaya,\n\nThen, in the presence of a large number of foreign journalists, the body of Pasternak was removed to the cemetery. According to Ivinskaya,\n\nTo the horror of the assembled Party officials, however, someone with \"a young and deeply anguished voice\" began reciting Pasternak's banned poem \"Hamlet\".\nAccording to Ivinskaya,\n\nThe final speaker at the graveside service said,\n\nAs the spectators cheered, the bells of Peredelkino's Church of the Transfiguration began to toll. Written prayers for the dead were then placed upon Pasternak's forehead and the coffin was closed and buried. Pasternak's gravesite would go on to become a major shrine for members of the Soviet dissident movement.\n\nAfter Pasternak's death, Olga Ivinskaya was arrested for the second time, with her daughter, Irina Emelyanova. Both were accused of being Pasternak's link with Western publishers and of dealing in hard currency for \"Doctor Zhivago\". All of Pasternak's letters to Ivinskaya, as well as many other manuscripts and documents, were seized by the KGB. The KGB quietly released them, Irina after one year, in 1962, and Olga in 1964. By this time, Ivinskaya had served four years of an eight-year sentence, in retaliation for her role in \"Doctor Zhivago\"'s publication. In 1978, her memoirs were smuggled abroad and published in Paris. An English translation by Max Hayward was published the same year under the title \"A Captive of Time: My Years with Pasternak\".\n\nIvinskaya was rehabilitated only in 1988. After the dissolution of the Soviet Union, Ivinskaya sued for the return of the letters and documents seized by the KGB in 1961. The Russian Supreme Court ultimately ruled against her, stating that, \"there was no proof of ownership,\" and that the, \"papers should remain in the state archive\". Olga Ivinskaya died of cancer on 8 September 1995. A reporter on NTV compared her role to that of other famous muses for Russian poets: \"As Pushkin would not be complete without Anna Kern, and Yesenin would be nothing without Isadora, so Pasternak would not be Pasternak without Olga Ivinskaya, who was his inspiration for \"Doctor Zhivago\".\".\n\nMeanwhile, Boris Pasternak continued to be pilloried by the Soviet State until Mikhail Gorbachev proclaimed Perestroika during the 1980s.\n\nIn 1988, after decades of circulating in Samizdat, \"Doctor Zhivago\" was serialized in the literary journal \"Novy Mir\".\n\nIn December 1989, Yevgenii Borisovich Pasternak was permitted to travel to Stockholm in order to collect his father's Nobel Medal. At the ceremony, acclaimed cellist and Soviet dissident Mstislav Rostropovich performed a Bach serenade in honor of his deceased countryman.\n\nA 2009 book by Ivan Tolstoi reasserts claims that British and American intelligence officers were involved in ensuring Pasternak's Nobel victory however another Russian researcher disagrees. When Yevgeny Borisovich Pasternak was questioned about this, he responded that his father was completely unaware of the actions of Western intelligence services. Yevgeny further declared that the Nobel Prize caused his father nothing but severe grief and harassment at the hands of the Soviet State.\n\nThe Pasternak family papers are stored at the Hoover Institution Archives, Stanford University. They contain correspondence, drafts of \"Doctor Zhivago\" and other writings, photographs, and other material, of Boris Pasternak and other family members.\n\nSince 2003, the novel Doctor Zhivago has entered the Russian school curriculum, where it is read in the 11th grade of high-school.\n\n\nThe first screen adaptation of \"Doctor Zhivago\", adapted by Robert Bolt and directed by David Lean, appeared in 1965. The film, which toured in the roadshow tradition, starred Omar Sharif, Geraldine Chaplin, and Julie Christie. Concentrating on the love triangle aspects of the novel, the film became a worldwide blockbuster, but was unavailable in Russia until Perestroika.\n\nIn 2002, the novel was adapted as a television miniseries. Directed by Giacomo Campiotti, the serial starred Hans Matheson, Alexandra Maria Lara, Keira Knightley, and Sam Neill.\n\nThe Russian TV version of 2006, directed by Alexander Proshkin and starring Oleg Menshikov as Zhivago, is considered more faithful to Pasternak's novel than David Lean's 1965 film.\n\nAccording to Ivinskaya:\n\nFor this reason, Pasternak regularly avoided literary cafes where young poets regularly invited them to read their verse. According to Ivinskaya, \"It was this sort of thing that moved him to say: 'Who started the idea that I love poetry? I can't stand poetry.'\"\n\nAlso according to Ivinskaya, \"'The way they could write!' he once exclaimed – by 'they' he meant the Russian classics. And immediately afterward, reading or, rather, glancing through some verse in the \"Literary Gazette\": 'Just look how tremendously well they've learned to rhyme! But there's actually nothing there – it would be better to say it in a news bulletin. What has poetry got to do with this?' By 'they' in this case, he meant the poets writing today.\"\n\nReluctant to conform to Socialist Realism, Pasternak turned to translation in order to provide for his family. He soon produced acclaimed translations of Sándor Petőfi, Johann Wolfgang von Goethe, Rainer Maria Rilke, Paul Verlaine, Taras Shevchenko, and Nikoloz Baratashvili. Osip Mandelstam, however, privately warned him, \"Your collected works will consist of twelve volumes of translations, and only one of your own work.\"\n\nIn a 1942 letter, Pasternak declared, \"I am completely opposed to contemporary ideas about translation. The work of Lozinski, Radlova, Marshak, and Chukovski is alien to me, and seems artificial, soulless, and lacking in depth. I share the nineteenth century view of translation as a literary exercise demanding insight of a higher kind than that provided by a merely philological approach.\"\n\nAccording to Ivinskaya, Pasternak believed in not being too literal in his translations, which he felt could confuse the meaning of the text. He instead advocated observing each poem from afar to plumb its true depths.\n\nPasternak's translations of William Shakespeare (\"Romeo and Juliet\", \"Antony and Cleopatra\", \"Othello\", \"King Henry IV\" (Parts I and II), \"Hamlet\", \"Macbeth\", \"King Lear\") remain deeply popular with Russian audiences because of their colloquial, modernised dialogues. Pasternak's critics, however, accused him of \"pasternakizing\" Shakespeare. In a 1956 essay, Pasternak wrote, \"Translating Shakespeare is a task which takes time and effort. Once it is undertaken, it is best to divide it into sections long enough for the work to not get stale and to complete one section each day. In thus daily progressing through the text, the translator finds himself reliving the circumstances of the author. Day by day, he reproduces his actions and he is drawn into some of his secrets, not in theory, but practically, by experience.\"\n\nAccording to Ivinskaya:\n\nWhile they were both collaborating on translating Rabindranath Tagore from Bengali into Russian, Pasternak advised Ivinskaya, \"1) Bring out the theme of the poem, its subject matter, as clearly as possible; 2) tighten up the fluid, non-European form by rhyming internally, not at the end of the lines; 3) use loose, irregular meters, mostly ternary ones. You may allow yourself to use assonances.\"\n\nLater, while she was collaborating with him on a translation of Vítězslav Nezval, Pasternak told Ivinskaya:\n\nAccording to Olga Ivinskaya, however, translation was not a genuine vocation for Pasternak. She later recalled:\n\nBoris Pasternak was also a composer, and had a promising musical career as a musician ahead of him, had he chosen to pursue it. He came from a musical family: his mother was a concert pianist and a student of Anton Rubinstein and Theodor Leschetizky, and Pasternak's early impressions were of hearing piano trios in the home. The family had a dacha (country house) close to one occupied by Alexander Scriabin; Sergei Rachmaninoff, Rainer Maria Rilke and Leo Tolstoy were all visitors to the family home. His father Leonid was a painter who produced one of the most important portraits of Scriabin, and Pasternak wrote many years later of witnessing with great excitement the creation of Scriabin's Symphony No. 3 (\"The Divine Poem\"), in 1903.\n\nPasternak began to compose at the age of 13. The high achievements of his mother discouraged him from becoming a pianist, but – inspired by Scriabin – he entered the Moscow Conservatory, but left abruptly in 1910 at the age of twenty, to study philosophy in Marburg University. Four years later he returned to Moscow, having finally decided on a career in literature, publishing his first book of poems, influenced by Alexander Blok and the Russian Futurists, the same year.\n\nPasternak's early compositions show the clear influence of Scriabin. His single-movement Piano Sonata of 1909 shows a more mature and individual voice. Nominally in B minor, it moves freely from key to key with frequent changes of key-signature and a chromatic dissonant style that defies easy analysis. Although composed during his time at the Conservatory, the Sonata was composed at Raiki, some 27 miles north-east of Moscow, where Leonid Pasternak had his painting studio and taught his students. (NB. This is not the site of the Pasternak family dacha, now open to the public, in the writers' colony at Peredelkino, which is about 16 miles south-west of the capital.)\n\n\n\n\n\n\n"}
{"id": "4668", "url": "https://en.wikipedia.org/wiki?curid=4668", "title": "Binomial coefficient", "text": "Binomial coefficient\n\nIn mathematics, any of the positive integers that occurs as a coefficient in the binomial theorem is a binomial coefficient. Commonly, a binomial coefficient is indexed by a pair of integers and is written formula_1 It is the coefficient of the term in the polynomial expansion of the binomial power , and it is given by the formula\n\nFor example: \nwhere formula_4, etc.\n\nArranging the numbers formula_5 in successive rows for formula_6 gives a triangular array called Pascal's triangle, satisfying the recurrence relation formula_7.\n\nThe binomial coefficients occur in many areas of mathematics, especially combinatorics.\nThe symbol formula_8 is usually read as \" choose \" because there are formula_8 ways to choose an (unordered) subset of elements from a fixed set of elements. For example, there are formula_10 ways to choose 2 elements from formula_11, namely formula_12, formula_13, formula_14, formula_15, formula_16, formula_17.\n\nMany properties of formula_18 also apply to the generalized binomial coefficients formula_19 for any complex number \"z\" and integer \"k\" ≥ 0.\n\nAndreas von Ettingshausen introduced the notation formula_18 in 1826, although the numbers were known centuries earlier (see Pascal's triangle). The earliest known detailed discussion of binomial coefficients is in a tenth-century commentary, by Halayudha, on an ancient Sanskrit text, Pingala's \"Chandaḥśāstra\". In about 1150, the Indian mathematician Bhaskaracharya gave an exposition of binomial coefficients in his book \"Līlāvatī\".\n\nAlternative notations include , , , , , and in all of which the stands for \"combinations\" or \"choices\". Many calculators use variants of the because they can represent it on a single-line display. In this form the binomial coefficients are easily compared to -permutations of, written as , etc.\n\nFor natural numbers (taken to include 0) \"n\" and \"k\", the binomial coefficient formula_18 can be defined as the coefficient of the monomial \"X\" in the expansion of . The same coefficient also occurs (if ) in the binomial formula\n\n(valid for any elements \"x\",\"y\" of a commutative ring),\nwhich explains the name \"binomial coefficient\".\n\nAnother occurrence of this number is in combinatorics, where it gives the number of ways, disregarding order, that \"k\" objects can be chosen from among \"n\" objects; more formally, the number of \"k\"-element subsets (or \"k\"-combinations) of an \"n\"-element set. This number can be seen as equal to the one of the first definition, independently of any of the formulas below to compute it: if in each of the \"n\" factors of the power one temporarily labels the term \"X\" with an index \"i\" (running from 1 to \"n\"), then each subset of \"k\" indices gives after expansion a contribution \"X\", and the coefficient of that monomial in the result will be the number of such subsets. This shows in particular that formula_18 is a natural number for any natural numbers \"n\" and \"k\". There are many other combinatorial interpretations of binomial coefficients (counting problems for which the answer is given by a binomial coefficient expression), for instance the number of words formed of \"n\" bits (digits 0 or 1) whose sum is \"k\" is given by formula_18, while the number of ways to write formula_24 where every \"a\" is a nonnegative integer is given by formula_25. Most of these interpretations are easily seen to be equivalent to counting \"k\"-combinations.\n\nSeveral methods exist to compute the value of formula_18 without actually expanding a binomial power or counting \"k\"-combinations.\n\nOne method uses the recursive, purely additive, formula\n\nwith initial/boundary values\n\nThe formula follows from considering the set {1,2,3,…,\"n\"} and counting separately (a) the \"k\"-element groupings that include a particular set element, say \"\"i\"\", in every group (since \"\"i\"\" is already chosen to fill one spot in every group, we need only choose \"k\" − 1 from the remaining \"n\" − 1) and (b) all the \"k\"-groupings that don't include \"\"i\"\"; this enumerates all the possible \"k\"-combinations of \"n\" elements. It also follows from tracing the contributions to \"X\" in . As there is zero \"X\" or \"X\" in , one might extend the definition beyond the above boundaries to include formula_18 = 0 when either \"k\" > \"n\" or \"k\" < 0. This recursive formula then allows the construction of Pascal's triangle, surrounded by white spaces where the zeros, or the trivial coefficients, would be.\n\nA more efficient method to compute individual binomial coefficients is given by the formula\n\nwhere the numerator of the first fraction formula_31 is expressed as a falling factorial power.\nThis formula is easiest to understand for the combinatorial interpretation of binomial coefficients.\nThe numerator gives the number of ways to select a sequence of \"k\" distinct objects, retaining the order of selection, from a set of \"n\" objects. The denominator counts the number of distinct sequences that define the same \"k\"-combination when order is disregarded.\n\nDue to the symmetry of the binomial coefficient with regard to \"k\" and \"n\"−\"k\", calculation may be optimised by setting the upper limit of the product above to the smaller of \"k\" and \"n\"−\"k\".\n\nFinally, though computationally unsuitable, there is the compact form, often used in proofs and derivations, which makes repeated use of the familiar factorial function:\n\nwhere \"n\"! denotes the factorial of \"n\". This formula follows from the multiplicative formula above by multiplying numerator and denominator by ; as a consequence it involves many factors common to numerator and denominator. It is less practical for explicit computation (in the case that \"k\" is small and \"n\" is large) unless common factors are first cancelled (in particular since factorial values grow very rapidly). The formula does exhibit a symmetry that is less evident from the multiplicative formula (though it is from the definitions)\n\nwhich leads to a more efficient multiplicative computational routine. Using the falling factorial notation,\n\nThe multiplicative formula allows the definition of binomial coefficients to be extended by replacing \"n\" by an arbitrary number \"α\" (negative, real, complex) or even an element of any commutative ring in which all positive integers are invertible:\n\nWith this definition one has a generalization of the binomial formula (with one of the variables set to 1), which justifies still calling the formula_35 binomial coefficients:\n\nThis formula is valid for all complex numbers \"α\" and \"X\" with |\"X\"| < 1. It can also be interpreted as an identity of formal power series in \"X\", where it actually can serve as definition of arbitrary powers of power series with constant coefficient equal to 1; the point is that with this definition all identities hold that one expects for exponentiation, notably\n\nIf \"α\" is a nonnegative integer \"n\", then all terms with \"k\" > \"n\" are zero, and the infinite series becomes a finite sum, thereby recovering the binomial formula. However, for other values of \"α\", including negative integers and rational numbers, the series is really infinite.\n\nPascal's rule is the important recurrence relation\n\nwhich can be used to prove by mathematical induction that formula_37 is a natural number for all \"n\" and \"k\", a fact that is not immediately obvious from formula (1).\n\nPascal's rule also gives rise to Pascal's triangle:\n\nRow number \"n\" contains the numbers formula_37 for \"k\" = 0,…,\"n\". It is constructed by starting with ones at the outside and then always adding two adjacent numbers and writing the sum directly underneath. This method allows the quick calculation of binomial coefficients without the need for fractions or multiplications. For instance, by looking at row number 5 of the triangle, one can quickly read off that\nThe differences between elements on other diagonals are the elements in the previous diagonal, as a consequence of the recurrence relation () above.\n\nBinomial coefficients are of importance in combinatorics, because they provide ready formulas for certain frequent counting problems:\n\nFor any nonnegative integer \"k\", the expression formula_45 can be simplified and defined as a polynomial divided by \"k\"!:\n\nthis presents a polynomial in \"t\" with rational coefficients.\n\nAs such, it can be evaluated at any real or complex number \"t\" to define binomial coefficients with such first arguments.\nThese \"generalized binomial coefficients\" appear in Newton's generalized binomial theorem.\n\nFor each \"k\", the polynomial formula_47 can be characterized as the unique degree \"k\" polynomial \"p\"(\"t\") satisfying \"p\"(0) = \"p\"(1) = ... = \"p\"(\"k\" − 1) = 0 and \"p\"(\"k\") = 1.\n\nIts coefficients are expressible in terms of Stirling numbers of the first kind:\nThe derivative of formula_47 can be calculated by logarithmic differentiation:\n\nOver any field of characteristic 0 (that is, any field that contains the rational numbers), each polynomial \"p\"(\"t\") of degree at most \"d\" is uniquely expressible as a linear combination formula_51 of binomial coefficients. The coefficient \"a\" is the \"k\"th difference of the sequence \"p\"(0), \"p\"(1), …, \"p\"(\"k\").\nExplicitly,\n\nEach polynomial formula_47 is integer-valued: it has an integer value at all integer inputs formula_53.\nTherefore, any integer linear combination of binomial coefficient polynomials is integer-valued too.\nConversely, () shows that any integer-valued polynomial is an integer linear combination of these binomial coefficient polynomials.\nMore generally, for any subring \"R\" of a characteristic 0 field \"K\", a polynomial in \"K\"[\"t\"] takes values in \"R\" at all integers if and only if it is an \"R\"-linear combination of binomial coefficient polynomials.\n\nThe integer-valued polynomial 3\"t\"(3\"t\" + 1)/2 can be rewritten as\n\nThe factorial formula facilitates relating nearby binomial coefficients. For instance, if \"k\" is a positive integer and \"n\" is arbitrary, then\n\nand, with a little more work,\nMoreover, the following may be useful:\nFor constant \"n\", we have the following recurrence:\n\nThe formula\n\nsays the elements in the \"n\" row of Pascal's triangle always add up to 2 raised to the \"n\" power. This is obtained from the binomial theorem () by setting \"x\" = 1 and \"y\" = 1. The formula also has a natural combinatorial interpretation: the left side sums the number of subsets of {1...,\"n\"} of sizes \"k\" = 0,1...,\"n\", giving the total number of subsets. (That is, the left side counts the power set of {1...,\"n\"}.) However, these subsets can also be generated by successively choosing or excluding each element 1...,\"n\"; the \"n\" independent binary choices (bit-strings) allow a total of formula_58 choices. The left and right sides are two ways to count the same collection of subsets, so they are equal. \n\nThe formulas\n\nand\nformula_59\nfollow from () after differentiating with respect to \"x\" (twice in the latter) and then substituting \"x\" = 1.\n\nThe Chu–Vandermonde identity, which holds for any complex-values \"m\" and \"n\" and any non-negative integer \"k\", is\n\nand can be found by examination of the coefficient of formula_60 in the expansion of (1 + \"x\") (1 + \"x\") = (1 + \"x\") using equation (). When \"m\" = 1, equation () reduces to equation (). In the special case \"n\" = 2\"m\", \"k\" = \"m\", using (), the expansion () becomes (as seen in Pascal's triangle at right)\nwhere the term on the right side is a central binomial coefficient.\n\nAnother form of the Chu–Vandermonde identity, which applies for any integers \"j\", \"k\", and \"n\" satisfying 0 ≤ \"j\" ≤ \"k\" ≤ \"n\", is\n\nThe proof is similar, but uses the binomial series expansion () with negative integer exponents.\nWhen \"j\" = \"k\", equation () gives the hockey-stick identity\n\nLet \"F\"(\"n\") denote the \"n\"-th Fibonacci number.\nThen\nThis can be proved by induction using () or by Zeckendorf's representation. A combinatorial proof is given below.\n\nFor integers \"s\" and \"t\" such that formula_63 series multisection gives the following identity for the sum of binomial coefficients:\n\nFor small \"s\", these series have particularly nice forms; for example,\n\nAlthough there is no closed formula for partial sums\n\nof binomial coefficients, one can again use () and induction to show that for \"k\" = 0, ..., \"n\" − 1,\n\nwith special case\n\nfor \"n\" > 0. This latter result is also a special case of the result from the theory of finite differences that for any polynomial \"P\"(\"x\") of degree less than \"n\",\nDifferentiating () \"k\" times and setting \"x\" = −1 yields this for\nformula_76,\nwhen 0 ≤ \"k\" < \"n\",\nand the general case follows by taking linear combinations of these.\n\nWhen \"P\"(\"x\") is of degree less than or equal to \"n\",\n\nwhere formula_77 is the coefficient of degree \"n\" in \"P\"(\"x\").\n\nMore generally for (),\nwhere \"m\" and \"d\" are complex numbers. This follows immediately applying () to the polynomial \"Q(x):=P(m + dx)\" instead of \"P(x)\", and observing that \"Q(x)\" has still degree less than or equal to \"n\", and that its coefficient of degree \"n\" is \"da\".\n\nThe series\nformula_79 is convergent for \"k\" ≥ 2. This formula is used in the analysis of the German tank problem. It follows from formula_80\nwhich is proved by induction on \"M\".\n\nMany identities involving binomial coefficients can be proved by combinatorial means. For example, for nonnegative integers formula_81, the identity\n\n(which reduces to () when \"q\" = 1) can be given a double counting proof, as follows. The left side counts the number of ways of selecting a subset of [\"n\"] = {1, 2, …, \"n\"} with at least \"q\" elements, and marking \"q\" elements among those selected. The right side counts the same thing, because there are formula_83 ways of choosing a set of \"q\" elements to mark, and formula_84 to choose which of the remaining elements of [\"n\"] also belong to the subset.\n\nIn Pascal's identity\nboth sides count the number of \"k\"-element subsets of [\"n\"]: the two terms on the right side group them into those that contain element \"n\" and those that do not.\n\nThe identity () also has a combinatorial proof. The identity reads\n\nSuppose you have formula_87 empty squares arranged in a row and you want to mark (select) \"n\" of them. There are formula_88 ways to do this. On the other hand, you may select your \"n\" squares by selecting \"k\" squares from among the first \"n\" and formula_89 squares from the remaining \"n\" squares; any \"k\" from 0 to \"n\" will work. This gives\nNow apply () to get the result.\n\nIf one denotes by the sequence of Fibonacci numbers, indexed so that , then the identity \nformula_91\nhas the following combinatorial proof. One may show by induction that counts the number of ways that a strip of squares may be covered by and tiles. On the other hand, if such a tiling uses exactly of the tiles, then it uses of the tiles, and so uses tiles total. There are formula_92 ways to order these tiles, and so summing this coefficient over all possible values of gives the identity.\n\nThe number of \"k\"-combinations for all \"k\", formula_93, is the sum of the \"n\"th row (counting from 0) of the binomial coefficients. These combinations are enumerated by the 1 digits of the set of base 2 numbers counting from 0 to formula_94, where each digit position is an item from the set of \"n\".\n\nDixon's identity is\n\nor, more generally,\n\nwhere \"a\", \"b\", and \"c\" are non-negative integers.\n\nCertain trigonometric integrals have values expressible in terms of\nbinomial coefficients:\n\nFor formula_97\n\nThese can be proved by using Euler's formula to convert trigonometric functions to complex exponentials, expanding using the binomial theorem, and integrating term by term.\n\nFor a fixed , the ordinary generating function of the sequence formula_101 is\n\nFor a fixed , the ordinary generating function of the sequence formula_103 is\n\nThe bivariate generating function of the binomial coefficients is\n\nAnother, symmetric, bivariate generating function of the binomial coefficients is\n\nA symmetric exponential bivariate generating function of the binomial coefficients is:\n\nIn 1852, Kummer proved that if \"m\" and \"n\" are nonnegative integers and \"p\" is a prime number, then the largest power of \"p\" dividing formula_108 equals \"p\", where \"c\" is the number of carries when \"m\" and \"n\" are added in base \"p\".\nEquivalently, the exponent of a prime \"p\" in formula_39\nequals the number of nonnegative integers \"j\" such that the fractional part of \"k\"/\"p\" is greater than the fractional part of \"n\"/\"p\". It can be deduced from this that formula_39 is divisible by \"n\"/gcd(\"n\",\"k\"). In particular therefore it follows that \"p\" divides formula_111 for all positive integers \"r\" and \"s\" such that \"s\" < \"p\". However this is not true of higher powers of \"p\": for example 9 does not divide formula_112.\n\nA somewhat surprising result by David Singmaster (1974) is that any integer divides almost all binomial coefficients. More precisely, fix an integer \"d\" and let \"f\"(\"N\") denote the number of binomial coefficients formula_39 with \"n\" < \"N\" such that \"d\" divides formula_39. Then\nSince the number of binomial coefficients formula_39 with \"n\" < \"N\" is \"N\"(\"N\" + 1) / 2, this implies that the density of binomial coefficients divisible by \"d\" goes to 1.\n\nBinomial coefficients have divisibility properties related to least common multiples of consecutive integers. For example:\n\nformula_117 divides formula_118.\n\nformula_117 is a multiple of formula_120.\n\nAnother fact:\nAn integer \"n\" ≥ 2 is prime if and only if\nall the intermediate binomial coefficients\nare divisible by \"n\".\n\nProof:\nWhen \"p\" is prime, \"p\" divides\nbecause formula_123 is a natural number and \"p\" divides the numerator but not the denominator.\nWhen \"n\" is composite, let \"p\" be the smallest prime factor of \"n\" and let \"k\" = n/p. Then 0 < \"p\" < \"n\" and\notherwise the numerator \"k\"(\"n\" − 1)(\"n\" − 2)×...×(\"n\" − \"p\" + 1) has to be divisible by \"n\" = \"k\"×\"p\", this can only be the case when (\"n\" − 1)(\"n\" − 2)×...×(\"n\" − \"p\" + 1) is divisible by \"p\". But \"n\" is divisible by \"p\", so \"p\" does not divide \"n\" − 1, \"n\" − 2, ..., \"n\" − \"p\" + 1 and because \"p\" is prime, we know that \"p\" does not divide (\"n\" − 1)(\"n\" − 2)×...×(\"n\" − \"p\" + 1) and so the numerator cannot be divisible by \"n\".\n\nThe following bounds for formula_39 hold for all values of \"n\" and \"k\" such that 1 ≤ \"k\" ≤ \"n\":\n\nThe first inequality follows from the fact that formula_127 and each of these formula_128 terms in this product is formula_129. A similar argument can be made to show formula_130. The final strict inequality follows from multiplying formula_131 by the Taylor series for formula_132.\n\nFrom the divisibility properties we can infer that\n\nwhere both equalities can be achieved.\n\nStirling's approximation yields the following approximation, when formula_134 are sufficiently large:\n\nIn particular, when formula_136 is sufficiently large:\n\nAlso:\n\nFor formula_140 and formula_89 both much larger than 1, Stirling's approximation also yields the following asymptotic approximation:\n\nwhere formula_143 is the binary entropy of formula_144.\nMore precisely, for all integers formula_145 with formula_146, we can estimate the sum of the first formula_147 binomial coefficients as follows:\n\nWhen formula_136 is large and formula_140 is much smaller than formula_136, one can also write\n\nand therefore\n\nIf more precision is desired, one can approximate formula_154 with an integral, obtaining\n\nFor formula_156 and formula_157, formula_158, and these approximations yield 12.312 and 12.133 respectively.\n\nThe infinite product formula (cf. Gamma function, alternative definition)\nyields the asymptotic formulas\nas formula_161.\n\nThis asymptotic behaviour is contained in the approximation\nas well. (Here formula_163 is the \"k\"-th harmonic number and formula_164 is the Euler–Mascheroni constant.)\n\nFurther, the asymptotic formula\nhold true, whenever formula_166 and formula_167 for some complex number formula_168.\n\nA simple and rough upper bound for the sum of binomial coefficients can be obtained using the binomial theorem:\n\nIf \"n\" is large and \"k\" is linear in \"n\", various precise asymptotic estimates exist for the binomial coefficient formula_170. For example, if formula_171 then\nwhere \"d\" = \"n\" − 2\"k\".\n\nBinomial coefficients can be generalized to multinomial coefficients defined to be the number:\nwhere\n\nWhile the binomial coefficients represent the coefficients of (\"x\"+\"y\"), the multinomial coefficients\nrepresent the coefficients of the polynomial\nThe case \"r\" = 2 gives binomial coefficients:\n\nThe combinatorial interpretation of multinomial coefficients is distribution of \"n\" distinguishable elements over \"r\" (distinguishable) containers, each containing exactly \"k\" elements, where \"i\" is the index of the container.\n\nMultinomial coefficients have many properties similar to those of binomial coefficients, for example the recurrence relation:\nand symmetry:\nwhere formula_179 is a permutation of (1,2...,\"r\").\n\nUsing Stirling numbers of the first kind the series expansion around any arbitrarily chosen point formula_180 is\n\nThe definition of the binomial coefficients can be extended to the case where formula_136 is real and formula_140 is integer.\n\nIn particular, the following identity holds for any non-negative integer formula_140 :\n\nThis shows up when expanding formula_186 into a power series using the Newton binomial series :\n\nOne can express the product of binomial coefficients as a linear combination of binomial coefficients:\n\nwhere the connection coefficients are multinomial coefficients. In terms of labelled combinatorial objects, the connection coefficients represent the number of ways to assign \"m\" + \"n\" − \"k\" labels to a pair of labelled combinatorial objects—of weight \"m\" and \"n\" respectively—that have had their first \"k\" labels identified, or glued together to get a new labelled combinatorial object of weight \"m\" + \"n\" − \"k\". (That is, to separate the labels into three portions to apply to the glued part, the unglued part of the first object, and the unglued part of the second object.) In this regard, binomial coefficients are to exponential generating series what falling factorials are to ordinary generating series.\n\nThe partial fraction decomposition of the reciprocal is given by\n\nNewton's binomial series, named after Sir Isaac Newton, is a generalization of the binomial theorem to infinite series:\n\nThe identity can be obtained by showing that both sides satisfy the differential equation (1 + \"z\") \"f\"'(\"z\") = α \"f\"(\"z\").\n\nThe radius of convergence of this series is 1. An alternative expression is\n\nwhere the identity\n\nis applied.\n\nBinomial coefficients count subsets of prescribed size from a given set. A related combinatorial problem is to count multisets of prescribed size with elements drawn from a given set, that is, to count the number of ways to select a certain number of elements from a given set with the possibility of selecting the same element repeatedly. The resulting numbers are called \"multiset coefficients\"; the number of ways to \"multichoose\" (i.e., choose with replacement) \"k\" items from an \"n\" element set is denoted formula_193.\n\nTo avoid ambiguity and confusion with \"n\"'s main denotation in this article,<br> let \"f\" = \"n\" = \"r\" + (\"k\" – 1) and \"r\" = \"f\" – (\"k\" – 1).\n\nMultiset coefficients may be expressed in terms of binomial coefficients by the rule\nOne possible alternative characterization of this identity is as follows:\nWe may define the falling factorial as\nand the corresponding rising factorial as\nso, for example,\nThen the binomial coefficients may be written as \nwhile the corresponding multiset coefficient is defined by replacing the falling with the rising factorial:\n\nFor any \"n\",\n\nIn particular, binomial coefficients evaluated at negative integers are given by signed multiset coefficients. In the special case formula_201, this reduces to formula_202\n\nFor example, if \"n\" = -4 and \"k\" = 7, then \"r\" = 4 and \"f\" = 10:\n\nThe binomial coefficient is generalized to two real or complex valued arguments using the gamma function or beta function via\nThis definition inherits these following additional properties from formula_205:\nmoreover,\n\nThe resulting function has been little-studied, apparently first being graphed in . Notably, many binomial identities fail: formula_208 but formula_208 for \"n\" positive (so formula_210 negative). The behavior is quite complex, and markedly different in various octants (that is, with respect to the \"x\" and \"y\" axes and the line formula_211), with the behavior for negative \"x\" having singularities at negative integer values and a checkerboard of positive and negative regions:\n\nThe binomial coefficient has a q-analog generalization known as the Gaussian binomial coefficient.\n\nThe definition of the binomial coefficient can be generalized to infinite cardinals by defining:\n\nwhere A is some set with cardinality formula_220. One can show that the generalized binomial coefficient is well-defined, in the sense that no matter what set we choose to represent the cardinal number formula_220, formula_222 will remain the same. For finite cardinals, this definition coincides with the standard definition of the binomial coefficient.\n\nAssuming the Axiom of Choice, one can show that formula_223 for any infinite cardinal formula_220.\n\nThe notation formula_225 is convenient in handwriting but inconvenient for typewriters and computer terminals. Many programming languages do not offer a standard subroutine for computing the binomial coefficient, but for example both the APL programming language and the (related) J programming language use the exclamation mark: k ! n .\n\nNaive implementations of the factorial formula, such as the following snippet in Python:\n\nfrom math import factorial\ndef binomialCoefficient(n, k):\nare very slow and are useless for calculating factorials of very high numbers (in languages such as C or Java they suffer from overflow errors because of this reason). A direct implementation of the multiplicative formula works well:\ndef binomialCoefficient(n, k):\n\nPascal's rule provides a recursive definition which can also be implemented in Python, although it is less efficient:\n\ndef binomialCoefficient(n, k):\nThe example mentioned above can be also written in functional style. The following Scheme example uses the recursive definition\nRational arithmetic can be easily avoided using integer division\nThe following implementation uses all these ideas\n\n (define (binomial-iter n k i prev)\n (if (< k (- n k))\nWhen computing formula_228 in a language with fixed-length integers, the multiplication by formula_229 may overflow even when the result would fit. The overflow can be avoided by dividing first and fixing the result using the remainder:\n\nImplementation in the C language:\n\nunsigned long binomial(unsigned long n, unsigned long k) {\n\nAnother way to compute the binomial coefficient when using large numbers is to recognize that\n\nwhere formula_232 formula_233 denotes the natural logarithm of the gamma function at formula_136. It is a special function that is easily computed and is standard in some programming languages such as using \"log_gamma\" in Maxima, \"LogGamma\" in Mathematica, \"gammaln\" in MATLAB and Python's SciPy module, \"lngamma\" in PARI/GP or \"lgamma\" in C, R, and Julia. Roundoff error may cause the returned value to not be an integer.\n\n\n"}
{"id": "4669", "url": "https://en.wikipedia.org/wiki?curid=4669", "title": "Bill Holbrook", "text": "Bill Holbrook\n\nBill Holbrook (born 1958) is an American cartoonist and webcomic writer and artist, best known for his syndicated comic strip \"On the Fastrack\".\n\nBorn in Los Angeles, Holbrook grew up in Huntsville, Alabama, and began drawing at an early age. While majoring in illustration and visual design at Auburn University, Holbrook served as art director of the student newspaper, doing editorial cartoons and a weekly comic strip. At the same time, his work was being published in the \"Huntsville Times\" and the \"Monroe Journal\". After graduation in 1980, he joined the \"Atlanta Constitution\" as an editorial staff artist.\n\nDuring a 1982 visit to relatives on the West Coast, Holbrook met \"Peanuts\" creator, Charles Schulz. Following his advice and encouragement, Holbrook created a strip in the fall of that year about a college graduate working in a rundown diner. It did not stir syndicate interest, but what he learned on the strip helped him when he created \"On the Fastrack\".\n\nEleven days before \"On the Fastrack\" made its syndicated debut (March 19, 1984), Holbrook met Teri Peitso on a blind date. They were married on Pearl Harbor Day, 1985. They have two daughters, Chandler and Haviland. Peitso-Holbrook's novels have been nominated for both Edgar Awards and Agatha Awards. She is currently an assistant professor in literacy education at Georgia State University. The family lives in the Atlanta area.\n\nIn October 1989, Holbrook began his second strip, \"Safe Havens\", and his third strip, \"Kevin and Kell\" was launched in September 1995.\n\nEvery week Holbrook writes the story line for the next three weeks for one of his strips and draws the next three weeks' worth of strips for another. In 2010, characters from \"On the Fastrack\" and \"Safe Havens\" began appearing in both strips.\n\n"}
{"id": "4670", "url": "https://en.wikipedia.org/wiki?curid=4670", "title": "Bruce Campbell", "text": "Bruce Campbell\n\nBruce Lorne Campbell (born June 22, 1958) is an American actor, producer, writer, comedian and director. One of his best-known roles is portraying Ash Williams in Sam Raimi's \"Evil Dead\" franchise, beginning with the 1978 short film \"Within the Woods\". He has starred in many low-budget cult films such as \"Crimewave\" (1985), \"Maniac Cop\" (1988), \"\" (1989), and \"Bubba Ho-Tep\" (2002).\n\nIn television, Campbell had lead roles in \"The Adventures of Brisco County, Jr.\" (1993–94) and \"Jack of all Trades\" (2000), starred as Autolycus (the King of Thieves) in \"\" and \"\" (1995–99), Sam Axe on the USA Network series \"Burn Notice\" (2007–13), and reprised his role as Ash Williams on the Starz series \"Ash vs. Evil Dead\" (2015–18).\n\nCampbell started his directing career with \"Fanalysis\" (2002) and \"A Community Speaks\" (2004), and then with the horror comedy feature films \"Man with the Screaming Brain\" (2005) and \"My Name Is Bruce\" (2007), the latter being a spoof of his career. He can also be seen as the role of the father in \"The Escort\" (2015).\n\nCampbell was born in Royal Oak, Michigan, the son of Joanne Louise (née Pickens), a homemaker, and Charles Newton Campbell, an amateur actor and traveling billboard inspector. He has an older brother, Don, and an older half-brother, Michael Rendine. He is of Scottish descent.\n\nCampbell began acting as a teenager and soon began making short Super 8 movies with friends. After meeting Sam Raimi in Wylie E. Groves High School, the two became very good friends and started making movies together. Campbell would go on to attend Western Michigan University while he continued to work on his acting career. Campbell and Raimi collaborated on a 30-minute Super 8 version of the first \"Evil Dead\" film, titled \"Within the Woods\", which was initially used to attract investors.\n\nA few years later, Campbell and Raimi got together with family and friends and began work on \"The Evil Dead\". Campbell starred and worked behind the camera, receiving a \"co-executive producer\" credit. Raimi wrote, directed and edited, while fellow Michigander Rob Tapert was producer. Following an endorsement by horror writer Stephen King, the film slowly began to receive distribution. Four years following its original release, it became the number one movie in the UK. It then received distribution in the United States, spawning two sequels: \"Evil Dead II\" and \"Army of Darkness\".\n\nCampbell was also drawn in the Marvel Zombie comics as his character, Ash Williams. He is featured in five comics, all in the series \"Marvel Zombies vs. Army of Darkness\". In them, he fights alongside the Marvel heroes against the heroes and people who have turned into zombies (deadites) while in search of the Necronomicon (Book of the Names of the Dead).\n\nHe has appeared in many of Raimi's films outside of the \"Evil Dead\" series, notably having cameos in the director's \"Spider-Man\" film series. Campbell also joined the cast in Raimi's \"Darkman\" and \"The Quick and the Dead\", though having no actual screen time in the latter film's theatrical cut.\n\nCampbell often takes on quirky roles, such as Elvis Presley in the film \"Bubba Ho-Tep\". Along with \"Bubba Ho-Tep\", he played a supporting role in \"Maniac Cop\" and \"Maniac Cop 2\", and spoofed his career in the self-directed \"My Name is Bruce.\"\n\nOther mainstream films for Campbell include supporting or featured roles in the Coen Brothers film \"The Hudsucker Proxy\", the Michael Crichton adaptation \"Congo\", the film version of \"McHale's Navy\", \"Escape From L.A.\" (the sequel to John Carpenter's \"Escape From New York\"), the Jim Carrey drama \"The Majestic\" and the 2005 Disney film \"Sky High\".\nCampbell had a starring voice role in the hit 2009 animated adaptation of the children's book \"Cloudy with a Chance of Meatballs\", and a supporting voice role in Pixar's \"Cars 2\".\n\nIn January 2010, he stated in an interview that his new film project is called \"Bruce vs. Frankenstein\"., a sequel to My Name is Bruce. The film would have been directed and produced by his friend Mike Richardson. It was later cancelled.\n\nCampbell produced the remake of \"The Evil Dead\", along with Raimi and Rob Tapert. Campbell made an appearance that may allude to his signature character, Ash, with the expectation he would reprise that role in \"Army of Darkness 2\". In a later interview with TV personality Erin Ashley Darling, Campbell announced that \"Army of Darkness 2\" is not happening, saying \"It's all internet B.S. There's no reality whatsoever. These random comments slip out of either my mouth, or Sam Raimi's mouth, next thing you know, we're making a sequel.\" In September 2017, during a panel at Fan Expo Canada, when asked if audiences could expect 4th \"Evil Dead\" film, Campbell said \"Everybody says Evil Dead 4! Evil Dead 4! You know, if we did an Evil Dead 4, Sam Raimi would spend $200 million on it, and it would bomb.\", elaborating that the only future for \"Evil Dead\" is unrestricted distribution via a premium cable network, as \"Ash vs Evil Dead\" is on Starz.\n\nOutside of film, Campbell has appeared in a number of television series. He starred in \"The Adventures of Brisco County, Jr.\" a boisterous science fiction comedy western created by Jeffrey Boam and Carlton Cuse that ran for one season. He played a lawyer turned bounty hunter who was trying to hunt down John Bly, the man who killed his father. He starred in the television series \"Jack of All Trades\", set on a fictional island occupied by the French in 1801. Campbell was also credited as co-executive producer, among others. The show was directed by Eric Gruendemann, and was produced by various people, including Sam Raimi. The show aired for two seasons, from 2000 to 2001. He had a recurring role as \"Bill Church Jr.\" based upon the character of Morgan Edge from the Superman comics on \"\".\n\nFrom 1996 to 1997, Campbell was a recurring guest star on the show \"Ellen\" as Ed Billik, who becomes Ellen's boss when she sells her bookstore in season four.\n\nHe is also known for his supporting role as the recurring character Autolycus (\"King of Thieves\") on both \"\" and \"\", which reunited him with producer Rob Tapert. Campbell played \"Hercules\"/\"Xena\" series producer Tapert in two episodes of \"Hercules\" set in the present. He directed a number of episodes of \"Hercules\" and \"Xena\", including the \"Hercules\" series finale.\n\nCampbell also landed the lead role of race car driver Hank Cooper in the Disney made-for-television remake of \"The Love Bug\".\n\nCampbell made a critically acclaimed dramatic guest role as a grief-stricken detective seeking revenge for his father's murder in a two-part episode of the fourth season of \"\". Campbell later played the part of a bigamous demon in \"The X-Files\" episode \"Terms of Endearment\". He also starred as Agent Jackman in the episode \"Witch Way Now?\" of the WB series \"Charmed\", as well as playing a state police officer in an episode of the short-lived series \"American Gothic\" titled \"Meet the Beetles\".\n\nCampbell co-starred on the television series \"Burn Notice\", which aired from 2007 to 2013 on USA Network. He portrayed Sam Axe, a beer-chugging, former Navy SEAL now working as an unlicensed private investigator and occasional mercenary with his old friend Michael Westen, the show's main character. When working under cover, his character frequently used the alias Chuck Finley, which Bruce later revealed was the name of one of his father's old co-workers. Campbell was the star of a 2011 \"Burn Notice\" made-for-television prequel focusing on Sam's Navy SEAL career, titled \"\".\n\nIn 2014, Campbell played Santa Claus in an episode of \"The Librarians\". Campbell played Ronald Reagan in season 2 of the FX original series \"Fargo\". Most recently Campbell is reprising his role as Ashley \"Ash\" Williams in \"Ash vs Evil Dead\", a series based upon the \"Evil Dead\" franchise that launched his career. \"Ash vs Evil Dead\" began airing on Starz on October 31, 2015, and was renewed by the cable channel for second and third seasons.\n\nCampbell is featured as a voice actor in several video game titles. He provides the voice of Ash in the three games based on the \"Evil Dead\" film series: \"\", \"\" and \"\". He also provided voice talent in other titles such as \"\", \"Spider-Man: The Movie\", \"Spider-Man 2\", \"Spider-Man 3\" and \"The Amazing Spider-Man\".\n\nHe provided the voice of main character Jake Logan in the PC title, \"\", the voice of main character Jake Burton in the PlayStation game \"Broken Helix\" and the voice of Magnanimous in \"Megas XLR\". Campbell voiced the pulp adventurer Lobster Johnson in \"\" and has done voice-over work for the Codemaster's game \"Hei$t\", a game which was announced on January 28, 2010 to have been \"terminated\". He also provided the voice of The Mayor in the 2009 film \"Cloudy With a Chance of Meatballs\", the voice of Rod \"Torque\" Redline in \"Cars 2\" and the voice of \"Fugax\" in the 2006 film \"The Ant Bully\".\n\nDespite the inclusion of his character \"Ash Williams\" in Telltale Games' \"Poker Night 2\", Danny Webber voices the character in the game, instead of Bruce Campbell.\n\nHe has a voice in the online MOBA game, \"Tome: Immortal Arena\" in 2014. Campbell also provided voice-over and motion capture for Sgt. Lennox in the Exo Zombies mode of \"\".\n\nIn addition to acting and occasionally directing, Campbell has become a writer, starting with an autobiography, \"If Chins Could Kill: Confessions of a B Movie Actor\", published on August 24, 2002. The autobiography was a successful \"New York Times\" Best Seller. The paperback version of the book adds a chapter about the reaction of fans at book signings.\n\"Whenever I do mainstream stuff, I think they're pseudo-interested, but they're still interested in seeing weirdo, offbeat stuff, and that's what I'm attracted to\".\n\"If Chins Could Kill\" follows Campbell's career to date as an actor in low-budget films and television, providing his insight into \"Blue-Collar Hollywood\".\n\nCampbell's next book, \"Make Love! The Bruce Campbell Way\" was published on May 26, 2005. The book's plot involves Bruce (depicted in a comical way) as the main character struggling to make it into the world of A-list movies. He later recorded an audio play adaptation of \"Make Love\" with fellow Michigan actors, including longtime collaborator Ted Raimi. This radio drama was released through the independent label Rykodisc and spans 6 discs with a 6-hour running time.\n\nIn addition to his books, Campbell also wrote a column for \"X Ray Magazine\" in 2001, an issue of the popular comic series \"The Hire\", and comic book adaptations of his \"Man with the Screaming Brain\". Most recently he wrote the introduction to Josh Becker's \"The Complete Guide to Low-Budget Feature Filmmaking\".\n\nIn late 2016, Campbell announced that he would be releasing a third book, \"Hail to the Chin: Further Confessions of a B Movie Actor,\" which will detail his life from where \"If Chins Could Kill\" left off. \"Hail to the Chin\" was released in August 2017, and accompanied by a book tour across the United States and Europe.\n\nCampbell maintained a blog on his official website, where he posted mainly about politics and the film industry. The blog has since been discontinued.\n\nSince 2014, the Bruce Campbell Horror Film Festival, narrated and organized by Campbell, has been held in the Muvico Theater in Rosemont, Illinois. The first festival had his original run from August 21 to 25, 2014 presented by Wizard World, as part of the Chicago Comiccon. The second festival ran from August 20 to 23, 2015, with the guests Tom Holland and Eli Roth. The third festival took place over four days in August 2016. Guests of the event were Sam Raimi, Robert Tapert and Doug Benson.\n\nCampbell's first wife was Christine Deveau, whom he married in 1983. They had two children, Rebecca and Andy, before their divorce in 1989. Campbell currently lives in Jacksonville, Oregon, with his second wife, costume designer Ida Gearon, whom he met on the set of the movie \"Mindwarp\".\n\nCampbell is also an ordained minister and has officiated weddings for couples.\n\n\n"}
{"id": "4671", "url": "https://en.wikipedia.org/wiki?curid=4671", "title": "Baron Aberdare", "text": "Baron Aberdare\n\nBaron Aberdare, of Duffryn in the County of Glamorgan, is a title in the Peerage of the United Kingdom. It was created on 23 August 1873 for the Liberal politician Henry Bruce. He served as Home Secretary from 1868 to 1873. His grandson, the third Baron, was a soldier, cricketer and tennis player and a member of the International Olympic Committee. His son, the fourth Baron, held office in the Conservative administration of Edward Heath and was later a Deputy Speaker of the House of Lords. Lord Aberdare was one of the ninety-two elected hereditary peers that were allowed to remain in the House of Lords after the passing of the House of Lords Act 1999. the title is held by his son, the fifth Baron, who succeeded in 2005 and was elected to the House of Lords in 2009.\n\nThe heraldic blazon for the coat of arms of the family is: \"Or, a saltire gules, on a chief of the last a martlet of the field\".\n\n\nThe heir apparent is the present holder's son the Hon Hector Morys Napier Bruce (b. 1974)<br>\nThe heir apparent's heir is the present holder's younger brother the Hon. James Henry Morys Bruce (b. 1948)<br>\nThe heir apparent's heir's heir is his son Robert Algernon Copley Bruce (b. 1994)\n\n"}
{"id": "4673", "url": "https://en.wikipedia.org/wiki?curid=4673", "title": "Boy band", "text": "Boy band\n\nA boy band (or boyband) is loosely defined as a vocal group consisting of young male singers, usually in their teenage years or in their twenties at the time of formation, singing love songs marketed towards young women. Being vocal groups, most boy band members do not play musical instruments, either in recording sessions or on stage, making the term something of a misnomer. However, exceptions do exist. Many boy bands dance as well as sing, usually giving highly choreographed performances.\n\nSome such bands form on their own. They can evolve out of church choral or gospel music groups, but are often created by talent managers or record producers who hold auditions. Due to this and their general commercial orientation towards a female audience of preteens, teenyboppers, or teens, the term may be used with negative connotations in music journalism. Boy bands are similar in concept to their counterparts, girl groups. Boy bands' popularity peaked four times: in the 1960s (e.g., The Jackson 5), in the 1990s and early 2000s when acts such as the Backstreet Boys, *NSYNC, A1 and Westlife, among others, dominated the top of the \"Billboard\" and pop charts, in the early 2010s with the emergence of new boy bands such as JLS, Big Time Rush and One Direction, and in the late 2010s with pop groups such as BTS and 5 Seconds of Summer.\n\nThe earliest forerunner of boy band music began in the late 19th century as a cappella barbershop quartets. They were usually a group of males and sang in four-part harmonies. Barbershop quartets were popular into the earlier part of the 20th century. A revival of the male vocal group took place in the late 1940s and 1950s with the use of doo-wop music. Doo-wop bands sang about topics such as love and other themes used in pop music. The earliest traces of boy bands were in the mid-1950s although the term boy band was not used. African American vocal group The Ink Spots was one of the first of what would now be called boy bands. The term boy band was not established until the late 1980s as before that they were called male vocal groups or \"hep harmony singing groups\".\n\nAlthough generally described as a rock band, the highest-selling band in history The Beatles are considered by a number or journalists \"the first\" or \"the original\" boyband, \"before anyone had thought of the term.\"\n\nThe Beatles inspired the decision to produce the 1966 television series \"The Monkees\", which spawned the music group of the same name, formed by the four starring actors. The rock and pop band started a career in music after their songs from the TV series released as records resulted successful.\n\nAlthough the term \"boy band\" was not commonly used yet, the earliest predecessors of this format were groups such as the Jackson 5 and the Osmonds which helped form the template for boy bands. The Jackson 5 were a sibilings group that established many musical conventions that boy bands follow. For instance, their music featured close harmonies from soul music and catchy pop hooks influenced as much as they were by Motown and acts like the Supremes. The group also incorporated choreographed dance moves to their performances. All members of the band sang, which is a common convention of a boy band, as opposed to having a front man and the rest on instruments; thus, no one person dominated the stage. Also a sibilings group, The Osmonds first started singing barbershop music for local audiences, before being hired to perform at Disneyland early in their career. Their appearance in a televised Disney special earned them additional TV spots, such as \"The Andy Williams Show\" and \"The Jerry Lewis Show\".\n\nOther antecedents (apart from those already mentioned) exist throughout the history of pop music. The genre has been copied into languages and cultures other than the Anglo-American. The Puerto Rican boy band Menudo, appealing to young Latina audiences, was founded in 1977. Menudo had a convention unique among boy bands: when a member turned 16, became too tall, or their voice changed, they were replaced. The members of Menudo were generally aged 12–16.\n\nThe Bay City Rollers were a Scottish pop band who were most popular in the mid-1970s. The \"British Hit Singles & Albums\" noted that they were \"tartan teen sensations from Edinburgh\", and were \"the first of many acts heralded as the 'Biggest Group since The Beatles' and one of the most screamed-at teeny-bopper acts of the 1970s\". For a fairly brief but fervent period (nicknamed \"Rollermania\"), they were worldwide teen idols. The group were one of the first bands, like The Monkees before them, to take the formula shown by The Beatles and apply it to a teen market. The group achieved the same amount of success but for a limited period of time. At the peak of their popularity in the UK, comparisons were being made to The Beatles. Also by this time, Bay City Roller fans had a completely distinctive style of dress, the main elements of which were ankle-length tartan trousers and tartan scarves, the group using the benefit of merchandise and promotion.\n\nIn the US, the Cleveland-based power pop group Raspberries was generally interpreted as a \"teen act\", although all the band members played their own music. Vocalist Eric Carmen later commented, \"It was not hip for people to like us, because their little sister liked us.\"\n\nBoston group New Edition was formed in 1978 and reached their height of popularity in the 1980s, meaning they are often credited for starting the boy-band trend, even though the term \"boy band\" did not exist until the 1990s. Maurice Starr was influenced by New Edition and popularized it with his protégé New Kids on the Block, the first commercially successful modern boy band, who formed in 1984 and found international success in 1988. Starr's idea was to take the traditional template from the R&B genre (in this case his teenage band New Edition) and apply it to a pop genre.\n\nBros (abbreviation of the word \"brothers\") were a British boy band active in the late 1980s and early 1990s, consisting of twin brothers Matt and Luke Goss along with Craig Logan. Formed in 1986, they scored multiple top 10 hits between 1987 and 1989 and in 1988 became the first modern era–style boy band to have a multiple platinum-selling album in Britain, with \"Push\", still one of the most successful boy-band albums in the UK. Other big boy bands in Britain during the late 1980s were Big Fun and Brother Beyond.\n\nSome managers in Europe soon created their own acts after being inspired by New Kids on the Block, beginning with Nigel Martin-Smith's Take That in the UK (formed in 1990) and followed by Tom Watkins, who had success with Bros in the late 1980s and formed East 17 in 1991. Bros were marketed and pitted against Take That as rivals with a harsher attitude, style and sound. Since reforming in 2006 after a decade-long hiatus, Take That have become one of the most successful groups in British music chart history and their albums and singles have also charted internationally, especially in Europe. Irish music manager Louis Walsh, who had witnessed the impact of these British boy bands, put out an advert for an \"Irish Take That\", thereby creating Boyzone in 1993. Let Loose (formed in 1993), MN8 and 911 (formed in 1995), and Damage (formed in 1996) were also successful boy bands in Britain; however, by the late 1990s all these bands had run their course and split up.\n\nAll these artists were very successful on both the singles and albums charts domestically and internationally; however, with the emergence of Britpop and the commercial co-option of indie rock, many boy bands were ridiculed by the British music press as having no artistic credibility, although some, such as East 17 and Take That, did write most of their own material. The media attention was then placed on the \"Battle of Britpop\", and the bands Oasis and Blur replaced the importance and rivalry of Take That and East 17 as the two new biggest bands in Britain. However, boy bands continued to find success in the late 1990s, such as Five, Another Level, Point Break and Westlife. In 1995 successful German music manager Frank Farian, who had been manager of Boney M and Milli Vanilli, put together Latin American band No Mercy who scored a few worldwide hits during the mid-90s.\n\nAlthough being American and the sons of Tito Jackson, a member of The Jackson 5, 3T had several hits singles across Europe in the mid-1990s, despite limited success in the US, and finished the second biggest selling act of 1996 in Europe behind Spice Girls.\n\nWith the success of North American boy bands like New Kids on the Block in East Asia, Japanese entertainment company Johnny & Associates formed SMAP in 1992. The group enjoyed tremendous success, selling over 35 million records. It paved the way for more Asian boy bands such as Arashi.\nIn the early 1990s in North America, with New Kids on the Block's continued success and Color Me Badd also having success, boy bands became a continued staple of the Billboard charts. Continuing this success in the mid-1990s, most prominent boy bands were African American and had R&B and gospel elements, such as the groups All-4-One (formed in 1993) and Boyz II Men (formed in 1988). Boyz II Men are also the most successful boy band act on the U.S. Hot 100 as well as the Australian Singles Chart. Although they had success on the Billboard charts, they were not marketed towards youth but more towards adults. It was not until 1997 and the change to pop-oriented groups such as Backstreet Boys, 98 Degrees, NSYNC, The Moffatts, and Hanson that boy bands exploded commercially and dominated the market in the United States. This late 1990s marked the height of boy band popularity in North America, which hasn't been seen since.\n\nArguably the most successful boy band manager from the U.S. was Lou Pearlman, who founded commercially successful acts such as the Backstreet Boys in 1993, NSYNC and LFO in 1995, O-Town in 2000, and US5 in 2005. Backstreet Boys and NSYNC became the two biggest boy bands in the late 1990s until the early 2000s, and Backstreet Boys went on to tie The Jackson 5 as the best-selling boy bands in history with over 100 million records sold.\n\nIn the late 1990s in the UK, producer Simon Cowell (noted in the U.S. for the \"American Idol/X Factor\" franchise) is also known for having managed British boyband Five (formed in 1997) and Irish boyband Westlife (formed in 1998). Westlife was created by Irishman Louis Walsh as a replacement for Boyzone and was initially managed by a former member of the band Ronan Keating. Westlife would eventually overtake Take That in number one's tally in the UK although Take That's overall UK sales are still higher. In 2012, the Official Charts Company revealed the biggest selling singles artists in British music chart history with Take That placed 15th overall and the highest selling boyband act (9.3 million), followed by Boyzone at 29 (7.1 million) and Westlife at 34 (6.8 million). Even though Cowell is known to have managed several successful boy bands, he is also infamous for passing on signing two of the biggest boybands to emerge from the 1990s and 2000s, Take That and Busted.\n\nWith the continued success of Backstreet Boys and *NSYNC, American and British groups like 98 Degrees, Westlife, O-Town, A1, Blue, and Busted gained quick popularity both domestically and internationally. International boy bands would also occasionally spring up, such as the Moldovan band O-Zone (better known today as an Internet meme), and Overground. American Christian boy band Plus One also enjoyed brief remarkable success during this time.\n\nAt the height of boy band popularity in North America, MTV created their own parody boyband, 2gether. Like The Monkees in the 1960s, they were a manufactured act composed of actors. 2gether played off of the idea that every successful boy band must have five distinct personality types: the bad boy, the shy one, the young one, the older brother type, and a heart throb.\n\nSince 2001, the dominance of traditional boy bands on pop charts began to fade in the western hemisphere, although Gil Kaufman of MTV has described \"new boy bands\" that are \"more likely to resemble My Chemical Romance, Sum 41, and Simple Plan.\n\nIn 2001, Taiwanese boy band F4 (called JVKV since 2007) blew up big as a result of the success of their TV drama Meteor Garden. Their popularity spread throughout Asia. With their success, many other Taiwanese boy bands emerged around this time, such as 5566 and Fahrenheit. In South Korea, Shinhwa also spread hallyu wave throughout Asia such as Japan, Thailand, Singapore, Taiwan, Hong Kong and China. Also in 2001, a new all-male pop band and dance group boyband hailing from Japan called Exile debuted under Avex Group's label Rhythm Zone with 14 members, putting them on par with Super Junior, a South Korean boy band, who had 13 members at its peak.\n\nJapanese boy band Arashi has sold over 30 million copies of their records since their first release in 1999. They had the yearly best-selling single in Japan in 2008 and 2009. In 2003 SMAP released the single \"Sekai ni Hitotsu Dake no Hana\" that has become the third best-selling single ever in Japan, with over 3 million copies sold.\n\nIn North America, the Jonas Brothers rose to fame from promotion on the Disney Channel in 2008. Other boy bands like JLS and Mindless Behavior also emerged and experienced remarkable success around this time. However, apart from them, boy bands haven't seen the commercial boom experienced in the genre from the mid to late nineties in North America.\n\nThe mid 2000s, especially the United Kingdom and the rest of Europe, saw the continued longevity of nineties boy bands such as Backstreet Boys and Westlife (before they disbanded in 2012), and the successful comeback of Take That in 2005, Boyzone in 2007, and New Kids on the Block in 2008. Some sections of the press have referred to these acts, particularly those who have reformed after a previous split, such as Take That, Boyzone, and 98 Degrees, as 'man bands'.\n\nIn the early 2010s, there was somewhat of a resurgence of boy band popularity in countries where the trend had not maintained, with the emergence of new boy bands like Big Time Rush, The Wanted, and One Direction and the formation of supergroup NKOTBSB which comprised members of New Kids on the Block and Backstreet Boys. NKOTBSB's success inspired boy bands who were fairly popular during the 1990s and 2000s to make a comeback, such as A1, Blue, 98 Degrees, Five, 911, and O-Town. Like 2gether and The Monkees, Big Time Rush was a manufactured act created for a television show.\n\nIn Southeast Asia, local boy bands also emerged as a result of the continued success of Korean and Japanese boy bands such as SMAP, Shinhwa, TVXQ!, Arashi, Exile, Super Junior, Big Bang, SHINee, and EXO. One of the boy bands who emerged as a result of Hallyu (Korean wave) is Indonesia's SM*SH who enjoyed prominent success domestically. In the Philippines, a major boy band has been formed by bringing the first reality boy band search of the country called Pinoy Boyband Superstar which held mid 2016, after all the series of auditions, rigorous training and competition, the winners formed as a group called Boyband PH a five-piece Pinoy boy band which managed by Star Magic\n\nIn South Korea, boy bands have been commercially successful. On the Gaon Music Chart year-end albums chart of 2016, nine of the top 10 and 17 of the top 20 albums are by boy bands or by subunits/members of boy bands. BIGBANG, EXO had the second and third best-selling albums. Other boy bands with albums in the yearly top 20 of 2016 are BTS, SHINee, GOT7, Seventeen, INFINITE and VIXX.\n\nIn Japan, Arashi continue to be very successful, being the best-selling music artist in Japan from 2013 through 2017 by value of sales and also having the yearly best-selling album in the country in 2010, 2011, 2013, 2015 and 2016. Other successful Japanese boy bands in this decade include Sandaime J Soul Brothers, the second best-selling music artist of 2016 in the country and Kanjani Eight, the fifth best-selling music artist of that year in Japan.\n\nSeen as important to a \"boy band\" group's commercial success is the group's image, carefully controlled by managing all aspects of the group's attire, promotional materials (which are frequently supplied to teen magazines), and music videos. The key factor of a boy band is being trendy. This means that the band conforms to the most recent fashion and musical trends in the popular music scene. Typically, each member of the group will have some distinguishing feature and be portrayed as having a particular personality stereotype, such as \"the baby,\" \"the bad boy,\" or \"the shy one.\" While managing the portrayal of popular musicians is as old as popular music, the particular pigeonholing of band members is a defining characteristic of boy and girl bands.\n\nIn most cases, their music is written, arranged and produced by a producer who works with the band at all times and controls the group's sound – if necessary, to the point of hiring session singers to record guide vocals for each member of the group to sing individually if the members cannot harmonize well together. However, for clarity of each voice, recording each voice individually is most commonly the norm with most modern vocal groups. In recent years auto-tune has become a popular tool for boy bands who are unable to sing to a high standard. Some boy bands have come under fire for this issue of using auto-tune. Some have also come under fire for lip syncing in their performances as well, for example New Kids on the Block.\n\nA typical boy band performance features elaborately choreographed dancing, with the members taking turns singing and/or rapping. Boy bands generally do not compose or produce their own material, unless the members lobby hard enough for creative control. However, some bands were created around the talent of a songwriter within the group like Gary Barlow of Take That or Tony Mortimer of East 17. It is not uncommon to find extra songs on an album written by one or more of the band members; however, their producers rarely use these as singles.\n\nSince the 21st century, however, boy bands have been expected to write or at least contribute in some part lyrically to songs. Apart from the groups mentioned above who all had at least one primary songwriter from their beginning, other groups soon caught up. From the late nineties, members of Backstreet Boys who had previously used writers like Max Martin during their early albums began writing their own songs. Newer groups from late 2000s such as JLS have all made a point from early interviews that they write their own songs and hold their own image as this is an important part of marketing. Some bands like The Wanted have even spent time learning the craft of songwriting.\n\nIndividuals can also go on to achieve greater success as a solo artist coming out of a boy band having used the groups popularity to build on. Usually this signals the end of the group until potential future reunions. Examples of this include Michael Jackson from The Jackson 5, Donny Osmond from The Osmonds, Ricky Martin from Menudo, Justin Timberlake from *NSYNC, and Ronan Keating from Boyzone. Sometimes the most successful solo star from a band is not the most popular member such as Robbie Williams as opposed to lead singer Gary Barlow from Take That. Some boy band members have gone on to successful careers elsewhere in the media. Michael Dolenz of The Monkees went on to become a successful television producer, working for ITV franchises such as LWT and Television South.\n\nAlthough most boy bands consist of R&B or pop influences, other music genres, most notably country music and folk music, are also represented. South 65 and Marshall Dyllon, for example, were both country music boy bands. Il Divo, created by Simon Cowell in 2004, are a vocal group that performs operatic pop in several (mainly Italian) languages. Since then operatic/classical boy bands have become quite popular and common, especially in the UK. Since 2001 there has been some crossover with power pop and pop punk from bands that play live instruments. Just recently some boy bands decided to go back to their original doo-wop roots, most notably, The Overtones.\n\nSince the 2000s, groups such as Backstreet Boys and LFO have disliked the term \"boy band\" and have preferred to be known as a \"male vocal group\". Being categorized among boy bands was also the main reason The Moffatts split up. Boy bands have been accused by the music press of emphasizing the appearance and marketing of the group above the quality of music, deliberately trying to appeal to a preteen audience and for conforming to trends instead of being original. Such criticisms can become extremely scathing. Boy bands are often seen as being short lived, although some acts such as The Jackson 5, Backstreet Boys, Human Nature, New Edition, SMAP, Shinhwa and Westlife (before they split up in 2012) have sustained lasting careers.\n\nThe following is a list of the best-selling boy bands based on claimed sales figures of over 40 million records:\n\n"}
{"id": "4674", "url": "https://en.wikipedia.org/wiki?curid=4674", "title": "B-tree", "text": "B-tree\n\nIn computer science, a B-tree is a self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time. The B-tree is a generalization of a binary search tree in that a node can have more than two children. Unlike self-balancing binary search trees, the B-tree is well suited for storage systems that read and write relatively large blocks of data, such as discs. It is commonly used in databases and file systems.\n\nWhat, if anything, the \"B\" stands for has never been established.\n\nIn B-trees, internal (non-leaf) nodes can have a variable number of child nodes within some pre-defined range. When data is inserted or removed from a node, its number of child nodes changes. In order to maintain the pre-defined range, internal nodes may be joined or split. Because a range of child nodes is permitted, B-trees do not need re-balancing as frequently as other self-balancing search trees, but may waste some space, since nodes are not entirely full. The lower and upper bounds on the number of child nodes are typically fixed for a particular implementation. For example, in a 2-3 B-tree (often simply referred to as a 2-3 tree), each internal node may have only 2 or 3 child nodes.\n\nEach internal node of a B-tree contains a number of keys. The keys act as separation values which divide its subtrees. For example, if an internal node has 3 child nodes (or subtrees) then it must have 2 keys: \"a\" and \"a\". All values in the leftmost subtree will be less than \"a\", all values in the middle subtree will be between \"a\" and \"a\", and all values in the rightmost subtree will be greater than \"a\".\n\nUsually, the number of keys is chosen to vary between formula_1 and formula_2, where formula_1 is the minimum number of keys, and formula_4 is the minimum degree or branching factor of the tree. In practice, the keys take up the most space in a node. The factor of 2 will guarantee that nodes can be split or combined. If an internal node has formula_2 keys, then adding a key to that node can be accomplished by splitting the hypothetical formula_6 key node into two formula_1 key nodes and moving the key that would have been in the middle to the parent node. Each split node has the required minimum number of keys. Similarly, if an internal node and its neighbor each have formula_1 keys, then a key may be deleted from the internal node by combining it with its neighbor. Deleting the key would make the internal node have formula_9 keys; joining the neighbor would add formula_1 keys plus one more key brought down from the neighbor's parent. The result is an entirely full node of formula_2 keys.\n\nThe number of branches (or child nodes) from a node will be one more than the number of keys stored in the node. In a 2-3 B-tree, the internal nodes will store either one key (with two child nodes) or two keys (with three child nodes). A B-tree is sometimes described with the parameters formula_12 — formula_13 or simply with the highest branching order, formula_13.\n\nA B-tree is kept balanced by requiring that all leaf nodes be at the same depth. This depth will increase slowly as elements are added to the tree, but an increase in the overall depth is infrequent, and results in all leaf nodes being one more node farther away from the root.\n\nB-trees have substantial advantages over alternative implementations when the time to access the data of a node greatly exceeds the time spent processing that data, because then the cost of accessing the node may be amortized over multiple operations within the node. This usually occurs when the node data are in secondary storage such as disk drives. By maximizing the number of keys within each internal node, the height of the tree decreases and the number of expensive node accesses is reduced. In addition, rebalancing of the tree occurs less often. The maximum number of child nodes depends on the information that must be stored for each child node and the size of a full disk block or an analogous size in secondary storage. While 2-3 B-trees are easier to explain, practical B-trees using secondary storage need a large number of child nodes to improve performance.\n\nThe term B-tree may refer to a specific design or it may refer to a general class of designs. In the narrow sense, a B-tree stores keys in its internal nodes but need not store those keys in the records at the leaves. The general class includes variations such as the B+ tree and the B tree.\n\nUsually, sorting and searching algorithms have been characterized by the number of comparison operations that must be performed using order notation. A binary search of a sorted table with records, for example, can be done in roughly comparisons. If the table had 1,000,000 records, then a specific record could be located with at most 20 comparisons: .\n\nLarge databases have historically been kept on disk drives. The time to read a record on a disk drive far exceeds the time needed to compare keys once the record is available. The time to read a record from a disk drive involves a seek time and a rotational delay. The seek time may be 0 to 20 or more milliseconds, and the rotational delay averages about half the rotation period. For a 7200 RPM drive, the rotation period is 8.33 milliseconds. For a drive such as the Seagate ST3500320NS, the track-to-track seek time is 0.8 milliseconds and the average reading seek time is 8.5 milliseconds. For simplicity, assume reading from disk takes about 10 milliseconds.\n\nNaively, then, the time to locate one record out of a million would take 20 disk reads times 10 milliseconds per disk read, which is 0.2 seconds.\n\nThe time won't be that bad because individual records are grouped together in a disk block. A disk block might be 16 kilobytes. If each record is 160 bytes, then 100 records could be stored in each block. The disk read time above was actually for an entire block. Once the disk head is in position, one or more disk blocks can be read with little delay. With 100 records per block, the last 6 or so comparisons don't need to do any disk reads—the comparisons are all within the last disk block read.\n\nTo speed the search further, the first 13 to 14 comparisons (which each required a disk access) must be sped up.\n\nA significant improvement can be made with an index. In the example above, initial disk reads narrowed the search range by a factor of two. That can be improved substantially by creating an auxiliary index that contains the first record in each disk block (sometimes called a sparse index). This auxiliary index would be 1% of the size of the original database, but it can be searched more quickly. Finding an entry in the auxiliary index would tell us which block to search in the main database; after searching the auxiliary index, we would have to search only that one block of the main database—at a cost of one more disk read. The index would hold 10,000 entries, so it would take at most 14 comparisons. Like the main database, the last 6 or so comparisons in the aux index would be on the same disk block. The index could be searched in about 8 disk reads, and the desired record could be accessed in 9 disk reads.\n\nThe trick of creating an auxiliary index can be repeated to make an auxiliary index to the auxiliary index. That would make an aux-aux index that would need only 100 entries and would fit in one disk block.\n\nInstead of reading 14 disk blocks to find the desired record, we only need to read 3 blocks. Reading and searching the first (and only) block of the aux-aux index identifies the relevant block in aux-index. Reading and searching that aux-index block identifies the relevant block in the main database. Instead of 150 milliseconds, we need only 30 milliseconds to get the record.\n\nThe auxiliary indices have turned the search problem from a binary search requiring roughly disk reads to one requiring only disk reads where is the blocking factor (the number of entries per block: entries per block in our example; reads).\n\nIn practice, if the main database is being frequently searched, the aux-aux index and much of the aux index may reside in a disk cache, so they would not incur a disk read.\n\nIf the database does not change, then compiling the index is simple to do, and the index need never be changed. If there are changes, then managing the database and its index becomes more complicated.\n\nDeleting records from a database is relatively easy. The index can stay the same, and the record can just be marked as deleted. The database remains in sorted order. If there are a large number of deletions, then searching and storage become less efficient.\n\nInsertions can be very slow in a sorted sequential file because room for the inserted record must be made. Inserting a record before the first record requires shifting all of the records down one. Such an operation is just too expensive to be practical. One solution is to leave some spaces. Instead of densely packing all the records in a block, the block can have some free space to allow for subsequent insertions. Those spaces would be marked as if they were \"deleted\" records.\n\nBoth insertions and deletions are fast as long as space is available on a block. If an insertion won't fit on the block, then some free space on some nearby block must be found and the auxiliary indices adjusted. The hope is that enough space is available nearby, such that a lot of blocks do not need to be reorganized. Alternatively, some out-of-sequence disk blocks may be used.\n\nThe B-tree uses all of the ideas described above. In particular, a B-tree:\n\nIn addition, a B-tree minimizes waste by making sure the interior nodes are at least half full. A B-tree can handle an arbitrary number of insertions and deletions.\n\nThe literature on B-trees is not uniform in its terminology .\n\n, , and others define the order of B-tree as the minimum number of keys in a non-root node. points out that terminology is ambiguous because the maximum number of keys is not clear. An order 3 B-tree might hold a maximum of 6 keys or a maximum of 7 keys. avoids the problem by defining the order to be maximum number of children (which is one more than the maximum number of keys).\n\nThe term leaf is also inconsistent. considered the leaf level to be the lowest level of keys, but Knuth considered the leaf level to be one level below the lowest keys . There are many possible implementation choices. In some designs, the leaves may hold the entire data record; in other designs, the leaves may only hold pointers to the data record. Those choices are not fundamental to the idea of a B-tree.\n\nFor simplicity, most authors assume there are a fixed number of keys that fit in a node. The basic assumption is the key size is fixed and the node size is fixed. In practice, variable length keys may be employed .\n\nAccording to Knuth's definition, a B-tree of order \"m\" is a tree which satisfies the following properties:\n\n\nEach internal node’s keys act as separation values which divide its subtrees. For example, if an internal node has 3 child nodes (or subtrees) then it must have 2 keys: \"a\" and \"a\". All values in the leftmost subtree will be less than \"a\", all values in the middle subtree will be between \"a\" and \"a\", and all values in the rightmost subtree will be greater than \"a\".\n\n\n\n\nA B-tree of depth \"n\"+1 can hold about \"U\" times as many items as a B-tree of depth \"n\", but the cost of search, insert, and delete operations grows with the depth of the tree. As with any balanced tree, the cost grows much more slowly than the number of elements.\n\nSome balanced trees store values only at leaf nodes, and use different kinds of nodes for leaf nodes and internal nodes. B-trees keep values in every node in the tree, and may use the same structure for all nodes. However, since leaf nodes never have children, the B-trees benefit from improved performance if they use a specialized structure.\n\nLet be the height of the classic B-tree (see Tree (data structure) § Terminology for the tree height definition). Let be the number of entries in the tree. Let \"m\" be the maximum number of children a node can have. Each node can have at most keys.\n\nIt can be shown (by induction for example) that a B-tree of height \"h\" with all its nodes completely filled has entries. Hence, the best case height (i.e. the minimum height) of a B-tree is:\n\nLet formula_1 be the minimum number of children an internal (non-root) node can have. For an ordinary B-tree, formula_17\n\nSearching is similar to searching a binary search tree. Starting at the root, the tree is recursively traversed from top to bottom. At each level, the search reduces its field of view to the child pointer (subtree) whose range includes the search value. A subtree's range is defined by the values, or keys, contained in its parent node. These limiting values are also known as separation values.\n\nBinary search is typically (but not necessarily) used within nodes to find the separation values and child tree of interest.\n\nAll insertions start at a leaf node. To insert a new element, search the tree to find the leaf node where the new element should be added. Insert the new element into that node with the following steps:\n\n\nIf the splitting goes all the way up to the root, it creates a new root with a single separator value and two children, which is why the lower bound on the size of internal nodes does not apply to the root. The maximum number of elements per node is \"U\"−1. When a node is split, one element moves to the parent, but one element is added. So, it must be possible to divide the maximum number \"U\"−1 of elements into two legal nodes. If this number is odd, then \"U\"=2\"L\" and one of the new nodes contains (\"U\"−2)/2 = \"L\"−1 elements, and hence is a legal node, and the other contains one more element, and hence it is legal too. If \"U\"−1 is even, then \"U\"=2\"L\"−1, so there are 2\"L\"−2 elements in the node. Half of this number is \"L\"−1, which is the minimum number of elements allowed per node.\n\nAn improved algorithm supports a single pass down the tree from the root to the node where the insertion will take place, splitting any full nodes encountered on the way. This prevents the need to recall the parent nodes into memory, which may be expensive if the nodes are on secondary storage. However, to use this improved algorithm, we must be able to send one element to the parent and split the remaining \"U\"−2 elements into two legal nodes, without adding a new element. This requires \"U\" = 2\"L\" rather than \"U\" = 2\"L\"−1, which accounts for why some textbooks impose this requirement in defining B-trees.\n\nThere are two popular strategies for deletion from a B-tree.\n\n\nThe algorithm below uses the former strategy.\n\nThere are two special cases to consider when deleting an element:\n\n\nThe procedures for these cases are in order below.\n\n\nEach element in an internal node acts as a separation value for two subtrees, therefore we need to find a replacement for separation. Note that the largest element in the left subtree is still less than the separator. Likewise, the smallest element in the right subtree is still greater than the separator. Both of those elements are in leaf nodes, and either one can be the new separator for the two subtrees. Algorithmically described below:\n\n\nRebalancing starts from a leaf and proceeds toward the root until the tree is balanced. If deleting an element from a node has brought it under the minimum size, then some elements must be redistributed to bring all nodes up to the minimum. Usually, the redistribution involves moving an element from a sibling node that has more than the minimum number of nodes. That redistribution operation is called a rotation. If no sibling can spare an element, then the deficient node must be merged with a sibling. The merge causes the parent to lose a separator element, so the parent may become deficient and need rebalancing. The merging and rebalancing may continue all the way to the root. Since the minimum element count doesn't apply to the root, making the root be the only deficient node is not a problem. The algorithm to rebalance the tree is as follows:\n\n\nWhile freshly loaded databases tend to have good sequential behavior, this behavior becomes increasingly difficult to maintain as a database grows, resulting in more random I/O and performance challenges.\n\nA common special case is adding a large amount of \"pre-sorted\" data into an initially empty B-tree. While it is quite possible to simply perform a series of successive inserts, inserting sorted data results in a tree composed almost entirely of half-full nodes. Instead, a special \"bulk loading\" algorithm can be used to produce a more efficient tree with a higher branching factor.\n\nWhen the input is sorted, all insertions are at the rightmost edge of the tree, and in particular any time a node is split, we are guaranteed that the no more insertions will take place in the left half. When bulk loading, we take advantage of this, and instead of splitting overfull nodes evenly, split them as \"unevenly\" as possible: leave the left node completely full and create a right node with zero keys and one child (in violation of the usual B-tree rules).\n\nAt the end of bulk loading, the tree is composed almost entirely of completely full nodes; only the rightmost node on each level may be less than full. Because those nodes may also be less than \"half\" full, to re-establish the normal B-tree rules, combine such nodes with their (guaranteed full) left siblings and divide the keys to produce two nodes at least half full. The only node which lacks a full left sibling is the root, which is permitted to be less than half full.\n\nIn addition to its use in databases, the B-tree (or ) is also used in filesystems to allow quick random access to an arbitrary block in a particular file. The basic problem is turning the file block formula_19 address into a disk block (or perhaps to a cylinder-head-sector) address.\n\nSome operating systems require the user to allocate the maximum size of the file when the file is created. The file can then be allocated as contiguous disk blocks. In that case, to convert the file block address formula_19 into a disk block address, the operating system simply adds the file block address formula_19 to the address of the first disk block constituting the file. The scheme is simple, but the file cannot exceed its created size.\n\nOther operating systems allow a file to grow. The resulting disk blocks may not be contiguous, so mapping logical blocks to physical blocks is more involved.\n\nMS-DOS, for example, used a simple File Allocation Table (FAT). The FAT has an entry for each disk block, and that entry identifies whether its block is used by a file and if so, which block (if any) is the next disk block of the same file. So, the allocation of each file is represented as a linked list in the table. In order to find the disk address of file block formula_19, the operating system (or disk utility) must sequentially follow the file's linked list in the FAT. Worse, to find a free disk block, it must sequentially scan the FAT. For MS-DOS, that was not a huge penalty because the disks and files were small and the FAT had few entries and relatively short file chains. In the FAT12 filesystem (used on floppy disks and early hard disks), there were no more than 4,080 entries, and the FAT would usually be resident in memory. As disks got bigger, the FAT architecture began to confront penalties. On a large disk using FAT, it may be necessary to perform disk reads to learn the disk location of a file block to be read or written.\n\nTOPS-20 (and possibly TENEX) used a 0 to 2 level tree that has similarities to a B-tree. A disk block was 512 36-bit words. If the file fit in a 512 (2) word block, then the file directory would point to that physical disk block. If the file fit in 2 words, then the directory would point to an aux index; the 512 words of that index would either be NULL (the block isn't allocated) or point to the physical address of the block. If the file fit in 2 words, then the directory would point to a block holding an aux-aux index; each entry would either be NULL or point to an aux index. Consequently, the physical disk block for a 2 word file could be located in two disk reads and read on the third.\n\nApple's filesystem HFS+, Microsoft's NTFS, AIX (jfs2) and some Linux filesystems, such as btrfs and Ext4, use B-trees.\n\nB-trees are used in the HFS and Reiser4 file systems.\n\nDragonFly BSD's HAMMER file system uses a modified B+-tree.\n\nLehman and Yao showed that all the read locks could be avoided (and thus concurrent access greatly improved) by linking the tree blocks at each level together with a \"next\" pointer. This results in a tree structure where both insertion and search operations descend from the root to the leaf. Write locks are only required as a tree block is modified. This maximizes access concurrency by multiple users, an important consideration for databases and/or other B-tree-based ISAM storage methods. The cost associated with this improvement is that empty pages cannot be removed from the btree during normal operations. (However, see for various strategies to implement node merging, and source code at.)\n\nUnited States Patent 5283894, granted in 1994, appears to show a way to use a 'Meta Access Method' to allow concurrent B+ tree access and modification without locks. The technique accesses the tree 'upwards' for both searches and updates by means of additional in-memory indexes that point at the blocks in each level in the block cache. No reorganization for deletes is needed and there are no 'next' pointers in each block as in Lehman and Yao.\n\nRudolf Bayer and Ed McCreight invented the B-tree while working at Boeing Research Labs in 1971 , but did not explain what, if anything, the \"B\" stands for: \"Boeing\", \"balanced\", \"broad\", \"bushy\", and \"Bayer\" have been suggested. McCreight has said that \"the more you think about what the B in B-trees means, the better you understand B-trees.\"\n\n\n\n\n\n"}
