{"id": "18309", "url": "https://en.wikipedia.org/wiki?curid=18309", "title": "Lucifer", "text": "Lucifer\n\nLucifer ( ; \"light-bringer\") was a Latin name for the planet Venus as the morning star in the ancient Roman era, and is often used for mythological and religious figures associated with the planet. Due to the unique movements and discontinuous appearances of Venus in the sky, mythology surrounding these figures often involved a fall from the heavens to earth or the underworld. Interpretations of a similar term in the Hebrew Bible, translated in the King James Version as \"Lucifer\", led to a Christian tradition of applying the name Lucifer and its associated stories of a fall from heaven to Satan. Most modern scholarship regards these interpretations as questionable, and translate the term in the relevant Bible passage as \"morning star\" or \"shining one\" rather than as a proper name, \"Lucifer\".\n\nAs a name for the devil, the more common meaning in English, \"Lucifer\" is the rendering of the Hebrew word in Isaiah () given in the King James Version of the Bible. The translators of this version took the word from the Latin Vulgate, which translated הֵילֵל by the Latin word \"lucifer\" (uncapitalized), meaning \"the morning star, the planet Venus\", or, as an adjective, \"light-bringing\".\n\nAs a name for the morning star, \"Lucifer\" is a proper name and is capitalized in English. In Greco-Roman civilization the morning star was often personified and considered a god or the title of a deity associated with the planet.\n\nThe motif of a heavenly being striving for the highest seat of heaven only to be cast down to the underworld has its origins in the motions of the planet Venus, known as the morning star.\n\nThe Sumerian goddess Inanna (Babylonian Ishtar) is associated with the planet Venus. Inanna's actions in several of her myths, including \"Inanna and Shukaletuda\" and \"Inanna's Descent into the Underworld\" appear to parallel the motion of Venus as it progresses through its synodic cycle. For example, in \"Inanna's Descent to the Underworld\", Inanna is able to descend into the netherworld, where she is killed, and then resurrected three days later to return to the heavens. The three-day disappearance of Inanna refers to the three-day planetary disappearance of Venus between its appearance as a morning and evening star.\n\nA similar theme is present in the Babylonian myth of Etana. The \"Jewish Encyclopedia\" comments:\n\nThe fall from heaven motif also has a parallel in Canaanite mythology. In ancient Canaanite religion, the morning star is personified as the god Attar, who attempted to occupy the throne of Ba'al and, finding he was unable to do so, descended and ruled the underworld. The original myth may have been about a lesser god Helel trying to dethrone the Canaanite high god El who lived on a mountain to the north. Hermann Gunkel's reconstruction of the myth told of a mighty warrior called Hêlal, whose ambition was to ascend higher than all the other stellar divinities, but who had to descend to the depths; it thus portrayed as a battle the process by which the bright morning star fails to reach the highest point in the sky before being faded out by the rising sun. However, the Eerdmans Commentary on the Bible argues that no evidence has been found of any Canaanite myth or imagery of a god being forcibly thrown from heaven, as in the \"Book of Isaiah\" (see below). It argues that the closest parallels with \"Isaiah\"'s description of the king of Babylon as a fallen morning star cast down from heaven are to be found not in Canaanite myths but in traditional ideas of the Jewish people, echoed in the Biblical account of the fall of Adam and Eve, cast out of God's presence for wishing to be as God, and the picture in of the \"gods\" and \"sons of the Most High\" destined to die and fall. This Jewish tradition has echoes also in Jewish pseudepigrapha such as 2 Enoch and the \"Life of Adam and Eve\". The \"Life of Adam and Eve\", in turn, shaped the idea of Iblis in the Quran.\n\nThe Greek myth of Phaethon, a personification of the planet Jupiter, follows a similar pattern.\n\nIn classical mythology, Lucifer (\"light-bringer\" in Latin) was the name of the planet Venus, though it was often personified as a male figure bearing a torch. The Greek name for this planet was variously Phosphoros (also meaning \"light-bringer\") or Heosphoros (meaning \"dawn-bringer\"). Lucifer was said to be \"the fabled son of Aurora and Cephalus, and father of Ceyx\". He was often presented in poetry as heralding the dawn.\n\nThe second century Roman mythographer Pseudo-Hyginus said of the planet: \n\nOvid, in his first century epic \"Metamorphoses\", describes Lucifer as ordering the heavens:\n\nIn the classical Roman period, Lucifer was not typically regarded as a deity and had few, if any, myths, though the planet was associated with various deities and often poetically personified. Cicero pointed out that \"You say that Sol the Sun and Luna the Moon are deities, and the Greeks identify the former with Apollo and the latter with Diana. But if Luna (the Moon) is a goddess, then Lucifer (the Morning-Star) also and the rest of the Wandering Stars (Stellae Errantes) will have to be counted gods; and if so, then the Fixed Stars (Stellae Inerrantes) as well.\"\n\nIn the Book of Isaiah, chapter 14, the King of Babylon is condemned in a prophetic vision by the prophet Isaiah and is called (, Hebrew for \"shining one, son of the morning\"). who is addressed as הילל בן שחר (\"Hêlêl ben Šāḥar\"), The title \"\"Helel ben Shahar\"\" may refer to the planet Venus as the morning star, but the text in Isaiah 14 gives no indication that Helel is the name of a star or planet. The Hebrew word transliterated as \"Hêlêl\" or \"Heylel\" (pron. as \"Hay-LALE\"), occurs only once in the Hebrew Bible. The Septuagint renders הֵילֵל in Greek as Ἑωσφόρος (\"heōsphoros\"), \"bringer of dawn\", the Ancient Greek name for the morning star. According to the King James Bible-based Strong's Concordance, the original Hebrew word means \"shining one, light-bearer\", and the translation given in the King James text is the Latin name for the planet Venus, \"Lucifer\".\n\nHowever, the translation of הֵילֵל as \"Lucifer\" has been abandoned in modern English translations of Isaiah 14:12. Present-day translations render הֵילֵל as \"morning star\" (New International Version, New Century Version, New American Standard Bible, Good News Translation, Holman Christian Standard Bible, Contemporary English Version, Common English Bible, Complete Jewish Bible), \"daystar\" (New Jerusalem Bible, The Message), \"Day Star\" (New Revised Standard Version, English Standard Version), \"shining one\" (New Life Version, New World Translation, JPS Tanakh), or \"shining star\" (New Living Translation). \n\nIn a modern translation from the original Hebrew, the passage in which the phrase \"Lucifer\" or \"morning star\" occurs begins with the statement: \"On the day the Lord gives you relief from your suffering and turmoil and from the harsh labour forced on you, you will take up this taunt against the king of Babylon: How the oppressor has come to an end! How his fury has ended!\" After describing the death of the king, the taunt continues:\n\nJ. Carl Laney has pointed out that in the final verses here quoted, the king of Babylon is described not as a god or an angel but as a man; and that man may have been not Nebuchadnezzar II, but rather his son, Belshazzar. Nebuchadnezzar was gripped by a spiritual fervor to build a temple to the moon god Sin (possibly analogous with Hubal, the primary god of pre-Islamic Mecca), and his son ruled as regent. The Abrahamic scriptural texts could be interpreted as a weak usurping of true kingly power, and a taunt at the failed regency of Belshazzar.\n\nFor the unnamed \"king of Babylon\" a wide range of identifications have been proposed. They include a Babylonian ruler of the prophet Isaiah's own time the later Nebuchadnezzar II, under whom the Babylonian captivity of the Jews began, or Nabonidus, and the Assyrian kings Tiglath-Pileser, Sargon II and Sennacherib. Verse 20 says that this king of Babylon will not be \"joined with them [all the kings of the nations] in burial, because thou hast destroyed thy land, thou hast slain thy people; the seed of evil-doers shall not be named for ever\", but rather be cast out of the grave, while \"All the kings of the nations, all of them, sleep in glory, every one in his own house\", pointing to Nebuchadnezzar II as a possible interpretation. Herbert Wolf held that the \"king of Babylon\" was not a specific ruler but a generic representation of the whole line of rulers.\n\nIsaiah 14:12 became a source for the popular conception of the fallen angel motif seen later in 1 Enoch 86–90 and 2 Enoch 29:3–4. Rabbinical Judaism has rejected any belief in rebel or fallen angels. In the 11th century, the \"Pirqe de-Rabbi Eliezer\" illustrates the origin of the \"fallen angel myth\" by giving two accounts, one relates to the angel in the Garden of Eden who seduces Eve, and the other relates to the angels, the \"benei elohim\" who cohabit with the daughters of man (Genesis 6:1–4). An association of Isaiah 14:12–18 with a personification of evil, called the devil developed outside of mainstream Rabbinic Judaism in pseudepigrapha and Christian writings, particularly with the apocalypses.\n\nSome Christian writers have applied the name \"Lucifer\" as used in the Book of Isaiah, and the motif of a heavenly being cast down to the earth, to Satan. Sigve K Tonstad argues that the New Testament War in Heaven theme of , in which the dragon \"who is called the devil and Satan … was thrown down to the earth\", was derived from the passage about the Babylonian king in Isaiah 14. Origen (184/185 – 253/254) interpreted such Old Testament passages as being about manifestations of the Devil; but writing in Greek, not Latin, he did not identify the devil with the name \"Lucifer\". Tertullian (c. 160 – c. 225), who wrote in Latin, also understood (\"I will ascend above the tops of the clouds; I will make myself like the Most High\") as spoken by the Devil, but \"Lucifer\" is not among the numerous names and phrases he used to describe the devil. Even at the time of the Latin writer Augustine of Hippo (354–430), \"Lucifer\" had not yet become a common name for the Devil.\n\nSome time later, the metaphor of the morning star that Isaiah 14:12 applied to a king of Babylon gave rise to the general use of the Latin word for \"morning star\", capitalized, as the original name of the devil before his fall from grace, linking Isaiah 14:12 with (\"I saw Satan fall like lightning from heaven\") and interpreting the passage in Isaiah as an allegory of Satan's fall from heaven.\n\nAs a result, \"Lucifer has become a byword for Satan or the Devil in the church and in popular literature\", as in Dante Alighieri's \"Inferno\", Joost van den Vondel's \"Lucifer\", and John Milton's \"Paradise Lost\". However, unlike the English word, the Latin word was not used exclusively in this way and was applied to others also, including Jesus. \n\nAdherents of the King James Only movement and others who hold that Isaiah 14:12 does indeed refer to the devil have decried the modern translations. Jealousy of humans, created in the divine image and given authority over the world is the motive that a modern writer, who denies that there is any such person as Lucifer, says that Tertullian attributed to the devil, and, while he cited Tertullian and Augustine as giving envy as the motive for the fall, an 18th-century French Capuchin preacher himself described the rebel angel as jealous of Adam's exaltation, which he saw as a diminution of his own status.\n\nHowever, the understanding of the morning star in Isaiah 14:12 as a metaphor referring to a king of Babylon continued also to exist among Christians. Theodoret of Cyrus (c. 393 – c. 457) wrote that Isaiah calls the king \"morning star\", not as being the star, but as having had the illusion of being it. The same understanding is shown in Christian translations of the passage, which in English generally use \"morning star\" rather than treating the word as a proper name, \"Lucifer\". So too in other languages, such as French, German, Portuguese, and Spanish. Even the Vulgate text in Latin is printed with lower-case \"lucifer\" (morning star), not upper-case \"Lucifer\" (proper name).\n\nCalvin said: \"The exposition of this passage, which some have given, as if it referred to Satan, has arisen from ignorance: for the context plainly shows these statements must be understood in reference to the king of the Babylonians.\" Luther also considered it a gross error to refer this verse to the devil.\nIn the Bogomil and Cathar text \"Gospel of the secret supper\", Lucifer is a glorified angel and the older brother of Jesus, but fell from heaven to establish his own kingdom and became the Demiurge. Therefore, he created the material world and trapped souls from heaven inside matter. Jesus descended to earth to free the captured souls. In contrast to mainstream Christianity, the cross was denounced as a symbol of Lucifer and his instrument in an attempt to kill Jesus.\n\nLucifer is regarded within The Church of Jesus Christ of Latter-day Saints as the pre-mortal name of the devil. Mormon theology teaches that in a heavenly council, Lucifer rebelled against the plan of God the Father and was subsequently cast out. The Church’s scripture reads:\"And this we saw also, and bear record, that an angel of God who was in authority in the presence of God, who rebelled against the Only Begotten Son whom the Father loved and who was in the bosom of the Father, was thrust down from the presence of God and the Son, and was called Perdition, for the heavens wept over him—he was Lucifer, a son of the morning. And we beheld, and lo, he is fallen! is fallen, even a son of the morning! And while we were yet in the Spirit, the Lord commanded us that we should write the vision; for we beheld Satan, that old serpent, even the devil, who rebelled against God, and sought to take the kingdom of our God and his Christ—Wherefore, he maketh war with the saints of God, and encompasseth them round about.\"After becoming Satan by his fall, Lucifer \"goeth up and down, to and fro in the earth, seeking to destroy the souls of men\". Members of the Church of Jesus Christ of Latter-Day Saints consider Isaiah 14:12 to be referring to both the king of the Babylonians and the devil.\n\nOther instances of \"lucifer\" in the Old Testament pseudepigrapha are related to the \"star\" Venus, in the Sibylline Oracles battle of the constellations (line 517) \"Lucifer fought mounted on the back of Leo\", or the entirely rewritten Christian version of the Greek Apocalypse of Ezra 4:32 which has a reference to Lucifer as Antichrist.\n\nIndications that in Christian tradition the Latin word \"lucifer\", unlike the English word, did not necessarily call a fallen angel to mind exist also outside the text of the Vulgate. Two bishops bore that name: Saint Lucifer of Cagliari, and Lucifer of Siena.\n\nIn Latin, the word is applied to John the Baptist and is used as a title of Jesus himself in several early Christian hymns. The morning hymn \"Lucis largitor splendide\" of Hilary contains the line: \"\"Tu verus mundi lucifer\"\" (you are the true light bringer of the world). Some interpreted the mention of the morning star (\"lucifer\") in Ambrose's hymn \"Aeterne rerum conditor\" as referring allegorically to Jesus and the mention of the cock, the herald of the day (\"praeco\") in the same hymn as referring to John the Baptist. Likewise, in the medieval hymn \"Christe qui lux es et dies\", some manuscripts have the line \"Lucifer lucem proferens\".\n\nThe Latin word \"lucifer\" is also used of Jesus in the Easter Proclamation prayer to God regarding the paschal candle: \"Flammas eius lucifer matutinus inveniat: ille, inquam, lucifer, qui nescit occasum. Christus Filius tuus, qui, regressus ab inferis, humano generi serenus illuxit, et vivit et regnat in saecula saeculorum\" (\"May this flame be found still burning by the Morning Star: the one Morning Star who never sets, Christ your Son, who, coming back from death's domain, has shed his peaceful light on humanity, and lives and reigns for ever and ever\"). In the works of Latin grammarians, Lucifer, like Daniel, was discussed as an example of a personal name.\n\nRudolf Steiner's writings, which formed the basis for Anthroposophy, characterised Lucifer as a spiritual opposite to Ahriman, with Christ between the two forces, mediating a balanced path for humanity. Lucifer represents an intellectual, imaginative, delusional, otherworldly force which might be associated with visions, subjectivity, psychosis and fantasy. He associated Lucifer with the religious/philosophical cultures of Egypt, Rome and Greece. Steiner believed that Lucifer, as a supersensible Being, had incarnated in China about 3000 years before the birth of Christ.\n\nLuciferianism is a belief system that venerates the essential characteristics that are affixed to Lucifer. The tradition, influenced by Gnosticism, usually reveres Lucifer not as the devil, but as a liberator, a guardian or guiding spirit or even the true god as opposed to Jehovah.\n\nIn Anton LaVey's \"The Satanic Bible\", Lucifer is one of the four crown princes of hell, particularly that of the East, the 'lord of the air', and is called the bringer of light, the morning star, intellectualism, and enlightenment. The title 'lord of the air' is based upon Ephesians 2:2, which uses the phrase 'prince of the power of the air' to refer to the pagan god Zeus, but that phrase later became conflated with Satan.\n\nAuthor Michael W. Ford has written on Lucifer as a \"mask\" of the adversary, a motivator and illuminating force of the mind and subconscious.\n\nLéo Taxil (1854–1907) claimed that Freemasonry is associated with worshipping Lucifer. In what is known as the Taxil hoax, he alleged that leading Freemason Albert Pike had addressed \"The 23 Supreme Confederated Councils of the world\" (an invention of Taxil), instructing them that Lucifer was God, and was in opposition to the evil god Adonai. Supporters of Freemasonry contend that, when Albert Pike and other Masonic scholars spoke about the \"Luciferian path,\" or the \"energies of Lucifer,\" they were referring to the Morning Star, the light bearer, the search for light; the very antithesis of dark, satanic evil. Taxil promoted a book by Diana Vaughan (actually written by himself, as he later confessed publicly) that purported to reveal a highly secret ruling body called the Palladium, which controlled the organization and had a satanic agenda. As described by \"Freemasonry Disclosed\" in 1897:\nTaxil's work and Pike's address continue to be quoted by anti-masonic groups.\n\nIn \"Devil-Worship in France\", Arthur Edward Waite compared Taxil's work to today's tabloid journalism, replete with logical and factual inconsistencies.\n\nIn a collection of folklore and magical practices supposedly collected in Italy by Charles Godfrey Leland and published in his \"Aradia, or the Gospel of the Witches\", the figure of Lucifer is featured prominently as both the brother and consort of the goddess Diana, and father of Aradia, at the center of an alleged Italian witch-cult. In Leland's mythology, Diana pursued her brother Lucifer across the sky as a cat pursues a mouse. According to Leland, after dividing herself into light and darkness:\n\nHere, the motions of Diana and Lucifer once again mirror the celestial motions of the moon and Venus, respectively. Though Leland's Lucifer is based on the classical personification of the planet Venus, he also incorporates elements from Christian tradition, as in the following passage: \n\nIn the several modern Wiccan traditions based in part on Leland's work, the figure of Lucifer is usually either omitted or replaced as Diana's consort with either the Etruscan god Tagni, or Dianus (Janus, following the work of folklorist James Frazer in \"The Golden Bough\").\n\n\n"}
{"id": "18310", "url": "https://en.wikipedia.org/wiki?curid=18310", "title": "Lambda phage", "text": "Lambda phage\n\nEnterobacteria phage λ (lambda phage, coliphage λ, officially Escherichia virus Lambda) is a bacterial virus, or bacteriophage, that infects the bacterial species \"Escherichia coli\" (\"E. coli\"). It was discovered by Esther Lederberg in 1950 when she noticed that streaks of mixtures of two \"E. coli\" strains, one of which treated with ultraviolet light, was \"nibbled and plaqued\". The wild type of this virus has a temperate lifecycle that allows it to either reside within the genome of its host through lysogeny or enter into a lytic phase (during which it kills and lyses the cell to produce offspring); mutant strains are unable to lysogenize cells – instead, they grow and enter the lytic cycle after superinfecting an already lysogenized cell.\n\nThe phage particle consists of a head (also known as a capsid), a tail, and tail fibers (see image of virus below). The head contains the phage's double-strand linear DNA genome. During infection, the phage particle recognizes and binds to its host, \"E. coli\", causing DNA in the head of the phage to be ejected through the tail into the cytoplasm of the bacterial cell. Usually, a \"lytic cycle\" ensues, where the lambda DNA is replicated and new phage particles are produced within the cell. This is followed by cell lysis, releasing the cell contents, including virions that have been assembled, into the environment. However, under certain conditions, the phage DNA may integrate itself into the host cell chromosome in the lysogenic pathway. In this state, the λ DNA is called a prophage and stays resident within the host's genome without apparent harm to the host. The host is termed a lysogen when a prophage is present. This prophage may enter the lytic cycle when the lysogen enters a stressed condition.\n\nThe virus particle consists of a head and a tail that can have tail fibers. The whole particle consists of 12–14 different proteins with more than 1000 protein molecules total and one DNA molecule located in the phage head. However, it is still not entirely clear whether the L and M proteins are part of the virion.\n\nThe genome contains 48,490 base pairs of double-stranded, linear DNA, with 12-base single-strand segments at both 5' ends. These two single-stranded segments are the \"sticky ends\" of what is called the \"cos\" site. The \"cos\" site circularizes the DNA in the host cytoplasm. In its circular form, the phage genome, therefore, is 48,502 base pairs in length. The lambda genome can be inserted into the \" E. coli\" chromosome and is then called a prophage. See section below for details.\n\nLambda phage is a non-contractile tailed phage, meaning during an infection event it cannot 'force' its DNA through a bacterial cell membrane. It must instead use an existing pathway to invade the host cell, having evolved the tip of its tail to interact with a specific pore to allow entry of its DNA to the hosts.\n\n\n\nOn initial infection, the stability of cII determines the lifestyle of the phage; stable cII will lead to the lysogenic pathway, whereas if cII is degraded the phage will go into the lytic pathway. Low temperature, starvation of the cells and high multiplicity of infection (MOI) are known to favor lysogeny (see later discussion).\n\nThis occurs without the N protein interacting with the DNA; the protein instead binds to the freshly transcribed mRNA. Nut sites contain 3 conserved \"boxes,\" of which only BoxB is essential.\n\nThis is the lifecycle that the phage follows following most infections, where the cII protein does not reach a high enough concentration due to degradation, so does not activate its promoters.\n\nRightward transcription expresses the O, P and Q genes. O and P are responsible for initiating replication, and Q is another antiterminator that allows the expression of head, tail, and lysis genes from \"P\".\n\n\nQ is similar to N in its effect: Q binds to RNA polymerase in \"Qut\" sites and the resulting complex can ignore terminators, however the mechanism is very different; the Q protein first associates with a DNA sequence rather than an mRNA sequence.\n\nLeftward transcription expresses the \"gam\", \"red\", \"xis\", and \"int\" genes. Gam and red proteins are involved in recombination. Gam is also important in that it inhibits the host RecBCD nuclease from degrading the 3’ ends in rolling circle replication. Int and xis are integration and excision proteins vital to lysogeny.\n\n\nThe lysogenic lifecycle begins once the cI protein reaches a high enough concentration to activate its promoters, after a small number of infections.\n\nThe prophage is duplicated with every subsequent cell division of the host. The phage genes expressed in this dormant state code for proteins that repress expression of other phage genes (such as the structural and lysis genes) in order to prevent entry into the lytic cycle. These repressive proteins are broken down when the host cell is under stress, resulting in the expression of the repressed phage genes. Stress can be from starvation, poisons (like antibiotics), or other factors that can damage or destroy the host. In response to stress, the activated prophage is excised from the DNA of the host cell by one of the newly expressed gene products and enters its lytic pathway.\n\nThe integration of phage λ takes place at a special attachment site in the bacterial and phage genomes, called \"att\". The sequence of the bacterial att site is called \"attB\", between the \"gal\" and \"bio\" operons, and consists of the parts B-O-B', whereas the complementary sequence in the circular phage genome is called \"attP\" and consists of the parts P-O-P'. The integration itself is a sequential exchange (see genetic recombination) via a Holliday junction and requires both the phage protein Int and the bacterial protein IHF (\"integration host factor\"). Both Int and IHF bind to \"attP\" and form an intasome, a DNA-protein-complex designed for site-specific recombination of the phage and host DNA. The original B-O-B' sequence is changed by the integration to B-O-P'-phage DNA-P-O-B'. The phage DNA is now part of the host's genome.\n\n\n\nThe classic induction of a lysogen involved irradiating the infected cells with UV light. Any situation where a lysogen undergoes DNA damage or the SOS response of the host is otherwise stimulated leads to induction.\n\nMultiplicity reactivation (MR) is the process by which multiple viral genomes, each containing inactivating genome damage, interact within an infected cell to form a viable viral genome. MR was originally discovered with phage T4, but was subsequently found in phage λ (as well as in numerous other bacterial and mammalian viruses). MR of phage λ inactivated by UV light depends on the recombination function of either the host or of the infecting phage. Absence of both recombination systems leads to a loss of MR.\n\nSurvival of UV-irradiated phage λ is increased when the E. coli host is lysogenic for an homologous prophage, a phenomenon termed prophage reactivation. Prophage reactivation in phage λ appears to occur by a recombinational repair process similar to that of MR.\n\nThe repressor found in the phage lambda is a notable example of the level of control possible over gene expression by a very simple system. It forms a 'binary switch' with two genes under mutually exclusive expression, as discovered by Barbara J. Meyer.\n\nThe lambda repressor gene system consists of (from left to right on the chromosome):\n\nThe lambda repressor is a self assembling dimer also known as the cI protein. It binds DNA in the helix-turn-helix binding motif. It regulates the transcription of the cI protein and the Cro protein.\n\nThe life cycle of lambda phages is controlled by cI and Cro proteins. The lambda phage will remain in the lysogenic state if cI proteins predominate, but will be transformed into the lytic cycle if cro proteins predominate.\n\nThe cI dimer may bind to any of three operators, O1, O2, and O3, in the order O1 = O2 > O3.\nBinding of a cI dimer to O1 enhances binding of a second cI dimer to O2, an effect called cooperativity. Thus, O1 and O2 are almost always simultaneously occupied by cI. However, this does not increase the affinity between cI and O3, which will be occupied only when the cI concentration is high.\n\nAt high concentrations of cI, the dimers will also bind to operators O1 and O2 (which are over 2 kb downstream from the R operators). When cI dimers are bound to O1, O2, O1, and O2 a loop is induced in the DNA, allowing these dimers to bind together to form an octamer. This is a phenomenon called \"long-range cooperativity\". Upon formation of the octamer, cI dimers may cooperatively bind to O3 and O3, repressing transcription of cI. This \"autonegative\" regulation ensures a stable minimum concentration of the repressor molecule and, should SOS signals arise, allows for more efficient prophage induction.\n\nAn important distinction here is that between the two decisions; lysogeny and lysis on infection, and continuing lysogeny or lysis from a prophage. The latter is determined solely by the activation of RecA in the SOS response of the cell, as detailed in the section on induction. The former will also be affected by this; a cell undergoing an SOS response will always be lysed, as no cI protein will be allowed to build up. However, the initial lytic/lysogenic decision on infection is also dependent on the cII and cIII proteins.\n\nIn cells with sufficient nutrients, protease activity is high, which breaks down cII. This leads to the lytic lifestyle. In cells with limited nutrients, protease activity is low, making cII stable. This leads to the lysogenic lifestyle. cIII appears to stabilize cII, both directly and by acting as a competitive inhibitor to the relevant proteases. This means that a cell \"in trouble\", i.e. lacking in nutrients and in a more dormant state, is more likely to lysogenise. This would be selected for because the phage can now lie dormant in the bacterium until it falls on better times, and so the phage can create more copies of itself with the additional resources available and with the more likely proximity of further infectable cells.\n\nA full biophysical model for lambda's lysis-lysogeny decision remains to be developed. Computer modeling and simulation suggest that random processes during infection drive the selection of lysis or lysogeny within individual cells. However, recent experiments suggest that physical differences among cells, that exist prior to infection, predetermine whether a cell will lyse or become a lysogen.\n\nLambda phage has been used heavily as a model organism, and has been a rich source for useful tools in microbial genetics, and later in molecular genetics. Uses include its application as a vector for the cloning of recombinant DNA; the use of its site-specific recombinase (int) for the shuffling of cloned DNAs by the gateway method; and the application of its Red operon, including the proteins Red alpha (also called 'exo'), beta and gamma in the DNA engineering method called recombineering. The 48 kb DNA fragment of lambda phage is not essential for productive infection and can be replaced by foreign DNA. Lambda phage will enter bacteria more easily than plasmids making it a useful vector that can destroy or can become part of the host's DNA. Lambda phage can be manipulated and used as an anti-cancer vaccine, nanoparticle, targeting human aspartyl (asparaginyl) β-hydroxylase (HAAH). Lambda phage has also been of major importance in the study of specialized transduction.\n\n\n\n"}
{"id": "18313", "url": "https://en.wikipedia.org/wiki?curid=18313", "title": "Louis Armstrong", "text": "Louis Armstrong\n\nLouis Daniel Armstrong (August 4, 1901 – July 6, 1971), nicknamed Satchmo, Satch, and Pops, was an American trumpeter, composer, vocalist and occasional actor who was one of the most influential figures in jazz. His career spanned five decades, from the 1920s to the 1960s, and different eras in the history of jazz. In 2017, he was inducted into the Rhythm & Blues Hall of Fame.\n\nArmstrong was born and raised in New Orleans. Coming to prominence in the 1920s as an \"inventive\" trumpet and cornet player, Armstrong was a foundational influence in jazz, shifting the focus of the music from collective improvisation to solo performance. Around 1922, he followed his mentor, Joe \"King\" Oliver, to Chicago to play in the Creole Jazz Band. In the Windy City, he networked with other popular jazz musicians, reconnecting with his friend, Bix Beiderbecke, and made new contacts, which included Hoagy Carmichael and Lil Hardin. He earned a reputation at \"cutting contests\", and relocated to New York in order to join Fletcher Henderson's band.\n\nWith his instantly recognizable rich, gravelly voice, Armstrong was also an influential singer, demonstrating great dexterity as an improviser, bending the lyrics and melody of a song for expressive purposes. He was also very skilled at scat singing. Armstrong is renowned for his charismatic stage presence and voice almost as much as for his trumpet playing. Armstrong's influence extends well beyond jazz, and by the end of his career in the 1960s, he was widely regarded as a profound influence on popular music in general. Armstrong was one of the first truly popular African-American entertainers to \"cross over\", that is, whose skin color became secondary to his music in an America that was extremely racially divided at the time. He rarely publicly politicized his race, often to the dismay of fellow African Americans, but took a well-publicized stand for desegregation in the Little Rock crisis. His artistry and personality allowed him access to the upper echelons of American society, then highly restricted for black men.\n\nArmstrong often stated that he was born on July 4, 1900. Although he died in 1971, it was not until the mid-1980s that his true birth date, August 4, 1901, was discovered by Tad Jones by researching baptismal records. At least three other biographies treat the July 4th birth date as a myth.\n\nArmstrong was born in New Orleans on August 4, 1901 to Mary Albert and William Armstrong. Albert was from Boutte, Louisiana, and gave birth at home when she was about sixteen. William Armstrong abandoned the family shortly after. About two years later, he had a daughter, Beatrice \"Mama Lucy\" Armstrong, who was raised by Albert.\n\nLouis Armstrong was raised by his grandmother until the age of five when he was returned to his mother. He spent his youth in poverty in a rough neighborhood known as The Battlefield. At six he attended the Fisk School for Boys, a school that accepted black children in the racially segregated system of New Orleans. He did odd jobs for the Karnoffskys, a family of Lithuanian Jews. While selling coal in Storyville, he heard spasm bands, groups that played music out of household objects. He heard the early sounds of jazz from bands that played in brothels and dance halls such as Pete Lala's, where King Oliver performed.\n\nThe Karnoffskys took him in and treated him like family. Knowing he lived without a father, they fed and nurtured him. In his memoir \"Louis Armstrong + the Jewish Family in New Orleans, La., the Year of 1907\", he described his discovery that this family was also subject to discrimination by \"other white folks\" who felt that they were better than Jews: \"I was only seven years old but I could easily see the ungodly treatment that the white folks were handing the poor Jewish family whom I worked for.\" He wore a Star of David pendant for the rest of his life and wrote about what he learned from them: \"how to live—real life and determination.\" His first musical performance may have been at the side of the Karnoffsky's junk wagon. To distinguish them from other hawkers, he tried playing a tin horn to attract customers. Morris Karnoffsky gave Armstrong an advance toward the purchase of a cornet from a pawn shop.\n\nWhen Armstrong was eleven, he dropped out of school. His mother moved into a one-room house on Perdido Street with him, Lucy, and her common-law husband, Tom Lee, next door to her brother Ike and his two sons. Armstrong joined a quartet of boys who sang in the streets for money. He also got into trouble. Cornetist Bunk Johnson said he taught the eleven-year-old to play by ear at Dago Tony's honky tonk. In his later years Armstrong credited King Oliver. He said about his youth, \"Every time I close my eyes blowing that trumpet of mine—I look right in the heart of good old New Orleans ... It has given me something to live for.\"\n\nBorrowing his stepfather's gun without permission, he fired a blank into the air and was arrested on December 31, 1912. He spent the night at New Orleans Juvenile Court, then was sentenced the next day to detention at the Colored Waif's Home. Life at the home was spartan. Mattresses were absent. Meals were often little more than bread and molasses. Captain Joseph Jones ran the home like a military camp and used corporal punishment.\n\nArmstrong developed his cornet skills by playing in the band. Peter Davis, who frequently appeared at the home at the request of Captain Jones, became Armstrong's first teacher and chose him as bandleader. With this band, the thirteen year-old Armstrong attracted the attention of Kid Ory.\n\nOn June 14, 1914, Armstrong was released into the custody of his father and his new stepmother, Gertrude. He lived in this household with two stepbrothers for several months. After Gertrude gave birth to a daughter, Armstrong's father never welcomed him, so he returned to his mother, Mary Albert. In her small home, he had to share a bed with his mother and sister. His mother still lived in The Battlefield, leaving him open to old temptations, but he sought work as a musician. He found a job at a dance hall owned by Henry Ponce, who had connections to organized crime. He met the six-foot tall drummer Black Benny, who became his guide and bodyguard.\n\nArmstrong played in brass band parades in New Orleans. He listened to the music of local musicians such as Kid Ory and his idol, King Oliver.\n\nArmstrong played in brass bands and riverboats in New Orleans, first on an excursion boat in September 1918. He traveled with the band of Fate Marable, which toured on the steamboat \"Sidney\" with the Streckfus Steamers line up and down the Mississippi River. Marable was proud of his musical knowledge, and he insisted that Armstrong and other musicians in his band learn sight reading. Armstrong described his time with Marable as \"going to the University\", since it gave him a wider experience working with written arrangements. He did return to New Orleans periodically. In 1919, Oliver decided to go north and resigned his position in Kid Ory's band; Armstrong replaced him. He also became second trumpet for the Tuxedo Brass Band.\n\nThroughout his riverboat experience, Armstrong's musicianship began to mature and expand. At twenty, he could read music. He became one of the first jazz musicians to be featured on extended trumpet solos, injecting his own personality and style. He started singing in his performances. In 1922, he moved to Chicago at the invitation of King Oliver. With Oliver's Creole Jazz Band he could make enough money to quit his day jobs. Although race relations were poor, Chicago was booming. The city had jobs for blacks making good wages at factories with some left over for entertainment.\n\nOliver's band was among the most influential jazz bands in Chicago in the early 1920s. Armstrong lived luxuriously in his own apartment with his first private bath. Excited as he was to be in Chicago, he began his career-long pastime of writing letters to friends in New Orleans. Armstrong could blow two hundred high Cs in a row. As his reputation grew, he was challenged to cutting contests by other musicians.\n\nHis first studio recordings were with Oliver for Gennett Records on April 56, 1923. They endured several hours on the train to remote Richmond, Indiana, and the band was paid little. The quality of the performances was affected by lack of rehearsal, crude recording equipment, bad acoustics, and a cramped studio. In addition, Richmond was associated with the Ku Klux Klan.\n\nLil Hardin Armstrong urged him to seek more prominent billing and develop his style apart from the influence of Oliver. She encouraged him to play classical music in church concerts to broaden his skills. She prodded him into wearing more stylish attire to offset his girth. Her influence eventually undermined Armstrong's relationship with his mentor, especially concerning his salary and additional money that Oliver held back from Armstrong and other band members.\n\nArmstrong and Oliver parted amicably in 1924. Shortly afterward, Armstrong received an invitation to go to New York City to play with the Fletcher Henderson Orchestra, the top African-American band of the time. He switched to the trumpet to blend in better with the other musicians in his section. His influence on Henderson's tenor sax soloist, Coleman Hawkins, can be judged by listening to the records made by the band during this period.\n\nArmstrong adapted to the tightly controlled style of Henderson, playing trumpet and experimenting with the trombone. The other members were affected by Armstrong's emotional style. His act included singing and telling tales of New Orleans characters, especially preachers. The Henderson Orchestra played in prominent venues for patrons only, including the Roseland Ballroom, with arrangements by Don Redman. Duke Ellington's orchestra went to Roseland to catch Armstrong's performances. Young musicians tried to outplay him but split their lips in their attempts.\n\nDuring this time, Armstrong recorded with Clarence Williams (a friend from New Orleans), the Williams Blue Five, Sidney Bechet, and blues singers Alberta Hunter, Ma Rainey, and Bessie Smith.\n\nIn 1925, Armstrong returned to Chicago largely at the insistence of Lil, who wanted to expand his career and his income. In publicity, much to his chagrin, she billed him as \"the World's Greatest Trumpet Player\". For a time he was a member of the Lil Hardin Armstrong Band and working for his wife. He formed Louis Armstrong and his Hot Five and recorded the hits \"Potato Head Blues\" and \"Muggles\". The word \"muggles\" was a slang term for marijuana, something he used often during his life.\n\nThe Hot Five included Kid Ory (trombone), Johnny Dodds (clarinet), Johnny St. Cyr (banjo), Lil Armstrong on piano, and usually no drummer. Over a twelve-month period starting in November 1925, this quintet produced twenty-four records. Armstrong's band leading style was easygoing, as St. Cyr noted, \"One felt so relaxed working with him, and he was very broad-minded ... always did his best to feature each individual.\" Among the most notable of the Hot Five and Seven records were \"Cornet Chop Suey\", \"Struttin' With Some Barbecue\", \"Hotter Than that\" and \"Potato Head Blues\", all featuring highly creative solos by Armstrong. His recordings soon after with pianist Earl \"Fatha\" Hines (most famously their 1928 \"Weather Bird\" duet) and Armstrong's trumpet introduction to and solo in \"West End Blues\" remain some of the most famous and influential improvisations in jazz history. Armstrong was now free to develop his personal style as he wished, which included a heavy dose of effervescent jive, such as \"Whip That Thing, Miss Lil\" and \"Mr. Johnny Dodds, Aw, Do That Clarinet, Boy!\"\n\nArmstrong also played with Erskine Tate's Little Symphony, which played mostly at the Vendome Theatre. They furnished music for silent movies and live shows, including jazz versions of classical music, such as \"Madame Butterfly\", which gave Armstrong experience with longer forms of music and with hosting before a large audience. He began to scat sing (improvised vocal jazz using nonsensical words) and was among the first to record it, on the Hot Five recording \"Heebie Jeebies\" in 1926. The recording was so popular that the group became the most famous jazz band in the United States, even though they had not performed live to any great extent. Young musicians across the country, black or white, were turned on by Armstrong's new type of jazz.\n\nAfter separating from Lil, Armstrong started to play at the Sunset Café for Al Capone's associate Joe Glaser in the Carroll Dickerson Orchestra, with Earl Hines on piano, which was renamed Louis Armstrong and his Stompers, though Hines was the music director and Glaser managed the orchestra. Hines and Armstrong became fast friends and successful collaborators.\n\nIn the first half of 1927, Armstrong assembled his Hot Seven group, which added drummer Al \"Baby\" Dodds and tuba player, Pete Briggs, while preserving most of his original Hot Five lineup. John Thomas replaced Kid Ory on trombone. Later that year he organized a series of new Hot Five sessions which resulted in nine more records. In the last half of 1928, he started recording with a new group: Zutty Singleton (drums), Earl Hines (piano), Jimmy Strong (clarinet), Fred Robinson (trombone), and Mancy Carr (banjo).\n\nArmstrong returned to New York in 1929, where he played in the pit orchestra for the musical \"Hot Chocolates\", an all-black revue written by Andy Razaf and pianist Fats Waller. He also made a cameo appearance as a vocalist, regularly stealing the show with his rendition of \"Ain't Misbehavin'\". His version of the song became his biggest selling record to date.\n\nArmstrong started to work at Connie's Inn in Harlem, chief rival to the Cotton Club, a venue for elaborately staged floor shows, and a front for gangster Dutch Schultz. Armstrong also had considerable success with vocal recordings, including versions of famous songs composed by his old friend Hoagy Carmichael. His 1930s recordings took full advantage of the new RCA ribbon microphone, introduced in 1931, which imparted a characteristic warmth to vocals and immediately became an intrinsic part of the 'crooning' sound of artists like Bing Crosby. Armstrong's famous interpretation of Carmichael's \"Stardust\" became one of the most successful versions of this song ever recorded, showcasing Armstrong's unique vocal sound and style and his innovative approach to singing songs that had already become standards.\n\nArmstrong's radical re-working of Sidney Arodin and Carmichael's \"Lazy River\" (recorded in 1931) encapsulated many features of his groundbreaking approach to melody and phrasing. The song begins with a brief trumpet solo, then the main melody is introduced by sobbing horns, memorably punctuated by Armstrong's growling interjections at the end of each bar: \"Yeah! ...\"Uh-huh\"...\"Sure\"...\"Way down, way down.\" In the first verse, he ignores the notated melody entirely and sings as if playing a trumpet solo, pitching most of the first line on a single note and using strongly syncopated phrasing. In the second stanza he breaks into an almost fully improvised melody, which then evolves into a classic passage of Armstrong \"scat singing\".\n\nAs with his trumpet playing, Armstrong's vocal innovations served as a foundation stone for the art of jazz vocal interpretation. The uniquely gravelly coloration of his voice became a musical archetype that was much imitated and endlessly impersonated. His scat singing style was enriched by his matchless experience as a trumpet soloist. His resonant, velvety lower-register tone and bubbling cadences on sides such as \"Lazy River\" exerted a huge influence on younger white singers such as Bing Crosby.\n\nThe Great Depression of the early 1930s was especially hard on the jazz scene. The Cotton Club closed in 1936 after a long downward spiral, and many musicians stopped playing altogether as club dates evaporated. Bix Beiderbecke died and Fletcher Henderson's band broke up. King Oliver made a few records but otherwise struggled. Sidney Bechet became a tailor, later moving to Paris and Kid Ory returned to New Orleans and raised chickens.\n\nArmstrong moved to Los Angeles in 1930 to seek new opportunities. He played at the New Cotton Club in Los Angeles with Lionel Hampton on drums. The band drew the Hollywood crowd, which could still afford a lavish night life, while radio broadcasts from the club connected with younger audiences at home. Bing Crosby and many other celebrities were regulars at the club. In 1931, Armstrong appeared in his first movie, \"Ex-Flame\" and was also convicted of marijuana possession but received a suspended sentence. He returned to Chicago in late 1931 and played in bands more in the Guy Lombardo vein and he recorded more standards. When the mob insisted that he get out of town, Armstrong visited New Orleans, had a hero's welcome, and saw old friends. He sponsored a local baseball team known as Armstrong's Secret Nine and had a cigar named after him. But soon he was on the road again. After a tour across the country shadowed by the mob, he fled to Europe.\n\nAfter returning to the United States, he undertook several exhausting tours. His agent Johnny Collins's erratic behavior and his own spending ways left Armstrong short of cash. Breach of contract violations plagued him. He hired Joe Glaser as his new manager, a tough mob-connected wheeler-dealer, who began to straighten out his legal mess, his mob troubles, and his debts. Armstrong also began to experience problems with his fingers and lips, which were aggravated by his unorthodox playing style. As a result, he branched out, developing his vocal style and making his first theatrical appearances. He appeared in movies again, including Crosby's 1936 hit \"Pennies from Heaven\". In 1937, Armstrong substituted for Rudy Vallee on the CBS radio network and became the first African American to host a sponsored, national broadcast.\n\nAfter spending many years on the road, Armstrong settled permanently in Queens, New York in 1943 in contentment with his fourth wife, Lucille. Although subject to the vicissitudes of Tin Pan Alley and the gangster-ridden music business, as well as anti-black prejudice, he continued to develop his playing. He recorded Hoagy Carmichael's \"Rockin' Chair\" for Okeh Records.\n\nDuring the next 30 years, Armstrong played more than 300 performances a year. Bookings for big bands tapered off during the 1940s due to changes in public tastes: ballrooms closed, and there was competition from television and from other types of music becoming more popular than big band music. It became impossible under such circumstances to finance a 16-piece touring band.\n\nDuring the 1940s, a widespread revival of interest in the traditional jazz of the 1920s made it possible for Armstrong to consider a return to the small-group musical style of his youth. Following a highly successful small-group jazz concert at New York Town Hall on May 17, 1947, featuring Armstrong with trombonist/singer Jack Teagarden, Armstrong's manager, Joe Glaser dissolved the Armstrong big band on August 13, 1947, and established a six-piece traditional jazz group featuring Armstrong with (initially) Teagarden, Earl Hines and other top swing and Dixieland musicians, most of whom were previously leaders of big bands. The new group was announced at the opening of Billy Berg's Supper Club.\n\nThis group was called Louis Armstrong and His All Stars and included at various times Earl \"Fatha\" Hines, Barney Bigard, Edmond Hall, Jack Teagarden, Trummy Young, Arvell Shaw, Billy Kyle, Marty Napoleon, Big Sid Catlett, Cozy Cole, Tyree Glenn, Barrett Deems, Mort Herbert, Joe Darensbourg, Eddie Shu and percussionist Danny Barcelona. During this period, Armstrong made many recordings and appeared in over thirty films. He was the first jazz musician to appear on the cover of \"Time\" magazine, on February 21, 1949.\n\nBy the 1950s, Armstrong was a widely beloved American icon and cultural ambassador who commanded an international fanbase. However, a growing generation gap became apparent between him and the young jazz musicians who emerged in the postwar era such as Charlie Parker, Miles Davis, and Sonny Rollins. The postwar generation regarded their music as abstract art and considered Armstrong's vaudevillian style, half-musician and half-stage entertainer, outmoded and Uncle Tomism, \"... he seemed a link to minstrelsy that we were ashamed of.\" He called bebop \"Chinese music\". While touring Australia, 1954, he was asked if he could play bebop. \"Bebop?\" he husked. \"I just play music. Guys who invent terms like that are walking the streets with their instruments under their arms.\"\n\nIn June 1950, Suzy Delair performed rehearsals of the song \"C'est si bon\" with Aimé Barelli and his Orchestra at the Monte Carlo casino where Louis Armstrong was finishing the evening. Armstrong enjoyed the song and he recorded the American version in New York City on June 26, 1950. In the 1960s, he toured Ghana and Nigeria.\n\nAfter finishing his contract with Decca Records, he became a freelance artist and recorded for other labels. He continued an intense international touring schedule, but in 1959 he suffered a heart attack in Italy and had to rest.\n\nIn 1964, after over two years without setting foot in a studio, he recorded his biggest-selling record, \"Hello, Dolly!\", a song by Jerry Herman, originally sung by Carol Channing. Armstrong's version remained on the Hot 100 for 22 weeks, longer than any other record produced that year, and went to No. 1 making him, at 62 years, 9 months and 5 days, the oldest person ever to accomplish that feat. In the process, he dislodged the Beatles from the No. 1 position they had occupied for 14 consecutive weeks with three different songs.\n\nArmstrong kept touring well into his 60s, even visiting part of the communist bloc in 1965. He also toured Africa, Europe, and Asia under the sponsorship of the US State Department with great success, earning the nickname \"Ambassador Satch\" and inspiring Dave Brubeck to compose his jazz musical \"The Real Ambassadors\". By 1968, he was approaching 70 and his health began to give out. He suffered heart and kidney ailments that forced him to stop touring. He did not perform publicly at all in 1969 and spent most of the year recuperating at home. Meanwhile, his longtime manager Joe Glaser died. By the summer of 1970, his doctors pronounced him fit enough to resume live performances. He embarked on another world tour, but a heart attack forced him to take a break for two months.\n\nArmstrong made his last recorded trumpet performances on his 1968 album \"Disney Songs the Satchmo Way\".\n\nThe Louis Armstrong House Museum website states:\n\nIn a memoir written for Robert Goffin between 1943 and 1944, Armstrong states, \"All white folks call me Louie\", suggesting that he himself did not. That said, Armstrong was registered as \"Lewie\" for the 1920 U.S. Census. On various live records he's called \"Louie\" on stage, such as on the 1952 \"Can Anyone Explain?\" from the live album \"In Scandinavia vol.1\". \"Lewie\" is the French pronunciation of \"Louis\" and is commonly used in Louisiana.\n\nArmstrong was performing at the Brick House in Gretna, Louisiana when he met Daisy Parker, a local prostitute. He started the affair as a client. He returned to Gretna on several occasions to visit her. He found the courage to look for her home to see her away from work. It was on this occasion that he found out that she had a common-law husband. Not long after this fiasco, Parker traveled to Armstrong's home on Perdido Street. They checked into Kid Green's hotel that evening. On the next day, March 19, 1919, Armstrong and Parker married at City Hall. They adopted a three-year-old boy, Clarence, whose mother, Armstrong's cousin Flora, had died soon after giving birth. Clarence Armstrong was mentally disabled as the result of a head injury at an early age, and Armstrong spent the rest of his life taking care of him. His marriage to Parker ended when they were separated in 1923.\n\nOn February 4, 1924, he married Lil Hardin Armstrong, King Oliver's pianist. She had divorced her first husband a few years earlier. His second wife helped him develop his career, but they separated in 1931 and divorced in 1938. Armstrong then married Alpha Smith. His marriage to his third wife lasted four years, and they divorced in 1942. Louis then married Lucille Wilson in October 1942, a singer at the Cotton Club, to whom he was married until his death in 1971.\n\nArmstrong's marriages never produced any offspring, though he loved children. However, in December 2012, 57-year-old Sharon Preston-Folta claimed to be his daughter from a 1950s affair between Armstrong and Lucille \"Sweets\" Preston, a dancer at the Cotton Club. In a 1955 letter to his manager, Joe Glaser, Armstrong affirmed his belief that Preston's newborn baby was his daughter, and ordered Glaser to pay a monthly allowance of $400 to mother and child.\n\nArmstrong was noted for his colorful and charismatic personality. His autobiography vexed some biographers and historians, as he had a habit of telling tales, particularly of his early childhood when he was less scrutinized, and his embellishments of his history often lack consistency.\n\nIn addition to an entertainer, Armstrong was a leading personality of the day. He was beloved by an American public that gave even the greatest African American performers little access beyond their public celebrity, and he was able to live a private life of access and privilege afforded to few other African Americans during that era.\n\nHe generally remained politically neutral, which at times alienated him from members of the black community who looked to him to use his prominence with white America to become more of an outspoken figure during the civil rights movement. However, he did criticize President Eisenhower for not acting forcefully enough on civil rights.\n\nThe trumpet is a notoriously hard instrument on the lips, and Armstrong suffered from lip damage over much of his life due to his aggressive style of playing and preference for narrow mouthpieces that would stay in place easier, but which tended to dig into the soft flesh of his inner lip. During his 1930s European tour, he suffered an ulceration so severe that he had to stop playing entirely for a year. Eventually he took to using salves and creams on his lips and also cutting off scar tissue with a razor blade. By the 1950s, he was an official spokesman for Ansatz-Creme Lip Salve.\n\nDuring a backstage meeting with trombonist Marshall Brown in 1959, Armstrong received the suggestion that he should go to a doctor and receive proper treatment for his lips instead of relying on home remedies, but he didn't get around to doing it until the final years of his life, by which point his health was failing and doctors considered surgery too risky.\n\nThe nicknames \"Satchmo\" and \"Satch\" are short for \"Satchelmouth\". The nickname has many possible origins. The most common tale that biographers tell is the story of Armstrong as a young boy in New Orleans dancing for pennies. He scooped the coins off the street and stuck them into his mouth to prevent bigger children from stealing them. Someone dubbed him \"satchel mouth\" for his mouth acting as a satchel. Another tale is that because of his large mouth, he was nicknamed \"satchel mouth\" which was shortened to \"Satchmo\".\n\nEarly on he was also known as \"Dipper\", short for \"Dippermouth\", a reference to the piece \"Dippermouth Blues\". and something of a riff on his unusual embouchure.\n\nThe nickname \"Pops\" came from Armstrong's own tendency to forget people's names and simply call them \"Pops\" instead. The nickname was turned on Armstrong himself. It was used as the title of a 2010 biography of Armstrong by Terry Teachout.\n\nArmstrong was largely accepted into white society, both on stage and off, a privilege reserved for very few African-American public figures at the time.\n\nSome musicians criticized Armstrong for playing in front of segregated audiences, and for not taking a strong enough stand in the American civil rights movement. The few exceptions made it more effective when he did speak out. Armstrong's criticism of President Eisenhower, calling him \"two-faced\" and \"gutless\" because of his inaction during the conflict over school desegregation in Little Rock, Arkansas in 1957 made national news. As a protest, Armstrong canceled a planned tour of the Soviet Union on behalf of the State Department saying: \"The way they're treating my people in the South, the government can go to hell\" and that he could not represent his government abroad when it was in conflict with its own people.\n\nThe FBI kept a file on Armstrong for his outspokenness about integration.\n\nWhen asked about his religion, Armstrong answered that he was raised a Baptist, always wore a Star of David, and was friends with the pope. He wore the Star of David in honor of the Karnoffsky family, who took him in as a child and lent him money to buy his first cornet. He was baptized a Catholic in the Sacred Heart of Jesus Church in New Orleans, and he met Pope Pius XII and Pope Paul VI.\n\nArmstrong was concerned with his health. He used laxatives to control his weight, a practice he advocated both to acquaintances and in the diet plans he published under the title \"Lose Weight the Satchmo Way\". Armstrong's laxative of preference in his younger days was Pluto Water, but when he discovered the herbal remedy Swiss Kriss, he became an enthusiastic convert, extolling its virtues to anyone who would listen and passing out packets to everyone he encountered, including members of the British Royal Family. (Armstrong also appeared in humorous, albeit risqué, cards that he had printed to send out to friends; the cards bore a picture of him sitting on a toilet—as viewed through a keyhole—with the slogan \"\"Satch says, 'Leave it all behind ya!'\"\") The cards have sometimes been incorrectly described as ads for Swiss Kriss. In a live recording of \"Baby, It's Cold Outside\" with Velma Middleton, he changes the lyric from \"Put another record on while I pour\" to \"Take some Swiss Kriss while I pour.\"\n\nArmstrong was a heavy marijuana smoker for much of his life and spent nine days in jail in 1930 after being arrested for drug possession outside a club. He described marijuana as \"a thousand times better than whiskey\".\n\nThe concern with his health and weight was balanced by his love of food, reflected in such songs as \"Cheesecake\", \"Cornet Chop Suey\", though \"Struttin' with Some Barbecue\" was written about a fine-looking companion, not about food. He kept a strong connection throughout his life to the cooking of New Orleans, always signing his letters, \"Red beans and ricely yours ...\"\n\nA fan of Major League Baseball, he founded a team in New Orleans that was known as Raggedy Nine and transformed the team into his Armstrong's \"Secret Nine Baseball\".\n\nArmstrong's gregariousness extended to writing. On the road, he wrote constantly, sharing favorite themes of his life with correspondents around the world. He avidly typed or wrote on whatever stationery was at hand, recording instant takes on music, sex, food, childhood memories, his heavy \"medicinal\" marijuana use—and even his bowel movements, which he gleefully described.\n\nLouis Armstrong was not, as is often claimed, a Freemason. Although he is usually listed as being a member of Montgomery Lodge No. 18 (Prince Hall) in New York, no such lodge has ever existed. However, Armstrong stated in his autobiography that he was a member of the Knights of Pythias, which although real is not a Masonic group.\n\nIn his early years, Armstrong was best known for his virtuosity with the cornet and trumpet. Along with his \"clarinet-like figurations and high notes in his cornet solos\", he was also known for his \"intense rhythmic 'swing', a complex conception involving ... accented upbeats, upbeat to downbeat slurring, and complementary relations among rhythmic patterns.\" The most lauded recordings on which Armstrong plays trumpet include the Hot Five and Hot Seven sessions, as well as those of the Red Onion Jazz Babies. Armstrong's improvisations, while unconventionally sophisticated for that era, were also subtle and highly melodic. The solo that Armstrong plays during the song Potato Head Blues has long been considered his best solo of that series.\n\nPrior to Armstrong, most collective ensemble playing in jazz, along with its occasional solos, simply varied the melodies of the songs. Armstrong was virtually the first to create significant variations based on the chord harmonies of the songs instead of merely on the melodies. This opened a rich field for creation and improvisation, and significantly changed the music into a soloist's art form.\n\nOften, Armstrong re-composed pop-tunes he played, simply with variations that made them more compelling to jazz listeners of the era. At the same time, however, his oeuvre includes many original melodies, creative leaps, and relaxed or driving rhythms. Armstrong's playing technique, honed by constant practice, extended the range, tone and capabilities of the trumpet. In his records, Armstrong almost single-handedly created the role of the jazz soloist, taking what had been essentially a collective folk music and turning it into an art form with tremendous possibilities for individual expression.\n\nArmstrong was one of the first artists to use recordings of his performances to improve himself. Armstrong was an avid audiophile. He had a large collection of recordings, including reel-to-reel tapes, which he took on the road with him in a trunk during his later career. He enjoyed listening to his own recordings, and comparing his performances musically. In the den of his home, he had the latest audio equipment and would sometimes rehearse and record along with his older recordings or the radio.\n\nAs his music progressed and popularity grew, his singing also became very important. Armstrong was not the first to record scat singing, but he was masterful at it and helped popularize it with the first recording on which he scatted, \"Heebie Jeebies\". At a recording session for Okeh Records, when the sheet music supposedly fell on the floor and the music began before he could pick up the pages, Armstrong simply started singing nonsense syllables while Okeh president E.A. Fearn, who was at the session, kept telling him to continue. Armstrong did, thinking the track would be discarded, but that was the version that was pressed to disc, sold, and became an unexpected hit. Although the story was thought to be apocryphal, Armstrong himself confirmed it in at least one interview as well as in his memoirs. On a later recording, Armstrong also sang out \"I done forgot the words\" in the middle of recording \"I'm A Ding Dong Daddy From Dumas\".\n\nSuch records were hits and scat singing became a major part of his performances. Long before this, however, Armstrong was playing around with his vocals, shortening and lengthening phrases, interjecting improvisations, using his voice as creatively as his trumpet. Armstrong once told Cab Calloway that his scat style was derived \"from the Jews \"rockin\"\", an Orthodox Jewish style of chanting during prayer.\n\nArmstrong was a gifted composer who wrote more than fifty songs, which in a number of cases have become jazz standards (e.g. \"Gully Low Blues\", \"Potato Head Blues\" and \"Swing That Music\").\n\nDuring his long career he played and sang with some of the most important instrumentalists and vocalists of the time; among them were Bing Crosby, Duke Ellington, Fletcher Henderson, Earl Hines, Jimmie Rodgers, Bessie Smith and perhaps most famously Ella Fitzgerald. His influence upon Crosby is particularly important with regard to the subsequent development of popular music: Crosby admired and copied Armstrong, as is evident on many of his early recordings, notably \"Just One More Chance\" (1931). The \"New Grove Dictionary of Jazz\" describes Crosby's debt to Armstrong in precise detail, although it does not acknowledge Armstrong by name:\n\nArmstrong recorded two albums with Ella Fitzgerald: \"Ella and Louis\", and \"Ella and Louis Again\" for Verve Records, with the sessions featuring the backing musicianship of the Oscar Peterson Trio and drummers Buddy Rich (on the first album), and Louie Bellson (on the second). Norman Granz then had the vision for Ella and Louis to record \"Porgy and Bess\".\n\nHis recordings for Columbia Records, \"Louis Armstrong Plays W.C. Handy\" (1954) and \"Satch Plays Fats\" (all Fats Waller tunes) (1955) were both being considered masterpieces, as well as moderately well selling. In 1961 the All Stars participated in two albums—\"The Great Summit\" and \"The Great Reunion\" (now together as a single disc) with Duke Ellington. The albums feature many of Ellington's most famous compositions (as well as two exclusive cuts) with Duke sitting in on piano. His participation in Dave Brubeck's high-concept jazz musical \"The Real Ambassadors\" (1963) was critically acclaimed, and features \"Summer Song\", one of Armstrong's most popular vocal efforts.\nIn 1964, his recording of the song \"Hello Dolly\" went to number one. An album of the same title was quickly created around the song, and also shot to number one (knocking The Beatles off the top of the chart). The album sold very well for the rest of the year, quickly going \"Gold\" (500,000). His performance of \"Hello Dolly\" won for best male pop vocal performance at the 1964 Grammy Awards.\n\nArmstrong had nineteen \"Top Ten\" records including \"Stardust\", \"What a Wonderful World\", \"When The Saints Go Marching In\", \"Dream a Little Dream of Me\", \"Ain't Misbehavin'\", \"You Rascal You\", and \"Stompin' at the Savoy\". \"We Have All the Time in the World\" was featured on the soundtrack of the James Bond film \"On Her Majesty's Secret Service\", and enjoyed renewed popularity in the UK in 1994 when it featured on a Guinness advert. It reached number 3 in the charts on being re-released.\n\nIn 1964, Armstrong knocked The Beatles off the top of the \"Billboard\" Hot 100 chart with \"Hello, Dolly!\", which gave the 63-year-old performer a U.S. record as the oldest artist to have a number one song. His 1964 song \"Bout Time\" was later featured in the film \"Bewitched\".\n\nArmstrong performed in Italy at the 1968 Sanremo Music Festival where he sang \"Mi Va di Cantare\" alongside his friend, the Eritrean-born Italian singer Lara Saint Paul. In February 1968, he also appeared with Lara Saint Paul on the Italian RAI television channel where he performed \"Grassa e Bella\", a track he sang in Italian for the Italian market and C.D.I. label.\n\nIn 1968, Armstrong scored one last popular hit in the United Kingdom with \"What a Wonderful World\", which topped the British charts for a month. Armstrong appeared on the October 28, 1970, \"Johnny Cash Show\", where he sang Nat King Cole's hit \"Ramblin' Rose\" and joined Cash to re-create his performance backing Jimmie Rodgers on \"Blue Yodel No. 9\".\n\nArmstrong enjoyed many types of music, from blues to the arrangements of Guy Lombardo, to Latin American folksongs, to classical symphonies and opera. He incorporated influences from all these sources into his performances, sometimes to the bewilderment of fans who wanted him to stay in convenient narrow categories. Armstrong was inducted into the Rock and Roll Hall of Fame as an \"early influence\". Some of his solos from the 1950s, such as the hard rocking version of \"St. Louis Blues\" from the \"WC Handy\" album, show that the influence went in both directions.\n\nArmstrong appeared in more than a dozen Hollywood films, usually playing a bandleader or musician. His most familiar role was as the bandleader \"cum\" narrator in the 1956 musical \"High Society\" in which he sang the title song and performed a duet with Bing Crosby on \"Now You Has Jazz\". In 1947, he played himself in the movie \"New Orleans\" opposite Billie Holiday, which chronicled the demise of the Storyville district and the ensuing exodus of musicians from New Orleans to Chicago. In the 1959 film \"The Five Pennies\" he played himself, sang, and playing several classic numbers. With Danny Kaye he performed a duet of \"When the Saints Go Marching In\" during which Kaye impersonated Armstrong. He had a part in the film alongside James Stewart in \"The Glenn Miller Story\".\n\nArmstrong was the first African American to host a nationally broadcast radio show in the 1930s. In 1969, he had a cameo role in the film version of \"Hello, Dolly!\" as the bandleader Louis. He sang the title song with actress Barbra Streisand. His solo recording of \"Hello, Dolly!\" is one of his most recognizable performances.\n\nArgentine writer Julio Cortázar, a self-described Armstrong admirer, asserted that a 1952 Louis Armstrong concert at the Théâtre des Champs-Élysées in Paris played a significant role in inspiring him to create the fictional creatures called Cronopios that are the subject of a number of Cortázar's short stories. Cortázar once called Armstrong himself \"Grandísimo Cronopio\" (The Great Cronopio).\n\nThere is a pivotal scene in \"Stardust Memories\" (1980) in which Woody Allen is overwhelmed by a recording of Armstrong's \"Stardust\" and experiences a nostalgic epiphany.\n\nAgainst his doctor's advice, Armstrong played a two-week engagement in March 1971 at the Waldorf-Astoria's Empire Room. At the end of it he was hospitalized for a heart attack. He was released from the hospital in May, and quickly resumed practicing his trumpet playing. Still hoping to get back on the road, Armstrong died of a heart attack in his sleep on July 6, 1971, a month before his 70th birthday. He was residing in Corona, Queens, New York City, at the time of his death. He was interred in Flushing Cemetery, Flushing, in Queens, New York City.\nHis honorary pallbearers included Bing Crosby, Ella Fitzgerald, Dizzy Gillespie, Pearl Bailey, Count Basie, Harry James, Frank Sinatra, Ed Sullivan, Earl Wilson, Alan King, Johnny Carson and David Frost. Peggy Lee sang The Lord's Prayer at the services while Al Hibbler sang \"Nobody Knows the Trouble I've Seen\" and Fred Robbins, a long-time friend, gave the eulogy.\n\nArmstrong was posthumously awarded the Grammy Lifetime Achievement Award in 1972 by the Academy of Recording Arts and Sciences. This Special Merit Award is presented by vote of the Recording Academy's National Trustees to performers who, during their lifetimes, have made creative contributions of outstanding artistic significance to the field of recording.\n\nRecordings of Armstrong were inducted into the Grammy Hall of Fame, which is a special Grammy award established in 1973 to honor recordings that are at least 25 years old, and that have \"qualitative or historical significance\".\n\nThe Rock and Roll Hall of Fame listed Armstrong's \"West End Blues\" on the list of 500 songs that shaped Rock and Roll.\n\nIn 1995, the U.S. Post Office issued a Louis Armstrong 32 cents commemorative postage stamp.\n\nIn 1999 Armstrong was nominated for inclusion in the American Film Institute's 100 Years ... 100 Stars.\n\nThe influence of Armstrong on the development of jazz is virtually immeasurable. His irrepressible personality both as a performer and as a public figure was so strong that to some it sometimes overshadowed his contributions as a musician and singer.\n\nAs a virtuoso trumpet player, Armstrong had a unique tone and an extraordinary talent for melodic improvisation. Through his playing, the trumpet emerged as a solo instrument in jazz and is used widely today. Additionally, jazz itself was transformed from a collectively improvised folk music to a soloist's serious art form largely through his influence. He was a masterful accompanist and ensemble player in addition to his extraordinary skills as a soloist. With his innovations, he raised the bar musically for all who came after him.\n\nThough Armstrong is widely recognized as a pioneer of scat singing, Ethel Waters precedes his scatting on record in the 1930s according to Gary Giddins and others. Billie Holiday and Frank Sinatra are just two singers who were greatly indebted to him. Holiday said that she always wanted Bessie Smith's 'big' sound and Armstrong's feeling in her singing. Even special musicians like Duke Ellington have praised Armstrong through strong testimonials. Duke Ellington, DownBeat magazine in 1971, said, \"If anybody was a master, it was Louis Armstrong. He was and will continue to be the embodiment of jazz.\" In 1950, Bing Crosby, the most successful vocalist of the first half of the 20th century, said, \"He is the beginning and the end of music in America.\"\n\nIn the summer of 2001, in commemoration of the centennial of Armstrong's birth, New Orleans's main airport was renamed Louis Armstrong New Orleans International Airport.\n\nIn 2002, the Louis Armstrong's Hot Five and Hot Seven recordings (1925–1928) were preserved in the United States National Recording Registry, a registry of recordings selected yearly by the National Recording Preservation Board for preservation in the National Recording Registry of the Library of Congress.\n\nThe US Open tennis tournament's former main stadium was named Louis Armstrong Stadium in honor of Armstrong who had lived a few blocks from the site.\n\n\"Congo Square\" was a common gathering place for African-Americans in New Orleans for dancing and performing music. The park where Congo Square is located was later renamed Louis Armstrong Park. Dedicated in April 1980, the park includes a 12-foot statue of Armstrong, trumpet in hand.\n\nThe house where Armstrong lived for almost 28 years was declared a National Historic Landmark in 1977 and is now a museum. The Louis Armstrong House Museum, at 34–56 107th Street (between 34th and 37th Avenues) in Corona, Queens, presents concerts and educational programs, operates as a historic house museum and makes materials in its archives of writings, books, recordings and memorabilia available to the public for research. The museum is operated by the City University of New York's Queens College, following the dictates of Lucille Armstrong's will. The museum opened to the public on October 15, 2003. A new visitors center is planned.\n\nAccording to literary critic Harold Bloom, \"The two great American contributions to the world's art, in the end, are Walt Whitman and, after him, Armstrong and jazz ... If I had to choose between the two, ultimately, I wouldn't. I would say that the genius of this nation at its best is indeed Walt Whitman and Louis Armstrong.\" \n\n\n\n"}
{"id": "18315", "url": "https://en.wikipedia.org/wiki?curid=18315", "title": "Long Island", "text": "Long Island\n\nLong Island is a densely populated island off the East Coast of the United States, beginning at New York Harbor approximately 0.35 miles (0.56 km) from Manhattan Island and extending eastward into the Atlantic Ocean. The island comprises four counties in the U.S. state of New York. Kings and Queens Counties (the New York City boroughs of Brooklyn and Queens, respectively) and Nassau County share the western third of the island, while Suffolk County occupies the eastern two-thirds. More than half of New York City's residents now live on Long Island, in Brooklyn and Queens. However, many people in the New York metropolitan area (including those in Brooklyn and Queens) colloquially use the term \"Long Island\" (or the Island) to refer exclusively to Nassau and Suffolk Counties, which are mainly suburban in character, conversely employing the term \"the City\" to mean Manhattan alone.\n\nBroadly speaking, \"Long Island\" may refer both to the main island and the surrounding outer barrier islands. North of the island is Long Island Sound, across which lie Westchester County, New York, and the state of Connecticut. Across the Block Island Sound to the northeast is the state of Rhode Island. To the west, Long Island is separated from the Bronx and the island of Manhattan by the East River. To the extreme southwest, it is separated from Staten Island and the state of New Jersey by Upper New York Bay, the Narrows, and Lower New York Bay. To the east lie Block Island—which belongs to the State of Rhode Island—and numerous smaller islands.\n\nBoth the longest and the largest island in the contiguous United States, Long Island extends eastward from New York Harbor to Montauk Point, with a maximum north-to-south distance of between Long Island Sound and the Atlantic coast. With a land area of 1,401 square miles (3,630 km), Long Island is the 11th-largest island in the United States and the 149th-largest island in the world—larger than the of the smallest U.S. state, Rhode Island.\n\nWith a Census-estimated population of 7,869,820 in 2017, constituting nearly 40% of New York State's population, Long Island is the most populated island in any U.S. state or territory, and the 18th-most populous island in the world (ahead of Ireland, Jamaica, and Hokkaidō). Its population density is . If Long Island geographically constituted an independent metropolitan statistical area, it would rank fourth most populous in the United States; while if it were a U.S. state, Long Island would rank 13th in population and first in population density. Long Island is culturally and ethnically diverse, featuring some of the wealthiest and most expensive neighborhoods in the Western Hemisphere near the shorelines as well as working-class areas in all four counties.\n\nAs a hub of commercial aviation, Long Island contains two of the New York City metropolitan area's three busiest airports, JFK International Airport and LaGuardia Airport, in addition to Islip MacArthur Airport; as well as two major air traffic control radar facilities, the New York TRACON and the New York ARTCC. Nine bridges and 13 tunnels (including railroad tunnels) connect Brooklyn and Queens to the three other boroughs of New York City. Ferries connect Suffolk County northward across Long Island Sound to the state of Connecticut. The Long Island Rail Road is the busiest commuter railroad in North America and operates 24/7. Biotechnology companies and scientific research play a significant role in Long Island's economy, including research facilities at Brookhaven National Laboratory, Cold Spring Harbor Laboratory, Plum Island Animal Disease Center, State University of New York at Stony Brook, the New York University Tandon School of Engineering, the City University of New York, and Hofstra Northwell School of Medicine.\n\n Prior to European contact, the Lenape people (named the \"Delaware\" by Europeans) inhabited the western end of Long Island, and spoke the Munsee dialect of Lenape, one of the Algonquian language family. Giovanni da Verrazzano was the first European to record an encounter with the Lenapes, after entering what is now New York Bay in 1524. The eastern portion of the island was inhabited by speakers of the Mohegan-Montauk-Narragansett language group of Algonquian languages; they were part of the Pequot and Narragansett peoples inhabiting the area that now includes Connecticut and Rhode Island.\n\nIn 1609, the English navigator Henry Hudson explored the harbor and purportedly landed at Coney Island. Adriaen Block followed in 1615, and is credited as the first European to determine that both Manhattan and Long Island are islands.\n\nNative American land deeds recorded by the Dutch from 1636 state that the Indians referred to Long Island as \"Sewanhaka\" (\"Sewanhacky\" and \"Sewanhacking\" were other spellings in the transliteration of Lenape). \"Sewan\" was one of the terms for wampum (commemorative stringed shell beads, for a while also used as currency by colonists in trades with the Lenape), and is also translated as \"loose\" or \"scattered\", which may refer either to the wampum or to Long Island. The name \" 't Lange Eylandt alias Matouwacs\" (later shortened to \"\"Lange Eylandt\"\") appears in Dutch maps from the 1650s. Later, the English referred to the land as \"Nassau Island\", after the Dutch Prince William of Nassau, Prince of Orange (who later also ruled as King William III of England). It is unclear when the name \"Nassau Island\" was discontinued.\n\nThe very first settlements on Long Island were by settlers from England and its colonies in present-day New England. Lion Gardiner settled nearby Gardiners Island. The first settlement on the geographic Long Island itself was on October 21, 1640, when Southold was established by the Rev. John Youngs and settlers from New Haven, Connecticut. Peter Hallock, one of the settlers, drew the long straw and was granted the honor to step ashore first. He is considered the first New World settler on Long Island. Southampton was settled in the same year. Hempstead followed in 1644, East Hampton in 1648, Huntington in 1653, Brookhaven in 1655, and Smithtown in 1665.\n\nWhile the eastern region of Long Island was first settled by the English, the western portion of Long Island was settled by the Dutch; until 1664, the jurisdiction of Long Island was split between the Dutch and English, roughly at the present border between Nassau County and Suffolk County. The Dutch founded six towns in present-day Brooklyn beginning in 1645. These included: Brooklyn, Gravesend, Flatlands, Flatbush, New Utrecht, and Bushwick. The Dutch had granted an English settlement in Hempstead, New York (now in Nassau County) in 1644, but after a boundary dispute they drove out English settlers from the Oyster Bay area. However, in 1664, the English returned to take over the Dutch colony of New Netherland, including Long Island.\n\nThe 1664 land patent granted to the Duke of York included all islands in Long Island Sound. The Duke of York held a grudge against Connecticut, as New Haven had hidden three of the judges who sentenced the Duke's father, King Charles I, to death in 1649. Settlers throughout Suffolk County pressed to stay part of Connecticut, but Governor Sir Edmund Andros threatened to eliminate the settlers' rights to land if they did not yield, which they did by 1676.\n\nAll of Long Island (as well as the islands between it and Connecticut) became part of the Province of New York within the Shire of York. Present-day Suffolk County was designated as the \"East Riding\" (of Yorkshire), present-day Brooklyn was part of the \"West Riding\", and present-day Queens and Nassau were part of the larger \"North Riding\". In 1683, Yorkshire was dissolved and the three original counties on Long Island were established: Kings, Queens, and Suffolk.\n\nEarly in the American Revolutionary War, the island was captured by the British from General George Washington in the Battle of Long Island, a decisive battle after which Washington narrowly evacuated his troops from Brooklyn Heights under a dense fog. After the British victory on Long Island, many Patriots fled, leaving mostly Loyalists behind. The island remained a British stronghold until the end of the war in 1783.\n\nGeneral Washington based his espionage activities on Long Island, due to the western part of the island's proximity to the British military headquarters in New York City. The Culper Spy Ring included agents operating between Setauket and Manhattan. This ring alerted Washington to valuable British secrets, including the treason of Benedict Arnold and a plan to use counterfeiting to induce economic sabotage.\n\nLong Island's colonists served both Loyalist and Patriot causes, with many prominent families divided among both sides. During the occupation British troops used a number of civilian structures for defense and demanded to be quartered in the homes of civilians. A number of structures from this era remain. Among these are Raynham Hall, the Oyster Bay home of patriot spy Robert Townsend, and the Caroline Church in Setauket, which contains bullet holes from a skirmish known as the Battle of Setauket. Also in existence is a reconstruction of Brooklyn's Old Stone House, on the site of the Maryland 400's celebrated last stand during the Battle of Long Island.\n\nIn the 19th century, Long Island was still mainly rural and devoted to agriculture. The predecessor to the Long Island Rail Road (LIRR) began service in 1836 from the South Ferry in Brooklyn, through the remainder of Brooklyn, to Jamaica in Queens. The line was completed to the east end of Long Island in 1844 (as part of a plan for transportation to Boston). Competing railroads (soon absorbed by the LIRR) were built along the south shore to accommodate travellers from those more populated areas. For the century from 1830 until 1930, total population roughly doubled every twenty years, with more dense development in areas near Manhattan. Several cities were incorporated, such as the 'City of Brooklyn' in Kings County, and Long Island City in Queens.\n\nUntil the 1883 completion of the Brooklyn Bridge, the only means of travel between Long Island and the rest of the United States was by boat or ship. As other bridges and tunnels were constructed, areas of the island began to be developed as residential suburbs, first around the railroads that offered commuting into the city. On January 1, 1898, Kings County and portions of Queens were consolidated into the 'City of Greater New York', abolishing all cities and towns within them. The easternmost of Queens County, which were not part of the consolidation plan,\nseparated from Queens in 1899 to form Nassau County.\n\nAt the close of the 19th century, wealthy industrialists who made vast fortunes during the Gilded Age began to construct large \"baronial\" country estates in Nassau County communities along the North Shore of Long Island, favoring the many properties with water views. Proximity to Manhattan attracted such men as J. P. Morgan, William K. Vanderbilt, and Charles Pratt, whose estates led to this area being nicknamed the Gold Coast. This period and the area was immortalized in fiction, such as F. Scott Fitzgerald's \"The Great Gatsby\", which has also been adapted in films.\n\nCharles Lindbergh lifted off from Roosevelt Field with his \"Spirit of Saint Louis\" for his historic 1927 solo flight to Europe, one of the events that helped to establish Long Island as an early center of aviation during the 20th Century. Other famous aviators such as Wiley Post originated notable flights from Floyd Bennett Field in Brooklyn, which became the first major airport serving New York City before it was superseded by the opening of La Guardia Airport in 1939. Long Island was also the site of Mitchel Air Force Base and was a major center of military aircraft production by companies such as Grumman and Fairchild Aircraft during World War II and for some decades afterward. Aircraft production on Long Island extended all the way into the Space Age – Grumman was one of the major contractors that helped to build the early lunar flight and space shuttle vehicles. Although the aircraft companies eventually ended their Long Island operations and the early airports were all later closed – Roosevelt Field, for instance, became the site of a major shopping mall – the Cradle of Aviation Museum on the site of the former Mitchel Field documents the Island's key role in the history of aviation.\n\nFrom the 1920s to the 1940s, Long Island began the transformation from backwoods and farms as developers created numerous suburbs. Numerous branches of the LIRR already enabled commuting from the suburbs to Manhattan. Robert Moses engineered various automobile parkway projects to span the island, and developed beaches and state parks for the enjoyment of residents and visitors from the city. Gradually, development also followed these parkways, with various communities springing up along the more traveled routes.\n\nAfter World War II, suburban development increased with incentives under the G.I. Bill, and Long Island's population skyrocketed, mostly in Nassau County and western Suffolk County. Second and third-generation children of immigrants moved out to eastern Long Island to settle in new housing developments built during the post-war boom. Levittown became noted as a suburb, where housing construction was simplified to be produced on a large scale. These provided opportunities for World War II military veterans returning home to buy houses and start a family.\n\nBy the start of the 21st century, a number of Long Island communities had converted their assets from industrial uses to post-industrial roles. Brooklyn reversed decades of population decline and factory closings to resurface as a globally renowned cultural and intellectual hotbed. Gentrification has affected much of Brooklyn and a portion of Queens, relocating a sizeable swath of New York City's population. On eastern Long Island, such villages as Port Jefferson, Patchogue, and Riverhead have been changed from inactive shipbuilding and mill towns into tourist-centric commercial centers with cultural attractions.\n\nThe descendants of late 19th and early 20th-century immigrants from southern and eastern Europe, and black migrants from the South, have been followed by more recent immigrants from Asia and Latin America. Long Island has many ethnic Irish, Jews, and Italians, as well as an increasing numbers of Asians and Hispanics, reflecting later migrations.\n\nThe westernmost end of Long Island contains the New York City boroughs of Brooklyn (Kings County) and Queens (Queens County). The central and eastern portions contain the suburban Nassau and Suffolk Counties. However, colloquial usage of the term \"Long Island\" usually refers only to Nassau and Suffolk Counties. For example, the Federal Reserve Bank of New York has a district named \"Long Island (Nassau-Suffolk Metro Division).\" At least as late as 1911, locations in Queens were still commonly referred to as being on Long Island. Some institutions in the New York City section of the island use the island's names, like Long Island University and Long Island Jewish Medical Center.\n\nIn 1985, the United States Supreme Court ruled in \"United States v. Maine\" that Long Island is legally not an island, because New York State's boundaries contained its offshore soil and seabeds. Despite the legal decision the United States Board on Geographic Names still considers Long Island an island, because it is surrounded by water.\n\nNassau County is more densely developed than Suffolk County. While affluent overall, Nassau County has pockets of more pronounced wealth with estates covering greater acreage within the Gold Coast of the North Shore and the Five Towns area on the South Shore. South Shore communities are built along protected wetlands of the island and contain white sandy beaches of Outer Barrier Islands fronting on the Atlantic Ocean. Dutch and English settlers from the time before the American Revolutionary War, as well as communities of Native Americans, populated the island. The 19th century saw the infusion of the wealthiest Americans in the so-called Gold Coast of the North Shore, where wealthy Americans and Europeans in the Gilded Age built lavish country homes.\n\nIn its easternmost sections, Suffolk County remains semi-rural, as in Greenport on the North Fork and some of the periphery of the area prominently known as The Hamptons, although summer tourism swells the population in those areas. The North Fork peninsula of Suffolk County's East End has developed a burgeoning Wine Country region. In addition, the South Fork peninsula is known for beach communities, including the Hamptons, and for the Montauk Point Lighthouse at the eastern tip of the island. The Pine Barrens is a preserved pine forest encompassing much of eastern Suffolk County.\n\nA detailed geomorphological study of Long Island provides evidence of glacial history of the kame and terminal moraines of the island which were formed by the advance and retreat of two ice sheets. Long Island, as part of the Outer Lands region, is formed largely of two spines of glacial moraine, with a large, sandy outwash plain beyond. These moraines consist of gravel and loose rock left behind during the two most recent pulses of Wisconsin glaciation during the Ice Ages some 21,000 years ago (19,000 BC). The northern moraine, which directly abuts the North Shore of Long Island at points, is known as the Harbor Hill moraine. The more southerly moraine, known as the Ronkonkoma moraine, forms the \"backbone\" of Long Island; it runs primarily through the very center of Long Island, roughly coinciding with the length of the Long Island Expressway.\n\nThe land to the south of this moraine to the South Shore is the outwash plain of the last glacier. One part of the outwash plain was known as the Hempstead Plains, and this land contained one of the few natural prairies to exist east of the Appalachian Mountains. The glaciers melted and receded to the north, resulting in the difference between the topography of the North Shore beaches and the South Shore beaches. The North Shore beaches are rocky from the remaining glacial debris, while the South Shore's are crisp, clear, outwash sand. Jayne's Hill, at , within Suffolk County near its border with Nassau County, is the highest hill along either moraine; another well-known summit is Bald Hill in Brookhaven Town, not far from its geographical center at Middle Island. The glaciers also formed Lake Ronkonkoma in Suffolk County and Lake Success in Nassau County, each a deep kettle lake.\n\nUnder the Köppen climate classification, Long Island lies in a transition zone between a humid subtropical climate (Cfa) and a humid continental climate (Dfa). The climate features long hot summers, with occasional thunderstorms, mild spring and fall weather, and cool to cold winters with a mix of snow and rain and stormier conditions. Springs can be cool and sometimes gloomy due to the relatively cooler temperatures of the Atlantic Ocean. The ocean also brings afternoon sea breezes that temper the heat in the warmer months and limit the frequency and severity of thunderstorms. Long Island has a moderately sunny climate, averaging 2,400 to 2,800 hours of sunshine annually.\n\nDue to its coastal location, Long Island winter temperatures are significantly milder than most of the state. The coldest month is January, when average temperatures range from , and the warmest month is July, when average temperatures range from . Temperatures seldom fall below or rise above . Long Island temperatures vary from west to east, with the western part (Nassau County, Queens, and Brooklyn) generally warmer than the east (Suffolk County). This is due to several factors: the western part is closer to the mainland and more densely developed, causing the \"urban heat island\" effect, and Long Island's land mass veers northward as one travels east. Also, daytime high temperatures on the eastern part of Long Island are cooler on most occasions, due to the moderating effect of the Atlantic Ocean and Long Island Sound. On dry nights with no clouds or wind, the Pine Barrens forest of eastern Suffolk County can be almost 20 degrees Fahrenheit (11 degrees Celsius) cooler than the rest of the island, due to radiational cooling. Average dew points, a measure of atmospheric moisture, typically lie in the range during July and August.\n\nPrecipitation is distributed fairly uniformly throughout the year, with approximately on average during each month. Average yearly snowfall totals range from approximately , with the north shore and western parts averaging more than the south shore and the east end. In any given winter, however, some parts of the island can see up to of snow or more. There are also some very quiet winters, in which most parts of the island could see less than of snow.\n\nOn August 13, 2014, flash flooding occurred in western-central Suffolk County after a record-setting rainfall deposited more than three months' worth of precipitation on the area within a few hours.\n\nLong Island is somewhat vulnerable to tropical cyclones. While it lies north of where most tropical cyclones turn eastward and out to sea (most landfalls on the East Coast of the USA occur from North Carolina southward), several tropical cyclones have struck Long Island, including a devastating Category 3, the 1938 New England Hurricane (also known as the \"Long Island Express\"), and another Category 3, Hurricane Carol in 1954. Other 20th-century storms that made landfall on Long Island at hurricane intensity include the Great Atlantic Hurricane of 1944, Hurricane Donna in 1960, Hurricane Belle in 1976, and Hurricane Gloria in 1985. Also, the eyewall of Hurricane Bob in 1991 brushed the eastern tip. In August 2011, portions of Long Island were evacuated in preparation for Hurricane Irene, a Category 1 hurricane which weakened to a tropical storm before it reached Long Island.\n\nOn October 29, 2012, Hurricane Sandy caused extensive damage to low-lying coastal areas of Nassau and Suffolk Counties, Brooklyn, and Queens, destroying or severely damaging thousands of area homes and other structures by ocean and bay storm surges. Hundreds of thousands of residents were left without electric power for periods of time ranging up to several weeks while the damage was being repaired. The slow-moving \"Superstorm Sandy\" (so-nicknamed because its winds weakened below hurricane intensity as it made landfall) caused 90% of Long Island households to lose power and an estimated $18 billion in damages in Nassau and Suffolk Counties alone. The storm also had a devastating impact on coastal communities in the Brooklyn and Queens portions of the island, including Coney Island in Brooklyn and the Rockaway Peninsula in Queens, although estimates of monetary damages there are usually calculated as part of the overall losses suffered in New York City as a whole. When allowance is made for inflation, the extent of Sandy's damages is second only to that of those caused by the 1938 Long Island Express. Although a lower central pressure was recorded in Sandy, the National Hurricane Center estimates that the 1938 hurricane had a lower pressure at landfall. Hurricane Sandy and its profound impacts have prompted the discussion of constructing seawalls and other coastal barriers around the shorelines of Long Island and New York City to minimize the risk of destructive consequences from another such event in the future.\n\nSeveral smaller islands, though geographically distinct, are in proximity to Long Island and are often grouped with it. These islands include Fire Island, the largest of the outer barrier islands that parallels the southern shore of Long Island for approximately ; Plum Island, which was home to the Plum Island Animal Disease Center, a biological weapons research facility; as well as Robins Island, Gardiners Island, Fishers Island, Long Beach Barrier Island, Jones Beach Island, Great Gull Island, Little Gull Island, and Shelter Island.\n\nLong Island is one of the most densely populated regions in the United States. As of the United States 2010 Census, the total population of all four counties of Long Island was 7,568,304, which was 39% of the population of the State of New York. As of 2017, the proportion of New York City residents living on Long Island had risen to 58%, given the 5,007,353 residents living in Brooklyn or Queens. Furthermore, the proportion of New York State's population residing on Long Island has also been increasing, with Long Island's Census-estimated population increasing 4.0% since 2010, to 7,869,820 in 2017, representing 39.6% of New York State's Census-estimated 2017 population of 19,849,399 and with a population density of on Long Island. Long Island's population is greater than 37 of the 50 U.S. states.\n\nAs of the 2010 census, the combined population of Nassau and Suffolk Counties was 2,832,882 people; Suffolk County's share being 1,493,350 and Nassau County's 1,339,532. Nassau County had a larger population for decades, but Suffolk County surpassed it in the 1990 census as growth and development continued to spread eastward. As Suffolk County has more than three times the land area of Nassau County, the latter still has a much higher population density and is growing faster in the 21st century, given its proximity to New York City. According to the U.S. Census Bureau's 2008 American Community Survey, Nassau and Suffolk Counties had the 10th and 26th highest median household incomes in the nation, respectively.\n\nPopulation figures from the U.S. Census Bureau \"Census 2010\"\nshow that whites are the largest racial group in all four counties, and are in the majority in Nassau and Suffolk Counties. In 2002, \"The New York Times\" cited a study by the non-profit group ERASE Racism, which determined that Nassau and Suffolk Counties constitute the most racially segregated suburbs in the United States.\n\nIn contrast, Queens is the most ethnically diverse county in the United States and the most diverse urban area in the world.\n\nAccording to a 2000 report on religion, which asked congregations to respond, Catholics are the largest religious group on Long Island, with non-affiliated in second place. Catholics make up 52% of the population of Nassau and Suffolk, versus 22% for the country as a whole, with Jews at 16% and 7%, respectively, versus 1.7% nationwide. Only a small percentage of Protestants responded, 7% and 8% respectively, for Nassau and Suffolk Counties. This is in contrast with 23% for the entire country on the same survey, and 50% on self-identification surveys.\n\nA growing population of nearly half a million Chinese Americans now live on Long Island. Rapidly expanding Chinatowns have developed in Brooklyn (布魯克林) and Queens (皇后), with Chinese immigrants also moving into Nassau County, as did earlier European immigrants, such as the Irish and Italians. More recently, a Little India (लघु भारत) community has emerged in Hicksville, Nassau County, spreading eastward from the more established Little India enclaves in Queens.\n\nLikewise, the Long Island Koreatown (롱 아일랜드 코리아타운) originated in Flushing, Queens, and is expanding eastward along Northern Boulevard and into Nassau County.\n\nLong Island is home to two Native American reservations, Poospatuck Reservation, and Shinnecock Reservation, both in Suffolk County. Numerous island place names are Native American in origin.\n\nA 2010 article in \"The New York Times\" stated that the expansion of the immigrant workforce on Long Island has not displaced any jobs from other Long Island residents. Half of the immigrants on Long Island hold white-collar positions.\n\nThe Counties of Nassau and Suffolk have been long renowned for their affluence. Long Island is home to some of the wealthiest communities in the United States, including The Hamptons, on the East End of the South Shore of Suffolk County; the Gold Coast, in the vicinity of the island's North Shore, along Long Island Sound; and increasingly, the western shoreline of Brooklyn, facing Manhattan. In 2016, according to \"Business Insider\", the 11962 zip code encompassing Sagaponack, within Southampton, was listed as the most expensive in the U.S., with a median home sale price of $8.5 million.\n\nLong Island has played a prominent role in scientific research and in engineering. It is the home of the Brookhaven National Laboratory in nuclear physics and Department of Energy research. Long Island is also home to the Cold Spring Harbor Laboratory, which was directed for 35 years by James D. Watson (who, along with Francis Crick and Rosalind Franklin, discovered the double helix structure of DNA). Companies such as Sperry Rand, Computer Associates (headquartered in Islandia), Zebra Technologies (now occupying the former headquarters of Symbol Technologies, and a former Grumman plant in Holtsville), have made Long Island a center for the computer industry. Stony Brook University of the State University of New York and New York Institute of Technology conduct advanced medical and technological research.\n\nLong Island is home to the East Coast's largest industrial park, the Hauppauge Industrial Park, hosting over 1,300 companies which employ more than 71,000 individuals. Companies in the park and abroad are represented by the Hauppauge Industrial Association. As many as 20% of Long Islanders commute to jobs in Manhattan. The eastern end of the island is still partly agricultural. Development of vineyards on the North Fork has spawned a major viticultural industry, replacing potato fields. Pumpkin farms have been added to traditional truck farming. Farms allow fresh fruit picking by Long Islanders for much of the year. Fishing continues to be an important industry, especially at Huntington, Northport, Montauk, and other coastal communities of the East End and South Shore.\n\nFrom about 1930 to about 1990, Long Island was considered one of the aerospace manufacturing centers of the United States, with companies such as Grumman Aircraft, Republic, Fairchild, and Curtiss having their headquarters and factories on Long Island. These operations have largely been phased out or significantly diminished.\n\nNassau County and Suffolk County each have their own governments, with a County Executive leading each. Each has a county legislature and countywide-elected officials, including district attorney, county clerk, and county comptroller. The towns in both counties have their own governments as well, with town supervisors and a town council. Nassau County is divided into three towns and two small incorporated cities (Glen Cove and Long Beach). Suffolk County is divided into ten towns.\n\nBrooklyn and Queens, on the other hand, do not have county governments. As boroughs of New York City, both have borough presidents, which have been largely ceremonial offices since the shutdown of the New York City Board of Estimate. The respective Borough Presidents are responsible for appointing individuals to the Brooklyn Community Boards and Queens Community Boards, each of which serves an advisory function on local issues. Brooklyn's sixteen members and Queens' fourteen members represent the first and second largest borough contingents of the New York City Council.\n\nQueens and Brooklyn are patrolled by the New York City Police Department. Nassau and Suffolk Counties are served by the Nassau County Police Department and Suffolk County Police Department, respectively, although several dozen villages and the two cities in Nassau County have their own police departments. The Nassau County Sheriff's Department and Suffolk County Sheriff's Office handle civil procedure, evictions, warrant service and enforcement, prisoner transport and detention, and operation of the county jail. New York State Police patrol state parks and parkways.\n\nThe secession of Nassau and Suffolk Counties on Long Island from New York State was proposed as early as 1896, but talk was revived towards the latter part of the twentieth century. On March 28, 2008, Suffolk County Comptroller Joseph Sawicki proposed a plan that would make Nassau and Suffolk Counties on Long Island the 51st state of the United States of America. Sawicki claimed that all of the Nassau and Suffolk taxpayers' money would remain locally, rather than the funds being dispersed all over the entire state of New York, with these counties sending to Albany over three billion dollars more than they receive back. The state of Long Island would have included nearly 3 million people (a larger population than that of fifteen other states). Nassau County executive Ed Mangano came out in support of such a proposal in April 2010 and commissioned a study on it.\n\nEvery major form of transportation serves Long Island, including aviation from John F. Kennedy International Airport, LaGuardia Airport, and Long Island MacArthur Airport, and multiple smaller airports; rail transportation on the Long Island Rail Road and the New York City Subway; bus routes from MTA Regional Bus Operations, Nassau Inter-County Express, and Suffolk County Transit; ferry service from NYC Ferry and multiple smaller ferry companies; and several major highways. There are historic and modern bridges, and recreational and commuter trails, serving various parts of Long Island.\n\nThere are ten road crossings out of Long Island, all within New York City limits at the extreme western end of the island. Plans for a Long Island Crossing at various locations in Nassau and Suffolk Counties (a proposed bridge or tunnel that would link Long Island to the south with New York or Connecticut to the north across Long Island Sound) have been discussed for decades, but there are no firm plans to construct such a crossing.\n\nThe MTA implements mass transportation for the New York metropolitan area including all five boroughs of New York City, the suburban counties of Dutchess, Nassau, Orange, Putnam, Rockland, Suffolk, and Westchester, all of which together are the \"Metropolitan Commuter Transportation District (MCTD)\".\n\nThe MTA is the largest public transportation provider in the Western Hemisphere. Its agencies serve 14.6 million people spread over 5,000 square miles (13,000 km²) from New York City through the southeastern section of the state (including Long Island and the lower Hudson Valley), and Connecticut. Combined the MTA agencies now move more than 2.6 billion rail and bus customers a year while employing some 70,000 workers.\n\nThe Long Island Rail Road (LIRR) is the busiest commuter railroad system in North America, carrying an average of 282,400 passengers each weekday on 728 daily trains. Chartered on April 24, 1834, and operating continuously since, it is also the oldest railroad in the U.S. that is still operating under its original charter and name. The Metropolitan Transportation Authority has operated the LIRR as one of its two commuter railroads since 1966, and the LIRR is one of the few railroads worldwide that provides service all the time, year round. In July 2017, a $2 billion plan to add a third railroad track to the LIRR Main Line between the Floral Park and Hicksville stations in Nassau County was approved. Other LIRR projects, such as the Ronkonkoma Branch Double Track Project, are also underway. Five \"readiness projects\" across the LIRR system, which will cost a combined $495 million, are also under construction in preparation for expanded peak-hour LIRR service after the completion of East Side Access, which will bring LIRR trains to Grand Central Terminal.\n\nNassau Inter-County Express (NICE) provides bus service in Nassau County, while Suffolk County Transit, an agency of the Suffolk County government, provides bus service in Suffolk County. In 2012, NICE replaced the former Long Island Bus in transporting Long Islanders across Nassau County while still allowing them to use MTA MetroCards as payment.\n\nThe Long Island Expressway, Northern State Parkway, and Southern State Parkway, all products of the automobile-centered planning of Robert Moses, are the island's primary east-west high-speed controlled-access highways.\n\nBeing such a large, populous island with several airports connecting the island to the rest of the world, there are several hundred transportation companies that service the Long Island/New York City area. Winston airport shuttle, the oldest of these companies in business since 1973, was the first to introduce door-to-door shared-ride service to and from the major airports, which almost all transportation companies now utilize.\n\nMany public and private high schools on Long Island are ranked among the best in the United States. Nassau and Suffolk Counties are the home of 125 public school districts containing a total of 656 public schools. It also hosts a number of private schools such as Friends Academy, Chaminade High School, Kellenberg Memorial High School, St. Anthony's High School, and North Shore Hebrew Academy, as well as parochial schools, many of which are operated by the Catholic Diocese of Rockville Centre.\n\nIn contrast, all of Brooklyn and Queens are served by the New York City Department of Education, the largest school district in the United States. Three of the nine specialized high schools in New York City are in the two Long Island boroughs, those being Brooklyn Latin School, Brooklyn Technical High School (one of the original three specialized schools), and Queens High School for the Sciences. Like Nassau and Suffolk Counties, they, too, are home to numerous private schools, such as Poly Prep Country Day School, Packer Collegiate Institute, and Saint Ann's School, and Berkeley Carroll School, and parochial schools operated by the Catholic Diocese of Brooklyn.\n\nLong Island is home to a range of higher-education institutions, both public and private. Brooklyn and Queens contain five of eleven senior colleges within CUNY, the public university system of New York City and one of the largest in the country. Among these are the notable institutions of Brooklyn College and Queens College. Brooklyn also contains private colleges such as Pratt Institute and the New York University Polytechnic School of Engineering, an engineering college that merged with New York University in 2014.\n\nSeveral colleges and universities within the State University of New York system are on Long Island, including Stony Brook (which noted its health sciences research and medical center), as well as Nassau Community College and Suffolk County Community College that serve their respective counties. Private institutions include the New York Institute of Technology, Hofstra University and Adelphi University (both in the Town of Hempstead), as well as Long Island University (with its C.W. Post campus, on a former Gold Coast estate in Brookville, and a satellite campus in downtown Brooklyn). Long Island also contains the Webb Institute, a small naval architecture college in Glen Cove. In addition, the island is home to the United States Merchant Marine Academy, a Federal Service Academy in Kings Point, on the North Shore.\n\nMusic on Long Island (Nassau and Suffolk) is strongly influenced by the proximity to New York City and by the youth culture of the suburbs.\nPsychedelic rock was widely popular in the 1960s as flocks of disaffected youth travelled to NYC to participate in protest and the culture of the time. R & B also has a history on Long Island, especially in areas close to New York City. In the late 1970s through the 1980s, the influence of radio station WLIR made Long Island one of the first places in the U.S. to hear and embrace European New Wave bands such as Depeche Mode, the Pet Shop Boys, and Culture Club. In the 1990s, hip-hop became very popular with rap pioneers Rakim, EPMD, and Public Enemy growing up on Long Island. Long Island was the home of a bustling emo scene in the 2000s, with bands such as Brand New, Taking Back Sunday, Straylight Run, From Autumn to Ashes and As Tall as Lions. More recently, newer acts have been making a name for themselves originating from Long Island, including Austin Schoeffel, Jon Bellion, and Envy on the Coast.\n\nFamous rock bands that originated on Long Island include The Rascals, The Ramones (from Queens), Dream Theater, Blue Öyster Cult, Twisted Sister and guitar virtuosos Donald (Buck Dharma) Roeser, John Petrucci, Steve Vai and Joe Satriani, as well as drummer Mike Portnoy. Rock and pop singer Billy Joel grew up in Hicksville, Long Island and his youthful life there is reflected in some of his music.\n\nThe Nassau Coliseum and Northwell Health at Jones Beach Theater are venues used by national touring acts as performance spaces for concerts. Northwell Health at Jones Beach Theater is an outdoor amphitheatre at Jones Beach State Park. It is a popular place to view summer concerts, with new as well as classic artists performing there during the summer months. It hosts a large Fourth of July fireworks show every year which fills the stands. People also park cars along the highway leading to the show, and others watch from the nearby beaches.\n\nLong Island is also known for its school music programs. Many schools in Suffolk County have distinguished music programs, with high numbers of students who are accepted into the statewide All-State music groups, or even the National All-Eastern Coast music groups. Both the Suffolk County and Nassau County Music Educator's Associations are recognized by The National Association for Music Education (NAfME),\nand host numerous events, competitions, and other music-related activities.\n\nLong Island has historically been a center for fishing and seafood. This legacy continues in the Blue Point oyster, a now ubiquitous variety that was originally harvested on the Great South Bay and was the favorite oyster of Queen Victoria. Clams are also a popular food and clam digging a popular recreational pursuit, with Manhattan clam chowder reputed to have Long Island origins.\n\nOf land-based produce, Long Island duck has a history of national recognition since the 19th century, with four duck farms continuing to produce 2 million ducks a year . Two symbols of Long Island's duck farming heritage are the Long Island Ducks minor-league baseball team and the Big Duck, a 1931 duck-shaped building that is a historic landmark and tourist attraction. In addition to Long Island's duck industry, Riverhead contains one of the largest buffalo farms on the East coast.\n\nLong Island is well known for its production of alcoholic beverages. Eastern Long Island is a significant producer of wines. Vineyards are most heavily concentrated on Long Island's North Fork, which contains 38 wineries. Most of these contain tasting rooms, which serve as popular tourist attractions for visitors from across the New York metropolitan area. Long Island has also become a producer of diverse craft beers, with 15 microbreweries existing across Nassau and Suffolk Counties . The largest of these is Blue Point Brewing Company, best known for its \"toasted lager\". Long Island is also globally known for its signature cocktail, the Long Island Iced Tea, which purportedly was invented at the popular Babylon, Oak Beach Inn nightclub in the 1970s.\n\nThe eateries on Long Island are largely a product of the region's local ethnic populations. Asian cuisines, Italian cuisine, Jewish cuisine, and Latin American cuisines were the most popular categories of ethnic cuisine on Long Island as of the second decade of the 2000s. Asian cuisines are predominantly represented by East Asian, South Asian, and Middle Eastern cuisines. Italian cuisine is found in ubiquitous pizzerias spread throughout the island, with the region hosting an annual competition, the Long Island Pizza Festival & Bake-Off. Jewish cuisine is likewise represented by delicatessens and bagel stores. Latin American cuisines span their geographical origins, ranging from Brazilian rodizios to Mexican taquerias.\n\nThe New York Mets baseball team plays at Citi Field in Flushing Meadows-Corona Park, Queens. Their former stadium, Shea Stadium was also home for the New York Jets football team from 1964 until 1983. The new stadium is designed with an exterior façade and main entry rotunda inspired by Brooklyn's famous Ebbets Field (see below). The New York Mets had planned to move their Double-A farm team to Long Island, as part of the ambitious but now-defunct plan for Nassau County called The Lighthouse Project. The Brooklyn Cyclones are a minor league baseball team, affiliated with the New York Mets. The Cyclones play at MCU Park just off the boardwalk on Coney Island in Brooklyn. An artificial turf baseball complex named Baseball Heaven is in Yaphank.\n\nThe Barclays Center, a sports arena, business, and residential complex built partly on a platform over the Atlantic Yards at Atlantic Avenue in Brooklyn, is the home of the Brooklyn Nets basketball team and the New York Islanders hockey team. The move from New Jersey in the summer of 2012 marked the return to Long Island for the Nets franchise, which played at Nassau Veterans Memorial Coliseum in Uniondale from 1972 to 1977. The Islanders played at Nassau Coliseum from their 1972 inception through 2015.\n\nEbbets Field, which stood in Brooklyn from 1913 until its demolition in 1960, was the home of the Brooklyn Dodgers baseball team, who moved to California after the 1957 Major League Baseball season to become the Los Angeles Dodgers. The Dodgers won several National League pennants in the 1940s and 1950s, losing several times in the World Series—often called \"Subway Series\"—to their Bronx rivals, the New York Yankees. The Dodgers won their lone championship in Brooklyn in the 1955 World Series versus the Yankees.\n\nDespite this success during the latter part of the team's stay in Brooklyn, they were a second-division team with an unspectacular winning record for much of their history there – but nonetheless became legendary for the almost-fanatical devotion of the Brooklynites who packed the relatively small ballpark to vigorously root for the team they affectionately called, \"Dem Bums\". Loss of the Dodgers to California was locally considered a civic tragedy that negatively affected the community far more than did the similar moves of other established teams to new cities in the 1950s, including the Dodgers' long-time arch-rival New York Giants, who also left for California after 1957.\n\nLong Island is also home to the Long Island Ducks minor league baseball team of the Atlantic League. Their stadium, Bethpage Ballpark, is in Central Islip. The Brooklyn Cyclones minor league baseball team, affiliated with the New York Mets, plays in the Short-Season A classification New York–Penn League. The Cyclones play at MCU Park just off the Coney Island boardwalk in the New York City borough of Brooklyn. The New York Dragons of the Arena Football League played their home games at Nassau Coliseum.The two main rugby union teams are the Long Island RFC in East Meadow and the Suffolk Bull Moose in Stony Brook.\n\nThe New York Sharks is a women's American football team that is a member of the Women's Football Alliance.The New York Sharks home field is at Aviator Sports Complex in Brooklyn.\n\nLong Island has a professional soccer club, the New York Cosmos, who play in the Division 2 North American Soccer League at James M. Shuart Stadium in Hempstead.\n\nLong Island has historically been a hotbed of lacrosse at the youth and college level, which made way for a Major League Lacrosse team in 2001, the Long Island Lizards. The Lizards play at Mitchel Athletic Complex in Uniondale.\n\nLong Island has a wide variety of golf courses found all over the island. Two of the most famous are the Shinnecock Hills Golf Club and the public Bethpage Black Course that both has hosted multiple U.S. Open tournaments as well as several other top level international championships. Queens also hosts one of the four tennis grand slams, the US Open. Every August (September, in Olympic years) the best tennis players in the world travel to Long Island to play the championships, which is held in the USTA National Tennis Center, adjacent to Citi Field in Flushing Meadows Park. The complex also contains the biggest tennis stadium in the world, the Arthur Ashe Stadium.\n\nLong Island also has two horse racing tracks, Aqueduct Racetrack in Ozone Park, Queens and Belmont Park on the Queens/Nassau border in Elmont, home of the Belmont Stakes. The longest dirt thoroughbred racecourse in the world is also at Belmont Park. Another category of sporting events popular in this region involves firematic racing events, involving many local volunteer fire departments.\n\nLong Island is home to numerous famous athletes, including Hall of Famers Jim Brown, Julius Erving, John Mackey, Whitey Ford, Nick Drahos, and Carl Yastrzemski. Others include Gold Medalists Sue Bird, Sarah Hughes and Derrick Adkins, D'Brickashaw Ferguson, Billy Donovan, Larry Brown, Rick Pitino, John McEnroe, Jumbo Elliott, Mick Foley, Zack Ryder, Matt Serra, Boomer Esiason, Vinny Testaverde, Craig Biggio, Frank Catalanotto, Greg Sacks, Rob Burnett, Steve Park, Frank Viola, Chris Weidman, Marques Colston and Speedy Claxton.\n\nSeveral NHL players were born and/or raised on Long Island, such as Vancouver Canucks Christopher Higgins and Matt Gilroy, Nashville Predators Eric Nystrom, Toronto Maple Leaf Mike Komisarek, Pittsburgh Penguin Rob Scuderi, and New Jersey Devil Keith Kinkaid. Both Komisarek and Higgins played on the same Suffolk County Hockey League team at an early age, and later played on the Montreal Canadiens together. Nick Drahos was an All Scholastic and All Long Island honoree at Lawrence High School, Nassau Co. in 1936 and 1937, and a two-time Unanimous National College All-American in the years of 1939 and 1940 at Cornell University.\n\n\n"}
{"id": "18317", "url": "https://en.wikipedia.org/wiki?curid=18317", "title": "Lower Peninsula of Michigan", "text": "Lower Peninsula of Michigan\n\nThe Lower Peninsula of Michigan is the southern of the two major landmasses of the U.S. state of Michigan, the other being the Upper Peninsula. It is surrounded by water on all sides except its southern border, which it shares with Indiana and Ohio. Although the Upper Peninsula is commonly referred to as \"the U.P.\" it is fairly uncommon for the Lower Peninsula to be called \"the L.P.\"\n\nBecause of its recognizable shape, the Lower Peninsula is nicknamed \"the mitten\", with the eastern region identified as \"The Thumb\". This has led to several folkloric creation myths for the area, one being that it is a hand print of Paul Bunyan, a giant lumberjack and popular European-American folk character in Michigan. When asked where they live, Lower Peninsula residents may hold up their right palm and point to a spot on it to indicate the location. The peninsula is sometimes divided into the Northern Lower Peninsula—which is more sparsely populated and largely forested—and the Southern Lower Peninsula—which is largely urban or farmland.\n\nThe Lower Peninsula dominates Michigan politics, and maps of it without the Upper Peninsula are sometimes presented as \"Michigan\", which contribute to resentment by \"Yoopers\" (residents of \"the U.P\"). Yoopers jokingly refer to residents of the Lower Peninsula as \"flat-landers\" (referring to the region's less rugged terrain) or \"trolls\" (because, living south of the Mackinac Bridge, they \"live under the bridge\").\n\nThe Lower Peninsula is bounded on the south by the states of Indiana and Ohio. It is bounded by the west by Lake Michigan and on the northeast by Lake Huron, which connect at the Straits of Mackinac. In the southeast, the waterway of the St. Clair River, Lake St. Clair, Detroit River, and Lake Erie separate it from the province of Ontario, Canada.\n\nAt its widest points, the Lower Peninsula is long from north to south and from east to west. It contains nearly two-thirds of Michigan's total land area. The surface of the peninsula is generally level, broken by conical hills and glacial moraines usually not more than a few hundred feet tall. The western coast features extensive sandy beaches and dunes. It is divided by a low water divide running north and south. The larger portion of the state is on the west of this and gradually slopes toward Lake Michigan. The highest point in the Lower Peninsula is not definitely established but is either Briar Hill at 1,705 feet (520 m), or one of several points nearby in the vicinity of Cadillac. The lowest point is the surface of Lake Erie at 571 feet (174 m).\n\nThe American Bird Conservancy and the National Audubon Society have designated several locations as internationally Important Bird Areas.\n\nThe Lower Peninsula is dominated by a geological basin known as the Michigan Basin. That feature is represented by a nearly circular pattern of geologic sedimentary strata in the area with a nearly uniform structural dip toward the center of the peninsula. The basin is centered in Gladwin County where the Precambrian basement rocks are deep. Around the margins, such as under Mackinaw City, Michigan, the Precambrian surface is around down. This contour on the bedrock clips the northern part of the lower peninsula and continues under Lake Michigan along the west. It crosses the southern counties of Michigan and continues on to the north beneath Lake Huron.\n\n\nPrimary Interstate Highways have two digits on their shields; auxiliary Interstate Highways have three digits. Interstate Highways include:\n\nU.S. Highways include:\n\nThe Great Lakes Circle Tour is a designated scenic road system connecting all of the Great Lakes and the St. Lawrence River.\n\nMichigan's Lower Peninsula can be divided into four main regions based on geological, soil, and vegetation differences; amount of urban areas or rural areas; minority populations; and agriculture. The four principal regions listed below can further be separated into sub-regions and overlapping areas.\n\n\n"}
{"id": "18318", "url": "https://en.wikipedia.org/wiki?curid=18318", "title": "Lake Toba", "text": "Lake Toba\n\nLake Toba () is a large natural lake in Indonesia occupying the caldera of a supervolcano. The lake is about long, wide, and up to deep. Located in the middle of the northern part of the Indonesian island of Sumatra, with a surface elevation of about , the lake stretches from to . It is the largest lake in Indonesia and the largest volcanic lake in the world.\n\nLake Toba is the site of a massive supervolcanic eruption estimated at VEI 8 that occurred 69,000 to 77,000 years ago, representing a climate-changing event. Recent advances in dating methods suggest a more accurate identification of 74,000 years ago as the date. It is the largest-known explosive eruption on Earth in the last 25 million years. According to the Toba catastrophe theory, it had global consequences for human populations; it killed most humans living at that time and is believed to have created a population bottleneck in central east Africa and India, which affects the genetic make-up of the human worldwide population to the present. \n\nIt has been accepted that the eruption of Toba led to a volcanic winter with a worldwide decrease in temperature between , and up to in higher latitudes. Additional studies in Lake Malawi in East Africa show significant amounts of ash being deposited from the Toba eruptions, even at that great distance, but little indication of a significant climatic effect in East Africa.\n\nOn 18 June 2018, Lake Toba was the scene of a ferry disaster, in which over 190 people drowned.\n\nThe Toba caldera complex in North Sumatra comprises four overlapping volcanic craters that adjoin the Sumatran \"volcanic front\". With it is the world's largest Quaternary caldera, and the fourth and youngest caldera. It intersects the three older calderas. An estimated of dense-rock equivalent pyroclastic material, known as the youngest Toba tuff, was released during one of the largest explosive volcanic eruptions in recent geological history. Following this eruption, a resurgent dome formed within the new caldera, joining two half-domes separated by a longitudinal graben.\n\nAt least four cones, four stratovolcanoes, and three craters are visible in the lake. The Tandukbenua cone on the northwestern edge of the caldera has only sparse vegetation, suggesting a young age of several hundred years. Also, the Pusubukit (Hill Center) volcano ( above sea level) on the south edge of the caldera is solfatarically active.\n\nThe \"Toba eruption\" (the \"Toba event\") occurred at what is now Lake Toba about 75,000±900 years ago. It was the last in a series of at least four caldera-forming eruptions at this location, with earlier calderas having formed around 788,000±2,200 years ago. This last eruption had an estimated VEI=8, making it the largest-known explosive volcanic eruption within the last 25 million years.\n\nBill Rose and Craig Chesner of Michigan Technological University have estimated that the total amount of material released in the eruption was about —about of ignimbrite that flowed over the ground, and approximately that fell as ash mostly to the west. However, based on the new method (crystal concentration and exponential), Toba possibly erupted of ignimbrite and co-ignimbrite. The pyroclastic flows of the eruption destroyed an area of least , with ash deposits as thick as by the main vent.\n\nThe eruption was large enough to have deposited an ash layer approximately thick over all of South Asia; at one site in central India, the Toba ash layer today is up to thick and parts of Malaysia were covered with of ash fall. In addition it has been variously calculated that of sulfurous acid or of sulfur dioxide were ejected into the atmosphere by the event.\n\nThe subsequent collapse formed a caldera that filled with water, creating Lake Toba. The island in the center of the lake is formed by a resurgent dome.\n\nThe exact year of the eruption is unknown, but the pattern of ash deposits suggests that it occurred during the northern summer because only the summer monsoon could have deposited Toba ashfall in the South China Sea. The eruption lasted perhaps two weeks, and the ensuing volcanic winter resulted in a decrease in average global temperatures by for several years. Ice cores from Greenland record a pulse of starkly reduced levels of organic carbon sequestration. Very few plants or animals in southeast Asia would have survived, and it is possible that the eruption caused a planet-wide die-off. However, the global cooling has been discussed by Rampino and Self. Their conclusion is that the cooling had already started before Toba's eruption. This conclusion was supported by Lane and Zielinski who studied the lake-core from Africa and GISP2. They concluded that there was no volcanic winter after Toba eruption and that high HSO deposits do not cause long-term effects.\n\nEvidence from studies of mitochondrial DNA suggests that humans may have passed through a genetic bottleneck around this time that reduced genetic diversity below what would be expected given the age of the species. According to the Toba catastrophe theory, proposed by Stanley H. Ambrose of the University of Illinois at Urbana–Champaign in 1998, the effects of the Toba eruption may have decreased the size of human populations to only a few tens of thousands of individuals. However, this hypothesis is not widely accepted because similar effects on other animal species have not been observed, and paleoanthropology suggests there was no population bottleneck.\n\nSince the major eruption ~70,000 years ago, eruptions of smaller magnitude have also occurred at Toba. The small cone of Pusukbukit formed on the southwestern margin of the caldera and lava domes. The most recent eruption may have been at Tandukbenua on the northwestern caldera edge, suggested by a lack of vegetation that could be due to an eruption within the last few hundred years.\n\nSome parts of the caldera have shown uplift due to partial refilling of the magma chamber, for example, pushing Samosir Island and the Uluan Peninsula above the surface of the lake. The lake sediments on Samosir Island show that it has risen by at least since the cataclysmic eruption. Such uplifts are common in very large calderas, apparently due to the upward pressure of below-ground magma. Toba is probably the largest resurgent caldera on Earth. Large earthquakes have recently occurred in the vicinity of the volcano, notably in 1987 along the southern shore of the lake at a depth of . Such earthquakes have also been recorded in 1892, 1916, and 1920–1922.\n\nLake Toba lies near the Great Sumatran fault, which runs along the centre of Sumatra in the Sumatra Fracture Zone. The volcanoes of Sumatra and Java are part of the Sunda Arc, a result of the northeasterly movement of the Indo-Australian Plate, which is sliding under the eastward-moving Eurasian Plate. The subduction zone in this area is very active: the seabed near the west coast of Sumatra has had several major earthquakes since 1995, including the 9.1 2004 Indian Ocean earthquake and the 8.7 2005 Nias–Simeulue earthquake, the epicenters of which were around from Toba.\n\nMost of the people who live around Lake Toba are ethnically Bataks. Traditional Batak houses are noted for their distinctive roofs (which curve upwards at each end, as a boat's hull does) and their colorful decor.\n\nThe flora of the lake includes various types of phytoplankton, emerged macrophytes, floating macrophytes, and submerged macrophytes, while the surrounding countryside is rainforest including areas of Sumatran tropical pine forests on the higher mountainsides.\n\nThe fauna includes several species of zooplankton and benthic animals. Since the lake is oligotrophic (nutrient-poor), the native fish fauna is relatively scarce, and the only endemics are \"Rasbora tobana\" (strictly speaking near-endemic, since also found in some tributary rivers that run into the lake) and \"Neolissochilus thienemanni\", locally known as the Batak fish. The latter species is threatened by deforestation (causing siltation), pollution, changes in water level and the numerous fish species that have been introduced to the lake. Other native fishes include species such as \"Aplocheilus panchax\", \"Nemacheilus pfeifferae\", \"Homaloptera gymnogaster\", \"Channa gachua\", \"Channa striata\", \"Clarias batrachus\", \"Barbonymus gonionotus\", \"Barbonymus schwanenfeldii\", \"Danio albolineatus\", \"Osteochilus vittatus\", \"Puntius binotatus\", \"Rasbora jacobsoni\", \"Tor tambra\", \"Betta imbellis\", \"Betta taeniata\" and \"Monopterus albus\". Among the many introduced species are \"Anabas testudineus\", \"Oreochromis mossambicus\", \"Oreochromis niloticus\", \"Ctenopharyngodon idella\", \"Cyprinus carpio\", \"Osphronemus goramy\", \"Trichogaster pectoralis\", \"Trichopodus trichopterus\", \"Poecilia reticulata\" and \"Xiphophorus hellerii\".\n\nThe sinking of the MV Sinar Bangun took place in June 2018, when an irregular operating vessel traveling at the lake capsized with many passengers on board. The incident caused the death of 190 people and injuries to a number of others. Preliminary reports found the vessel was in operation with irregularities. Ignoring overloading on the vessel and operating in rough weather conditions were concluded as the main reason leading to the disaster. Around 50 cars and 100 motorbikes, which were aboard, also sank into the lake on that day.\n\n\n\n"}
{"id": "18320", "url": "https://en.wikipedia.org/wiki?curid=18320", "title": "Lens (optics)", "text": "Lens (optics)\n\nA lens is a transmissive optical device that focuses or disperses a light beam by means of refraction. A simple lens consists of a single piece of transparent material, while a compound lens consists of several simple lenses (\"elements\"), usually arranged along a common axis. Lenses are made from materials such as glass or plastic, and are ground and polished or molded to a desired shape. A lens can focus light to form an image, unlike a prism, which refracts light without focusing. Devices that similarly focus or disperse waves and radiation other than visible light are also called lenses, such as microwave lenses, electron lenses, acoustic lenses, or explosive lenses.\n\nThe word \"lens\" comes from \" lēns \", the Latin name of the lentil, because a double-convex lens is lentil-shaped. The lentil plant also gives its name to a geometric figure.\n\nSome scholars argue that the archeological evidence indicates that there was widespread use of lenses in antiquity, spanning several millennia. The so-called Nimrud lens is a rock crystal artifact dated to the 7th century BC which may or may not have been used as a magnifying glass, or a burning glass. Others have suggested that certain Egyptian hieroglyphs depict \"simple glass meniscal lenses\".\n\nThe oldest certain reference to the use of lenses is from Aristophanes' play \"The Clouds\" (424 BC) mentioning a burning-glass.\nPliny the Elder (1st century) confirms that burning-glasses were known in the Roman period.\nPliny also has the earliest known reference to the use of a corrective lens when he mentions that Nero was said to watch the gladiatorial games using an emerald (presumably concave to correct for nearsightedness, though the reference is vague). Both Pliny and Seneca the Younger (3 BC–65 AD) described the magnifying effect of a glass globe filled with water.\n\nPtolemy (2nd century) wrote a book on \"Optics\", which however survives only in the Latin translation of an incomplete and very poor Arabic translation.\nThe book was, however, received, by medieval scholars in the Islamic world, and commented upon by Ibn Sahl (10th century), who was in turn improved upon by Alhazen (\"Book of Optics\", 11th century). The Arabic translation of Ptolemy's \"Optics\" became available in Latin translation in the 12th century (Eugenius of Palermo 1154). Between the 11th and 13th century \"reading stones\" were invented. These were primitive plano-convex lenses initially made by cutting a glass sphere in half. The medieval (11th or 12th century) rock cystal Visby lenses may or may not have been intended for use as burning glasses.\n\nSpectacles were invented as an improvement of the \"reading stones\" of the high medieval period in Northern Italy in the second half of the 13th century. This was the start of the optical industry of grinding and polishing lenses for spectacles, first in Venice and Florence in the late 13th century, and later in the spectacle-making centres in both the Netherlands and Germany.\nSpectacle makers created improved types of lenses for the correction of vision based more on empirical knowledge gained from observing the effects of the lenses (probably without the knowledge of the rudimentary optical theory of the day). The practical development and experimentation with lenses led to the invention of the compound optical microscope around 1595, and the refracting telescope in 1608, both of which appeared in the spectacle-making centres in the Netherlands.\nWith the invention of the telescope and microscope there was a great deal of experimentation with lens shapes in the 17th and early 18th centuries by those trying to correct chromatic errors seen in lenses. Opticians tried to construct lenses of varying forms of curvature, wrongly assuming errors arose from defects in the spherical figure of their surfaces. Optical theory on refraction and experimentation was showing no single-element lens could bring all colours to a focus. This led to the invention of the compound achromatic lens by Chester Moore Hall in England in 1733, an invention also claimed by fellow Englishman John Dollond in a 1758 patent.\nMost lenses are \"spherical lenses\": their two surfaces are parts of the surfaces of spheres. Each surface can be \"convex\" (bulging outwards from the lens), \"concave\" (depressed into the lens), or \"planar\" (flat). The line joining the centres of the spheres making up the lens surfaces is called the \"axis\" of the lens. Typically the lens axis passes through the physical centre of the lens, because of the way they are manufactured. Lenses may be cut or ground after manufacturing to give them a different shape or size. The lens axis may then not pass through the physical centre of the lens.\n\nToric or sphero-cylindrical lenses have surfaces with two different radii of curvature in two orthogonal planes. They have a different focal power in different meridians. This forms an astigmatic lens. An example is eyeglass lenses that are used to correct astigmatism in someone's eye.\n\nMore complex are aspheric lenses. These are lenses where one or both surfaces have a shape that is neither spherical nor cylindrical. The more complicated shapes allow such lenses to form images with less aberration than standard simple lenses, but they are more difficult and expensive to produce.\n\nLenses are classified by the curvature of the two optical surfaces. A lens is \"biconvex\" (or \"double convex\", or just \"convex\") if both surfaces are convex. If both surfaces have the same radius of curvature, the lens is \"equiconvex\". A lens with two concave surfaces is \"biconcave\" (or just \"concave\"). If one of the surfaces is flat, the lens is \"plano-convex\" or \"plano-concave\" depending on the curvature of the other surface. A lens with one convex and one concave side is \"convex-concave\" or \"meniscus\". It is this type of lens that is most commonly used in corrective lenses.\n\nIf the lens is biconvex or plano-convex, a collimated beam of light passing through the lens converges to a spot (a \"focus\") behind the lens. In this case, the lens is called a \"positive\" or \"converging\" lens. The distance from the lens to the spot is the focal length of the lens, which is commonly abbreviated \"f\" in diagrams and equations. An extended hemispherical lens is a special type of plano-convex lens, in which the lens's curved surface is a full hemisphere and the lens is much thicker than the radius of curvature.\n\nIf the lens is biconcave or plano-concave, a collimated beam of light passing through the lens is diverged (spread); the lens is thus called a \"negative\" or \"diverging\" lens. The beam, after passing through the lens, appears to emanate from a particular point on the axis in front of the lens. The distance from this point to the lens is also known as the focal length, though it is negative with respect to the focal length of a converging lens.\nConvex-concave (meniscus) lenses can be either positive or negative, depending on the relative curvatures of the two surfaces. A \"negative meniscus\" lens has a steeper concave surface and is thinner at the centre than at the periphery. Conversely, a \"positive meniscus\" lens has a steeper convex surface and is thicker at the centre than at the periphery. An ideal thin lens with two surfaces of equal curvature would have zero optical power, meaning that it would neither converge nor diverge light. All real lenses have nonzero thickness, however, which makes a real lens with identical curved surfaces slightly positive. To obtain exactly zero optical power, a meniscus lens must have slightly unequal curvatures to account for the effect of the lens' thickness.\n\nThe focal length of a lens \"in air\" can be calculated from the lensmaker's equation:\n\nwhere\n\nThe focal length \"f\" is positive for converging lenses, and negative for diverging lenses. The reciprocal of the focal length, 1/\"f\", is the optical power of the lens. If the focal length is in metres, this gives the optical power in dioptres (inverse metres).\n\nLenses have the same focal length when light travels from the back to the front as when light goes from the front to the back. Other properties of the lens, such as the aberrations are not the same in both directions.\n\nThe signs of the lens' radii of curvature indicate whether the corresponding surfaces are convex or concave. The sign convention used to represent this varies, but in this article a \"positive\" \"R\" indicates a surface's center of curvature is further along in the direction of the ray travel (right, in the accompanying diagrams), while \"negative\" \"R\" means that rays reaching the surface have already passed the center of curvature. Consequently, for external lens surfaces as diagrammed above, and indicate \"convex\" surfaces (used to converge light in a positive lens), while and indicate \"concave\" surfaces. The reciprocal of the radius of curvature is called the curvature. A flat surface has zero curvature, and its radius of curvature is infinity.\n\nIf \"d\" is small compared to \"R\" and \"R\", then the \"thin lens\" approximation can be made. For a lens in air, \"f\" is then given by\n\nAs mentioned above, a positive or converging lens in air focuses a collimated beam travelling along the lens axis to a spot (known as the focal point) at a distance \"f\" from the lens. Conversely, a point source of light placed at the focal point is converted into a collimated beam by the lens. These two cases are examples of image formation in lenses. In the former case, an object at an infinite distance (as represented by a collimated beam of waves) is focused to an image at the focal point of the lens. In the latter, an object at the focal length distance from the lens is imaged at infinity. The plane perpendicular to the lens axis situated at a distance \"f\" from the lens is called the \"focal plane\".\n\nIf the distances from the object to the lens and from the lens to the image are \"S\" and \"S\" respectively, for a lens of negligible thickness, in air, the distances are related by the thin lens formula:\n\nThis can also be put into the \"Newtonian\" form:\n\nwhere formula_10 and formula_11.\nTherefore, if an object is placed at a distance from a positive lens of focal length \"f\", we will find an image distance \"S\" according to this formula. If a screen is placed at a distance \"S\" on the opposite side of the lens, an image is formed on it. This sort of image, which can be projected onto a screen or image sensor, is known as a \"real image\".\nThis is the principle of the camera, and of the human eye. The focusing adjustment of a camera adjusts \"S\", as using an image distance different from that required by this formula produces a defocused (fuzzy) image for an object at a distance of \"S\" from the camera. Put another way, modifying \"S\" causes objects at a different \"S\" to come into perfect focus.\n\nIn some cases \"S\" is negative, indicating that the image is formed on the opposite side of the lens from where those rays are being considered. Since the diverging light rays emanating from the lens never come into focus, and those rays are not physically present at the point where they \"appear\" to form an image, this is called a virtual image. Unlike real images, a virtual image cannot be projected on a screen, but appears to an observer looking through the lens as if it were a real object at the location of that virtual image. Likewise, it appears to a subsequent lens as if it were an object at that location, so that second lens could again focus that light into a real image, \"S\" then being measured from the virtual image location behind the first lens to the second lens. This is exactly what the eye does when looking through a magnifying glass. The magnifying glass creates a (magnified) virtual image behind the magnifying glass, but those rays are then re-imaged by the lens of the eye to create a \"real image\" on the retina.\nUsing a positive lens of focal length \"f\", a virtual image results when , the lens thus being used as a magnifying glass (rather than if as for a camera). Using a negative lens () with a \"real object\" () can only produce a virtual image (), according to the above formula. It is also possible for the object distance \"S\" to be negative, in which case the lens sees a so-called \"virtual object\". This happens when the lens is inserted into a converging beam (being focused by a previous lens) \"before\" the location of its real image. In that case even a negative lens can project a real image, as is done by a Barlow lens.\n\nFor a thin lens, the distances \"S\" and \"S\" are measured from the object and image to the position of the lens, as described above. When the thickness of the lens is not much smaller than \"S\" and \"S\" or there are multiple lens elements (a compound lens), one must instead measure from the object and image to the principal planes of the lens. If distances \"S\" or \"S\" pass through a medium other than air or vacuum a more complicated analysis is required.\n\nThe linear \"magnification\" of an imaging system using a single lens is given by\n\nwhere \"M\" is the magnification factor defined as the ratio of the size of an image compared to the size of the object. The sign convention here dictates that if \"M\" is negative, as it is for real images, the image is upside-down with respect to the object. For virtual images \"M\" is positive, so the image is upright.\n\nLinear magnification \"M\" is not always the most useful measure of magnifying power. For instance, when characterizing a visual telescope or binoculars that produce only a virtual image, one would be more concerned with the angular magnification—which expresses how much larger a distant object appears through the telescope compared to the naked eye. In the case of a camera one would quote the plate scale, which compares the apparent (angular) size of a distant object to the size of the real image produced at the focus. The plate scale is the reciprocal of the focal length of the camera lens; lenses are categorized as long-focus lenses or wide-angle lenses according to their focal lengths.\n\nUsing an inappropriate measurement of magnification can be formally correct but yield a meaningless number. For instance, using a magnifying glass of 5 cm focal length, held 20 cm from the eye and 5 cm from the object, produces a virtual image at infinity of infinite linear size: . But the \"angular magnification\" is 5, meaning that the object appears 5 times larger to the eye than without the lens. When taking a picture of the moon using a camera with a 50 mm lens, one is not concerned with the linear magnification Rather, the plate scale of the camera is about 1°/mm, from which one can conclude that the 0.5 mm image on the film corresponds to an angular size of the moon seen from earth of about 0.5°.\n\nIn the extreme case where an object is an infinite distance away, , and , indicating that the object would be imaged to a single point in the focal plane. In fact, the diameter of the projected spot is not actually zero, since diffraction places a lower limit on the size of the point spread function. This is called the diffraction limit.\n\nLenses do not form perfect images, and a lens always introduces some degree of distortion or \"aberration\" that makes the image an imperfect replica of the object. Careful design of the lens system for a particular application minimizes the aberration. Several types of aberration affect image quality, including spherical aberration, coma, and chromatic aberration.\n\n\"Spherical aberration\" occurs because spherical surfaces are not the ideal shape for a lens, but are by far the simplest shape to which glass can be ground and polished, and so are often used. Spherical aberration causes beams parallel to, but distant from, the lens axis to be focused in a slightly different place than beams close to the axis. This manifests itself as a blurring of the image. Lenses in which closer-to-ideal, non-spherical surfaces are used are called \"aspheric\" lenses. These were formerly complex to make and often extremely expensive, but advances in technology have greatly reduced the manufacturing cost for such lenses. Spherical aberration can be minimised by carefully choosing the surface curvatures for a particular application. For instance, a plano-convex lens, which is used to focus a collimated beam, produces a sharper focal spot when used with the convex side towards the beam source.\n\n\"Coma\", or \"comatic aberration\", derives its name from the comet-like appearance of the aberrated image. Coma occurs when an object off the optical axis of the lens is imaged, where rays pass through the lens at an angle to the axis θ. Rays that pass through the centre of a lens of focal length \"f\" are focused at a point with distance from the axis. Rays passing through the outer margins of the lens are focused at different points, either further from the axis (positive coma) or closer to the axis (negative coma). In general, a bundle of parallel rays passing through the lens at a fixed distance from the centre of the lens are focused to a ring-shaped image in the focal plane, known as a \"comatic circle\". The sum of all these circles results in a V-shaped or comet-like flare. As with spherical aberration, coma can be minimised (and in some cases eliminated) by choosing the curvature of the two lens surfaces to match the application. Lenses in which both spherical aberration and coma are minimised are called \"bestform\" lenses.\n\n\"Chromatic aberration\" is caused by the dispersion of the lens material—the variation of its refractive index, \"n\", with the wavelength of light. Since, from the formulae above, \"f\" is dependent upon \"n\", it follows that light of different wavelengths is focused to different positions. Chromatic aberration of a lens is seen as fringes of colour around the image. It can be minimised by using an achromatic doublet (or \"achromat\") in which two materials with differing dispersion are bonded together to form a single lens. This reduces the amount of chromatic aberration over a certain range of wavelengths, though it does not produce perfect correction. The use of achromats was an important step in the development of the optical microscope. An apochromat is a lens or lens system with even better chromatic aberration correction, combined with improved spherical aberration correction. Apochromats are much more expensive than achromats.\n\nDifferent lens materials may also be used to minimise chromatic aberration, such as specialised coatings or lenses made from the crystal fluorite. This naturally occurring substance has the highest known Abbe number, indicating that the material has low dispersion.\n\nOther kinds of aberration include \"field curvature\", \"barrel \" and \"pincushion distortion\", and \"astigmatism\".\n\nEven if a lens is designed to minimize or eliminate the aberrations described above, the image quality is still limited by the diffraction of light passing through the lens' finite aperture. A diffraction-limited lens is one in which aberrations have been reduced to the point where the image quality is primarily limited by diffraction under the design conditions.\n\nSimple lenses are subject to the optical aberrations discussed above. In many cases these aberrations can be compensated for to a great extent by using a combination of simple lenses with complementary aberrations. A \"compound lens\" is a collection of simple lenses of different shapes and made of materials of different refractive indices, arranged one after the other with a common axis.\n\nThe simplest case is where lenses are placed in contact: if the lenses of focal lengths \"f\" and \"f\" are \"thin\", the combined focal length \"f\" of the lenses is given by\n\nSince 1/\"f\" is the power of a lens, it can be seen that the powers of thin lenses in contact are additive.\n\nIf two thin lenses are separated in air by some distance \"d\", the focal length for the combined system is given by\n\nThe distance from the front focal point of the combined lenses to the first lens is called the \"front focal length\" (FFL):\n\nSimilarly, the distance from the second lens to the rear focal point of the combined system is the \"back focal length\" (BFL):\n\nAs \"d\" tends to zero, the focal lengths tend to the value of \"f\" given for thin lenses in contact.\n\nIf the separation distance is equal to the sum of the focal lengths (\"d\" = \"f\"+\"f\"), the FFL and BFL are infinite. This corresponds to a pair of lenses that transform a parallel (collimated) beam into another collimated beam. This type of system is called an \"afocal system\", since it produces no net convergence or divergence of the beam. Two lenses at this separation form the simplest type of optical telescope. Although the system does not alter the divergence of a collimated beam, it does alter the width of the beam. The magnification of such a telescope is given by\n\nwhich is the ratio of the output beam width to the input beam width. Note the sign convention: a telescope with two convex lenses (\"f\" > 0, \"f\" > 0) produces a negative magnification, indicating an inverted image. A convex plus a concave lens (\"f\" > 0 > \"f\") produces a positive magnification and the image is upright. For further information on simple optical telescopes, see Refracting telescope § Refracting telescope designs.\n\nCylindrical lenses have curvature in only one direction. They are used to focus light into a line, or to convert the elliptical light from a laser diode into a round beam. They are also used in motion picture anamorphic lenses.\nA Fresnel lens has its optical surface broken up into narrow rings, allowing the lens to be much thinner and lighter than conventional lenses. Durable Fresnel lenses can be molded from plastic and are inexpensive.\n\nLenticular lenses are arrays of microlenses that are used in lenticular printing to make images that have an illusion of depth or that change when viewed from different angles.\n\nA gradient index lens has flat optical surfaces, but has a radial or axial variation in index of refraction that causes light passing through the lens to be focused.\n\nAn axicon has a conical optical surface. It images a point source into a line \"along\" the optic axis, or transforms a laser beam into a ring.\n\nDiffractive optical elements can function as lenses.\n\nSuperlenses are made from negative index metamaterials and claim to produce images at spatial resolutions exceeding the diffraction limit. The first superlenses were made in 2004 using such a metamaterial for microwaves. Improved versions have been made by other researchers. the superlens has not yet been demonstrated at visible or near-infrared wavelengths.\n\nA prototype flat ultrathin lens, with no curvature has been developed.\n\nA single convex lens mounted in a frame with a handle or stand is a magnifying glass.\n\nLenses are used as prosthetics for the correction of visual impairments such as myopia, hypermetropia, presbyopia, and astigmatism. (See corrective lens, contact lens, eyeglasses.) Most lenses used for other purposes have strict axial symmetry; eyeglass lenses are only approximately symmetric. They are usually shaped to fit in a roughly oval, not circular, frame; the optical centres are placed over the eyeballs; their curvature may not be axially symmetric to correct for astigmatism. Sunglasses' lenses are designed to attenuate light; sunglass lenses that also correct visual impairments can be custom made.\n\nOther uses are in imaging systems such as monoculars, binoculars, telescopes, microscopes, cameras and projectors. Some of these instruments produce a virtual image when applied to the human eye; others produce a real image that can be captured on photographic film or an optical sensor, or can be viewed on a screen. In these devices lenses are sometimes paired up with curved mirrors to make a catadioptric system where the lens's spherical aberration corrects the opposite aberration in the mirror (such as Schmidt and meniscus correctors).\n\nConvex lenses produce an image of an object at infinity at their focus; if the sun is imaged, much of the visible and infrared light incident on the lens is concentrated into the small image. A large lens creates enough intensity to burn a flammable object at the focal point. Since ignition can be achieved even with a poorly made lens, lenses have been used as burning-glasses for at least 2400 years. A modern application is the use of relatively large lenses to concentrate solar energy on relatively small photovoltaic cells, harvesting more energy without the need to use larger and more expensive cells.\n\nRadio astronomy and radar systems often use dielectric lenses, commonly called a lens antenna to refract electromagnetic radiation into a collector antenna.\n\nLenses can become scratched and abraded. Abrasion-resistant coatings are available to help control this.\n\n\n\n"}
{"id": "18322", "url": "https://en.wikipedia.org/wiki?curid=18322", "title": "Lamorna Birch", "text": "Lamorna Birch\n\nSamuel John \"Lamorna\" Birch, RA, RWS (7 June 1869 – 7 January 1955) was an English artist in oils and watercolours. At the suggestion of fellow artist Stanhope Forbes, Birch adopted the \"soubriquet\" \"Lamorna\" to distinguish himself from Lionel Birch, an artist who was also working in the area at that time.\n\nLamorna Birch was born in Egremont, Cheshire, England. He was self-taught as an artist, except for a brief period of study at the Académie Colarossi in Paris during 1895.\n\nBirch settled in Lamorna, Cornwall in 1892, initially lodging at nearby Boleigh Farm. Many of his most famous pictures date from this time and the beautiful Lamorna Cove is usually their subject matter. He was attracted to Cornwall by the Newlyn group of artists but he ended up starting a second group based around his adopted home of Lamorna. He married Houghton (Mouse) Emily Vivian, the daughter of a mining agent from Camborne and they lived at Flagstaff Cottge, Lamorna.\n\nHe exhibited at the Royal Academy from 1893, was elected as an Associate (ARA) in 1926 and made a Royal Academician (RA) in 1934, and showed more than two hundred paintings there. He held his first one-man exhibition at the Fine Art Society in 1906 and is said to have produced more than 20,000 pictures. Like a number of his contemporaries, he was profiled as an 'Artist of Note' in \"The Artist\" magazine, by Richard Seddon, in the June 1944 edition.\n\n\n\nBirch has paintings at Penlee House and in the collection of Derby Art Gallery.\n"}
{"id": "18323", "url": "https://en.wikipedia.org/wiki?curid=18323", "title": "LDP", "text": "LDP\n\nLDP may mean:\n\n\n\n\n\n\n"}
{"id": "18325", "url": "https://en.wikipedia.org/wiki?curid=18325", "title": "Labour", "text": "Labour\n\nLabour (British spelling) or labor (American spelling) may refer to: \n\n\n\n\n\n"}
{"id": "18327", "url": "https://en.wikipedia.org/wiki?curid=18327", "title": "Library of Congress Classification", "text": "Library of Congress Classification\n\nThe Library of Congress Classification (LCC) is a system of library classification developed by the Library of Congress. It is used by most research and academic libraries in the U.S. and several other countries.\n\nLCC should not be confused with LCCN, the system of Library of Congress Control Numbers assigned to all books (and authors), which also defines URLs of their online catalog entries, such as \"82006074\" and \"<nowiki>http://lccn.loc.gov/82006074</nowiki>\". The Classification is also distinct from Library of Congress Subject Headings, the system of labels such as \"Boarding schools\" and \"Boarding schools—Fiction\" that describe contents systematically. Finally, the classifications may be distinguished from the call numbers assigned to particular copies of books in the collection, such as \"PZ7.J684 Wj 1982 FT MEADE Copy 1\" where the classification is \"PZ7.J684 Wj 1982\".\n\nThe classification was invented by Herbert Putnam in 1897, just before he assumed the librarianship of Congress. With advice from Charles Ammi Cutter, it was influenced by his Cutter Expansive Classification, the Dewey Decimal System, and the Putnam Classification System (developed while Putnam was head librarian at the Minneapolis Public Library). It was designed specifically for the purposes and collection of the Library of Congress to replace the fixed location system developed by Thomas Jefferson. By the time Putnam departed from his post in 1939, all the classes except K (Law) and parts of B (Philosophy and Religion) were well developed.\n\nLCC has been criticized for lacking a sound theoretical basis; many of the classification decisions were driven by the practical needs of that library rather than epistemological considerations. Although it divides subjects into broad categories, it is essentially enumerative in nature. That is, it provides a guide to the books actually in one library's collections, not a classification of the world.\n\nIn 2007 \"The Wall Street Journal\" reported that in the countries it surveyed most public libraries and small academic libraries used the older Dewey Decimal Classification system.\n\nThe National Library of Medicine classification system (NLM) uses the initial letters \"W\" and \"QS\"–\"QZ\", which are not used by LCC. Some libraries use NLM in conjunction with LCC, eschewing LCC's \"R\" for Medicine. Others use LCC's \"QP\"–\"QR\" schedules and include Medicine \"R\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "18328", "url": "https://en.wikipedia.org/wiki?curid=18328", "title": "Library classification", "text": "Library classification\n\nA library classification is a system of knowledge organization by which library resources are arranged and ordered systematically. Library classifications use a notational system that represents the order of topics in the classification and allows items to be stored in that order. Library classification systems group related materials together, typically arranged in a hierarchical tree structure. A different kind of classification system, called a faceted classification system, is also widely used which allows the assignment of multiple classifications to an object, enabling the classifications to be ordered in multiple ways. The library classification numbers can be considered identifiers for resources but are distinct from the International Standard Book Number (ISBN) or International Standard Serial Number (ISSN) system.\n\nLibrary classification is an aspect of library and information science. It is distinct from scientific classification in that it has as its goal to provide a useful ordering of documents rather than a theoretical organization of knowledge. Although it has the practical purpose of creating a physical ordering of documents, it does generally attempt to adhere to accepted scientific knowledge.\n\nLibrary classification is distinct from the application of subject headings in that classification organizes knowledge into a systematic order, while subject headings provide access to intellectual materials through vocabulary terms that may or may not be organized as a knowledge system.\nThe characteristics that a bibliographic classification demands for the sake of reaching these purposes are: a useful sequence of subjects at all levels, a concise memorable notation, and a host of techniques and devices of number synthesis\n\nLibrary classifications were preceded by classifications used by bibliographers such as Conrad Gessner. The earliest library classification schemes organized books in broad subject categories. The earliest known library classification scheme is the Pinakes by Callimachus, a scholar at the Library of Alexandria during the Third Century BCE. During the Renaissance and Reformation era, \"Libraries were organized according to the whims or knowledge of individuals in charge.\" This changed the format in which various materials were classified. Some collections were classified by language and others by how they were printed. \n\nAfter the printing revolution in the sixteenth century, the increase in available printed materials made such broad classification unworkable, and more granular classifications for library materials had to be developed in the nineteenth century.\n\nAlthough libraries created order within their collections from as early as the fifth century B.C., the Paris Bookseller's classification, developed in 1842 by Jacques Charles Brunet, is generally seen as the first of the modern book classifications. Brunet provided five major classes: theology, jurisprudence, sciences and arts, belles-lettres, and history.\n\nThere are many standard systems of library classification in use, and many more have been proposed over the years. However, in general, classification systems can be divided into three types depending on how they are used:\n\n\nIn terms of functionality, classification systems are often described as:\n\n\nThere are few completely enumerative systems or faceted systems; most systems are a blend but favouring one type or the other. The most common classification systems, LCC and DDC, are essentially enumerative, though with some hierarchical and faceted elements (more so for DDC), especially at the broadest and most general level. The first true faceted system was the colon classification of S. R. Ranganathan.\n\nClassification types denote the classification or categorization according to the form or characteristics or qualities of a classification scheme or schemes. Method and system has similar meaning. Method or methods or system means the classification schemes like Dewey Decimal Classification or Universal Decimal Classification. The types of classification is for identifying and understanding or education or research purposes while classification method means those classification schemes like DDC, UDC.\nThe most common systems in English-speaking countries are:\n\nOther systems include:\n\n\n\nNewer classification systems tend to use the principle of synthesis (combining codes from different lists to represent the different attributes of a work) heavily, which is comparatively lacking in LC or DDC.\n\nLibrary classification is associated with library (descriptive) cataloging under the rubric of \"cataloging and classification\", sometimes grouped together as \"technical services\". The library professional who engages in the process of cataloging and classifying library materials is called a \"cataloger\" or \"catalog librarian\". Library classification systems are one of the two tools used to facilitate subject access. The other consists of alphabetical indexing languages such as Thesauri and Subject Headings systems.\n\nLibrary classification of a piece of work consists of two steps. Firstly, the \"aboutness\" of the material is ascertained. Next, a call number (essentially a book's address) based on the classification system in use at the particular library will be assigned to the work using the notation of the system.\n\nIt is important to note that unlike subject heading or thesauri where multiple terms can be assigned to the same work, in library classification systems, each work can only be placed in one class. This is due to shelving purposes: A book can have only one physical place. However, in classified catalogs one may have main entries as well as added entries. Most classification systems like the Dewey Decimal Classification (DDC) and Library of Congress Classification also add a cutter number to each work which adds a code for the author of the work.\n\nClassification systems in libraries generally play two roles. Firstly, they facilitate subject access by allowing the user to find out what works or documents the library has on a certain subject. Secondly, they provide a known location for the information source to be located (e.g. where it is shelved).\n\nUntil the 19th century, most libraries had closed stacks, so the library classification only served to organize the subject catalog. In the 20th century, libraries opened their stacks to the public and started to shelve library material itself according to some library classification to simplify subject browsing.\n\nSome classification systems are more suitable for aiding subject access, rather than for shelf location. For example, Universal Decimal Classification, which uses a complicated notation of pluses and colons, is more difficult to use for the purpose of shelf arrangement but is more expressive compared to DDC in terms of showing relationships between subjects. Similarly faceted classification schemes are more difficult to use for shelf arrangement, unless the user has knowledge of the citation order.\n\nDepending on the size of the library collection, some libraries might use classification systems solely for one purpose or the other. In extreme cases, a public library with a small collection might just use a classification system for location of resources but might not use a complicated subject classification system. Instead all resources might just be put into a couple of wide classes (travel, crime, magazines etc.). This is known as a \"mark and park\" classification method, more formally called reader interest classification.\n\nAs a result of differences in notation, history, use of enumeration, hierarchy, and facets, classification systems can differ in the following ways:\n\n\n"}
{"id": "18329", "url": "https://en.wikipedia.org/wiki?curid=18329", "title": "Lexus", "text": "Lexus\n\nLexus originated from a corporate project to develop a new premium sedan, code-named F1, which began in 1983 and culminated in the launch of the Lexus LS in 1989. Subsequently, the division added sedan, coupé, convertible and SUV models. Lexus did not exist as a brand in its home market until 2005, and all vehicles marketed internationally as Lexus from 1989 to 2005 were released in Japan under the Toyota marque and an equivalent model name. In 2005, a hybrid version of the RX crossover debuted and additional hybrid models later joined the division's lineup. Lexus launched its own F marque performance division in 2007 with the debut of the IS F sport sedan, followed by the LFA supercar in 2009.\n\nLexus vehicles are largely produced in Japan, with manufacturing centered in the Chūbu and Kyūshū regions, and in particular at Toyota's Tahara, Aichi, Chūbu and Miyata, Fukuoka, Kyūshū plants. Assembly of the first Lexus built outside the country, the Ontario, Canada-produced RX 330, began in 2003. Following a corporate reorganization from 2001 to 2005, Lexus began operation of its own design, engineering and manufacturing centers.\n\nSince the 2000s, Lexus has increased sales outside its largest market, the United States. The division inaugurated dealerships in the Japanese domestic market in 2005, becoming the first Japanese premium car marque to launch in its country of origin. The brand was introduced in Southeast Asia, Latin America, Europe and other regions.\n\nThe brand was created around the same time as Japanese rivals Nissan and Honda developed their Infiniti and Acura premium brands. The Japanese government imposed voluntary export restraints for the U.S. market, so it was more profitable for Japanese automakers to export more expensive cars to the U.S.\n\nIn 1983, Toyota chairman Eiji Toyoda issued a challenge to build the world's best car. The project, code-named F1 (“Flagship One”) developed the Lexus LS 400 to expand Toyota’s product line in the premium segment. The F1 project followed the Toyota Supra sports car and the premium Toyota Mark II models. Both the Supra and Mark II were rear-wheel drive cars with a powerful 7M-GE or 7M-GTE inline-six engine. The largest sedan Toyota built at the time was the limited-production, 1960s-vintage Toyota Century, a domestic, hand-built limousine, and V8-powered model, followed by the inline-six-engined Toyota Crown premium sedan. The Century was conservatively styled for the Japanese market and along with the Crown not slated for export after a restyle in 1982. The F1 designers targeted their new sedan at international markets and began development on a new V8 engine.\n\nJapanese manufacturers exported more expensive models in the 1980s due to voluntary export restraints negotiated by the Japanese government and U.S. trade representatives that restricted mainstream car sales. In 1986, Honda launched its Acura marque in the U.S., influencing Toyota's plans for a luxury division. The initial Acura model was an export version of the Honda Legend, itself launched in Japan in 1985 as a rival to the Toyota Crown, Nissan Cedric/Gloria and Mazda Luce. In 1987, Nissan unveiled its plans for a premium brand, Infiniti, and revised its Nissan President sedan in standard wheelbase form for export as the Infiniti Q45, which it launched in 1990. Mazda began selling the Luce as the Mazda 929 in North America in 1988 and later began plans to develop an upscale marque to be called Amati, but its plans did not come to fruition.\n\nToyota researchers visited the U.S. in May 1985 to conduct focus groups and market research on luxury consumers. During that time, several F1 designers rented a home in Laguna Beach, California to observe the lifestyles and tastes of American upper class consumers. Meanwhile, F1 engineering teams conducted prototype testing on locations ranging from the German autobahn to U.S. roads. Toyota’s market research concluded that a separate brand and sales channel were needed to present its new sedan, and plans were made to develop a new network of dealerships in the U.S. market.\n\nIn 1986, Toyota’s longtime advertising agency Saatchi & Saatchi formed a specialized unit, Team One, to handle marketing for the new brand. Image consulting firm Lippincott & Margulies was hired to develop a list of 219 prospective names; Vectre, Verone, Chaparel, Calibre and Alexis were chosen as top candidates. While Alexis quickly became the front runner, concerns were raised that the name applied to people more than cars (being associated with the Alexis Carrington character on the popular 1980s prime time drama \"Dynasty\"). As a result, the first letter was removed and the \"i\" replaced with a \"u\" to morph the name to Lexus.\n\nTheories of the etymology of the Lexus name have suggested it is the combination of the words \"luxury\" and \"elegance,\" and that it is an acronym for \"luxury exports to the U.S.\" According to Team One interviews, the brand name has no specific meaning and simply denotes a luxurious and technological image. Prior to the release of the first vehicles, database service LexisNexis obtained a temporary injunction forbidding the name Lexus from being used because it might cause product confusion. The injunction threatened to delay the division's launch and marketing efforts. The U.S. appeals court lifted the injunction, deciding that there was little likelihood of confusion between the two products.\n\nThe original Lexus slogan, developed after Team One representatives visited Lexus designers in Japan and noted an obsessive attention to detail, became \"\"The Relentless Pursuit of Perfection.\"\" The Lexus logo was developed by Molly Designs and Hunter Communications. The final design for the Lexus logo featured a stylized “\"L\"” within an oval, and according to Toyota, was rendered using a mathematical formula. The first teaser ads featuring the Lexus name and logo appeared at the Chicago, Los Angeles and New York auto shows in 1988.\n\nThe F1 project was completed in 1989, involving 60 designers, 24 engineering teams, 1,400 engineers, 2,300 technicians, 220 support workers, approximately 450 prototypes and more than $1 billion in costs. The resulting car, the Lexus LS 400, had a design that shared no major elements with previous Toyota vehicles, with a new 4.0 L V8 gasoline engine and rear-wheel drive. The car debuted in January 1989 at the North American International Auto Show in Detroit and official sales of the vehicle began the following September at a network of 81 new Lexus dealerships in the U.S. The LS 400 was sold along with the smaller ES 250, a rebadged version of the Japanese market Toyota Camry Prominent/Toyota Vista. The launch of Lexus was accompanied by a multimillion-dollar advertising campaign.\n\nThe LS 400 was praised for its quietness, well-appointed and ergonomic interior, engine performance, build quality, aerodynamics, fuel economy and value. However, it was criticized by some automobile columnists for derivative styling and a suspension regarded as too compromising of handling for ride comfort. In some markets it was priced against mid-size, six-cylinder Mercedes-Benz and BMW models. It was rated by \"Car and Driver\" magazine as better than the higher-priced Mercedes-Benz 420 SEL and BMW 735i in terms of ride, handling and performance. The LS 400 also won motoring awards from automotive publications including \"Automobile Magazine\" and \"Wheels Magazine\". Lexus quickly established customer loyalty and its debut was generally regarded as a shock to existing luxury marques. BMW's and Mercedes-Benz's U.S. sales figures dropped 29 percent and 19 percent, respectively, with BMW executives accusing Lexus of dumping in that market, while 35 percent of Lexus buyers traded in a Lincoln or Cadillac.\n\nIn December 1989, Lexus initiated a voluntary recall of all 8,000 LS 400s based upon two customer complaints over defective wiring and an overheated brake light. A 20-day operation to replace the parts on affected vehicles included technicians to pick up, repair and return cars to customers free of charge, and also flying personnel and renting garage space for owners in remote locations. This response was covered in media publications and helped establish the marque's early reputation for customer service.\n\nBy the end of 1989, a total of 16,392 LS 400 and ES 250 sedans were sold in the four months following the U.S. launch. Although sales had begun at a slower pace than expected, the final tally matched the division's target of 16,000 units for that year. Following initial models, plans called for the addition of a sports coupe along with a redesigned ES sedan.\n\nIn 1990, during its first full year of sales, Lexus sold 63,594 LS 400 and ES 250 sedans in the U.S., the majority being the LS model. That year, Lexus also began limited exports to the United Kingdom, Switzerland, Canada and Australia. In 1991, Lexus launched its first sports coupe, the SC 400, which shared the LS 400s V8 engine and rear-wheel drive design. This was followed by the second generation ES 300 sedan, which succeeded the ES 250 and became Lexus' top seller. At the conclusion of 1991, Lexus had become the top-selling premium car import in the U.S., with sales reaching 71,206 vehicles. That year, Lexus ranked highest in J.D. Power and Associates' studies on initial vehicle quality, customer satisfaction and sales satisfaction for the first time. The marque also began increasing U.S. model prices past those of comparable American premium makes, but still below high-end European models. By 1992, the LS 400's base price had risen 18 percent.\n\nIn 1993, Lexus launched the mid-size GS 300 sports sedan, based on the Toyota Aristo using the Toyota \"S\" platform from the Toyota Crown, which had sold for two years prior in Japan. The GS 300 was priced below the LS 400 in the marque's lineup. That same year, Lexus became one of the first marques to debut a certified pre-owned program, with the aim of improving trade-in model values. The marque introduced the second generation LS 400 in 1994. In May 1995, sales were threatened by the U.S. government's proposal of 100 percent tariffs on upscale Japanese cars in response to the widening U.S.-Japan trade deficit. SUVs were exempt from the proposed sanctions. Normal sales operations resumed by late 1995 when the Japanese auto manufacturers collectively agreed to greater American investments and the tariffs were not enacted.\nIn 1996, Lexus debuted its first sport utility vehicle, the LX 450, followed by the third generation ES 300 sedan, and the second generation GS 300 and GS 400 sedans in 1997. The marque's plans for developing an SUV model had accelerated during the U.S.-Japan tariff discussions of 1995. Lexus added the first luxury-branded crossover SUV, the RX 300 in 1998. The RX crossover targeted suburban buyers who desired an upmarket SUV but did not need the LX's off-road capability. It was particularly successful, eventually becoming the marque's top-selling model ahead of the ES sedan. The same year, Lexus made its debut in South America's most populous country when it launched sales in Brazil. In 1999, the IS was introduced, an entry-level sport sedan. Lexus also recorded its 1 millionth vehicle sold in the U.S. market, being ranked as the top-selling premium car maker in the U.S. overall.\n\nIn July 2000, Lexus introduced the IS 300 in North America, following global launch in 1999 (as the IS 200) and the third generation LS 430. In 2001, the first convertible was introduced, as well as the SC 430 and a redesigned ES 300. The GX 470 mid-size SUV debuted in 2002, followed by the second generation RX 330 in 2003. The following year, Lexus recorded its 2 millionth U.S. vehicle sale, and the first luxury-branded production hybrid SUV, the RX 400h. This vehicle used Toyota's Hybrid Synergy Drive system that combined gasoline and electric motors.\n\nIn 2005, Lexus completed an organizational separation from parent company Toyota, with dedicated design, engineering, training, and manufacturing centers working exclusively for the division. This effort coincided with Lexus' launch in its home market of Japan and an expanded global launch of the brand in markets such as China. Executives aimed to increase Lexus sales outside of its largest market in the U.S. To accompany this expansion, next generation Lexus vehicles were redesigned as \"global models\" for international release. In the European market, where Lexus had long faced struggling sales owing to low brand recognition, few dedicated dealerships, and 1990s import quotas, the marque announced plans to introduce hybrid and diesel powertrains, increase the number of Lexus dealerships, and expand operations in emerging markets such as Russia.\n\nLexus' arrival in the Japanese market in July 2005 marked the first introduction of a Japanese premium car marque in the domestic market. New generation LS, IS, ES, GS, and RX models subsequently became available in Japan along with the SC 430, ending domestic sales of Toyota-branded models under the Celsior, Altezza, Windom, Aristo, Harrier, and Soarer nameplates, respectively. The Altezza and Aristo were previously exclusive to Japanese Toyota retail sales channels called Toyota Vista Store, the Windom was exclusive to Toyota Corolla Store, the Celsior and Harrier were exclusive to Toyopet Store, and the Soarer was previously available at both Toyota Store and Toyopet Store locations. Lexus models sold in Japan featured higher specifications and a price premium compared with their discontinued Toyota counterparts. Sales for the first half-year were slower than expected, affected by the contraction of the domestic auto market and price increases, but improved in subsequent months with an expanded lineup.\n\nThrough the mid-2000s, Lexus experienced sales successes in South Korea and Taiwan, becoming the top-selling import make in both markets in 2005; the marque also sold well in the Middle East, where it ranked first or second among rivals in multiple countries, and in Australia, where Lexus reached third in luxury car sales in 2006. Division executives in 2006 announced an expansion goal from 68 countries to 76 worldwide by 2010. By the end of the decade, this expansion resulted in official launches in Malaysia and South Africa in 2006, Indonesia in 2007, Chile in 2008, and the Philippines in 2009.\n\nIn 2006, Lexus began sales of the GS 450h, a V6 hybrid performance sedan, and launched the fourth generation LS line, comprising both standard- and long-wheelbase V8 (LS 460 and LS 460 L) and hybrid (LS 600h and LS 600h L) versions. The fifth generation ES 350 also debuted in the same year. The LS 600h L subsequently went on sale as the most expensive sedan ever produced in Japan. By the end of 2006, Lexus' annual sales had reached 475,000 vehicles worldwide. In January 2007, Lexus announced a new F marque performance division, which would produce racing-inspired versions of its performance models. The IS F, made its debut at the 2007 North American International Auto Show, accompanied by a concept car, the LF-A.\n\nIn October 2007, Lexus entered the Specialty Equipment Market Association show in the U.S. for the first time with the IS F, and announced its F-Sport performance trim level and factory-sanctioned accessory line. Increased emphasis on sporty models was an effort to target rivals from Mercedes-Benz's AMG and BMW's M divisions. Models such as the SC 400 and GS 400 had received favorable reactions from sport luxury buyers, most Lexus models had been characterized as favoring comfort over sporty road feel and handling, compared with European rivals. By the end of 2007, Lexus annual worldwide sales had surpassed 500,000 vehicles, and the marque ranked as the top-selling premium import in China for the first time. The largest sales markets in order of size for 2007 were the U.S., Japan, the UK, China, Canada, and Russia.\n\nIn 2008, amidst the late-2000s recession and a weakened world car market, global sales fell 16 percent to 435,000, with declines in markets such as the U.S. and Europe where deliveries fell by 21 percent and 27.5 percent, respectively. In 2009, the marque launched the HS 250h, a dedicated hybrid sedan for North America and Japan, the RX 450h, the second generation hybrid SUV replacing the earlier RX 400h, and later that year debuted the production LFA exotic coupe. In late 2009, citing higher sales of hybrid models over their petrol counterparts, Lexus announced plans to become a hybrid-only marque in Europe. By the end of the decade, Lexus ranked as the fourth-largest premium car make in the world by volume, and was the number one selling premium car marque in the U.S. for 10 consecutive years.\n\nIn 2010, Lexus underwent a gradual sales recovery in North America and Asia as the marque focused on adding hybrids and new model derivatives. Sales in the U.S. held steady despite the 2009–2010 Toyota vehicle recalls, several of which included Lexus models. The ES 350 and certain IS models were affected by a recall for potentially jamming floor mats, while parent company Toyota bore the brunt of negative publicity amid investigations over its series of product recalls and problem rates per-vehicle. The redesigned GX 460 was also voluntarily recalled in April 2010 for a software update, one week after \"Consumer Reports\" issued a recommendation not to buy the SUV, citing a possible rollover risk following the slow stability control response to a high-speed emergency turn. Although the publication knew of no reported incidents, the GX 460 received updated stability control software.\n\nIn late 2010 and early 2011, Lexus began sales of the CT 200h, a compact four-door hybrid hatchback designed for Europe, in multiple markets. Sales of lower-displacement regional models were also expanded, beginning with the ES 240 in China followed by the RX 270; Japan, Russia, and Taiwan were among markets which received model variants intended for reduced emissions or import taxes. In March 2011, the Tōhoku earthquake and tsunami caused severe disruption to Lexus' Japan-based production lines, hindering the marque's near-term sales prospects. Lexus' U.S. executives stated that due to vehicle shortages amidst close competition from BMW, Mercedes-Benz, and Audi, the marque would not remain the country's top-selling premium car brand.\n\nCumulative sales results for 2011 indicated a 14 percent sales drop in the U.S. market, along with sales increases of 40 percent and 27 percent in Europe and Japan respectively, for a global sales total of 410,000 units. Lexus' streak of 11 consecutive years as the best-selling luxury marque in the U.S. ended that year, with the title going to BMW followed by Mercedes-Benz. While 45 percent of Lexus sales in the U.S. in 2011 relied upon the RX luxury crossover SUV, rival Mercedes-Benz's best-selling offering was the E-Class mid-luxury sedan, which commands considerably higher prices. Subsequently, Toyota chairman Akio Toyoda vowed to restore passion to the marque and further increase its organizational independence, admitting that \"...back then we did not regard Lexus as a brand, but as a distribution channel\". As a result of Toyoda's organizational changes, Lexus senior managers report directly to the chairman for the first time in the marque's history.\n\nIn January 2012, the marque began sales of the fourth generation GS line, including GS 350 and GS 450h variants, as well as a lower-displacement GS 250 model for select markets. In April 2012, the sixth generation ES line, include ES 350 and ES 300h variants, debuted at the New York International Auto Show.\n\nIn April 2014, Lexus unveiled the five-seater NX crossover. The vehicle features a very first for a Lexus vehicle: a turbocharger. Its nomenclature is denoted as the 200t. In August 2014, Toyota announced it would be cutting its Lexus spare parts prices in China by up to 35 percent. The company admitted the move was in response to a probe foreshadowed earlier in the month by China's National Development and Reform Commission of Lexus spare parts policies, as part of an industry-wide investigation into what the Chinese regulator considers exorbitantly high prices being charged by automakers for spare parts and after-sales servicing.\n\nIn March 2016, Lexus announced that it will be producing a new flagship vehicle: the two-door LC 500. The vehicle will be produced for late 2017 in a V8 version putting out 467 horsepower. The LC 500h, a V6 hybrid variant, could potentially become available in late 2017 or early 2018.\n\nLexus International, headed by managing officer Tokuo Fukuichi, coordinates the worldwide operations of Toyota's luxury division. Other executives at Lexus' global headquarters, located in Nagoya, Aichi, include Mark Templin, executive vice president of Lexus International, and managers of the marque's Japan Sales and Marketing and global Product and Marketing Planning divisions. While organizationally separate from its parent company, Lexus International reports directly to Toyota chief executive officer Akio Toyoda.\n\nIn the U.S., Lexus operations are headed by Jeffrey Bracken, group vice president and general manager of the U.S. Lexus division, located in Southern California. In Europe, Lexus operations are headed by Alain Uyttenhoven, vice president of Lexus Europe, located in Brussels. Companion design facilities are located in Southern California and central Japan, with the head design studio devoted entirely to Lexus models in Toyota City, Aichi.\n\nLexus sales operations vary in structure by region. In many markets, such as the U.S., the dealership network is a distinct organization from corporate headquarters, with separately owned and operated Lexus showrooms. By contrast, in Japan all 143 dealerships in the country are owned and operated by Lexus. Several markets have a designated, third party regional distributor; for example, in the United Arab Emirates, sales operations are managed by Al-Futtaim Motors LLC, and in Costa Rica, Lexus vehicles are sold via regional distributor Purdy Motors S.A. Other officially sanctioned regional distributors have sold Lexus models prior to the launch of, or in absence of, a dedicated dealership network.\nThe Lexus brand launched in the Indian market in 2017, with the models RX450h, LX450d, LX570, ES300h, NX, LS. Dealerships in Mumbai, Delhi, Gurgaon and Bangalore became operational in March 2017, when the brand began sales in India. A second set of dealerships will be in Chandigarh, Cochin and Chennai and will be operational toward the end of 2017. This made Lexus the fifth luxury brand to be launched in India, after Mercedes-Benz, Porsche, BMW and Audi.\n\nGlobal sales of Lexus vehicles reached an all-time high in 2007, with a total of 518,000. Sales decreased in subsequent years due to the effects of the 2008 recession and the Japanese tsunami of 2011. Following this, sales recovered and reached a new high of 523,000 in 2013.\n\nIn 2014, the Lexus brand set a new global sales record after selling 582,000 vehicles. This made Lexus the fourth best selling luxury brand in the world, trailing BMW, Audi and Mercedes-Benz.\n\nGlobal sales of Lexus vehicles increased by 12 percent in 2015 to reach another annual sales record with 652,000 units sold worldwide.\n\nGlobal cumulative sales of Lexus brand hybrid electric cars reached the 500,000 mark in November 2012. The 1 million sales milestone was achieved in March 2016. The Lexus RX 400h/RX 450h ranks as the top selling Lexus hybrid with 335,000 units delivered worldwide , followed by the Lexus CT 200h with 267,000 units.\n\nLexus has not sold as well in Europe, where it suffers from smaller brand recognition, image, and a less-developed dealership network. In European markets, the Lexus LS has ranked behind Jaguar, Mercedes-Benz, Audi, and BMW in flagship luxury car sales. Automotive analysts have suggested a possible rationale for the sales disparity, in that European buyers place less emphasis on vehicle reliability and have more brand loyalty to established domestic marques. In contrast, the Lexus LS has ranked second in sales to the Mercedes-Benz S-Class (and ahead of rivals from BMW, Audi, and Jaguar) in markets outside Europe, such as South Africa.\n\nCurrently all of Lexus’s models for the US market are imported from Japan, with the exception of the RX, which is also produced in Cambridge, Ontario for North America, and the ES, which is also produced in Georgetown, Kentucky. The RX midsized crossover is Lexus’s best selling model in the United States, while the ES mid-sized car is the most popular sedan in the line-up.\n\nFinancial data of Lexus operations are not disclosed publicly. However, automotive analysts estimate that the Lexus division contributes a disproportionate share of Toyota's profits, relative to its limited production and sales volume. Interviews with retired division officials indicate that depending on sales volume, vehicle product development cycles, and exchange rates, Lexus sales have accounted for as much as half of Toyota's annual U.S. profit in certain years. Division executives have employed pricing strategies aimed at sustaining profit margins rather than sales volume, with historically fewer price incentives than rival brands. In 2006, Lexus entered Interbrand's list of the Top 100 Global Brands for the first time, with an estimated brand value of approximately $3 billion annually. In 2009, Interbrand ranked Lexus as Japan's seventh largest brand, between Panasonic and Nissan, based on revenue, earnings, and market value.\n\nThe global Lexus lineup features sedans of different size classes, including the compact IS and HS models, mid-size ES and GS models, and the full-size LS. The 2-door coupe range consists of the RC and the LC. Former convertibles include the SC and IS C models. Sport-utility vehicles range in size from the compact NX and RX crossover, to the mid-size GX and the full-size LX. Hybrid models include the CT hatchback, HS sedan, and variants of the GS, LS, LC, IS, NX and RX. The F marque line formerly produced a variant of the IS and the LFA and currently produces a variant of the GS sedan and the RC coupe.\n\nLexus produces its highest-performance models under its F marque division. The name refers to Flagship and Fuji Speedway in Japan, whose first corner, 27R, inspired the shape of the \"\"F\"\" emblem. F marque models are developed by the Lexus Vehicle Performance Development Division. The first F marque model, the IS F, went on sale in 2007, followed by the LFA in 2009. A related F-Sport performance trim level and factory-sanctioned accessory line is available for standard Lexus models such as the IS 250 and IS 350. F-Sport succeeded an earlier in-house tuning effort, the TRD-based L-Tuned, which had offered performance packages on the IS and GS sedans in the early 2000s (decade).\n\nThe latest editions to the performance F Sport marque include the Lexus RC F Sport and Lexus GS F Sport and Lexus LS F Sport.\n\nLexus production models are named alphanumerically using two-letter designations followed by three digits. The first letter indicates relative status in the Lexus model range (ranking), and the second letter refers to car body style or type (e.g. LS for 'luxury sedan'). The three digits indicate engine displacement in liters multiplied by a factor of one hundred (e.g. 350 for a 3.5 L engine). A space is used between the letters and numbers. The same letter may be used differently depending on the model; 'S' can refer to 'sedan' or 'sport' (e.g. in LS and SC), while 'X' refers to 'luxury utility vehicle' or SUV. On hybrids, the three digits refer to the combined gasoline-electric output. For certain models, a lower case letter placed after the alphanumeric designation indicates powerplant type ('h' for hybrid, 'd' for diesel, 't' for turbocharged), while capital letter(s) placed at the end indicates a class subtype (e.g. 'L' for long-wheelbase, 'C' for coupe, 'AWD' for all-wheel drive). On F marque models, the two-letter designation and the letter 'F' are used with no numbers or hyphens (e.g. IS F).\n\nLexus design has traditionally placed an emphasis on targeting specific vehicle development standards. Since the marque's inception, design targets have ranged from aerodynamics and ride quality to interior ergonomics. The backronym \"IDEAL\" (\"Impressive, Dynamic, Elegant, Advanced, and Lasting\") is used in the development process. Each vehicle is designed according to approximately 500 specific product standards, known as \"Lexus Musts,\" on criteria such as leather seat stitching. Design elements from the marque's concept vehicle line, the LF series (including the 2003 LF-S and 2004 LF-C), have been incorporated in production models.\n\nVehicle cabins have incorporated electroluminescent Optitron gauges, SmartAccess, a smart key entry and startup system, and multimedia features. Beginning with the 2010 RX and HS models, the Remote Touch system, featuring a computer mouse-like controller with haptic feedback, was introduced; other models have featured touchscreen controls (through the 2009 model year) as a navigation screen interface. 2014 saw the introduction of the next version of Lexus’ remote-touch innovations—the Remote Touch Interface Touchpad in the new RC Coupe.\n\nIn 1989, Lexus became among the first premium car marques to equip models with premium audio systems, in partnership with stereo firm Nakamichi. Since 2001, optional surround sound systems are offered via high-end audio purveyor Mark Levinson. For reduced cabin noise, the first LS 400 introduced sandwich steel plating, and later models added acoustic glass. In 2006, the LS 460 debuted the first ceiling air diffusers and infrared body temperature sensors in a car. Telematics services include G-Book with G-Link in Asia and Lexus Enform in North America.\n\nIn 2006, Lexus incorporated the first production eight-speed automatic transmission in an automobile with the LS 460, and the gearbox was later adapted for the GS 460 and IS F models. Continuously variable transmissions, regenerative brakes, and electric motors have been used on all Lexus hybrid models. In 2007, Lexus executives signaled intentions to equip further models with hybrid powertrains, catering to demands for a decrease in both carbon pollution and oil reliance. Hybrid models have been differentiated by separate badging and lighting technology; in 2008, the LS 600h L became the first production vehicle to use LED headlamps.\n\nSafety features on Lexus models range from stability and handling programs (Vehicle Stability Control and Vehicle Dynamics Integrated Management) to backup cameras, swivel headlights, and sonar warning systems. The Lexus Pre-Collision System (PCS) integrates multiple safety systems. In 2007, Lexus introduced the first car safety systems with infrared and pedestrian detection capabilities, lane keep assist, a Driver Monitoring System with facial recognition monitoring of driver attentiveness, and rear pre-collision whiplash protection, as part of the LS 460 PCS. As a safety precaution, Lexus GPS navigation systems in many regions feature a motion lockout when the vehicle reaches a set speed; to prevent distraction, navigation inputs are limited, while voice input and certain buttons are still accessible. This safety feature has attracted criticism because passengers cannot use certain functions when the vehicle is in motion. Pre-2007 models came with a hidden manufacturer override option, and updated European models allow operation in motion.\n\nProduction models in development have included convertibles, crossovers, and dedicated hybrids. Under the F marque, Lexus plans to produce high-performance vehicles with its first expressions being the IS F and the LFA. Lexus officials have also discussed standard production model usage of varying platforms. The LS uses a dedicated platform, while the entry-level Lexus ES had been criticized for being too similar to the Toyota Camry, with which it shared platforms until its sixth generation, in both styling and powertrain design. The Nürburgring test track in Germany has also seen Lexus prototype testing.\n\nLexus introduced a new design language known as \"L-finesse\" in the mid-2000s with its LF series concepts and the 2006 Lexus GS. L-finesse is represented by three Japanese kanji characters which translate as \"Intriguing Elegance, Incisive Simplicity, and Seamless Anticipation\". Design characteristics, including a fastback profile, lower-set grille, and the use of both convex and concave surfaces, are derived from Japanese cultural motifs (e.g. the phrase \"kirikaeshi\" in arrowhead shapes). While earlier Lexus models were criticized for reserved and derivative styling, and often mistaken for understated domestic market cars, automotive design analyses described L-finesse as adding a distinctive nature and embrace of Japanese design identity. Opinions varied for L-finesse's debut on the GS; \"Sports Car International\" analysis praised the vehicle's in-person appearance; \"Automobile Magazine\" criticized the daring of its forward styling, and compared subsequent rival models for design similarities. In 2012, the arrival of the redesigned fourth generation Lexus GS featured the introduction of a spindle-shaped grille design, intended to be used on all forthcoming Lexus models. L-finesse exhibitions were presented at Milan's Salone del Mobile from 2005 through 2009.\n\nThe first Lexus vehicles were manufactured in Toyota's Tahara plant, a highly sophisticated, computerized manufacturing plant in Japan. Lexus production techniques include methods and standards of quality control that differ from Toyota models. At the Tahara plant, separate assembly lines were developed for Lexus vehicles, along with new molds and specialized manufacturing equipment. Welding processes, body panel fit tolerances, and paint quality requirements are more stringent. Lexus plant workers, typically veteran technicians, are identified via repeated performance evaluations and ranked according to skill grade, with limited applicants accepted. The highest level \"takumi\" (Japanese for \"artisan\") engineers are responsible for maintaining production standards at key points in the assembly process, such as testing engine performance. Production vehicles are given visual inspections for flaws, individually test-driven at high speeds, and subjected to vibration tests.\n\nThrough the 2000s (decade), most Lexus sedan and SUV production has occurred in Japan at the Tahara plant in Aichi and Miyata plant in Fukuoka. In addition to the Tahara factory, Lexus vehicles have been produced at the Miyata plant (Toyota Motor Kyushu, Inc.) in Miyawaka, Fukuoka, Higashi Fuji plant (Kanto Auto Works, Ltd.) in Susono, Shizuoka, and Sanage plant (Toyota Boshoku Corp.; Araco) in Toyota City, Aichi. Front-wheel drive cars, such as the ES and HS, are produced in the Fukuoka Prefecture. The Kokura plant in Kitakyushu, Fukuoka, which opened in 2008, is a dedicated hybrid production site for Lexus models such as the gasoline-electric RX. The North American–market RX 350 (since the 2004 model year) is produced at the Cambridge plant (Toyota Canada, Inc.) in the city of Cambridge, in Ontario, Canada, which is the first Lexus production site located outside Japan. In late 2015, Lexus started to assemble North American-spec ES 350 sedans at the Georgetown plant (TMMK, Inc.).\n\nIn the 2000s (decade), \"Consumer Reports\" named Lexus among the top five most reliable brands in its Annual Car Reliability Surveys of over one million vehicles across the U.S.\nLexus has become known for efforts to provide an upscale image, particularly with service provided after the sale. The waiting areas in service departments are replete with amenities, ranging from refreshment bars to indoor putting greens. Dealerships typically offer complimentary loaner cars or \"courtesy cars\" and free car washes, and some have added on-site cafes and designer boutiques. Service bays are lined with large picture windows for owners to watch the servicing of their vehicle. In 2005, Lexus also began reserving parking lots at major sporting arenas, entertainment events, and shopping malls, with the only requirement for free entry being the ownership of a Lexus vehicle. An online owner publication, \"Lexus Magazine\", features automotive and lifestyle articles and is published online monthly and on a mobile site.\n\nSince 2002, Lexus has scored consecutive top ratings in the \"Auto Express\" and 76,000-respondent \"Top Gear\" customer satisfaction surveys in the UK. Lexus has also repeatedly topped the 79,000-respondent J.D. Power Customer Service Index and Luxury Institute, New York surveys in the U.S. As a result of service satisfaction levels, the marque has one of the highest customer loyalty rates in the industry. To improve customer service, employees are instructed to follow the \"Lexus Covenant,\" the marque's founding promise (which states that \"Lexus will treat each customer as we would a guest in our home\"), and some dealerships have incorporated training at upscale establishments such as Nordstrom department stores and Ritz-Carlton hotels.\n\nLexus first entered the motorsport arena in 1999 when its racing unit, Team Lexus, fielded two GS 400 race vehicles in the Motorola Cup North American Street Stock Championship touring car series. In its 1999 inaugural season, Team Lexus achieved its first victory with its sixth race at Road Atlanta. Led by Sports Car Club of America and International Motor Sports Association driver Chuck Goldsborough, based in Baltimore, Maryland, Team Lexus capitalized on the debut of the first generation Lexus IS by entering three IS 300s in the third race of the 2001 Grand-Am Cup season at Phoenix, Arizona. Team Lexus won its first IS 300 victory that year at the Virginia International Raceway. In 2002, Team Lexus' competitive efforts in the Grand-Am Cup ST1 (Street Tuner) class achieved victories in the Drivers' and Team Championships, as well as a sweep of the top three finishes at Circuit Mont-Tremblant in Quebec, Canada.\n\nAfter the release of the Lexus brand in the Japanese domestic market in 2005, Lexus sanctioned the entry of four SC 430 coupes in the Super GT series of the All Japan Grand Touring Car Championship in the GT500 class. In the first race of the 2006 series, an SC 430 took the chequered flag, and drivers André Lotterer and Juichi Wakisaka raced the SC 430 to capture the GT500 championship for that year. In 2007, another SC 430 won the GT500 opening round race. In 2006, Lexus raced a hybrid vehicle for the first time, entering a GS 450h performance hybrid sedan in partnership with Sigma Advanced Racing Development at the 24 Hours of Tokachi race in Hokkaido, Japan. Lexus Canada also entered the GS 450h in 2007's Targa Newfoundland event. In 2009, Lexus Super GT Team SC 430 and IS 350 racers won the GT500 and GT300 championships, respectively.\n\nLexus' participation in endurance racing further includes the Rolex 24 Hours of Daytona, sanctioned by the Grand American Road Racing Association. After entering the Rolex Sports Car Series in 2004, Lexus has won over 15 Rolex Series event races. In 2005, Lexus was runner-up, and in 2006, it won the championship. Although Toyota has won this race in the past, it was the first time that its luxury arm emerged as the winner. In 2007, six Lexus-powered Daytona prototypes were entered in the Rolex 24 Hours of Daytona event at the Daytona International Speedway. Lexus was a repeat winner of the event, with a Lexus-Riley prototype driven by Scott Pruett, Juan Pablo Montoya, and Salvador Durán of Chip Ganassi Racing finishing first; Lexus-Riley prototypes also took three of the top ten spots. In 2008, Lexus won its third consecutive win at Daytona. For the 2010 season, Lexus departed from the Rolex Sports Car Series, and Ganassi Racing switched to BMW/Dinan engines.\n\nThe LF-A prototype also competed on the Nürburgring from 2008 to 2011 in VLN endurance races and in the 24 Hours Nürburgring, also with the IS F. On 14 May 2011, a CT 200h tuned up by Gazoo Racing competed in the Adenauer ADAC Rundstrecken-Trophy, a six-hour endurance race.\n\n3GT Racing, a partnership of Lexus and Paul Gentilozzi, entered two Lexus RC F GT3 at the 2017 IMSA WeatherTech SportsCar Championship.\n\nFrom its inception, Lexus has been advertised to luxury consumers using specific marketing strategies, with a consistent motif used for the marque's advertisements. Beginning in 1989, television ads were narrated by actor James Sloyan (the voice of \"Mr. Lexus\" until 2009), and accompanied by vehicles that performed unusual stunts onscreen. The first decade of Lexus commercials (1989–99) consisted primarily of disjunctive verbal descriptions, such as \"relentless,\" \"pursuit,\" and \"perfection,\" while vehicles were used to claim superiority in precision, idling, and interior quiet and comfort on camera. Examples included the champagne glass \"Balance\" (1989) and rolling \"Ball Bearing\" (1992). In the 2000s (decade), commercials included descriptions of features, or a narration of the events onscreen, and were often targeted at the marque's German competitors. An annual \"December to Remember\" campaign featured scenes of family members surprising loved ones with the gift of a new Lexus. The marque returned to the champagne glass theme in a 2006 LS 460 spot showing the sedan maneuvering between two stacks of glasses using its self-parking system, and in a 2010 LFA spot showing its engine sound shattering a glass via resonance frequency.\n\nIndustry observers have attributed Lexus' early marketing successes to higher levels of perceived quality and lower prices than competitors, which have enabled the marque to attract customers upgrading from mass-market cars. A reputation for dependability, bolstered by reliability surveys, also became a primary factor in attracting new customers from rival premium makes. Lexus has since grown to command higher price premiums than rival Japanese makes, with new models further increasing in price and reaching the more than $100,000 ultra-luxury category long dominated by rival European marques.\n\nAutomotive analysts have also noted Lexus' relative newcomer status as a marketing challenge for the brand, although some have debated the requirement of a long history. European rivals have marketed their decades of heritage and pedigree, whereas Lexus' reputation rests primarily upon its perceived quality and shared history with parent company Toyota. Several analysts have stated that Lexus will have to develop its own heritage over time by highlighting technological innovations and producing substantial products.\n\nLexus' marketing efforts have extended to sporting and charity event sponsorships, including the U.S. Open tennis Grand Slam event from 2005 to 2009, and the United States Golf Association's U.S. Open, U.S. Women's Open, U.S. Senior Open, and U.S. Amateur tournaments since 2007. Lexus has organized an annual Champions for Charity golf series in the U.S. since 1989. Endorsement contracts have also been signed with professional athletes Andy Roddick, Annika Sörenstam, and Peter Jacobsen.\n\nSince 2008, Lexus has run the video website L Studio. Shows on L Studio include \"Web Therapy\".\n\nLexus unveiled its new \"Experience Amazing\" tagline in the U.S. in a 60-second advertisement at the February 2017 Super Bowl LI. The new tagline replaced Lexus's previous slogan, \"The Pursuit of Perfection\".\n\nOn 30 March 2018, Lexus premiered a fake partnership with 23 and Me during a spot on Saturday Night Live, for a pretend program that allows buyers to customize vehicles based on their DNA, as an April Fool's Day joke.\n\n\n\n"}
{"id": "18330", "url": "https://en.wikipedia.org/wiki?curid=18330", "title": "Transgender rights", "text": "Transgender rights\n\nA person may be considered to be a transgender person if their gender identity is inconsistent or not culturally associated with the sex they were assigned at birth, and consequently also with the gender role and social status that is typically associated with that sex. They may have, or may intend to establish, a new gender status that accords with their gender identity. \"Transsexual\" is generally considered a subset of \"transgender\", but some transsexual people reject being labelled \"transgender\".\n\nGlobally, most legal jurisdictions recognize the two traditional gender identities and social roles, man and woman, but tend to exclude any other gender identities, and expressions. However, there are some countries which recognize, by law, a third gender. There is now a greater understanding of the breadth of variation outside the typical categories of \"man\" and \"woman\", and many self-descriptions are now entering the literature, including \"pangender\", \"genderqueer\", \"polygender\" and \"agender\". Medically and socially, the term \"transsexualism\" is being replaced with \"gender identity\" or \"gender dysphoria\", and terms such as \"transgender people\", \"trans men\" and \"trans women\" are replacing the category of transsexual people.\n\nThis raises many legal issues and aspects of transgenderism. Most of these issues are generally considered a part of family law, especially the issues of marriage and the question of a transsexual person benefiting from a partner's insurance or social security.\n\nThe degree of legal recognition provided to transgenderism varies widely throughout the world. Many countries now legally recognise sex reassignments by permitting a change of legal gender on an individual's birth certificate. Many transsexual people have permanent surgery to change their body, sexual reassignment surgery (SRS) or semi-permanently change their body by hormonal means, hormone replacement therapy (HRT). In many countries, some of these modifications are required for legal recognition. In a few, the legal aspects are directly tied to health care; i.e. the same bodies or doctors decide whether a person can move forward in their treatment, and the subsequent processes automatically incorporate both matters.\n\nIn some jurisdictions, transgender people (who are considered non-transsexual) can benefit from the legal recognition given to transsexual people. In some countries, an explicit medical diagnosis of \"transsexualism\" is (at least formally) necessary. In others, a diagnosis of \"gender dysphoria\", or simply the fact that one has established a non-conforming gender role, can be sufficient for some or all of the legal recognition available. The DSM-V recognizes gender dysphoria as an official diagnosis.\n\nThe Constitution of South Africa forbids discrimination on the basis of sex, gender and sexual orientation (amongst other grounds). The Constitutional Court has indicated that \"sexual orientation\" includes transsexuality.\n\nIn 2003 Parliament enacted the Alteration of Sex Description and Sex Status Act, which allows a transgender person who has undergone medical or surgical gender reassignment to apply to the Department of Home Affairs to have the sex description altered on their birth record. Once the birth record is altered they can be issued with a new birth certificate and identity document, and are considered \"for all purposes\" to be of the new sex.\n\nIn September 2017, the Botswana High Court ruled that the refusal of the Registrar of National Registration to change a transgender man's gender marker was \"unreasonable and violated his constitutional rights to dignity, privacy, freedom of expression, equal protection of the law, freedom from discrimination and freedom from inhumane and degrading treatment\". LGBT activists celebrated the ruling, describing it as a great victory. At first, the Botswana Government announced it would appeal the ruling, but decided against it in December, supplying the trans man in question with a new identity document that reflects his gender identity.\n\nA similar case, where a transgender woman sought to change her gender marker to female, was heard in December 2017. The High Court ruled that the Government must recognise her gender identity. She dedicated her victory to \"every single trans diverse person in Botswana\".\n\nIn 2009 the Chinese government made it illegal for minors to change their officially listed gender, stating that sexual reassignment surgery, available to only those over the age of twenty, was required in order to apply for a revision of their identification card and residence registration.\n\nIn early 2014 the Shanxi province started allowing minors to apply for the change with the additional information of their guardian's identification card. This shift in policy allows post-surgery marriages to be recognized as heterosexual and therefore legal.\n\nTransgender youth in China face many challenges. One study found that Chinese parents report 0.5% (1:200) of their 6 to 12-year boys and 0.6% (1:167) of girls often or always ‘state the wish to be the other gender’. 0.8% (1.125) of 18- to 24-year-old university students who are birth-assigned males (whose sex/gender as indicated on their ID card is male) report that the ‘sex/gender I feel in my heart’ is female, while another 0.4% indicating that their perceived gender was ‘other’. Among birth-assigned females, 2.9% (1:34) indicated they perceived their gender as male, while another 1.3% indicating ‘other’.\n\nThe Court of Final Appeal of Hong Kong ruled that a transsexual woman has the right to marry her boyfriend. The ruling was made on 13 May 2013.\n\nOn 16 September 2013, Eliana Rubashkyn a transgender woman claimed that she was discriminated and sexually abused by the customs officers, including being subjected to invasive body searches and denied usage of a female toilet, although Hong Kong officers denied the allegations. After being released, she applied for and was granted refugee status by the United Nations High Commissioner for Refugees (UNHCR), rendering her effectively stateless awaiting acceptance to a third country.\n\nIn April 2014, the Supreme Court of India declared transgender to be a 'third gender' in Indian law. The transgender community in India (made up of Hijras and others) has a long history in India and in Hindu mythology. Justice KS Radhakrishnan noted in his decision that, \"Seldom, our society realizes or cares to realize the trauma, agony and pain which the members of Transgender community undergo, nor appreciates the innate feelings of the members of the Transgender community, especially of those whose mind and body disown their biological sex\", adding:\n\nBeginning in the mid-1980s, transgender individuals were officially recognized by the government and allowed to undergo sex reassignment surgery. \nOfficially the leader of Iran's Islamic Revolution, Ayatollah Ruhollah Khomeini, issued a fatwa declaring sex reassignment surgery permissible for \"diagnosed transsexuals\". The government provides up to half the cost for those needing financial assistance, and a sex change is recognised on the birth certificate. Despite this, Iran's transgender people face discrimination in society. Founded in 2007 by Maryam Khatoon Molkara the Iranian Society to Support Individuals with Gender Identity Disorder (نجمن حمایت از بیماران مبتلا به اختلالات هویت جنسیایران) is Iran's main transsexual organization.\n\nAdditionally, the Iranian government's response to homosexuality is to pressure lesbian and gay individuals, who are not in fact transsexual, towards sex reassignment surgery. Eshaghian's documentary, \"Be Like Others\", chronicles a number of stories of Iranian gay men who feel transitioning is the only way to avoid further persecution, jail, or execution. Maryam Khatoon Molkara—who convinced Khomeini to issue the fatwa on transsexuality—confirmed that some people who undergo operations are gay rather than transsexual.\n\nOn 10 July 2003, the National Diet of Japan unanimously approved a new law that enables transsexual people to amend their legal sex. It is called \"\" (Act on Special Cases in Handling Gender for People with Gender Identity Disorder) The law, effective on 16 July 2004, however, has controversial conditions which demand the applicants be both unmarried and childless. On 28 July 2004, Naha Family Court in Okinawa Prefecture returned a verdict to a transsexual woman in her 20s, allowing her family registry record or koseki to be amended as she was born a female. It is generally believed to be the first court approval under the new law. Since 2018 sex reassignment surgeries are paid for by the Japanese government, who are covered by the Japanese national health insurance as long as patients are not receiving hormone treatment and do not have any other pre-existing conditions. However applicants are required to be single, sterile, childless, under the age of 20 as well as to undergo a psychiatric evaluation to receive a diagnosis of “Gender Identity Disorder”, also known as gender dysphoria in western countries. Once completed the patient has to only pay 30% of the surgery costs.\n\nThere is no legislation expressly allowing transsexuals to legally change their gender in Malaysia. The relevant legislations are the Births and Deaths Registration Act 1957 and National Registration Act 1959. Therefore, judges currently exercise their discretion in interpreting the law and defining the gender. There are conflicting decisions on this matter. There is a case in 2003 where the court allowed a transsexual to change her gender indicated in the identity card, and granted a declaration that she is a female. However, in 2005, in another case, the court refused to amend the gender of a transsexual in the identity card and birth certificate. Both cases applied the United Kingdom case of Corbett v Corbett in defining legal gender.\n\nPeople have started accepting acts of sex reassignment surgery to change their sex as a norm either compelled by gender dysphoria or just for the sake of it. There are situations where such cases have come into the limelight. A 2008 ruling at Pakistan's Lahore High Court gave permission to Naureen, 28, to have a sex change operation, although the decision was applicable only towards people suffering from gender dysphoria.\n\nIn 2009, the Pakistan Supreme Court ruled in favour of a group of transvestites. The landmark ruling stated that as citizens they were entitled to the equal benefit and protection of the law and called upon the government to take steps to protect transvestites from discrimination and harassment. Pakistan's chief justice Iftikhar Chaudhry was the architect of major extension of rights to Pakistan's transgender community during his term.\n\nThere are anti-discrimination laws in employment for transgender or transsexual people\n(known as Khuwaja Sira, formerly hijra, or Third Gender).\n\nAnd there are anti-discrimination laws in the provision of goods and services for transgender or transsexual individuals\n(known as Khuwaja Sira, formerly hijra, or Third Gender).\n\nThe Court of cassation, the highest court in Jordan allowed a Transsexual Woman to change her legal Name and Sex to Female in 2014 after she brought forth Medical Reports from Australia. The head of the Jordanian Department of civil Status and Passports stated that two to three cases of change of sex reach the department annually, all based on Medical Reports and Court orders.\n\nThe Supreme Court of the Philippines Justice Leonardo Quisumbing on 12 September 2008, allowed Jeff Cagandahan, 27, to change both his birth certificate, gender and name from Jennifer to Jeff, to male: \"We respect respondent’s congenital condition and his mature decision to be a male. Life is already difficult for the ordinary person. We cannot but respect how respondent deals with his unordinary state and thus help make his life easier, considering the unique circumstances in this case. In the absence of a law on the matter, the court will not dictate on respondent concerning a matter so innately private as one's sexuality and lifestyle preferences, much less on whether or not to undergo medical treatment to reverse the male tendency due to rare medical condition, congenital adrenal hyperplasia. In the absence of evidence that respondent is an 'incompetent,' and in the absence of evidence to show that classifying respondent as a male will harm other members of society [...] the court affirms as valid and justified the respondent's position and his personal judgment of being a male.\" Court records showed that – at 6, he had small ovaries; at 13, his ovarian structure was minimized and he had no breasts and did not menstruate. The psychiatrist testified that \"he has both male and female sex organs, but was genetically female, and that since his body secreted male hormones, his female organs did not develop normally.\" The Philippines National Institutes of Health said \"people with congenital adrenal hyperplasia lack an enzyme needed by the adrenal gland to make the hormones cortisol and aldosterone.\n\nThis, however, only applies to cases involving congenital adrenal hyperplasia and other intersex situations. The Philippine Supreme Court has also ruled that Filipino citizens do not have the right to legally change their sex on official documents (driver's license, passport, birth certificate, Social Security records, etc.) if they are transsexual and have undergone sexual reassignment surgery. The Court said that if the man, now anatomically a female, were to be allowed to legally change his sex it would have \"serious and wide-ranging legal and public policy consequences,\" citing the institution of marriage in particular.\n\nIn South Korea, it is possible for transgender individuals to change their legal gender, although it depends on the decision of the judge for each case. Since the 1990s, however, it has been approved in most of the cases. The legal system in Korea does not prevent marriage once a person has changed their legal gender.\n\nIn 2006, the Supreme Court of Korea ruled that transsexuals have the right to alter their legal papers to reflect their reassigned sex. A trans woman can be registered, not only as female, but also as being \"born as a woman.\"\n\nWhile same-sex marriage is not approved by South Korean law, a transsexual woman obtains the marital status of 'female' automatically when she marries to a man, even if she has previously been designated as \"male.\"\n\nIn 2013 a court ruled that transsexuals can change their legal sex without undergoing genital surgery.\n\nA majority of countries in Europe give transgender people the right to at least change their first name, most of which also provide a way of changing birth certificates. Several European countries recognize the right of transsexuals to marry in accordance with their post-operative sex. Croatia, Czech Republic, Denmark, Finland, France, Germany, Ireland, Italy, the Netherlands, Norway, Poland, Portugal, Romania, Sweden, Spain, and the United Kingdom all recognize this right. The Convention on the recognition of decisions regarding a sex change provides regulations for mutual recognition of sex change decisions and has been signed by five European countries and ratified by Spain and the Netherlands.\n\nIn Finland, people wishing to change their legal gender must be sterilized or \"for some other reason infertile\". A recommendation from the UN Human Rights Council to eliminate the sterilization requirement was rejected by the Finnish government in 2017.\n\nIn France, there is currently no law that defines sex-change procedures. However, it is possible to ask for a sex- or a name change before the Court. The judge decides to grant or refuse the change.\n\nSince 1980, Germany has a law that regulates the change of first names and legal gender. It is called (Law about the change of first name and determination of gender identity in special cases (Transsexual law – TSG)). Requirements that applicants for a change in gender were infertile post-surgery declared unconstitutional by supreme court ruling in a 2011.\n\nOn 10 October 2017, the Greek Parliament passed, by a comfortable majority, the \"Legal Gender Recognition Bill\" which grants the transgender people in Greece the right to change their legal gender freely by abolishing any conditions and requirements, such as undergoing any medical interventions, sex reassignment surgeries or sterilisation procedures to have their gender legally recognized on their IDs. The bill grants this right to anyone aged 17 and older. However, even underaged children between the age of 15 and 17 will have access to the legal gender recognition process, but under certain conditions, such as obtaining a certificate from a medical council. The bill was opposed by the Holy Synod of the Orthodox Church, the Communist Party of Greece, Golden Dawn and New Democracy.\n\nThe Legal Gender Recognition Bill followed a 20 July 2016 decision of the County Court of Athens, which ruled that a person who wants to change their legal gender on the Registry Office files is no longer obliged to already have undergone a sex reassignment surgery. This decision was applied by the Court on a case-by-case basis.\n\nIn the Republic of Ireland, it was not possible for a transsexual person to alter their birth certificate until 2015. The High Court took a case by Lydia Foy in 2002 that was turned down, as a birth certificate was deemed to be a historical document.\n\nOn July 15, 2015, Ireland passed the Gender Recognition Act of 2015 that allows legal gender changes without the requirement of medical intervention or assessment by the state. Such change is possible through self-determination for any person aged 18 or over resident in Ireland and registered on Irish registers of birth or adoption. Persons aged 16 to 18 years must secure a court order to exempt them from the normal requirement to be at least 18. Ireland is one of four legal jurisdictions in the world where people may legally change gender through self-determination.\n\nThe first milestone sentence in the case of gender shifting was given by Warsaw's Voivode Court in 1964. The court reasoned that it be possible, in face of civil procedure and acting on civil registry records, to change one's legal gender after their genital reassignment surgery had been conducted. In 1983, the Supreme Court ruled that in some cases, when the attributes of the individual's preferred gender were predominant, it is possible to change one's legal gender even before genital reassignment surgery.\n\nIn 2011, Anna Grodzka, the first transgender MP in the history of Europe who underwent a genital reassignment operation was appointed. In the Polish Parliamentary Election 2011 she gained 19 337 votes (45 079 voted for her party in the constituency) in the City of Cracow and came sixth in her electoral district (928 914 people, voter turnout 55,75%). Grodzka is reportedly the only transsexual person with ministerial responsibilities in the world since 10 November 2011 (as of 2015).\n\nThe law allows an adult person to change their legal gender without any requirements. Minors aged 16 and 17 are able to do so with parental consent and a psychological opinion, confirming that their decision has been taken freely and without any outside pressure. The law also prohibits both direct and indirect discrimination based on gender identity, gender expression and sex characteristics, and bans non-consensual sex assignment treatment and/or surgical intervention on intersex children\n\nIn Romania it is legal for transgender people to change their first name to reflect their gender identity based on personal choice. Since 1996, it has been possible for someone who has gone through genital reassignment surgery to change their legal gender in order to reflect their post-operative sex. Transgender people then have the right to marry in accordance with their post-operative sex.\n\nThe Sex Discrimination Act 1975 made it illegal to discriminate on the ground of anatomical sex in employment, education, and the provision of housing, goods, facilities and services. The Equality Act 2006 introduced the Gender Equality Duty in Scotland, which made public bodies obliged to take seriously the threat of harassment or discrimination of transsexual people in various situations. In 2008, the Sex Discrimination (Amendment of Legislation) Regulations extended existing regulation to outlaw discrimination when providing goods or services to transsexual people. The Equality Act 2010 officially adds \"gender reassignment\" as a \"protected characteristic.\".\n\nThe Gender Recognition Act 2004 effectively granted full legal recognition for binary transgender people. In contrast to some systems elsewhere in the world, the Gender Recognition process does not require applicants to be post-operative. They need only demonstrate that they have suffered gender dysphoria, have lived as \"your new gender\" for two years, and intend to continue doing so until death.\n\nJurisdiction over legal classification of sex in Canada is assigned to the provinces and territories. This includes legal change of gender classification.\n\nAnd on June 19, 2017 Bill C-16, after having passed the legislative process in the House of Commons of Canada and the Senate of Canada, became law upon receiving Royal Assent which put it into immediate force. The law updated the Canadian Human Rights Act and the Criminal Code to include \"gender identity and gender expression\" as protected grounds from discrimination, hate publications and advocating genocide. The bill also added \"gender identity and expression\" to the list of aggravating factors in sentencing, where the accused commits a criminal offence against an individual because of those personal characteristics. Similar transgender laws also exist in all the provinces and territories. And conversion therapy is banned in the provenances of Manitoba, Ontario, and Nova Scotia, and the city of Vancouver, though it should be noted that the Nova Scotia law is hampered by a clause that allows \"mature minors\" between the ages of 16 and 18 to consent.\n\nJurisdiction over legal classification of sex in Mexico is assigned to the states and Mexico City. This includes legal change of gender classification.\n\nOn 13 March 2004, amendments to the Mexico City Civil Code that allow transgender people to change their gender and name on their birth certificates, took effect.\n\nIn September 2008, the PRD-controlled Mexico City Legislative Assembly approved a law, in a 37-17 vote, making gender changes easier for transgender people.\n\nOn 13 November 2014, the Legislative Assembly of Mexico City unanimously (46-0) approved a gender identity law. The law makes it easier for transgender people to change their legal gender. Under the new law, they simply have to notify the Civil Registry that they wish to change the gender information on their birth certificates. Sex reassignment surgery, psychological therapies or any other type of diagnosis are no longer required. The law took effect in early 2015. On 13 July 2017, the Michoacán Congress approved (22-1) a gender identity law. Nayarit approved (23-1) a similar law on 20 July 2017.\n\nPursuant to the U.S. Const., Amend. 10, which reserves to the states (or to the people) all powers not assigned to the federal government, the legal classification of sex is a matter of state jurisdiction in the United States. The principle is generally extended to the District of Columbia and U.S. territories, though the federal government has power to overrule any decision those non-state entities might make. \n\nRegardless of the legal sex classification determined by a state or territory, the federal government may make its own determination of sex classification for federally issued documents. For instance, the U.S. Department of State requires a medical certification of \"appropriate clinical treatment for transition to the updated gender (male or female)\" to amend the gender designation on a U.S. passport, but sex reassignment surgery is not a requirement to obtain a U.S. passport in the updated gender.\n\nSouth America has some of the most progressive legislation in the world regarding transgender rights. Transgender persons are allowed to change their name and gender on legal documents in a majority of countries. Argentina, Brazil, Bolivia, Colombia and Ecuador allow individuals to change their name and gender without undergoing medical treatment, sterilization or judicial permission. In Uruguay a judicial order is required. In Chile transgender persons can change their legal gender and name after completion of medical intervention. Judicial permissions are required. Peru allows legal name change after surgery, however gender change is not allowed by courts.\n\nIn 2012 the Argentine Congress passed the Ley de Género (Gender Law), which allows individuals over 18 to change the gender marker in their DNI (national ID) on the basis of a written declaration only. Argentina thus became the first country to adopt a gender recognition policy based entirely on individual autonomy, without any requirement for third party diagnosis, surgeries or obstacles of any type.\n\nThe Gender Identity law allows individuals over 18 to legally change their name, gender and photography on legal documents. No surgeries or judicial order are required. The law took effect on August 1, 2016.\n\nChanging legal gender assignment in Brazil is legal according to the Superior Court of Justice of Brazil, as stated in a decision rendered on October 17, 2009.\n\nAnd in 2008, Brazil's public health system started providing free sexual reassignment operations in compliance with a court order. Federal prosecutors had argued that sexual reassignment surgery was covered under a constitutional clause guaranteeing medical care as a basic right.\n\nPatients must be at least 18 years old and diagnosed as transsexuals with no other personality disorders, and must undergo psychological evaluation with a multidisciplinary team for at least two years, begins with 16 years old. \nThe national average is of 100 surgeries per year, according to the Ministry of Health of Brazil.\n\nSince 2015, a Colombian person may change their legal gender and name manifesting their solemn will before a notar, no surgeries or judicial order required.\n\nSince 2016, Ecuadorians are allowed to change their birth name and gender identity (instead of the sex assigned at birth) on legal documents and national ID cards. The person who wants to change the word \"sex\" for \"gender\" in the identity card shall present two witnesses to accredit the self-determination of the applicant.\n\nIn October 2009, lawmakers passed the Gender identity law allowing transgender people over the age of 18 to change their name and legal gender on all official documents. Surgery, diagnosis or hormone therapy are not a requirement but a judicial permission is required. Applicants cannot request a second change for at least five years.\n\nBirth certificates are within the jurisdiction of the states, whereas marriage and passports are matters for the Commonwealth. All Australian jurisdictions now recognise the affirmed sex of an individual, with varying requirements. In the landmark case \"New South Wales Registrar of Births, Deaths and Marriages v Norrie\" [2014] the High Court of Australia held that the \"Births Deaths and Marriages Registration Act 1995\" (NSW) did not require a person having undergone genital reassignment surgery to identify as either a man or a woman. The ruling permits a gender registration of \"non-specific\".\n\nPassports are issued in the preferred gender, without requiring a change to birth certificates or citizenship certificates. A letter is needed from a medical practitioner which certifies that the person has had or is receiving appropriate treatment.\n\nAustralia was the only country in the world to require the involvement and approval of the judiciary (Family Court of Australia) with respect to allowing transgender children access to hormone replacement therapy. This ended in late 2017, when the Family Court issued a landmark ruling establishing that, in cases where there is no dispute between a child, their parents, and their treating doctors, hormone treatment can be prescribed without court permission.\n\nThe Constitution of Fiji which was promulgated in September 2013 includes a provision banning discrimination based on sexual orientation and gender identity or expression.\n\nGender changes are legal in Guam. In order for transgender people to change their legal gender in Guam, they must provide the Office of Vital Statistics a sworn statement from a physician that they have undergone sex reassignment surgery. The Office will subsequently amend the birth certificate of the requester.\n\nCurrently, the Human Rights Act 1993 does not explicitly prohibit discrimination on the basis of gender. Whilst it is believed that gender identity is protected under the laws preventing discrimination on the basis of either sex or sexual orientation, it is not known how this applies to those who have not had, or will not have, gender reassignment surgery.\n\nTransgender persons in the Northern Mariana Islands may change their legal gender following sex reassignment surgery and a name change. The \"Vital Statistics Act of 2006\", which took effect in March 2007, states that: \"Upon receipt of a certified copy of an order of the CNMI Superior Court indicating the sex of an individual born in the CNMI has been changed by surgical procedure and whether such individual’s name has been changed, the certificate of birth of such individual shall be amended as prescribed by regulation.\" \n\nIn Samoa crimes motivated by sexual orientation and/or gender identity are criminalized under Section 7(1)(h) of the \"Sentencing Act 2016\".\n\n"}
{"id": "18331", "url": "https://en.wikipedia.org/wiki?curid=18331", "title": "Ligase", "text": "Ligase\n\nIn biochemistry, a ligase is an enzyme that can catalyze the joining of two large molecules by forming a new chemical bond, usually with accompanying hydrolysis of a small pendant chemical group on one of the larger molecules or the enzyme catalyzing the linking together of two compounds, e.g., enzymes that catalyze joining of C-O, C-S, C-N, etc. In general, a ligase catalyzes the following reaction:\n\nor sometimes\n\nwhere the lowercase letters can signify the small, dependent groups. Ligase can join two complementary fragments of nucleic acid and repair single stranded breaks that arise in double stranded DNA during replication.\n\nThe common names of ligases often include the word \"ligase\", such as DNA ligase, an enzyme commonly used in molecular biology laboratories to join together DNA fragments. Other common names for ligases include the word \"synthetase\", because they are used to synthesize new molecules.\n\nBiochemical nomenclature has sometimes distinguished synthetases from synthases and sometimes treated the words as synonyms. Under one definition, synthases \"do not\" use energy from nucleoside triphosphates (such as ATP, GTP, CTP, TTP, and UTP), whereas synthetases \"do\" use nucleoside triphosphates. It is also said that a synthase is a lyase (a lyase is an enzyme that catalyzes the breaking of various chemical bonds by means other than hydrolysis and oxidation, often forming a new double bond or a new ring structure) and does not require any energy, whereas a synthetase is a ligase (a ligase is an enzyme that binds two chemicals or compounds) and thus requires energy. However, the Joint Commission on Biochemical Nomenclature (JCBN) dictates that \"synthase\" can be used with any enzyme that catalyses synthesis (whether or not it uses nucleoside triphosphates), whereas \"synthetase\" is to be used synonymously.\n\nLigases are classified as EC 6 in the EC number classification of enzymes. Ligases can be further classified into six subclasses:\n\n\nSome ligases associate with biological membranes as peripheral membrane proteins or anchored through a single transmembrane helix, for example certain ubiquitin ligase related proteins.\n\nThe word \"ligase\" uses combining forms of \"lig-\" (from the Latin verb \"ligāre\", \"to bind\" or \"to tie together\") + \"-ase\" (denoting an enzyme), yielding \"binding enzyme\".\n\n\n"}
{"id": "18334", "url": "https://en.wikipedia.org/wiki?curid=18334", "title": "Logo (programming language)", "text": "Logo (programming language)\n\nLogo is an educational programming language, designed in 1967 by Wally Feurzeig, Seymour Papert, and Cynthia Solomon. \"Logo\" is not an acronym: the name was coined by Feurzeig while he was at Bolt, Beranek and Newman, and derives from the Greek \"logos\", meaning \"word\" or \"thought\".\n\nA general-purpose language, Logo is widely known for its use of turtle graphics, in which commands for movement and drawing produced line or vector graphics, either on screen or with a small robot termed a turtle. The language was conceived to teach concepts of programming related to Lisp and only later to enable what Papert called \"body-syntonic reasoning\", where students could understand, predict, and reason about the turtle's motion by imagining what they would do if they were the turtle. There are substantial differences among the many dialects of Logo, and the situation is confused by the regular appearance of turtle graphics programs that are named Logo.\n\nLogo is a multi-paradigm adaptation and dialect of Lisp, a functional programming language. There is no standard Logo, but UCBLogo has the best facilities for handling lists, files, I/O, and recursion in scripts, and can be used to teach all computer science concepts, as UC Berkeley lecturer Brian Harvey did in his \"Computer Science Logo Style\" trilogy.\n\nLogo is usually an interpreted language, although there have been developed compiled Logo dialects (such as Lhogho and Liogo). Logo is not case-sensitive but retains the case used for formatting.\n\nLogo was created in 1967 at Bolt, Beranek and Newman (BBN), a Cambridge, Massachusetts research firm, by Wally Feurzeig, Cynthia Solomon, and Seymour Papert. Its intellectual roots are in artificial intelligence, mathematical logic and developmental psychology. The first four years of Logo research, development and teaching work was done at BBN. The first implementation of Logo, called Ghost, was written in LISP on a PDP-1. The goal was to create a mathematical land where children could play with words and sentences. Modeled on LISP, the design goals of Logo included accessible power and informative error messages. The use of virtual Turtles allowed for immediate visual feedback and debugging of graphic programming.\n\nThe first working Logo turtle robot was created in 1969. A display turtle preceded the physical floor turtle. Modern Logo has not changed too much from the basic concepts before the first turtle. The first turtle was a tethered floor roamer, not radio-controlled or wireless. At BBN Paul Wexelblat developed a turtle named Irving that had touch sensors and could move forwards, backwards, rotate, and ding its bell. The earliest year-long school users of Logo were in 1968-69 at Muzzey Jr High, Lexington MA. The virtual and physical turtles were first used by fifth-graders at the Bridge School in Lexington, MA in 1970-71.\n\nLogo's most-known feature is the turtle (derived originally from a robot of the same name), an on-screen \"cursor\" that showed output from commands for movement and small retractable pen, together producing line graphics. It has traditionally been displayed either as a triangle or a turtle icon (though it can be represented by any icon). Turtle graphics were added to the Logo language by Seymour Papert in the late 1960s to support Papert's version of the turtle robot, a simple robot controlled from the user's workstation that is designed to carry out the drawing functions assigned to it using a small retractable pen set into or attached to the robot's body.\n\nAs a practical matter, the use of turtle geometry instead of a more traditional model mimics the actual movement logic of the turtle robot. The turtle moves with commands that are relative to its own position, \"LEFT 90\" means spin left by 90 degrees. Some Logo implementations, particularly those that allow the use of concurrency and multiple turtles, support collision detection and allow the user to redefine the appearance of the turtle cursor, essentially allowing the Logo turtles to function as sprites.\n\nMultiple turtles are supported by MSWLogo, as well as 3D graphics. Input from COM ports and LPT ports are also allowed by MSWLogo through windows GUI. Interrupts can be triggered via keyboard and mouse events. Simple GIF animations may also be produced on MSWLogo version 6.5 with the \"gifsave\" command.\n\nTurtle geometry is also sometimes used in environments other than Logo as an alternative to a strictly coordinate-addressed graphics system. For instance, the idea of turtle graphics is also useful in Lindenmayer system for generating fractals.\n\nSome modern derivatives of Logo allow thousands of independently moving turtles. There are two popular implementations: Massachusetts Institute of Technology's StarLogo and Northwestern University Center for Connected Learning's (CCL) NetLogo. They allow exploring emergent phenomena and come with many experiments in social studies, biology, physics, and other areas. NetLogo is widely used in agent-based simulation in the biological and social sciences.\n\nAlthough there is no one agreed-upon standard, there is a broad consensus on core aspects of the language. As of March 2009 there were 197 implementations and dialects of Logo, each with its own strengths. Most of those 197 are no longer in wide use, but many are still under active development. Commercial Logos that are still widely used in schools include \"MicroWorlds Logo\" and \"Imagine Logo\".\n\n\nLogo was a primary influence on the Smalltalk programming language. It is also the main influence on the Etoys educational programming environment and language, which is essentially a Logo written in Squeak (a variant of Smalltalk). Logo influenced the procedure/method model in AgentSheets and AgentCubes to program agents similar to the notion of a turtle in Logo. Logo provided the underlying language for Boxer. Boxer was developed at University of California, Berkeley and MIT and is based on a \"literacy model\", making it easier to use for nontechnical people.\n\nKTurtle is a variation of Logo implemented at Qt for the KDE environment loosely based on Logo.\n\nAnother result of Logo's influence is the Kojo, a variant of Scala and Scratch educational programming language, which runs on Squeak, a variant of Smalltalk, which was inspired by Logo.\n\nIn 2015, Cubetto, an education robotics system for children 3 years and older, was developed through crowd-source funding. Cubetto influenced both by LOGO and by Montessori. Cubetto features a small cubic Turtle that turns only through 90 degrees. Cubetto has been described to be an update of button-box MIT LOGO system TORTIS.\n\n\n"}
{"id": "18337", "url": "https://en.wikipedia.org/wiki?curid=18337", "title": "Last rites", "text": "Last rites\n\nThe last rites, in Roman Catholicism, are the last prayers and ministrations given to an individual of the faith, when possible, shortly before death. The last rites go by various names. They may be administered to those awaiting execution, mortally injured, or terminally ill.\n\nWhat in the judgment of the Roman Catholic Church are properly described as the Last Rites are Viaticum (Holy Communion administered to someone who is dying), and the ritual prayers of Commendation of the Dying, and Prayers for the Dead.\n\nOf these, only Viaticum is a sacrament.\n\nThe sacrament of Anointing of the Sick has often been postponed until someone is near death, so much so that, in spite of the fact that in all celebrations of this sacrament, the liturgy prays for recovery of the health of the sick person if that would be conducive to his salvation, Anointing of the Sick has been thought to be exclusively for the dying and has been called Extreme Unction (Final Anointing). If administered to someone who is not just ill but near death, Anointing of the Sick is generally accompanied by celebration of the sacraments of Penance and Viaticum. In such cases, the normal order of administration is: first Penance, then Anointing, then Viaticum.\n\nAlthough these three sacraments are not, in the proper sense, the Last Rites, they are sometimes mistakenly spoken of as such.\n\nThe Eucharist given as Viaticum is the only sacrament essentially associated with dying: \"The celebration of the Eucharist as Viaticum is the sacrament proper to the dying Christian\".\n\nIn the Roman Ritual's \"Pastoral Care of the Sick: Rites of Anointing and Viaticum\", Viaticum is the only sacrament dealt with in \"Part II: Pastoral Care of the Dying\". Within that part, the chapter on Viaticum is followed by two more chapters, one on \"Commendation of the Dying\", with short texts, mainly from the Bible, a special form of the litany of the saints, and other prayers, and the other on \"Prayers for the Dead\". A final chapter provides \"Rites for Exceptional Circumstances\", namely, the \"Continuous Rite of Penance, Anointing, and Viaticum\", \"Rite for Emergencies\", and \"Christian Initiation for the Dying\". The last of these concerns the administration of the sacraments of Baptism and Confirmation to those who have not received them.\n\nIn addition, the priest has authority to bestow a blessing in the name of the Pope on the dying person, to which a plenary indulgence is attached.\n\nPeople awaiting execution would receive Confession and Viaticum, but not Anointing of the Sick, since their impending death is not on account of an illness.\n\nIn the Orthodox Church and those Eastern Catholic Churches which follow the Byzantine Rite, the last rites consist of the Sacred Mysteries (sacraments) of Confession and the reception of Holy Communion.\n\nFollowing these sacraments, when a person dies, there are a series of prayers known as \"The Office at the Parting of the Soul From the Body\". This consists of a blessing by the priest, the usual beginning, and after the Lord's Prayer, Psalm 50. Then a Canon to the Theotokos is chanted, entitled, \"On behalf of a man whose soul is departing, and who cannot speak\". This is an elongated poem speaking in the person of the one who is dying, asking for forgiveness of sin, the mercy of God, and the intercession of the saints. The rite is concluded by three prayers said by the priest, the last one being said \"at the departure of the soul.\"\n\nThere is an alternative rite known as \"The Office at the Parting of the Soul from the Body When a Man has Suffered for a Long Time\". The outline of this rite is the same as above, except that Psalm 70 and Psalm 143 precede Psalm 50, and the words of the canon and the prayers are different.\n\nThe rubric in the Book of Needs (priest's service book) states, \"With respect to the Services said at the parting of the soul, we note that if time does not permit to read the whole Canon, then customarily just one of the prayers, found at the end of the Canon, is read by the Priest at the moment of the parting of the soul from the body.\"\n\nAs soon as the person has died the priest begins \"The Office After the Departure of the Soul From the Body\" (also known as \"The First Pannikhida\").\n\nIn the Orthodox Church Holy Unction is not considered to be solely a part of a person's preparation for death, but is administered to any Orthodox Christian who is ill, physically or spiritually, to ask for God's mercy and forgiveness of sin. There is an abbreviated form of Holy Unction to be performed for a person in imminent danger of death, which does not replace the full rite in other cases.\n\n\nhttp://www.usccb.org/beliefs-and-teachings/how-we-teach/catechesis/upload/Sacramental-Catechesis-11-19-12.pdf\n\n"}
{"id": "18338", "url": "https://en.wikipedia.org/wiki?curid=18338", "title": "Lamorna", "text": "Lamorna\n\nLamorna () is a village, valley and cove in west Cornwall, England, UK. It is on the Penwith peninsula approximately south of Penzance and lies within the Cornwall Area of Outstanding Natural Beauty (AONB); almost a third of Cornwall has AONB designation, with the same status and protection as a National Park. The South West Coast Path passes through the cove. According to the Post Office the population at the 2011 census is included in the civil parish of St Buryan\n\nFirst recorded as \"Nansmorno\" (in 1305), than \"Nansmurnou\" (1309), \"Nansmorne\" (1319), \"Nansmornou\" (1339), \"Nansmorna\" (1387) and \"Namorna\" (1388). \"Nans\" means valley plus possibly \"mor\" which is the sea.\n\nLamorna Cove is at the southern end of a north-west to south-east valley. The cove is delineated by Carn Dhu (Black Rock) on the eastern side, Lamorna Point on the western side and Mount's Bay to seaward. The parish boundary runs through the stream with the civil parish of Paul on the eastern side and St Buryan to the west. The valley is privately owned from The Wink (public house) down to the cove, which is reached by a narrow lane to the car park and quay. The small village, half a mile inland, was originally known as Nantewas.\n\nThe first record of tin streaming is in the 1380s when Alan Hoskyn was killed (murder was not proven) during a dispute, with Trewoofe, following the diversion of the stream. Mounds along the river are evidence of past activity. Kemyel Mill was operated by the Hoskyn family from at least the 14th-century to the 1920s and is now a gift shop under different ownership. There were two mills, one milled corn for animal feed, and the other flour. Both mills are grade II listed buildings.\n\nIn the 17th-century a privateer owned by the Penrose family was regularly moored in the cove and was wrecked during a storm. At one time five cannon were on the sea floor in and one is now at Stoney Cross, Leicestershire where it is used at an underwater archaeological training area. A number of silver coins found in 1984 and 1985 includes one dated 1653. The wreck is a popular diving site.\n\nA school for fifty to sixty infant boys and girls opened for the first time in the village in March 1881. The schoolroom, with a screen at the eastern end, was paid for by Canon Coulson and built on land on which he owned the freehold. The room converted to a mission room for Anglicans by removing a screen to reveal a chancel and the converted chapel had a capacity of seventy to eighty for services. Previously children had to go to St Buryan for schooling.\n\nThe valley is now tree covered, but until around the 1950s the stream and hill side was grazed by cows, horses and pigs. On the slopes, daffodils and early potatoes were grown with the flowers sent to markets at Covent Garden, Birmingham and Wales.\n\nThe local community radio station is Coast FM (formerly Penwith Radio), which broadcasts on 96.5 and 97.2 FM.\n\nWaste tips on the eastern side of the cove are a reminder of the granite quarries first opened by John Freeman, on St Aubyn land, in 1849 and continued working until 1911. Famous buildings and constructions include Admiralty Pier at Dover, London County Council offices, the Thames Embankment and Portland Breakwater. Stone from the cove was also used locally to build the Bishop Rock Lighthouse, Mousehole north pier and the Wolf Rock Lighthouse. Granite was dragged by chains to an iron pier, where the stream enters the sea, and transported by ship. A plinth weighing 20 tons was sent to The Great Exhibition of 1851 by sea but eventually, due to the hazards of loading ships, granite was sent by road via Kemyal and Paul Hill through Newlyn, to the cutting yards in Wherrytown. The present quay was built in the late 19th-century, possibly rebuilt on an older quay and is a grade II listed building. A quarry on the west side of the cove failed due to the high quartz content of the granite. An area of and known as the ″Lamorna Harbour Works″ was put up for auction at the Mart, Tokenhouse-yard, City of London on 16 June 1881. The property, on both sides of the valley, included ″the exceedingly valuable″ granite quarry with harbour, wharf and pier, a powder magazine, lime and mill house, carpenter's shops, 12 horse-power water-wheel, foreman's resident and a subsantial and superior dwelling-house. \n\nThe Lamorna Cove Hotel, built in the 1870s and known as Cliffe House, was originally the quarry manager's home, and had a school and chapel (with bell tower) for the quarry workers and their families. It was first used as a hotel in the 1920s. During the Second World War the hotel was occupied by seven French fishing families who fished out of Newlyn.\n\nIn the late nineteenth and early twentieth centuries Lamorna became popular with artists of the Newlyn School. It is particularly associated with the artist S J \"Lamorna\" Birch who lived there from 1908. The colony included Birch, Alfred Munnings, Laura Knight and Harold Knight. This period is dramatised in the 1998 novel \"Summer in February\" by Jonathan Smith and adapted for the 2013 movie directed by Christopher Menaul. Lamorna was also the home of the jeweller Ella Naper and her husband, the painter Charles, who built Trewoofe House. The Lamorna Arts Festival was launched in 2009 to celebrate the original Lamorna Colony and today's Lamorna art community.\n\nLamorna has been immortalised in the song \"Way Down to Lamorna\", about a wayward husband receiving his comeuppance from his wife. The song is beloved of many Cornish singers, including Brenda Wootton.\n\nThe actor Robert Newton (1905–1956) was educated in Lamorna and his ashes were scattered in the sea off Lamorna by his son, Nicholas Newton.\n\nThe authors Derek Tangye and Jean Tangye lived above Lamorna where he wrote his famous books \"The Minack Chronicles\". A piece of land called \"Oliver Land\" has been preserved as a wildlife sanctuary in memory of the couple. Lamorna was the village used in the novel \"The Memory Garden\" by Rachel Hore (2007) and was a location used for the shooting of Sam Peckinpah's 1971 thriller \"Straw Dogs\". \"Lamorna Cove\" was the title of a poem by W. H. Davies published in 1929.\n\nThe name of Lamorna's pub, The Wink, alludes to smuggling, \"the wink\" being a signal that contraband could be obtained. The pub is the subject of a novel by Martha Grimes, entitled \"The Lamorna Wink\". The interior contains an important collection of maritime artefacts, including the nameplate of the battleship Warspite.\n\nThe Lamorna Pottery was founded in 1947 by Christopher James Ludlow (known as Jimmy) and Derek Wilshaw. It is currently a gift shop and café.\n\n"}
{"id": "18339", "url": "https://en.wikipedia.org/wiki?curid=18339", "title": "Law of multiple proportions", "text": "Law of multiple proportions\n\nIn chemistry, the law of multiple proportions is one of the basic laws of stoichiometry used to establish the atomic theory, alongside the law of conservation of mass (matter) and the law of definite proportions. It is sometimes called Dalton's Law after its discoverer, the British chemist John Dalton, who published it in the first part of the first volume of his \"New System of Chemical Philosophy\" (1808). Here is the statement of the law:\n\nFor example, Dalton knew that the element carbon forms two oxides by combining with oxygen in different proportions. A fixed mass of carbon, say 100 grams, may react with 133 grams of oxygen to produce one oxide, or with 266 grams of oxygen to produce the other. The ratio of the masses of oxygen that can react with 100 grams of carbon is 266:133 = 2:1, a ratio of small whole numbers. Dalton interpreted this result in his atomic theory by proposing (correctly in this case) that the two oxides have one and two oxygen atoms respectively for each carbon atom. In modern notation the first is CO (carbon monoxide) and the second is CO (carbon dioxide).\n\nJohn Dalton first expressed this observation in 1804. A few years previously, the French chemist Joseph Proust had proposed the \"law of definite proportions\", which expressed that the elements combined to form compounds in certain well-defined proportions, rather than mixing in just any proportion; and Antoine Lavoisier proved the law of conservation of mass, which helped out Dalton. Careful study of the actual numerical values of these proportions led Dalton to propose his law of multiple proportions. This was an important step toward the atomic theory that he would propose later that year, and it laid the basis for chemical formulas for compounds.\n\nAnother example of the law can be seen by comparing ethane (CH) with propane (CH). The weight of hydrogen which combines with 1 g carbon is 0.252 g in ethane and 0.224 g in propane. The ratio of those weights is 1.125, which can be expressed as the ratio of two small numbers 9:8.\n\nThe law of multiple proportions is best demonstrated using simple compounds. For example, if one tried to demonstrate it using the hydrocarbons decane (chemical formula CH) and undecane (CH), one would find that 100 grams of carbon could react with 18.46 grams of hydrogen to produce decane or with 18.31 grams of hydrogen to produce undecane, for a ratio of hydrogen masses of 121:120, which is hardly a ratio of \"small\" whole numbers.\n\nThe law fails with non-stoichiometric compounds and also doesn't work well with polymers and oligomers.\n"}
{"id": "18340", "url": "https://en.wikipedia.org/wiki?curid=18340", "title": "Law of averages", "text": "Law of averages\n\nThe law of averages is the fallacious belief that a particular outcome or event is inevitable or certain simply because it is statistically possible. Depending on context or application it can be considered a valid common-sense observation or a misunderstanding of probability. This notion can lead to the gambler's fallacy when one becomes convinced that a particular outcome must come soon simply because it has not occurred recently (e.g. believing that because three consecutive coin flips yielded \"heads\", the next coin flip must be virtually guaranteed to be \"tails\").\n\nAs invoked in everyday life, the \"law\" usually reflects wishful thinking or a poor understanding of statistics rather than any mathematical principle. While there is a real theorem that a random variable will reflect its underlying probability over a very large sample, the law of averages typically assumes that unnatural short-term \"balance\" must occur. Typical applications also generally assume no bias in the underlying probability distribution, which is frequently at odds with the empirical evidence.\n\nThe gambler's fallacy is a particular misapplication of the law of averages in which the gambler believes that a particular outcome is more likely because it has not happened recently, or (conversely) that because a particular outcome has recently occurred, it will be less likely in the immediate future.\n\nAs an example, consider a roulette wheel that has landed on red in three consecutive spins. An onlooker might apply the law of averages to conclude that on its next spin it must (or at least is much more likely to) land on black. Of course, the wheel has no memory and its probabilities do not change according to past results. So even if the wheel has landed on red in ten or a hundred consecutive spins, the probability that the next spin will be black is still no more than 48.6% (assuming a \"fair\" European wheel with only one green zero; it would be exactly 50% if there were no green zero and the wheel were fair, and 47.4% for a fair American wheel with one green \"0\" and one green \"00\"). Similarly, there is no statistical basis for the belief that lottery numbers which haven't appeared recently are due to appear soon. (There is some value in choosing lottery numbers that are, in general, less \"popular\" than others — not because they are any more or less likely to come up, but because the largest prizes are usually shared among all of the people who chose the winning numbers. The unpopular numbers are just as likely to come up as the popular numbers are, and in the event of a big win, one would likely have to share it with fewer other people. See parimutuel betting)\n\nOn the other hand, in some locales, modern slot machines are rigged so they \"do\" give wins a certain proportion of the time — the results are not truly random. This is carefully managed so as to encourage people to keep playing, while the casino takes its designated amount of profit.\n\nAnother application of the law of averages is a belief that a sample's behaviour must line up with the expected value based on population statistics. For example, suppose a fair coin is flipped 100 times. Using the law of averages, one might predict that there will be 50 heads and 50 tails. While this is the single most likely outcome, there is only an 8% chance of it occurring. Predictions based on the law of averages are even less useful if the sample does not reflect the population.\n\nIn this example, one tries to increase the probability of a rare event occurring at least once by carrying out more trials. For example, a job seeker might argue, \"If I send my résumé to enough places, the law of averages says that someone will eventually hire me.\" Assuming a non-zero probability, it is true that conducting more trials increases the overall likelihood of the desired outcome. However, there is no particular number of trials that guarantees that outcome; rather, the probability that it will already have occurred approaches but never quite reaches 100%.\n\nThe Steve Goodman song \"A Dying Cub Fan's Last Request\" mentions the Law of Averages in reference to the Chicago Cubs lack of championship success. At the time Goodman recorded the song in 1981, the Cubs had not won a National League championship since the year the United States dropped the atomic bomb on Japan (1945), and had not won a World Series since 1908. This futility would continue until the Cubs would finally win both in 2016.\n\n"}
{"id": "18341", "url": "https://en.wikipedia.org/wiki?curid=18341", "title": "Outline of linguistics", "text": "Outline of linguistics\n\nThe following outline is provided as an overview of and topical guide to linguistics:\n\nLinguistics is the scientific study of natural language. Someone who engages in this study is called a linguist. Linguistics can be theoretical or applied.\n\nLinguistics can be described as all of the following:\n\n\n\nSub-fields of structure-focused linguistics include:\n\n\n\n\n\n\n\nHistory of linguistics\n\n\"When were the basic concepts first described and by whom?\"\n\n\n\"What basic concepts / terms do I have to know to talk about linguistics?\"\n\n\"People who had a significant influence on the development of the field\"\n\n\n\n\n"}
{"id": "18342", "url": "https://en.wikipedia.org/wiki?curid=18342", "title": "Outline of law", "text": "Outline of law\n\nLaw (\"article link\") is the set of rules and principles (laws) by which a society is governed, through enforcement by governmental authorities. Law is also the field which concerns the creation and administration of laws, and includes any and all legal systems.\n\nLaw can be described as all of the following:\n\n\n\n\nPublic law\n\n\n\n\n\n\n\nHistory of law\n\n\n\n\n\n\nSources of law\n\nLegislatures\n\nCourts\n\nPrisons\n\n\n"}
{"id": "18345", "url": "https://en.wikipedia.org/wiki?curid=18345", "title": "Outline of literature", "text": "Outline of literature\n\nThe following outline is provided as an overview of and topical guide to literature:\n\nLiterature – prose, written or oral, including fiction and non-fiction, drama, and poetry. \"See also: outline of poetry.\"\n\nLiterature can be described as all of the following:\n\n\n\nOral literature\n\n\nNon-fiction\n\nFiction\n\n\nHistory of literature\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "18352", "url": "https://en.wikipedia.org/wiki?curid=18352", "title": "AvtoVAZ", "text": "AvtoVAZ\n\nAvtoVAZ (), formerly known as VAZ (Volzhsky Avtomobilny Zavod) (ВАЗ, Во́лжский автомоби́льный заво́д, or Volga Automobile Plant), is a Russian automobile manufacturer. The company has been a subsidiary of the French Groupe Renault since 2016.\n\nThe company is best known for its flagship series of Lada vehicles. In the Soviet Union, its products used various names, including Zhiguli, Oka, and Sputnik which were phased out in the 1990s and replaced by Lada for the Russian market. \n\nAvtoVAZ produces over 400,000 cars a year, under its Lada brand as well as cars of Renault–Nissan–Mitsubishi Alliance brands Renault, Nissan and Datsun. The AvtoVAZ factory is the largest car manufacturer in Russia and Eastern Europe.\n\nThe company was established in the late 1960s in cooperation with Fiat, with Viktor Polyakov (later Minister of Automobile Industry) as director, and Vladimir Solovyov as chief designer, and intended to produce popular economy cars that would meet the growing demand for personal transport. It was set up as a collaboration between Italy and the Soviet Union and built on the banks of the Volga River in 1966. A new town, Tolyatti, named after the Italian Communist Party leader Palmiro Togliatti, was built around the factory. The cost of the VAZ plant was estimated at $800 million in 1970 (equivalent to $ billion in ).\n\nThe car brand to be produced (\"Zhiguli\") was envisaged as a \"people's car\" like the Citroën 2CV or the VW Type 1. Production was intended to be 220,000 cars a year, beginning in 1971 (other sources listed 300,000 in 1971); car production actually began before the plant was finished in 1970. The VAZ trademark, at first, was a silver Volga boat on a red pentagonal background, with \"Togliatti\" superposed in Cyrillic (Тольятти); the first badges, manufactured in Turin, mistakenly had the Cyrillic \"Я\" rendered \"R\" instead (Тольʀтти), making them collector's items.\n\nUnlike most Soviet enterprises, the company was not vertically integrated, rather depending for components on a variety of suppliers over which it exerted little control.\n\nThe first VAZ-2101 was produced on 22 April 1970, the 100th anniversary of Lenin's birth. About 22,000 VAZ-2101s were built in 1970, with capacity at the end of 1973 reaching 660,000 a year; 21 December, the one millionth 2101 was built. A third production line was added in October 1974, boosting output to 2,230 cars a day. The same year, total VAZ production reached 1.5 million.\n\nThe VAZ plant was described as 'ultra-modern' by the Chicago Tribune in a 1973 article. Production reached 750,000 cars a year in 1975, making the Tolyatti plant the third most productive in the world. Between 1977 and 1981, AvtoVAZ acquired 30 welding robots from Japanese firms.\n\nThe original, Fiat-based models included the VAZ-2101 sedan and the VAZ-2102 station wagon. 1972 saw the introduction of a deluxe version of the sedan, VAZ-2103, which was based on the Fiat 124 Special and featured a new 1.5 L engine and twin headlights. In 1974, the original VAZ-2101 was updated with new engines and interiors, whereas the VAZ-2102 underwent the same improvements in 1976. The body style with two round headlights was manufactured until 1988.\n\nThe VAZ-2106, introduced in December 1975 as an updated version of the VAZ-2103, was based on the 1972 Fiat 124 Special T, featuring different interiors and new 1.6 L engine. The 2106 was one of the most popular rear-wheel drive AvtoVAZ models in the past; its production ended in 2001 from Tolyatti, but continued at Izhavto (Izhevsk), ending there in December 2005.\n\nIn 1974, VAZ was given permission to begin producing Wankel engines under licence from NSU. Work began in 1976, with a single-rotor Lada appearing in 1978; the first 250 of these went on sale in the summer of 1980.\n\nAfter having built a number of prototypes and experimental vehicles, AvtoVAZ designers launched the first car entirely of their own design, the VAZ-2121 Niva, in 1977. This highly popular and innovative SUV was made with off-road use in mind, featuring a gearbox with a central differential lock lever as well as a low- and high-range selector lever.\n\nThe VAZ-2105, based on the Fiat 124 mechanicals but modernised and restyled, was introduced in 1979 and marketed outside the Soviet Union under the Riva or Laika trade names, depending on the country. Square headlights and new body panels distinguish this car from the earlier models. The 2105 was third best selling automobile platform after the Volkswagen Beetle and the Ford Model T, and one of the longest production run platforms alongside the Volkswagen Beetle, the Hindustan Ambassador and the Volkswagen Type 2.\n\nIn May 1980, a series of mass strikes at the Togliatti plant involving hundreds of thousands of workers were reported by the western press. In 1982 the VAZ-2107, a deluxe version of the 2105, was introduced; it featured a better engine, refined interiors and a chrome radiator grille. In 1984, the VAZ-2104 station wagon completed the line-up.\n\nBased on the success of the Niva, the design department prepared a new family of front-wheel drive models by 1984, which was of a completely domestic design. Production started with the VAZ-2108 \"Sputnik\" three-door hatchback, the series was commercially known as Samara. It was the first front-wheel drive serial car built in the Soviet Union after the LuAZ-\n969V. The Samara engine was mostly designed and produced in-house, had a new single overhead camshaft (SOHC) design and was driven by a more modern rubber belt. The five-door VAZ-2109 hatchback followed in 1987, and the four-door 1.5 L sedan, the VAZ-21099, was introduced in 1990. The same year, the front sides and radiator grille were restyled on the whole Samara range.\n\nA white 2108 would become the nine millionth Lada built, on 24 May 1985, with the ten millionth, on 9 October 1986, also a 2108. The twelve millionth, a right-hand drive 2109, was produced 6 July 1989.\n\nThe VAZ-1111 Oka micro-car was introduced in 1988, and in 1991 the production was transferred to the KamAZ and SeAZ factories.\n\nBy the late 1980s AvtoVAZ was suffering from the deterioration of its capital goods such as tools and machinery, resulting from insufficient levels of investment over a long period. Unproductive and antiquated management techniques also contributed to the decline, as did the absence of market competition.\n\nThe first privately owned AvtoVAZ dealership was established by Boris Berezovsky in 1989. Dealerships quickly turned into criminal rackets that at times simply stole cars from the factory.\n\nIn June 1991 Bear Stearns was hired by the Soviet government to conduct an appraisal of AvtoVAZ and negotiate a venture with a Western partner, in preparation for the privatization of the company. An independent trade union was started during the same year, as workers deemed the traditional trade union to be too close to the interests of management.\n\nIn January 1993 AvtoVaz was re-established as a joint-stock company under Russian law. The company came to be controlled by the management, including Vladimir Kadannikov, head of AvtoVAZ. It was listed on the Moscow Stock Exchange. As with many other privatized post-Soviet companies the financial situation at AvtoVAZ was dire, with workers being unpaid for months at a time.\n\nIn 1994 Boris Berezovsky’s dealership company, called Logovaz, accounted for nearly 10% of the domestic sales of AvtoVAZ. Despite the state of the Russian economy at the time demand for AvtoVAZ cars remained buoyant, but widespread corruption in the distribution network led the company to accumulate massive debts.\n\nThe 110-series sedan was introduced in 1995, two years late on its original 1993 deadline. Development costs for the car were estimated at $2 billion. The 2111 station wagon followed in 1998 and the 2112 hatchback completed the range in 2001. A five-door version of the Niva, the VAZ-2131, was introduced in 1995.\n\nBy 1995 car sales, distribution and spare parts at AvtoVAZ were all controlled by criminal organizations. This situation was made possible by the close relationship that existed between the criminals and part of the management. Additionally, gangsters were used to control the workers and break strikes.\n\nBy late 1996 AvtoVAZ had become the country's largest tax debtor, owing $2.4 billion in unpaid taxes. In 1997, the Ministry of Internal Affairs launched Operation Cyclone, an investigation which ultimately uncovered evidence that gangsters connected to AvtoVAZ had carried out at least 65 murders of company managers, dealers and business rivals.\n\nThe 1998 Russian financial crisis improved the company's market position, by improving the effectiveness of export sales and making imported cars too expensive for most Russians. The VAZ-2120 Nadezhda, a minivan based on the Lada Niva, was introduced in 1998. In the second half of the 1990s some efforts were made to improve the quality of production, but in 1999 there were still nearly 50,000 cases of cars being assembled with missing parts.\n\nIn 2001 GM-AvtoVAZ, a joint-venture with General Motors, was established. Increased competition from foreign car manufacturers saw the company's share of the Russian market fall to 49% in 2002, compared to 56% four years earlier. In 2003, VAZ presented the concept car Lada Revolution, an open single seater sports car powered by a 1.6 L engine producing . Production of the Wankel engine used on some Lada models (mostly the police version) stopped in 2004.\n\n2005 saw the introduction of the new Kalina B-segment lineup to the market. AvtoVAZ has built a new modern plant for this model and is hoping to sell some 200,000 cars annually. The Kalina had been originally designed in the early 1990s, and its launch was repeatedly delayed, exemplifying the company's difficulty in bringing products to market in time.\n\nIn October 2005 the control of the company, which had until then been exercised by subsidiaries of AvtoVAZ connected to Kadannikov, was transferred to Rosoboronexport. March 2007 saw the start of production of Lada Priora, a restyled and modernised 110-series model.\n\nIn March 2008, Renault purchased a 25% stake in AvtoVAZ in a US$1 billion deal, with Rostec retaining the remaining 75%. The deal was agreed at a time when the Russian car market was booming.\n\nThe onset of the Great Recession caused considerable problems to the company. By April 2009 AvtoVAZ was on the verge of bankruptcy, which was only avoided because of $600 million bailout from the Russian government.\n\nAs an anti-crisis measure, the Russian government introduced a car scrappage scheme in March 2010. Avtovaz sales doubled in the second quarter of 2010 as a result, and the company returned to profit. By the end of 2010, automotive production in Russia had returned to pre-crisis levels.\n\nIn 2011 production of the classic Fiat 124-based 2105 and 2107 series models was completely moved from the Togliatti plant to the IzhAvto plant near Izhevsk, to make space for the company's forthcoming 2016 model. In April 2012, AvtoVAZ confirmed the end of the model 2107 (Lada Riva or Lada Nova), after more than forty years.\n\nSales of the Lada Granta, a subcompact car developed in collaboration with Renault, started in December 2011. The Lada Largus was launched in the Russian market in the middle of July 2012.\n\nIn August 2012, the Lada XRAY concept car was launched at the Moscow International Automobile Salon. The XRAY was designed by chief designer Steve Mattin, formerly of Volvo and Mercedes-Benz. The second generation of the Lada Kalina, basically a facelifted first generation, was also revealed at the 2012 Moscow International Motor Show. The Kalina is also produced as the more powerful version named Lada Kalina Sport.\n\nOn 3 May 2012, the Renault-Nissan alliance has signed letter of intent to raise its stake in Avtovaz to 51.01%. On 12 December 2012, the Renault–Nissan Alliance formed a joint venture with Rostekhnologii (Alliance Rostec Auto BV) with the aim of becoming the long-term controlling shareholder of AvtoVAZ.\n\nIn the same year, it was announced that Avtovaz and Sollers plan to jointly produce vehicles in Kazakhstan. The plant, which will be open in 2016, will be built in Ust-Kamenogorsk, in the eastern part of the country, and will produce around 120,000 cars a year.\n\nIn November 2013, Bo Andersson joined AvtoVAZ as CEO, the first non-Russian to head the company. He became involved in conflicts with local suppliers, which he accused of supplying low-quality products.\n\nThe takeover of AvtoVAZ was completed in June 2014, and the two companies of the Renault-Nissan Alliance took a combined 67.1% stake of Alliance Rostec, which in turn acquired a 74.5% of AvtoVAZ, thereby giving Renault and Nissan indirect control over the Russian manufacturer.\n\nIn 2014, AvtoVAZ sold 448,114 vehicles, down 16.3 percent comparing to the previous year, due to the overall market slowdown in Russia. The total production of the Togliatti factory is 910,000 vehicles. By 2014 the company's liabilities exceeded assets by 68 billion rubles, leading auditor Ernst & Young to express “significant doubt” about the company's “ability to continue as a going concern”.\nIn 2014, the Largus got a new modification, the Lada Largus Cross. In the fall of 2014 AvtoVAZ began production of a new Kalina model, the Lada Kalina Cross.\n\nProduction of the Lada Vesta, based on a new b\\C platform developed by AvtoVAZ in cooperation with Renault-Nissan Alliance, started on September 25, 2015, at Lada Izhevsk manufacturing site. For the first time in LADA history, one year has passed between concept-car and start of production. Lada XRAY is the first compact city crossover in company’s history. Starts of sales was held on February 14, 2016.\n\nTotal Lada sales in 2015 amounted to 269,096 cars, of which 207,389 were built by AvtoVAZ in Tolyatti, while the rest were made by Lada Izhevsk, giving the company a 17.9% share of the Russian automotive market.\n\nIn March 2016 Nicolas Maure became the company's CEO. In April 2016, Carlos Ghosn, Renault-Nissan Chairman, ceded his AvtoVAZ chairmanship position to Sergey Skvortsov, Deputy General Director of Russian state-owned Rostec, the minority shareholder in Avtovaz.\n\nDespite massive layoffs since 2008, the company continues to be unprofitable as of 2016. In October 2016 Renault invested $1.33 billion in another recapitalization of AvtoVAZ, this time without involvement from Nissan, making the company a subsidiary of the French group. In September 2017 Nissan sold its AvtoVAZ stake to Renault for €45 million. In December 2018, Renault and Rostec completed the acquisition of all AvtoVAZ shares through their Alliance Rostec venture.\n\nAfter its re-establishment as a joint stock company in 1993, the ownership structure of AvtoVAZ became opaque, with two different management groups controlling the majority of the shares, one led by company chairman Kadannikov, holding 33.2% through the AVVA company, while another group held 19.2% through the AFC company. AvtoVAZ, in turn, owned over 80% of AVVA, which was said to be under the influence of Boris Berezovsky.\n\n, AvtoVAZ's owner is Alliance Rostec Auto B.V., which is a joint venture of Renault and Russian company Rostec. Renault owns a controlling 67.61% stake of Alliance Rostec Auto, while Rostec owns a 32.39%. Following a recapitalization of AvtoVAZ in 2016, Renault holds over 50% of the company, making it a subsidiary of the French group.\n\nProduction sites for Lada vehicles in Russia:\n\n\n\nExports of AvtoVAZ vehicles to the West began in 1974; Ladas were sold as in several Western nations during the 1970s and 1980s, including Canada, the United Kingdom, France, Belgium, Luxembourg and the Netherlands, though trade sanctions banned their export to the United States. Under the original agreement with Fiat, the car could not be sold in competition with the 124 until its replacement (the Fiat 131 Mirafiori) had been released and all Fiat production of the 124 had ceased.\n\nEconomic instability in the former Soviet Union in the 1990s, tightening emissions and safety legislation meant that AvtoVAZ withdrew from most Western markets by the late 1997. In later years, Lada is again exported. The Lada is marketed in Russia, Azerbaijan, Armenia, Republic of Belarus, Bolivia, Bulgaria, Republic of Chile, Egypt, Georgia, Germany, Hungary, Kazakhstan, Kyrgyzstan, Latvia, Lithuania, Republic of Lebanon, Republic of Moldova, Republic of Slovakia, Republic of Tajikistan, Republic of Turkmenistan, Republic of Ukraine, Republic of Uzbekistan, Republic of South Ossetia, Serbian Republic, Syrian Arab Republic, Republic of Peru and the Kingdom of Jordan. (Source)\n\nIn 2015, 28,461 Lada cars were exported, mostly to Kazakhstan (14,278 vehicles), Azerbaijan (4,690), Belarus (2,360), Egypt (2,128) and Germany (1,515).\n\nIn 1970, AvtoVAZ CEO Viktor Polyakov set the task to create sport versions of the Lada 2101. The engines were built in Italy, whereas fine tuning was done by engineers in Togliatti. In 1971, three sport cars based on the 2101 model took part in the Soviet Winter Rally Championship. Later in the same year, a VAZ-Autoexport team earned their first prize, the Silver Cup in the 1971 Tour d'Europe.\n\nIn the 1970s–1980s, the Autoexport racing team, using different Lada models, participated in different motorsport competitions. A special Zhiguli class was created for the Soviet Rally Championship. There were different rally and track races featuring Avtovaz sports cars. In 1978, a Lada Niva took part in the famous Dakar Rally. It was also successful in a number of international competitions. In 1981, Guy Moerenhout Racing made two special models for Lada Belgium: Lada 21011 RS Sport, model with two Weber carburetors and special sport equipment, and Lada Niva Dream, with big wing extension, special colours and larger wheels. In the late 1990s, Lada Canada supported a rally operation in the Canadian Rally Championship, winning in the 'Production 1750' class on numerous occasions.\n\nIn 2012, the Lada Granta Cup was launched. The first stage of the new race series began in Moscow on the Myachkovo race track.\n\nIn 2008, AvtoVAZ took part in the WTCC World Championship, raced and developed by Russian Bears Motorsport, although badged as a factory team. The team raced the Lada 110 in the 2008 season, but ran a trio of Lada Prioras in the 2009 WTCC. The team scored their first championship points at Imola with renowned BTCC two-time champion James Thompson.\n\nLada withdrew from the WTCC for the 2010 season, but returned in 2012, with TMS Sport entering a Lada Granta WTCC for Thompson in two rounds. The team added a second car for the 2013 season, driven by Alexey Dudukalo, and achieved their best result to date, finishing fifth in their home race in Russia.\n\nIn 2013, AvtoVAZ returned to the WTCC championship. The team received a new car: the Lada Granta WTCC with the new driver, WTCC World Champion Robert Huff.\n\nThe team returned for the 2014 World Touring Car Championship season, again fielding a Granta. Since the beginning of 2015, the Lada team takes part in the WTCC as Lada Sport Rosneft. Starting with the 2015 season, Lada Sport currently uses Lada Vesta.\n\nHC Lada Togliatti, an ice hockey team currently playing in the Kontinental Hockey League, takes its name from the marque. They won two league titles as well as the 1996–97 European Cup.\n\nLada sponsored Aldershot Football Club of the English Football League for two seasons leading up their bankruptcy in 1992. Lada also sponsored Colo Colo (Chile) during their championship season in 1991.\n\nLada sponsored the Renault F1 Team in 2010 after they signed Russia's first Formula One driver Vitaly Petrov.\n\n\n"}
{"id": "18353", "url": "https://en.wikipedia.org/wiki?curid=18353", "title": "Lundy", "text": "Lundy\n\nLundy () is the largest island in the Bristol Channel. It lies off the coast of Devon, England, about a third of the distance across the channel from Devon to South Wales. Lundy gives its name to a British sea area and is one of the islands of England. It has been designated by Natural England as national character area 159, one of England's natural regions.\n\nLundy is included in the district of Torridge with a resident population of 28 people in 2007; these include a warden, a ranger, an island manager, a farmer, bar and house-keeping staff and volunteers. Most live in and around the village at the south of the island. Most visitors are day-trippers, although there are 23 holiday properties and a camp site for over-night visitors, mostly also around the south of the island.\n\nIn a 2005 opinion poll of \"Radio Times\" readers, Lundy was named as Britain's tenth greatest natural wonder. The entire island has been designated as a Site of Special Scientific Interest and it was England's first statutory Marine Nature reserve, and the first Marine Conservation Zone, because of its unique flora and fauna. It is managed by the Landmark Trust on behalf of the National Trust.\n\nThe name Lundy is believed to come from the old Norse word for \"puffin island\" (compare Lundey), ' being the Old Norse word for a puffin and ', an island, although an alternative explanation has been suggested with Lund referring to a copse, or wooded area. It is known in Welsh as \"Ynys Wair\", \"Gwair's Island\", in reference to an alternative name for the wizard Gwydion.\n\nLundy has evidence of visitation or occupation from the Neolithic period onward, with Mesolithic flintwork, Bronze Age burial mounds, four inscribed gravestones from the early medieval period, and an early medieval monastery (possibly dedicated to St Elen or St Helen).\n\nBeacon Hill Cemetery was excavated by Charles Thomas in 1969. The cemetery contains four inscribed stones, dated to the 5th or 6th century AD. The site was originally enclosed by a curvilinear bank and ditch, which is still visible in the south west corner. However, the other walls were moved when the Old Light was constructed in 1819. Celtic Christian enclosures of this type were common in Western Britain and are known as ' in Welsh and ' in Cornish. There are surviving examples in Luxulyan, in Cornwall; Mathry, Meidrim and Clydau in Wales; and Stowford, Jacobstowe, Lydford and Instow, in Devon.\n\nThomas proposed a five-stage sequence of site usage:\n\n23 cist graves were found during this excavation. Considering that the excavation only uncovered a small area of the cemetery, there may be as many as 100 graves.\n\nFour Celtic inscribed stones have been found in Beacon Hill Cemetery:\n\nLundy was granted to the Knights Templar by Henry II in 1160. The Templars were a major international maritime force at this time, with interests in North Devon, and almost certainly an important port at Bideford or on the River Taw in Barnstaple. This was probably because of the increasing threat posed by the Norse sea raiders; however, it is unclear whether they ever took possession of the island. Ownership was disputed by the Marisco family who may have already been on the island during King Stephen's reign. The Mariscos were fined, and the island was cut off from necessary supplies. Evidence of the Templars' weak hold on the island came when King John, on his accession in 1199, confirmed the earlier grant.\n\nIn 1235 William de Marisco () was implicated in the murder of Henry Clement, a messenger of Henry III. Three years later, an attempt was made to kill Henry III by a man who later confessed to being an agent of the Marisco family. William de Marisco fled to Lundy where he lived as a virtual king. He built a stronghold in the area now known as Bulls' Paradise with thick walls.\n\nIn 1242, Henry III sent troops to the island. They scaled the island's cliff and captured William de Marisco and 16 of his \"subjects\". Henry III built the castle (sometimes referred to as the Marisco Castle) in an attempt to establish the rule of law on the island and its surrounding waters. In 1275 the island is recorded as being in the Lordship of King Edward I but by 1322 it was in the possession of Thomas, 2nd Earl of Lancaster and was among the large number of lands seized by Edward II following Lancaster's execution for rebelling against the King.At some point in the 13th century the monks of the Cistercian order at Cleeve Abbey held the rectory of the island.\n\nOver the next few centuries, the island was hard to govern. Trouble followed as both English and foreign pirates and privateers – including other members of the Marisco family – took control of the island for short periods. Ships were forced to navigate close to Lundy because of the dangerous shingle banks in the fast flowing River Severn and Bristol Channel, with its tidal range of , one of the greatest in the world. This made the island a profitable location from which to prey on passing Bristol-bound merchant ships bringing back valuable goods from overseas.\n\nIn 1627 a group known as the Salé Rovers, from the Republic of Salé occupied Lundy for five years. These Barbary Pirates, under the command of a Dutch renegade named Jan Janszoon, flew an Ottoman flag over the island. Some captured Europeans were held on Lundy before being sent to Algiers to be sold as slaves. From 1628 to 1634 the island was plagued by pirate ships of French, Basque, English and Spanish origin. These incursions were eventually ended by Sir John Penington, but in the 1660s and as late as the 1700s the island still fell prey to French privateers.\n\nIn the English Civil War, Thomas Bushell held Lundy for King Charles I, rebuilding Marisco Castle and garrisoning the island at his own expense. He was a friend of Francis Bacon, a strong supporter of the Royalist cause and an expert on mining and coining. It was the last Royalist territory held between the first and second civil wars. After receiving permission from Charles I, Bushell surrendered the island on 24 February 1647 to Richard Fiennes, representing General Fairfax. In 1656, the island was acquired by Lord Saye and Sele.\n\nThe late 18th and early 19th centuries were years of lawlessness on Lundy, particularly during the ownership of Thomas Benson (1708-1772), a Member of Parliament for Barnstaple in 1747 and Sheriff of Devon, who notoriously used the island for housing convicts whom he was supposed to be deporting. Benson leased Lundy from its owner, John Leveson-Gower, 1st Earl Gower (1694–1754) (who was an heir of the Grenville family of Bideford and of Stowe, Kilkhampton in Cornwall), at a rent of £60 per annum and contracted with the Government to transport a shipload of convicts to Virginia, but diverted the ship to Lundy to use the convicts as his personal slaves. Later Benson was involved in an insurance swindle. He purchased and insured the ship \"Nightingale\" and loaded it with a valuable cargo of pewter and linen. Having cleared the port on the mainland, the ship put into Lundy, where the cargo was removed and stored in a cave built by the convicts, before setting sail again. Some days afterwards, when a homeward-bound vessel was sighted, the \"Nightingale\" was set on fire and scuttled. The crew were taken off the stricken ship by the other ship, which landed them safely at Clovelly.\n\nSir Vere Hunt, 1st Baronet of Curragh, a rather eccentric Irish politician and landowner, and unsuccessful man of business, purchased the island from John Cleveland in 1802 for £5,270 (£ today). Sir Vere Hunt planted in the island a small, self-contained Irish colony with its\nown constitution and divorce laws, coinage and stamps. The tenants came from Sir Vere Hunt's Irish estate and they experienced agricultural difficulties while on the island. This led Sir Vere Hunt to seek someone who would take the island off his hands, failing in his attempt to sell the island to the British Government as a base for troops. After the 1st Baronet's death his son, Sir Aubrey (Hunt) de Vere, 2nd Baronet, also had great difficulty in securing any profit from the property. In the 1820s John Benison agreed to purchase the island for £4,500 but then refused to complete sale as he felt that the 2nd Baronet could not make out a good title in respect of the sale terms, namely that the island was free from tithes and taxes.\n\nWilliam Hudson Heaven purchased Lundy in 1834, as a summer retreat and for the shooting, at a cost of 9,400 guineas (£9,870, or £ today). He claimed it to be a \"free island\", and successfully resisted the jurisdiction of the mainland magistrates. Lundy was in consequence sometimes referred to as \"the kingdom of Heaven\". It belongs in fact to the county of Devon, and has always been part of the hundred of Braunton. Many of the buildings on the island today, including St. Helen's Church, designed by the architect John Norton, and Millcombe House (originally known simply as the Villa), date from the Heaven period. The Georgian-style villa was built in 1836. However, the expense of building the road from the beach (no financial assistance being provided by Trinity House, despite their regular use of the road following the construction of the lighthouses), the villa and the general cost of running the island had a ruinous effect on the family's finances, which had been damaged by reduced profits from their sugar plantations in Jamaica.\n\nIn 1957 a message in a bottle from one of the seamen of was washed ashore between Babbacombe and Peppercombe in Devon. The letter, dated 15 August 1843 read: \"Dear Brother, Please e God i be with y against Michaelmas. Prepare y search Lundy for y Jenny ivories. Adiue William, Odessa\". The bottle and letter are on display at the Portledge Hotel at Fairy Cross, in Devon, England. was a three-masted full-rigged ship reputed to be carrying ivory and gold dust that was wrecked on Lundy on 20 February 1797 at a place thereafter called Jenny's Cove. Some ivory was apparently recovered some years later but the leather bags supposed to contain gold dust were never found.\n\nWilliam Heaven was succeeded by his son the Reverend Hudson Grosset Heaven who, thanks to a legacy from Sarah Langworthy (née Heaven), was able to fulfill his life's ambition of building a stone church on the island. St Helen's was completed in 1896, and stands today as a lasting memorial to the Heaven period. It has been designated by English Heritage a Grade II listed building. He is said to have been able to afford either a church or a new harbour. His choice of the church was not however in the best financial interests of the island. The unavailability of the money for re-establishing the family's financial soundness, coupled with disastrous investment and speculation in the early 20th century, caused severe financial hardship.\nHudson Heaven died in 1916, and was succeeded by his nephew, Walter Charles Hudson Heaven. With the outbreak of the First World War, matters deteriorated seriously, and in 1918 the family sold Lundy to Augustus Langham Christie. In 1924, the Christie family sold the island along with the mail contract and the MV \"Lerina\" to Martin Coles Harman, who proclaimed himself a king. Harman issued two coins of Half Puffin and One Puffin denominations in 1929, nominally equivalent to the British halfpenny and penny, resulting in his prosecution under the United Kingdom's Coinage Act of 1870. The House of Lords found him guilty in 1931, and he was fined £5 with fifteen guineas (£5 + £15.75) expenses. The coins were withdrawn and became collectors' items. In 1965 a \"fantasy\" restrike four-coin set, a few in gold, was issued to commemorate 40 years since Harman purchased the island. Harman's son, John Pennington Harman was awarded a posthumous Victoria Cross during the Battle of Kohima, India in 1944. There is a memorial to him at the VC Quarry on Lundy. Martin Coles Harman died in 1954.\n\nResidents did not pay taxes to the United Kingdom and had to pass through customs when they travelled to and from Lundy Island. Although the island was ruled as a virtual fiefdom, its owner never claimed to be independent of the United Kingdom, in contrast to later territorial \"micronations\". \n\nFollowing the death of Harman's son Albion in 1968, Lundy was put up for sale in 1969. Jack Hayward, a British millionaire, purchased the island for £150,000 (£ today) and gave it to the National Trust, who leased it to the Landmark Trust. The Landmark Trust has managed the island since then, deriving its income from arranging day trips, letting out holiday cottages and from donations. In May 2015 a sculpture by Antony Gormley was erected on Lundy. It is one of five life-sized sculptures, \"Land\", placed near the centre and at four compass points of the UK in a commission by the Landmark Trust, to celebrate its 50th anniversary. The others are at Lowsonford (Warwickshire), Saddell Bay (Scotland), the Martello Tower (Aldeburgh, Suffolk), and Clavell Tower (Kimmeridge Bay, Dorset).\n\nThe island is visited by over 20,000 day-trippers a year, but during September 2007 had to be closed for several weeks owing to an outbreak of Norovirus.\n\nAn inaugural Lundy Island half-marathon took place on 8th July 2018 with 267 competitors.\n\nA naval footnote in the history of Lundy was the wreck of the Royal Navy battleship HMS \"Montagu\". Steaming in heavy fog, she ran hard aground near Shutter Rock on the island's southwest corner at about 2:00 a.m. on 30 May 1906. Thinking they were aground at Hartland Point on the English mainland, a landing party went ashore for help, only finding out where they were after encountering the lighthouse keeper at the island's north light.\n\nStrenuous efforts by the Royal Navy to salvage the badly damaged battleship during the summer of 1906 failed, and in 1907 it was decided to give up and sell her for scrap. \"Montagu\" was scrapped at the scene over the next fifteen years. Diving clubs still visit the site, where armour plate and live 12-inch (305-millimetre) shells remain on the seabed.\n\nDuring the Second World War two German Heinkel He 111 bombers crash landed on the island in 1941. The first was on 3 March, when all the crew survived and were taken prisoner.\n\nThe second was on 1 April when the pilot was killed and the other crew members were taken prisoner. This plane had bombed a British ship and one engine was damaged by anti aircraft fire, forcing it to crash land. A few remains can be found on the crash site. Reportedly to avoid reprisals the crew concocted a story that they were on a reconnaissance mission.\n\nThe island of Lundy is long from north to south by a little over wide, with an area of . The highest point on Lundy is Beacon Hill, above sea level. A few yards off the northeastern coast is Seal's Rock which is so called after the seals which rest on and inhabit the islet. It is less than wide. Near the jetty is a small pocket beach.\n\nThe island is primarily composed of granite of 59.8 ± 0.4 – 58.4 ± 0.4 million years (from the Palaeocene epoch), with slate at the southern end; the plateau soil is mainly loam, with some peat. Among the igneous dykes cutting the granite are a small number composed of a unique orthophyre. This was given the name Lundyite in 1914, although the term – never precisely defined – has since fallen into disuse.\n\nLundy island lies on the borderline where the North Atlantic Ocean and the Bristol Channel meet, so it has quite a mild climate. Lundy has cool, wet winters and mild, wet summers. It is often windy. Fog is a continual experience. The record high temperature is 28.8 °C (83.8 °F) on 2 August 1990, and the record low temperature is -4.5 °C (23.9 °F) recorded just six months later on 7 February 1991.\n\nThe vegetation on the plateau is mainly dry heath, with an area of waved Calluna heath towards the northern end of the island, which is also rich in lichens, such as \"Teloschistes flavicans\" and several species of Cladonia and Parmelia.\n\nOther areas are either a dry heath/acidic grassland mosaic, characterised by heaths and western gorse (\"Ulex gallii\"), or semi-improved acidic grassland in which Yorkshire fog (\"Holcus lanatus\") is abundant. Tussocky (Thrift) (Holcus/Armeria) communities occur mainly on the western side, and some patches of bracken (\"Pteridium aquilinum\") on the eastern side.\n\nThere is one endemic plant species, the Lundy cabbage \"(Coincya wrightii)\", a species of primitive brassica.\n\nBy the 1980s the eastern side of the island had become overgrown by rhododendrons \"(Rhododendron ponticum)\" which had spread from a few specimens planted in the garden of Millcombe House in Victorian times, but in recent years significant efforts have been made to eradicate this non-native plant. \n\nTwo invertebrate taxa are endemic to Lundy, with both feeding on the endemic Lundy cabbage (\"Coincya wrightii\"). These are the Lundy cabbage flea beetle (\"Psylliodes luridipennis\"), a species of leaf beetle (family Chrysomelidae) and the Lundy cabbage weevil (\"Ceutorhynchus contractus\" var. \"pallipes\"), a variety of true weevil (family Curculionidae). In addition, the Lundy cabbage is the main host of a flightless form of \"Psylliodes napi\" (another species of flea beetle) and a wide variety of other invertebrate species which are not endemic to the island. Another resident invertebrate of note is \"Atypus affinis\", the only British species of purseweb spider.\n\nThe number of puffins (\"Fratercula arctica\"), which may have given the island its name, declined in the late 20th and early 21st centuries, with the 2005 breeding population estimated to be only two or three pairs, as a consequence of depredations by brown and black rats (\"Rattus rattus\") (which have now been eliminated) and possibly also as a result of commercial fishing for sand eels, the puffins' principal prey. Since 2005, the breeding numbers have been slowly increasing. Adults were seen taking fish into four burrows in 2007, and six burrows in 2008.\nAs an isolated island on major migration routes, Lundy has a rich bird life and is a popular site for birdwatching. Large numbers of black-legged kittiwake (\"Rissa tridactyla\") nest on the cliffs, as do razorbill (\"Alca torda\"), guillemot (\"Uria aalge\"), herring gull (\"Larus argentatus\"), lesser black-backed gull (\"Larus fuscus\"), fulmar (\"Fulmarus glacialis\"), shag (\"Phalacrocorax aristotelis\"), oystercatcher (\"Haematopus ostralegus\"), skylark (\"Alauda arvensis\"), meadow pipit (\"Anthus pratensis\"), common blackbird (\"Turdus merula\"), robin (\"Erithacus rubecula\") and linnet (\"Carduelis cannabina\"). There are also smaller populations of peregrine falcon (\"Falco peregrinus\") and raven (\"Corvus corax\").\n\nLundy has attracted many vagrant birds, in particular species from North America. The island's bird list totals 317 species. This has included the following species, each of which represents the sole British record: Ancient murrelet, eastern phoebe and eastern towhee. Records of bimaculated lark, American robin and common yellowthroat were also firsts for Britain (American robin has also occurred two further times on Lundy). Veerys in 1987 and 1997 were Britain's second and fourth records, a Rüppell's warbler in 1979 was Britain's second, an eastern Bonelli's warbler in 2004 was Britain's fourth, and a black-faced bunting in 2001 Britain's third.\n\nOther British Birds rarities that have been sighted (single records unless otherwise indicated) are: Little bittern, glossy ibis, gyrfalcon (3 records), little and Baillon's crakes, collared pratincole, semipalmated (5 records), least (2 records), white-rumped and Baird's (2 records) sandpipers, Wilson's phalarope, laughing gull, bridled tern, Pallas's sandgrouse, great spotted, black-billed and yellow-billed (3 records) cuckoos, European roller, olive-backed pipit, citrine wagtail, Alpine accentor, thrush nightingale, red-flanked bluetail, black-eared (2 records) and desert wheatears, White's, Swainson's (3 records), and grey-cheeked (2 records) thrushes, Sardinian (2 records), Arctic (3 records), Radde's and western Bonelli's warblers, Isabelline and lesser grey shrikes, red-eyed vireo (7 records), two-barred crossbill, yellow-rumped and blackpoll warblers, yellow-breasted (2 records) and black-headed (3 records) buntings, rose-breasted grosbeak (2 records), bobolink and Baltimore oriole (2 records).\n\nLundy is home to an unusual range of mammals, almost all introduced, including a distinct breed of wild pony, the Lundy pony. Until recently, Lundy and the Shiant Isles in the Hebrides were the only two places in the UK where the black rat (\"Rattus rattus\") could be found regularly. It has since been eradicated on the island, in order to protect the nesting seabirds.\n\nOther species which have made the island their home include the grey seal (\"Halichoerus grypus\"), Sika deer (\"Cervus nippon\"), pygmy shrew (\"Sorex minutus\") and feral goats (\"Capra aegagrus hircus\"). Unusually, 20% of the rabbits (\"Leporidae\") on the island are melanistic compared with 4% which is typical in the UK. In mid-2006 the rabbit population was devastated by myxomatosis, leaving only 60 pairs from the previous 15–20,000 individuals.\n\nSoay sheep (\"Ovis aries\") on the island have been shown to vary their behaviours according to nutritional requirements, the distribution of food and the risk of predation.\n\nIn 1971 a proposal was made by the Lundy Field Society to establish a marine reserve, and the survey was led by Dr Keith Hiscock, supported by a team of students from Bangor University. Provision for the establishment of statutory Marine Nature Reserves was included in the Wildlife and Countryside Act 1981, and on 21 November 1986 the Secretary of State for the Environment announced the designation of a statutory reserve at Lundy.\n\nThere is an outstanding variety of marine habitats and wildlife, and a large number of rare and unusual species in the waters around Lundy, including some species of seaweed, branching sponges, sea fans and cup corals.\n\nIn 2003 the first statutory No Take Zone (NTZ) for marine nature conservation in the UK was set up in the waters to the east of Lundy island. In 2008 this was declared as having been successful in several ways including the increasing size and number of lobsters within the reserve, and potential benefits for other marine wildlife. However, the no take zone has received a mixed reaction from local fishermen.\n\nOn 12 January 2010 the island became Britain's first Marine Conservation Zone designated under the Marine and Coastal Access Act 2009, designed to help to preserve important habitats and species.\n\nThere are two ways to get to Lundy, depending on the time of year. In the summer months (April to October) visitors are carried on the Landmark Trust's own vessel, MS \"Oldenburg\", which sails from both Bideford and Ilfracombe. Sailings are usually three days a week, on Tuesdays, Thursdays and Saturdays, with additional sailings on Wednesdays during July and August. The voyage takes on average two hours, depending on ports, tides and weather. The \"Oldenburg\" was first registered in Bremen, Germany in 1958 and has been sailing to Lundy since being bought by the Lundy Company Ltd in 1985.\n\nIn the winter months (November to March) the island is served by a scheduled helicopter service from Hartland Point. The helicopter operates on Mondays and Fridays, with flights between 12 noon and 2 pm. The heliport is a field at the top of Hartland Point, not far from the Beacon.\n\nA grass runway of is available, allowing access to small STOL aircraft skilfully piloted.\n\nProperly equipped and experienced canoeists can kayak to the island from Hartland Point or Lee Bay. This takes 4 to 6 hours depending on wind and tides.\n\nEntrance to Lundy is free for anyone arriving by scheduled transport. Visitors arriving by non-scheduled transport are charged an entrance fee, currently (May 2016) £6.00, and there is an additional charge payable by those using light aircraft. Anyone arriving on Lundy by non-scheduled transport is also charged an additional fee for transporting luggage to the top of the island.\n\nIn 2007, Derek Green, Lundy's general manager, launched an appeal to raise £250,000 to save the mile-long Beach Road, which had been damaged by heavy rain and high seas. The road was built in the first half of the 19th century to provide people and goods with safe access to the top of the island, above the only jetty. The fund-raising was completed on 10 March 2009.\n\nFoundations for a lighthouse on Lundy were laid in 1787, but the first lighthouse (now known as the Old Light) was not built until Trinity House obtained a 999-year lease in 1819. The granite tower, on the summit of Chapel Hill, was designed by Daniel Asher Alexander, and built by Joseph Nelson at a cost of £36,000. Because the site, Beacon Hill, is above sea level, the highest base for a lighthouse in Britain, the light was often obscured by fog. To counter this problem, the Fog Signal Battery was built about 1861.\n\nThe lighthouse had two lights; the lower a fixed white light and the upper a quick flashing white light, showing every 60 seconds. However, this quick revolution gave the impression it was a fixed light with no flashes detectable. This may have contributed to the grounding, at Cefn Sidan, of the \"La Jeune Emma\", bound from Martinique to Cherbourg in 1828. 13 of the 19 on board drowned, including Adeline Coquelin, the 12-year-old niece of Napoleon Bonaparte's divorced wife Joséphine de Beauharnais.\n\nOwing to the ongoing complaints about the difficulty of sighting the light in fog, the lighthouse was abandoned in 1897 when the North and South Lundy lighthouses were built. The Old Light and the associated keepers' houses are kept open by the Landmark Trust.\n\nThe current North Lundy and South Lundy lighthouses were built in 1897 at the extremities of the island to replace the Old Light. Both lighthouses are painted white and are run and maintained by Trinity House.\n\nThe North lighthouse is tall, slightly taller than the south one, and has a focal plane of . It produces a quick white flash every 15 seconds, and was originally lit by a petroleum vapour burner. Oil was lifted up from a small quay using a sled and winch, and then transported using a small railway (again winch-powered). The remains of this can be still seen, but it was abandoned in 1971 and the lighthouse now uses a discharge bulb fed from the island's main supply. The northern light was modernised in 1991 and converted to solar power, since when the light has been mounted on top of the old fog horn building rather than in the tower.\n\nThe South lighthouse has a focal length of and a quick white flash every 5 seconds. It can be seen as a small white dot from Hartland Point, 11 miles to the south east. It was automated and converted to solar power in 1994. The old fresnel lens has been in use since 2001 in Dungeness Lighthouse.\n\nThere is a small power station comprising three Cummins B and C series diesel engines, offering an approximately 150 kVA 3-phase supply to most of the island buildings. Waste heat from the engine jackets is used for a district heating pipe. There are also plans to collect the waste heat from the engine exhaust heat gases to feed into the district heat network to improve the efficiency further. The power is normally switched off between 00:00 and 06:30.\n\nLundy has 23 holiday properties, sleeping between one and 14 people. These include a lighthouse, a castle and a Victorian mansion. Many of the buildings are constructed from the island's granite.\n\nThe island also has a campsite, at the south of the island in the field next to the shop. It has hot and cold running water, with showers and toilets, in an adjacent building.\n\nThe island is popular with rock climbers, having the UK's longest continuous slab climb, \"The Devil's Slide\".\n\nThe island is an unparished area of Torridge district in the county of Devon. It forms part of the ward of Clovelly Bay. It is part of the constituency electing the Member of Parliament for Torridge and West Devon and the South West England constituency for the European Parliament.\n\nIn 2013 the island became a separate Church of England ecclesiastical parish. \n\nOwing to a decline in population and lack of interest in the mail contract, the GPO ended its presence on Lundy at the end of 1927. For the next two years Harman handled the mail to and from the island without charge.\n\nOn 1 November 1929, he decided to offset the expense by issuing two postage stamps (½ puffin in pink and 1 puffin in blue). One puffin is equivalent to one English penny. The printing of Puffin stamps continues to this day and they are available at face value from the Lundy Post Office. One used to have to stick Lundy stamps on the back of the envelope; but Royal Mail now allows their use on the front of the envelope, but placed on the left side, with the right side reserved for the Royal Mail postage stamp or stamps. Lundy stamps are cancelled by a circular Lundy handstamp. The face value of the Lundy Island stamps covers the cost of postage of letters and postcards from the island to the Bideford Post Office on the mainland for onward delivery to their final destination anywhere in the world. The Lundy Post Office gets a bulk rate discount for mailing letters and postcards from Bideford.\n\nLundy stamps are a type of postage stamp known to philatelists as \"local carriage labels\" or \"local stamps\". Issues of increasing value were made over the years, including air mail, featuring a variety of people. Many are now highly sought-after by collectors. The market value of the early issues has risen substantially over the years. For the many thousands of annual visitors Lundy stamps have become part of the collection of the many British Local Posts collectors. The first catalogues of these stamps included Gerald Rosen's 1970 \"Catalogue of British Local Stamps\". Later specialist catalogues include \"Stamps of Lundy Island\" by Stanley Newman, first published in 1984, \"Phillips Modern British Locals CD Catalogue\", published since 2003, and \"Labbe's Specialised Guide to Lundy Island Stamps\", published since 2005 and now in its 11th Edition. Labbe's Guide is considered the gold standard of Lundy catalogues owing to its extensive approach to varieties, errors, specialised items and \"fantasy\" issues.\n\nThere is a comprehensive collection of these stamps in the Chinchen Collection, donated by Barry Chinchen to the British Library Philatelic Collections in 1977 and now held by the British Library. This is also the home of the Landmark Trust Lundy Island Philatelic Archive which includes artwork, texts and essays as well as postmarking devices and issued stamps.\n\nA ship named \"Lundy Island\", 3,095 tons, was captured and sunk on 10 January 1917 by the Seeadler, a windjammer under the German navy, but flying the Norwegian flag.\n\nLundy island is prominently featured in John Bellairs' 1990 juvenile gothic mystery, \"The Secret of the Underground Room\". The plot highlights several geographical and historical points of interest, including the (De) Marisco family.\n\nLundy features in the 1919 novel \"Last of the Grenvilles\" by Frederick Harcourt Kitchin (under his pseudonym, Bennett Copplestone)\n\nLundy is featured as one of the segments in \"The Darkest Hour,\" Series 2 / Episode 4 of BBC Radio 4's \"Wireless Nights\" by Jarvis Cocker.\n\n\n\n"}
{"id": "18356", "url": "https://en.wikipedia.org/wiki?curid=18356", "title": "Lindow Man", "text": "Lindow Man\n\nLindow Man, also known as Lindow II and (in jest) as Pete Marsh, is the preserved bog body of a man discovered in a peat bog at Lindow Moss near Wilmslow in Cheshire, North West England. The human remains were found on 1 August 1984 by commercial peat-cutters. Lindow Man is not the only bog body to have been found in the moss; Lindow Woman was discovered the year before, and other body parts have also been recovered. The find, described as \"one of the most significant archaeological discoveries of the 1980s\", caused a media sensation. It helped invigorate study of British bog bodies, which had previously been neglected in comparison to those found in the rest of Europe.\n\nAt the time of death, Lindow Man was a healthy male in his mid-20s, and he may have been someone of high status, as his body shows little evidence of heavy or rough work. There has been debate over the reason for Lindow Man's death, because the nature of his demise was violent, perhaps ritualistic; after a last meal of charred bread, Lindow Man was strangled, hit on the head, and his throat cut. Dating the body has proven problematic, but it is thought that Lindow Man was deposited into Lindow Moss, face down, some time between 2 BC and 119 AD, in either the Iron Age or Romano-British period. The recovered body has been preserved by freeze-drying and is on permanent display at the British Museum, although it occasionally travels to other venues such as the Manchester Museum.\n\nLindow Moss is a peat bog in Lindow, an area of Wilmslow, Cheshire, which has been used as common land since the medieval period. It formed after the last ice age, one of many such peat bogs in north-east Cheshire and the Mersey basin that formed in hollows caused by melting ice. Investigations have not yet discovered settlement or agricultural activity around the edge of Lindow Moss that would have been contemporary with Lindow Man; however, analysis of pollen in the peat suggests there was some cultivation in the vicinity. Once covering over , the bog has now shrunk to a tenth of its original size. It is a dangerous place; an 18th-century writer recorded people drowning there. For centuries the peat from the bog was used as fuel, and it continued to be extracted until the 1980s, by which time the process had been mechanised. Lindow Moss is a lowland raised mire; this type of peat bog often produces the best preserved bog bodies, allowing more detailed analysis. Lowland raised mires occur mainly in northern England and extend south to the Midlands. Lindow Man is one of 27 bodies to be recovered from such areas.\n\nOn 13 May 1983, two peat workers at Lindow Moss, Andy Mould and Stephen Dooley, noticed an unusual object—about the size of a football—on the elevator taking peat to the shredding machine. They removed the object for closer inspection, joking that it was a dinosaur egg. Once the peat had been removed, their discovery turned out to be a decomposing, incomplete human head with one eye and some hair intact. Forensics identified the skull as belonging to a European woman, probably aged 30–50. Police initially thought the skull was that of Malika Reyn-Bardt, who had disappeared in 1960 and was the subject of an ongoing investigation. While in prison on another charge, her husband, Peter Reyn-Bardt, had boasted that he had killed his wife and buried her in the back garden of their bungalow, which was on the edge of the area of mossland where peat was being dug. The garden was examined but no body was recovered there. When Reyn-Bardt was confronted with the discovery of the skull from Lindow Moss, he confessed to the murder of his wife. It was later radiocarbon dated, revealing it to be nearly 2,000 years old. \"Lindow Woman\", as it became known, dated from around 210 AD. This emerged shortly before Reyn-Bardt went to trial, but he was convicted on the evidence of his confession.\n\nA year later a further discovery was made at Lindow Moss, just south-west of the Lindow Woman. On 1 August 1984, Andy Mould, who had been involved in the discovery of Lindow Woman, took what he thought was a piece of wood off the elevator of the peat-shredding machine. He threw the object at Eddie Slack, his workmate. When it hit the ground, peat fell off the object and revealed it to be a human foot. The police were called and the foot was taken away for examination. Rick Turner, the Cheshire County Archaeologist, was notified of the discovery and succeeded in finding the rest of the body, which later became known as Lindow Man. Some skin had been exposed and had started to decay, so to prevent further deterioration of the body, it was re-covered with peat. The complete excavation of the block containing the remains was performed on 6 August. Until it could be dated, it was moved to the Macclesfield District General Hospital for storage. As the body of Malika Reyn-Bardt had still not been found, it was thought possible the body might be hers, until it was determined to be male, and radiocarbon dated. The owners of the land on which Lindow Man was found donated the body to the British Museum, and on 21 August it was transported to London.\n\nAt the time, the body was dubbed \"Pete Marsh\" (a pun on \"peat marsh\") by Middlesex Hospital radiologists, a name subsequently adopted by local journalists, as was the similar \"Pete Bogg\" (a pun on \"peat bog\"). The find was announced to the press during the second week of investigation. As the best preserved bog body found in Britain, its discovery caused a domestic media sensation and received global coverage. Sparking excitement in the country's archaeological community, who had long expected such a find, it was hailed as one of the most important archaeological discoveries of the 1980s. A \"Q.E.D.\" documentary about Lindow Man broadcast by the BBC in 1985 attracted 10 million viewers.\n\nLindow Man's official name is Lindow II, as there are other finds from the area: Lindow I (Lindow Woman) refers to a human skull, Lindow III to a \"fragmented headless body\", and Lindow IV to the upper thigh of an adult male, possibly that of Lindow Man. After the discovery of Lindow Man, there were no further archaeological excavations at Lindow Moss until 1987. A large piece of skin was found by workmen on the elevator on 6 February 1987. On this occasion, the police left the investigation to the archaeologists. Over 70 pieces were found, constituting Lindow III. Although the bone was not as well preserved as that of Lindow Man, the other tissues survived in better condition. The final discovery was that of Lindow IV on 14 June 1988. Part of a left leg and buttocks were found on the elevator, from a site just west of where Lindow Man was found. Nearly three months later, on 12 September, a right thigh was discovered in the peat on the bucket of a digger. The proximity of the discovery sites, coupled with the fact that the remains were shown to come from an adult male, means that Lindow IV is probably part of Lindow Man.\n\nLindow Man marked the first discovery in Britain of a well-preserved bog body; its condition was comparable to that of Grauballe Man and Tollund Man from Denmark. Before Lindow Man was found, it was estimated that 41 bog bodies had been found in England and Wales and 15 in Scotland. Encouraged by the discovery of Lindow Man, a gazetteer was compiled, which revealed a far higher number of bog bodies: over 85 in England and Wales and over 36 in Scotland. Prior to the discovery of the bodies in Lindow Moss, British bog bodies had been a relatively neglected subject compared to European examples. The interest caused by Lindow Man led to more in-depth research of accounts of discoveries in bogs since the 17th century; by 1995, the numbers had changed to 106 in England and Wales and 34 in Scotland. The remains covered a large time frame.\n\nIn life, Lindow Man would have measured between 5'6\" and 5'8\" (1.68 and 1.73 m) tall and weighed about . It was possible to ascertain that his age at death was around the mid-20s. The body retains a trimmed beard, moustache, and sideburns of brown hair, as well as healthy teeth with no visible cavities, and manicured fingernails, indicating he did little heavy or rough work. Apart from a fox-fur armband, Lindow Man was discovered completely naked. When he died, Lindow Man was suffering from slight osteoarthritis and an infestation of whipworm and maw worm. As a result of decalcification of the bones and pressure from the peat under which Lindow Man was buried, his skull was distorted. While some preserved human remains may contain DNA, peat bogs such as Lindow Moss are generally poor for such a purpose, and it is unlikely that DNA could be recovered from Lindow Man.\n\nLindow Man and Lindow III were found to have elevated levels of copper on their skin. The cause for this was uncertain as there could have been natural causes, although a study by Pyatt \"et al.\" proposed that the bodies may have been painted with a copper-based pigment. To test this, skin samples were taken from places likely to be painted and tested against samples from areas where painting was unlikely. It was found that the copper content of the skin of the torso was higher than the control areas, suggesting that the theory of Pyatt \"et al.\" may have been correct. However, the conclusion was ambiguous as the overall content was above that expected of a male, and variations across the body may have been due to environmental factors. Similarly, green deposits were found in the hair, originally thought to be a copper-based pigment used for decoration, but it was later found to be the result of a reaction between the keratin in the hair and the acid of the peat bog.\n\nDating Lindow Man is problematic as samples from the body and surrounding peat have produced dates spanning a 900-year period. Although the peat encasing Lindow Man has been radiocarbon dated to about 300 BC, Lindow Man himself has a different date. Early tests at different laboratories returned conflicting dates for the body; later tests suggested a date between 2 BC and 119 AD. There has been a tendency to ascribe the body to the Iron Age period rather than Roman due to the interpretation that Lindow Man's death may have been a ritual sacrifice or execution. Explanations for why the peat in which he was found is much older have been sought. Archaeologist P. C. Buckland suggests that as the stratigraphy of the peat appears undisturbed, Lindow Man may have been deposited into a pool that was already some 300 years old. Geographer K. E. Barber has argued against this hypothesis, saying that pools at Lindow Moss would have been too shallow, and suggests that the peat may have been peeled back to allow the burial and then replaced, leaving the stratigraphy apparently undisturbed.\n\nLindow Man's last meal was preserved in his stomach and intestines and was analysed in some detail. It was hoped that investigations into the contents of the stomach would shed light on the contemporary diet, as was the case with Grauballe Man and Tollund Man in the 1950s. The analysis of the contents of the digestive system of bog bodies had become one of the principal endeavours of investigating such remains. Analysis of the grains present revealed his diet to be mostly of cereals. He probably ate slightly charred bread, although the burning may have had ritual significance rather than being an accident. Some mistletoe pollen was also found in the stomach, indicating that Lindow Man died in March or April.\n\nOne of the conclusions of the study was that the people buried in Lindow Moss may have had a less varied diet than their European counterparts. According to Jody Joy, curator of the Iron Age collection at the British Museum, the importance of Lindow Man lies more in how he lived rather than how he died, as the circumstances surrounding his demise may never be fully established.\n\nAs the peat was cleaned off the body in the laboratory, it became clear that Lindow Man had suffered a violent death. The injuries included a V-shaped, cut on top of his head; a possible laceration at the back of the head, ligature marks on the neck where a sinew cord was found, a possible wound on the right side of the neck, a possible stab wound in the upper right chest, a broken neck, and a fractured rib. Xeroradiography revealed that the blow on top of the head (causing the V-shaped cut) was caused by a relatively blunt object; it had fractured the skull and driven fragments into the brain. Swelling along the edges of the wound indicated that Lindow Man had lived after being struck. The blow, possibly from a small axe, would have caused unconsciousness, but Lindow Man could have survived for several hours afterwards. The ligature marks on the neck were caused by tightening the sinew cord found around his neck, possibly a garrotte or necklace.\n\nIt is not possible to confirm whether some injuries took place before or after death, due to the body's state of decay. This is the case for the wound in the upper right chest and the laceration on the back of the skull. The cut on the right of the neck may have been the result of the body becoming bloated, causing the skin to split; however, the straight edges to the wound suggest that it may have been caused by a sharp instrument, such as a knife. The ligature marks on the neck may have occurred after death. In some interpretations of Lindow Man's death, the sinew is a garrotte used to break the man's neck. However, Robert Connolly, a lecturer in physical anthropology, suggests that the sinew may have been ornamental and that ligature marks may have been caused by the body swelling when submerged. The rib fracture may also have occurred after death, perhaps during the discovery of the body, but is included in some narratives of Lindow Man's death. The broken neck would have proven the fatal injury, whether caused by the sinew cord tightening around the neck or by blows to the back of the head. After death, Lindow Man was deposited into Lindow Moss face down.\n\nArchaeologist Don Brothwell considers that many of the older bodies need re-examining with modern techniques, such as those used in the analysis of Lindow Man. The study of bog bodies, including these found in Lindow Moss, has contributed to a wider understanding of well-preserved human remains, helping to develop new methods in analysis and investigation. The use of sophisticated techniques, such as computer tomography (CT) scans, has marked the investigation of the Lindow bodies as particularly important. Such scans allow the reconstruction of the body and internal examination. Of the 27 bodies recovered from lowland raised mires in England and Wales, only those from Lindow Moss and the remains of Worsley Man have survived, together with a shoe from another body. The remains have a date range from the early 1st to the 4th centuries. Investigation into the other bodies relies on contemporary descriptions of the discovery.\n\nThe physical evidence allows a general reconstruction of how Lindow Man was killed, although some details are debated, but it does not explain why he was killed. In North West England, there is little evidence for religious or ritual activity in the Iron Age period. What evidence does survive is usually in the form of artefacts recovered from peat bogs. Late Iron Age burials in the region often took the form of a crouched inhumation, sometimes with personal ornaments. Although dated to the mid-1st century AD, the type of burial of Lindow Man was more common in the pre-historic period. In the latter half of the 20th century, scholars widely believed that bog bodies demonstrating injuries to the neck or head area were examples of ritual sacrifice. Bog bodies were associated with Germanic and Celtic cultures, specifically relating to head worship.\n\nAccording to Brothwell, Lindow Man is one of the most complex examples of \"overkill\" in a bog body, and possibly has ritual meaning as it was \"extravagant\" for a straightforward murder. Archaeologists John Hodgson and Mark Brennand suggest that bog bodies may have been related to religious practice, although there is division in the academic community over this issue. In the case of Lindow Man, scholars debate whether the killing was murder or done as part of ritual. Anne Ross, an expert on Iron Age religion, proposed that the death was an example of human sacrifice and that the \"triple death\" (throat cut, strangled, and hit on the head) was an offering to several different gods. The wide date range for Lindow Man's death (2 BC to 119 AD) means he may have met his demise after the Romans conquered northern England in the 60s AD. As the Romans outlawed human sacrifice, such timing would open up other possibilities. This conclusion was emphasised by historian Ronald Hutton, who challenged the interpretation of sacrificial death. Connolly suggests that as Lindow Man was found naked, he could have been the victim of a violent robbery.\n\nJoy said,\n\"The jury really is still out on these bodies, whether they were aristocrats, priests, criminals, outsiders, whether they went willingly to their deaths or whether they were executed – but Lindow was a very remote place in those days, an unlikely place for an ambush or a murder\".\n\n Environment and situation are the crucial factors that determine how corpses decay. For instance, corpses will decay differently depending on the weather, the way they are buried, and the medium in which they are buried. Peat slows the decay of corpses. It was feared that, once Lindow Man was removed from that environment, which had preserved the body for nearly 2,000 years, the remains would rapidly start to deteriorate, so steps were taken to ensure preservation. After rejecting methods that had been used to maintain the integrity of other bog bodies, such as the \"pit-tanning\" used on Grauballe Man, which took a year and a half, scientists settled on freeze-drying. In preparation, the body was covered in a solution of 15% polyethylene glycol 400 and 85% water to prevent its becoming distorted. The body was then frozen solid and the ice vaporised to ensure Lindow Man did not shrink. Afterwards, Lindow Man was put in a specially constructed display case to control the environment, maintaining the temperature at and the humidity at 55%.\n\nLindow Man is held in the British Museum. Before the remains were transferred there, people from North West England launched an unsuccessful campaign to keep the body in Manchester. The bog body has been on temporary display in other venues: at the Manchester Museum on three occasions, April to , March to , and to ; and at the Great North Museum in Newcastle from August to . The 2008–09 Manchester display, titled \"Lindow Man: A Bog Body Mystery Exhibition at the Manchester Museum\", won the category \"Best Archaeological Innovation\" in the 2010 British Archaeological Awards, run by the Council for British Archaeology.\n\nCritics have complained that, by museum display of the remains, the body of Lindow Man has been objectified rather than treated with the respect due the dead. Emma Restall Orr, a neo-druid, has questioned whether the body should be displayed at all. This is part of a wider discussion about the scientific treatment of human remains and museum researchers and archaeologists using them as information sources.\n\n\n\n\n"}
{"id": "18360", "url": "https://en.wikipedia.org/wiki?curid=18360", "title": "Lombok", "text": "Lombok\n\nLombok is an island in West Nusa Tenggara province, Indonesia. It forms part of the chain of the Lesser Sunda Islands, with the Lombok Strait separating it from Bali to the west and the Alas Strait between it and Sumbawa to the east. It is roughly circular, with a \"tail\" (Sekotong Peninsula) to the southwest, about across and a total area of about . The provincial capital and largest city on the island is Mataram. \n\nLombok is somewhat similar in size and density, and shares some cultural heritage with the neighboring island of Bali to the west. However, it is administratively part of West Nusa Tenggara, along with the larger and more sparsely populated island of Sumbawa to the east. Lombok is surrounded by a number of smaller islands locally called Gili.\n\nThe island is home to some 3.35 million Indonesians as recorded in the decennial 2014 census. \n\nLombok is under the administration of the Governor of the province of West Nusa Tenggara (\"Nusa Tenggara Barat\"). The province is administered from the provincial capital of Mataram in West Lombok.\n\nThe island is administratively divided into four \"kabupaten\" (regencies) and one \"kota\" (city). They are as follows, with their areas and populations at the 2010 Census and according to the latest (January 2014) official estimates:\n\nOther than the \"Babad Lombok\" document which records the 1257 Samalas eruption, little is known about Lombok before the seventeenth century. Before this time it was made up of numerous competing and feuding petty states each of which were presided over by a Sasak 'prince'. This disunity was taken advantage of by the neighbouring Balinese who took control of western Lombok in the early seventeenth century. The Makassarese meanwhile invaded eastern Lombok from their colonies in neighbouring Sumbawa. The Dutch had first visited Lombok in 1674 and the Dutch East India Company concluded its first treaty with the Sasak Princess of Lombok. The Balinese had managed to take over the whole island by 1750, but Balinese infighting resulted in the island being split into four feuding Balinese kingdoms. In 1838, the Mataram kingdom brought its rivals under control.\n\nRelations between the Sasak and Balinese in western Lombok were largely harmonious and intermarriage was common. In the island's east, however, relations were less cordial and the Balinese maintained control from garrisoned forts. While Sasak village government remained in place, the village head became little more than a tax collector for the Balinese. Villagers became a kind of serf and Sasak aristocracy lost much of its power and land holdings.\n\nDuring one of the many Sasak peasant rebellions against the Balinese, Sasak chiefs sent envoys to the Dutch in Bali and invited them to rule Lombok. In June 1894, the governor general of the Dutch East Indies, Van der Wijck, signed a treaty with Sasak rebels in eastern Lombok. He sent a large army to Lombok and the Balinese raja capitulated to Dutch demands. (see Dutch intervention in Lombok) The younger princes however overruled the raja and attacked and routed the Dutch. The Dutch counterattacked overrunning Mataram and the raja surrendered. The entire island was annexed to the Netherlands East Indies in 1895. The Dutch ruled over Lombok's 500,000 people with a force of no more than 250 by cultivating the support of the Balinese and Sasak aristocracy. The Dutch are remembered in Lombok as liberators from Balinese hegemony.\n\nDuring World War II a Japanese invasion force comprising elements of the 2nd Southern Expeditionary Fleet invaded and occupied the Lesser Sunda Islands, including the island of Lombok. They sailed from Soerabaja harbour at 09:00 hrs on 8 March 1942 and proceeded towards Lombok Island. On 9 May 1942 at 17:00 hrs the fleet sailed into port of Ampenan on Lombok Island. The Dutch defenders were soon defeated and the island occupied.\n\nFollowing the cessation of hostilities the Japanese forces occupying Indonesia were withdrawn and Lombok returned temporarily to Dutch control. Following the subsequent Indonesian independence from the Dutch, the Balinese and Sasak aristocracy continued to dominate Lombok. In 1958, the island was incorporated into the province of West Nusa Tenggara with Mataram becoming the provincial capital. Mass killings of communists occurred across the island following the abortive coup attempt in Jakarta and Central Java. During President Suharto's New Order administration (1967–1998), Lombok experienced a degree of stability and development but not to the extent of the boom and wealth in Java and Bali. Crop failures led to famine in 1966 and food shortages in 1973. The national government's \"transmigrasi\" program moved a lot of people out of Lombok. The 1980s saw external developers and speculators instigate a nascent tourism boom although local's share of earnings was limited. Indonesia's political and economic crises of the late 1990s hit Lombok hard. In January 2000, riots broke out across Mataram with Christians and ethnic Chinese the main victims, with alleged \"agents provocateur\" from outside Lombok. Tourism slumped, but in recent years has seen a renewed growth.\nThe July 2018 Lombok earthquake killed 20 people and injured hundreds more, the earthquake caused significant damage to Lombok island and was the foreshock of a larger earthquake that followed eight days later. The 5 August 2018 Lombok earthquake had a moment magnitude of 7.0, and it caused catastrophic damage to North Lombok and also caused damage to nearby Bali; it caused over 550 deaths and more than 7000 are injured. Another 19 August 2018 Lombok earthquake that occur, killing 13 people and damaging 1800 buildings.\n\nThe island is to the immediate east of the Lombok Strait which marks the biogeographical division between the fauna of the Indomalayan ecozone and the distinctly different fauna of Australasia; this distinction, known as the \"Wallace Line\" (or \"Wallace's Line\") takes its name from Alfred Russel Wallace (1823–1913). Wallace was the first person to comment on the division between the two regions, as well as on the abrupt boundary between the two biomes.\n\nTo the east of Lombok lies the Alas Strait, a narrow body of water separating the island of Lombok from the nearby island of Sumbawa.\n\nThe island's topography is dominated by the centrally-located stratovolcano Mount Rinjani, the second-highest volcano in Indonesia, which rises to , making Lombok the 8th-highest island. The most recent eruption of Rinjani occurred in September 2016 at Gunung Barujari. In a 2010 eruption, ash was reported as rising into the atmosphere from the Barujari cone in Rinjani's caldera lake of Segara Anak. Lava flowed into the caldera lake, raising its temperature, while ash fall damaged crops on the slopes of Rinjani. The volcano and its crater lake, Segara Anak (child of the sea), are protected by the Gunung Rinjani National Park established in 1997. Recent evidence indicates an ancient volcano, Mount Samalas, of which now only a caldera remains, was the source of the 1257 Samalas eruption, one of the largest volcanic eruptions in recorded history, which caused worldwide changes in weather.\n\nThe highlands of Lombok are forest-clad and mostly undeveloped. The lowlands are highly cultivated. Rice, soybeans, coffee, tobacco, cotton, cinnamon, cacao, cloves, cassava, corn, coconuts, copra, bananas and vanilla are the major crops grown in the fertile soils of the island. The southern part of the island is fertile but drier, especially toward the southern coastline.\n\nLombok is surrounded by many islets, including:\n\nThe water supply in Lombok is stressed and this places strain both upon the water supply of the provincial capital, Mataram, and upon that of the island in general. The southern and central areas are reported to be the most critically affected. West Nusa Tenggara province in general is threatened with a water crisis caused by increasing forest and water table damage and degradation. 160 thousand hectares of a total of 1960 thousand hectares are thought to have been affected. The Head of Built Environment and Security Forest Service Forest West Nusa Tenggara Andi Pramari stated in Mataram on Wednesday, May 6, 2009 that, \"If this situation is not addressed it can be expected that within five years it may be difficult for people to obtain water in this part of NTB (West Nusa Tenggara). Not only that, the productivity of agriculture in value added will fall, and the residents are experiencing water deficiency in their wells\". High cases of timber theft in the region of NTB are contributing to this problem.\n\nIn September 2010 in Central Lombok, some villagers reportedly walked for several hours to fetch a single pail of water. Nieleando, a small coastal village about 50 kilometers from the provincial capital, Mataram, has seen dry wells for years. It has been reported that occasionally the problem escalates sufficiently for disputes and fighting between villagers to occur. The problems have been reported to be most pronounced in the districts of Jonggat, Janapria, Praya Timur, Praya Barat, Praya Barat Daya and Pujut. In 2010 provincial authorities declared all six districts drought areas. Sumbawa, the other main island of the province, also experienced severe drought in 2010, making it a province-wide issue.\n\nAreas in southern Lombok Island were classified as arid and prone to water shortages due to low rainfall and lack of water sources. On May 2011, groundbreaking began on Pandanduri dam construction, which will span about 430 hectares and cost an estimated Rp.800 billion ($92.8 million). When finished, the dam will accommodate about 25.7 million cubic meters of water and be able to irrigate 10,350 hectares of farmland. Project construction was expected to last five years.\n\nThe island's inhabitants are 85% Sasak, whose origins are thought to have migrated from Java in the first millennium BC. Other residents include an estimated 10–15% Balinese, with the small remainder being Tionghoa-peranakan, Javanese, Sumbawa and Arab Indonesians.\n\nThe Sasak population are culturally and linguistically closely related to the Balinese, but unlike the Hindu Balinese, the majority are Muslim and the landscape is punctuated with mosques and minarets. Islamic traditions and holidays influence the Island's daily activities.\n\nIn 2008 the Island of Lombok had 866,838 households and an average of 3.635 persons per household.\n\nThe 2014 census recorded a population of 4,773,795 people in the province of NTB, of which 70.24% reside on Lombok, giving it a population of 3,352,988 at that date.\n\nThe island's indigenous Sasak people are predominantly Muslim however before the arrival of Islam Lombok experienced a long period of Hindu and Buddhist influence that reached the island through Java. A minority Balinese Hindu culture remains in Lombok. Islam may have first been brought to Lombok by traders arriving from Sumbawa in the 17th century who then established a following in eastern Lombok. Other accounts describe the first influences arriving in the first half of the sixteenth century. The palm leaf manuscript Babad Lombok which contains the history of Lombok describes how Sunan Prapen was sent by his father The Susuhunan Ratu of Giri on a military expedition to Lombok and Sumbawa in order to convert the population and propagate the new religion. However, the new religion took on a highly syncretistic character, frequently mixing animist and Hindu-Buddhist beliefs and practices with Islam.\n\nA more orthodox version of Islam increased in popularity in the early twentieth century. The Indonesian government religionization programs (acquiring of a religion) in Lombok during 1967 and 1968 led to a period of some considerable confusion in religious allegiances and practices. These religionization programs later led to the emergence of more conformity in religious practices in Lombok. The Hindu minority religion is still practised in Lombok alongside the majority Muslim religion.\n\nHinduism is followed by ethnic Balinese and by a minority of the indigenous Sasak. All the main Hindu religious ceremonies are celebrated in Lombok and there are many villages throughout Lombok that have a Hindu majority population. According to local legends two of the oldest villages on the island, Bayan, and Sembalun, were founded by a prince of Majapahit. According to the 2010 population census declared adherents of Hinduism numbered 101,000 people with the highest concentration in the Mataram Regency where they accounted for 14% of the population. The Ditjen Bimas Hindu (DBH)/ Hindu Religious Affairs Directorate's own analysis conducted in close association with Hindu communities throughout the country found that the number of Hindus in the population is much higher than counted in the government census. The survey carried out in 2012 found the Hindu population of Lombok to be 445,933. This figure is more in line with the commonly stated view that 10–15% of the Islands population is Hindu.\n\nThe Nagarakertagama, the 14th-century palm leaf poem that was found on Lombok places the island as one of the vassals of the Majapahit empire. This manuscript contained detailed descriptions of the Majapahit Kingdom and also affirmed the importance of Hindu-Buddhism in the Majapahit empire by describing temple, palaces and several ceremonial observances.\n\nChristianity is practised by a small minority including some ethnic Chinese and immigrants from Bali and East Nusa Tenggara. There are Roman Catholic churches and parishes in Ampenan, Mataram, Praya and Tanjung. There is a catholic hospital in Mataram as well. Two Buddhist temples can be visited in and around Tanjung where about 800 Buddhists live.\n\nThe history of a small Arab community in Lombok has history dating back to early settlement by traders from Yemen. The community is still evident mainly in Ampenan, the old Port of Mataram. Due to the siting of a UNHCR refugee centre in Lombok some refugees from middle eastern countries have intermarried with Lombok people.\n\nA non-orthodox Islamic group found only on Lombok are the Wektu Telu (\"Three times\"), who pray three times daily, instead of the five times stipulated in the Quran. Waktu Telu beliefs are entwined with animism, and is influenced not only by Islam, but also Hinduism and pantheistic beliefs. There are also remnants of Boda who maintain Pagan Sasak beliefs and could be representative of an original Sasak culture, undiluted by later Islamic innovations.\n\nMany influences of animist belief prevail within the Sasak people, most of whom believe in the existence of spirits or \"ghosts\". They regard both food and prayer as indispensable whenever they seek to communicate with spirits, including the dead and ritualistic traditional practices endure. Traditional magic is practised to ward off evil and illness and to seek solutions to disputations and antipathy. Magic may be practised by an individual alone but normally a person experienced in such things is sought out to render a service. Normally money or gifts are made to this person and the most powerful practitioners are treated with considerable respect.\n\nMany of the visitors to Lombok and much of the islands goods come across the Lombok Strait by sea or air links from Bali. Only separate the two islands. Lombok is often marketed as \"an unspoiled Bali,\" or \"Bali's sister island.\" With support from the central government, Lombok and Sumbawa are being developed as Indonesia's second destination for international and domestic tourism. Lombok has retained a more natural, uncrowded and undeveloped environment, which attract travelers who come for its relaxed pace and the opportunity to explore the island's unspoiled natural environment. The more contemporary marketing campaigns for Lombok/Sumbawa seek to differentiate from Bali and promote the island of Lombok as a standalone destination. The opening of the Lombok International Airport on 1 October 2011 assisted in this endeavor.\n\nNusa Tenggara Barat and Lombok may be considered economically depressed by First World standards and a large majority of the population live in poverty. Still, the island is fertile, has sufficient rainfall in most areas for agriculture, and possesses a variety of climate zones. Consequently, food in abundant quantity and variety is available inexpensively at local farmer's markets, though locals still suffer from famine due to drought and subsistence farming. A family of 4 can eat rice, vegetables, and fruit for as little as US$0.50. Even though a family's income may be as small as US$1.00 per day from fishing or farming, many families are able to live a contented and productive life on a low income. However, the people of Lombok are coming under increasing pressure from rising food and fuel prices. Access to housing, education and health services remains difficult for many of the island's indigenous population although public education is free throughout the province and elementary schools are tried to be present in even remote areas.\n\nThe percentage of the population living in poverty in urban areas of Nusa Tenggara Barat in 2008 was 29.47% and in 2009 it was 28.84%. For those living in rural areas in 2008 it was 19.73% and in 2009 it reduced marginally to 18.40%. For combined urban and village the figures were 23.81% and in 2009 it fell slightly to 22.78%.\n\nIn Mataram in 2008 the percentage of the population that was unmarried was 40.74%, married 52.01%, divorced 2.51% and widowed 4.75%.\n\nTourism is an important source of income on Lombok. The most developed tourism area of the island is on the west coast of the island and is centered about the township of Senggigi. The immediate surrounds of the township contain the most developed tourism facilities. The west coast coastal tourism strip is spread along a strip following the coastal road north from Mataram and the old airport at Ampenan. The principal tourism area extends to Tanjung in the northwest at the foot of Mount Rinjani and includes the Sire and Medana Peninsulas and the highly popular Gili Islands lying immediately offshore. These three small islands are most commonly accessed by boat from Bangsal near Pemenang, Teluk Nare a little to the south, or from further south at Senggigi and Mangsit beach. Many hotels and resorts offer accommodations ranging from budget to luxurious. Recently direct fast boat services have been running from Bali making a direct connection to the Gili islands. Although rapidly changing in character, the Gili islands still provide both a lay-back backpacker's retreat and a high-class resort destination.\n\nOther tourist destinations include Mount Rinjani, Gili Bidara, Gili Lawang, Narmada Park and Mayura Park and Kuta (distinctly different from Kuta, Bali). Sekotong, in southwest Lombok, is popular for its numerous and diverse scuba diving locations.\n\nThe Kuta area is also famous for its largely deserted, white sand beaches. The Smalltown is rapidly developing since the opening of the International airport in Praya. Increasing amounts of surfers from around the globe come here seeking out perfect surf and the slow and rustic feel of Lombok. South Lombok surfing is considered some of the best in the world. Large polar lows push up through the Indian Ocean directing long range, high period swell from as far south as Heard Island from late March through to September or later. This coincided with the dry season and South-East trade winds that blow like clockwork. Lombok is famous for its diversity of breaks, which includes world-renowned \"Desert Point\" at Banko Banko in the southwest of the island.\n\nThe northern west coast near Tanjung has many new upmarket hotel and villa developments centered about the Sire and Medana peninsular nearby to the Gili islands and a new boating marina at Medana Bay. These new developments complement the already existing five-star resorts and a large golf course already established there.\n\nTourist development started in the mid-1980s when Lombok attracted attention as an 'unspoiled' alternative to Bali. Initially, low budget bungalows proliferated at places like the Gili islands and Kuta, Lombok on the South Coast. These tourist accommodations were largely owned by and operated by local business entrepreneurs. Areas in proximity to the airport, places like Senggigi, experienced rampant land speculation for prime beachfront land by big businesses from outside Lombok.\n\nIn the 1990s the national government in Jakarta began to take an active role in planning for and promoting Lombok's tourism. Private organizations like the Bali Tourism Development Corporation (BTDC) and the Lombok Tourism Development Corporation (LTDC) were formed. LTDC prepared detailed land use plans with maps and areas zoned for tourist facilities. Large hotels provide primary employment for the local population. Ancillary business, ranging from restaurants to art shops have been started by local businessmen. These businesses provide secondary employment for local residents.\n\nThe 1997 Asian Financial Crisis and the fall of Suharto regime in 1998 marked the beginning a decade of setbacks for tourism. Spurred by rapid devaluation of the currency and the transition to true democracy caused all of Indonesia to experience a period of domestic unrest. Many of Indonesian Provinces struggled with elements of the population desiring autonomy or independence from the Republic of Indonesia. At the same time, fanatical Islamic terrorism in Indonesia further aggravated domestic unrest across the archipelago.\n\nIn January 2000, radical Islamic agitators from the newly formed Jemaah Islamiyah provoked religious and ethnic violence in the Ampenan area of Mataram and the southern area of Senggigi. Many foreign expatriates and tourists were temporarily evacuated to Bali. Numerous foreign embassies issued Travel Warnings advising of the potential danger of traveling to Indonesia.\n\nSubsequently, the 2002 Bali bombings, the 2005 Bali bombings and the Progress of the SARS outbreak in Asia all dramatically impacted tourism activities in Lombok. Tourism was slow to return to Lombok, provoked in part by a worldwide reluctance to travel because of global tensions. Only since 2007–2008, when most developed countries lifted their Travel Warnings has tourism recovered to pre-2000 levels.\n\nThe years leading up to 2010 has seen a rapid revival and promotion of tourism recovery in the tourism industry. The number of visitors has far surpassed pre-2000 levels. All signs indicate the long-term trend will see a steady increase in the number of visitor arrivals.\n\nBoth the local government and many residents recognize that tourism and services related to tourism will continue to be a major source of income for the island. The island's natural environment and the customary hospitality of its residents make it an obvious tourist destination.\n\nLombok retains the allure of an undeveloped and natural environment. Tourism visits to this tropical island are increasing again as both international and local tourists are re-discovering the charms of Lombok. With this new interest comes the development of a number of boutique resorts on the island providing quality accommodation, food, and drinks in near proximity to the relatively unspoiled countryside.\n\nThe Indonesian government is actively promoting both Lombok and neighboring Sumbawa as Indonesia's number two tourist destination after Bali. Then–President of Indonesia, Susilo Bambang Yudhoyono, Ministry of Cultural and Tourism and the regional Governor had made public statements supporting the development of Lombok as a tourism destination and setting a goal of 1 million visitors annually by the year 2012 for the combined destination of Lombok and Sumbawa. This has seen infrastructure improvements to the island including road upgrades and the construction of a much delayed new International airport in the islands south. Bali Tourism Development Corporation (BTDC) has been empowered to develop Mandalika Resort Area at southern part of the island, extending from Kuta along 8 kilometers of sandy beach. Despite this, Sumbawa retains a very rustic feel compared to Lombok.\n\nLombok International Airport (\"Bandara Internasional Lombok\") is south west of the small regional city of Praya in South central Lombok. It commenced operations on 1 October 2011. It replaced Selaparang airport near Ampenan. It is the only operational international airport within the province of West Nusa Tenggara (\"Nusa Tenggara Barat\").\n\nSelaparang Airport in Ampenan was closed for operations on the evening of 30 September 2011. It previously provided facilities for domestic services to Java, Bali, and Sumbawa and international services to Singapore to Kuala Lumpur via Surabaya and Jakarta. It was the island's original airport and is situated on Jalan Adi Sucipto on the north western outskirts of Mataram. The terminals and basic airport infrastructure remain intact but it is closed to all civil airline traffic.\n\nLembar Harbor seaport in the southwest has shipping facilities and a ferry for road vehicles and passenger services. In 2013, the gross tonnage is 4.3 million Gross Tonnages or increase by 72 percent from 2012 data means in Lombok and West Nusa Tenggara the economy progress significantly.\nLabuhan Lombok ferry port on the east coast provides a ferry for road vehicles and passenger services to Poto Tano on Sumbawa.\n\nPelni Shipping Line provides a national network of passenger ship services throughout the Indonesian archipelago. Pelni have offices in Ampenan.\n\nFlights from Ngurah Rai International Airport to Lombok International Airport take about 40 minutes. Lombok international airport is located in southwest Lombok, 1.5 hours drive to Senggigi main tourist areas in the west Lombok, 2 hours drive to the jetty of Teluk Nara before you cross to Gili Islands and about 30 minutes drive to Kuta south Lombok.\n\nPublic Ferries depart from Padang Bai (Southeast Bali) and Lembar (Southwest Lombok) every two hours, taking a minimum of 4–5 hours make the crossing in either direction.\n\nFastboat services are available from various departure points on Bali and principally serve the Gili Islands, with some significant onward traffic to the Lombok mainland. Arrival points on Lombok are dependent upon the operator, at either Teluk Nare/Teluk Kodek, Bangsal harbour or the township of Senggigi, all on the northwest coast. Operating standards vary widely.\n\n\n"}
{"id": "18362", "url": "https://en.wikipedia.org/wiki?curid=18362", "title": "Lego", "text": "Lego\n\nLego (; stylised as LEGO) is a line of plastic construction toys that are manufactured by The Lego Group, a privately held company based in Billund, Denmark. The company's flagship product, Lego, consists of colourful interlocking plastic bricks accompanying an array of gears, figurines called minifigures, and various other parts. Lego pieces can be assembled and connected in many ways to construct objects including vehicles, buildings, and working robots. Anything constructed can then be taken apart again, and the pieces used to make other objects.\n\nThe Lego Group began manufacturing the interlocking toy bricks in 1949. Movies, games, competitions, and six Legoland amusement parks have been developed under the brand. As of July 2015, 600 billion Lego parts had been produced.\n\nIn February 2015, Lego replaced Ferrari as Brand Finance's \"world's most powerful brand\".\n\nThe Lego Group began in the workshop of Ole Kirk Christiansen (1891–1958), a carpenter from Billund, Denmark, who began making wooden toys in 1932. In 1934, his company came to be called \"Lego\", derived from the Danish phrase \"leg godt\" , which means \"play well\". In 1947, Lego expanded to begin producing plastic toys. In 1949 Lego began producing, among other new products, an early version of the now familiar interlocking bricks, calling them \"Automatic Binding Bricks\". These bricks were based on the Kiddicraft Self-Locking Bricks, which had been patented in the United Kingdom in 1939 and released in 1947. Lego had received a sample of the Kiddicraft bricks from the supplier of an injection-molding machine that it purchased. The bricks, originally manufactured from cellulose acetate, were a development of the traditional stackable wooden blocks of the time.\n\nThe Lego Group's motto is \"det bedste er ikke for godt\" which means roughly \"only the best is the best\" (more literally \"the best is never too good\"). This motto, which is still used today, was created by Christiansen to encourage his employees never to skimp on quality, a value he believed in strongly. By 1951 plastic toys accounted for half of the Lego company's output, even though the Danish trade magazine \"Legetøjs-Tidende\" (\"Toy-Times\"), visiting the Lego factory in Billund in the early 1950s, felt that plastic would never be able to replace traditional wooden toys. Although a common sentiment, Lego toys seem to have become a significant exception to the dislike of plastic in children's toys, due in part to the high standards set by Ole Kirk.\n\nBy 1954, Christiansen's son, Godtfred, had become the junior managing director of the Lego Group. It was his conversation with an overseas buyer that led to the idea of a toy system. Godtfred saw the immense potential in Lego bricks to become a system for creative play, but the bricks still had some problems from a technical standpoint: their locking ability was limited and they were not versatile. In 1958, the modern brick design was developed; it took five years to find the right material for it, ABS (acrylonitrile butadiene styrene) polymer. The modern Lego brick design was patented on 28 January 1958.\n\nThe Lego Group's Duplo product line was introduced in 1969 and is a range of simple blocks whose lengths measure twice the width, height, and depth of standard Lego blocks and are aimed towards younger children.\n\nIn 1978, Lego produced the first minifigures, which have since become a staple in most sets.\n\nIn May 2011, Space Shuttle Endeavour mission STS-134 brought 13 Lego kits to the International Space Station, where astronauts built models to see how they would react in microgravity, as a part of the Lego Bricks in Space program.\n\nIn May 2013, the largest model ever created was displayed in New York City and was made of over 5 million bricks; a 1:1 scale model of an X-wing fighter. Other records include a tower and a railway.\n\nIn February 2015, Lego replaced Ferrari as the \"world's most powerful brand.\"\n\nLego's popularity is demonstrated by its wide representation and usage in many forms of cultural works, including books, films and art work. It has even been used in the classroom as a teaching tool. In the US, Lego Education North America is a joint venture between Pitsco, Inc. and the educational division of the Lego Group.\n\nIn 1998, Lego bricks were one of the original inductees into the National Toy Hall of Fame at The Strong in Rochester, New York.\n\nLego pieces of all varieties constitute a universal system. Despite variation in the design and the purposes of individual pieces over the years, each piece remains compatible in some way with existing pieces. Lego bricks from 1958 still interlock with those made in the current time, and Lego sets for young children are compatible with those made for teenagers. Six bricks of 2 × 4 studs can be combined in 915,103,765 ways.\n\nEach Lego piece must be manufactured to an exacting degree of precision. When two pieces are engaged they must fit firmly, yet be easily disassembled. The machines that manufacture Lego bricks have tolerances as small as 10 micrometres.\nPrimary concept and development work takes place at the Billund headquarters, where the company employs approximately 120 designers. The company also has smaller design offices in the UK, Spain, Germany, and Japan which are tasked with developing products aimed specifically at these markets. The average development period for a new product is around twelve months, split into three stages. The first stage is to identify market trends and developments, including contact by the designers directly with the market; some are stationed in toy shops close to holidays, while others interview children. The second stage is the design and development of the product based upon the results of the first stage. As of September 2008 the design teams use 3D modelling software to generate CAD drawings from initial design sketches. The designs are then prototyped using an in-house stereolithography machine. These prototypes are presented to the entire project team for comment and for testing by parents and children during the \"validation\" process. Designs may then be altered in accordance with the results from the focus groups. Virtual models of completed Lego products are built concurrently with the writing of the user instructions. Completed CAD models are also used in the wider organisation, for marketing and packaging.\n\nLego Digital Designer is an official piece of Lego software for Mac OS X and Windows which allows users to create their own digital Lego designs. The program once allowed customers to order their custom designs with a service to ship physical models from Digital Designer to consumers; the service ended in 2012.\n\nSince 1963, Lego pieces have been manufactured from a strong, resilient plastic known as acrylonitrile butadiene styrene (ABS). As of September 2008, Lego engineers use the NX CAD/CAM/CAE PLM software suite to model the elements. The software allows the parts to be optimised by way of mould flow and stress analysis. Prototype moulds are sometimes built before the design is committed to mass production. The ABS plastic is heated to until it reaches a dough-like consistency. It is then injected into the moulds at pressures between 25 and 150 tonnes, and takes approximately 15 seconds to cool. The moulds are permitted a tolerance of up to twenty micrometres, to ensure the bricks remain connected. Human inspectors check the output of the moulds, to eliminate significant variations in colour or thickness. According to the Lego Group, about eighteen bricks out of every million fail to meet the standard required. Lego factories recycle all but about 1 percent of their plastic waste from the manufacturing process. If the plastic cannot be re-used in Lego bricks, it is processed and sold on to industries that can make use of it. Lego has a self-imposed 2030 deadline to find a more eco-friendly alternative to the ABS plastic it currently uses in its bricks.\n\nManufacturing of Lego bricks occurs at several locations around the world. Moulding is done in Billund, Denmark; Nyíregyháza, Hungary; Monterrey, Mexico and most recently in Jiaxing, China. Brick decorations and packaging are done at plants in Denmark, Hungary, Mexico and Kladno in the Czech Republic. The Lego Group estimates that in five decades it has produced 400 billion Lego blocks. Annual production of Lego bricks averages approximately 36 billion, or about 1140 elements per second. According to an article in \"BusinessWeek\" in 2006, Lego could be considered the world's No. 1 tire manufacturer; the factory produces about 306 million small rubber tires a year. The claim was reiterated in 2012.\n\nIn December 2012, the BBC's \"More or Less\" radio program asked the Open University's engineering department to determine \"how many Lego bricks, stacked one on top of the other, it would take for the weight to destroy the bottom brick?\" Using a hydraulic testing machine, the engineering department determined the average maximum force a 2×2 Lego brick can stand is 4,240 newtons; since an average 2×2 Lego brick has a mass of , according to their calculations it would take a stack of 375,000 bricks to cause the bottom brick to collapse, which represents a stack in height.\n\nPrivate tests have shown several thousand assembly-disassembly cycles before the bricks begin to wear out, although Lego tests show fewer cycles.\n\nIn 2018, Lego announced that it will be using bio-derived polyethylene to make its botanical elements (parts such as leaves, bushes and trees).\n\nSince the 1950s, the Lego Group has released thousands of sets with a variety of themes, including space, robots, pirates, trains, Vikings, castle, dinosaurs, undersea exploration, and wild west. Some of the classic themes that continue to the present day include Lego City (a line of sets depicting city life introduced in 1973) and Lego Technic (a line aimed at emulating complex machinery, introduced in 1977).\n\nOver the years, Lego has licensed themes from numerous cartoon and film franchises and even some from video games. These include \"Batman\", \"Indiana Jones\", \"Pirates of the Caribbean\", \"Harry Potter\", \"Star Wars\", and \"Minecraft\". Although some of the licensed themes, Lego Star Wars and Lego Indiana Jones, had highly successful sales, Lego has expressed a desire to rely more upon their own characters and classic themes, and less upon licensed themes related to movie releases.\n\nFor the 2012 Summer Olympics in London Lego released a special Lego Minifigures serie and for the 2016 Summer Olympics and 2016 Summer Paralympics in Rio, Lego released a kit with the Olympic and Paralympic mascots Vinicius and Tom.\n\nOne of the largest Lego sets commercially produced was a minifig-scaled edition of the Star Wars Millennium Falcon. Designed by Jens Kronvold Fredericksen, it was released in 2007 and contained 5,195 pieces. It was surpassed by a 5,922-piece Taj Mahal. A redesigned Millenium Falcon recently retook the top spot in 2017 with 7,541 pieces.\n\nLego also initiated a robotics line of toys called 'Mindstorms' in 1999, and has continued to expand and update this range ever since. The roots of the product originate from a programmable brick developed at the MIT Media Lab, and the name is taken from a paper by Seymour Papert, a computer scientist and educator who developed the educational theory of constructionism, and whose research was at times funded by the Lego Group.\n\nThe programmable Lego brick which is at the heart of these robotics sets has undergone several updates and redesigns, with the latest being called the 'EV3' brick, being sold under the name of Lego Mindstorms EV3. The set includes sensors that detect touch, light, sound and ultrasonic waves, with several others being sold separately, including an RFID reader.\n\nThe intelligent brick can be programmed using official software available for Windows and Mac computers, and is downloaded onto the brick via Bluetooth or a USB cable. There are also several unofficial programs and compatible programming languages that have been made to work with the brick, and many books have been written to support this community.\n\nThere are several robotics competitions which use the Lego robotics sets. The earliest is Botball, a national U.S. middle- and high-school competition stemming from the MIT 6.270 Lego robotics tournament. Other Lego robotics competitions include Junior FIRST LEGO League (Jr.FLL) for students ages 6–9 and FIRST Lego League (FLL) for students ages 9–16 (age 9–14 in the United States, Canada, and Mexico). Jr.FLL and FLL offer real-world engineering challenges to participants. FLL uses Lego-based robots to complete tasks. Jr.FLL participants build models out of Lego elements. In its 2010 season, there were 16,070 FLL teams in over 55 countries. In its 2010 season, there were 2,147 Jr.FLL teams with 12,882 total student participants in the United States and Canada. The international RoboCup Junior football competition involves extensive use of Lego Mindstorms equipment which is often pushed to its extreme limits.\n\nThe capabilities of the Mindstorms range have now been harnessed for use in Iko Creative Prosthetic System, a prosthetic limbs system designed for children. Designs for these Lego prosthetics allow everything from mechanical diggers to laser-firing spaceships to be screwed on to the end of a child's limb. Iko is the work of the Chicago-based Colombian designer Carlos Arturo Torres, and is a modular system that allows children to customise their own prosthetics with the ease of clicking together plastic bricks. Designed with Lego's Future Lab, the Danish toy company's experimental research department, and Cirec, a Colombian foundation for physical rehabilitation, the modular prosthetic incorporates myoelectric sensors that register the activity of the muscle in the stump and send a signal to control movement in the attachment. A processing unit in the body of the prosthetic contains an engine compatible with Lego Mindstorms, the company's robotics line, which lets the wearer build an extensive range of customised, programmable limbs.\n\nThe definitive shape of the Lego bricks, with the inner tubes, was patented by the Lego Group in 1958. Several competitors have attempted to take advantage of Lego's popularity by producing blocks of similar dimensions, and advertising them as being compatible with Lego bricks. In 2002, Lego sued the CoCo Toy Company in Beijing for copyright infringement over its \"Coko bricks\" product. CoCo was ordered to cease manufacture of the products, publish a formal apology and pay damages. Lego sued the English company Best-Lock Construction Toys in German courts in 2004 and 2009; the Federal Patent Court of Germany denied Lego trademark protection for the shape of its bricks for the latter case. In 2005, the Lego Company sued Canadian company Mega Bloks for trademark violation, but the Supreme Court of Canada upheld Mega Bloks' rights to sell their product. In 2010, the European Court of Justice ruled that the eight-peg design of the original Lego brick \"merely performs a technical function [and] cannot be registered as a trademark.\"\n\nFirst launched in 1996, the Lego website has developed over the years, and provides many extra services beyond an online store and a product catalogue. There are also moderated message boards that were founded in 2001. The site also includes instruction booklets for all Lego sets dating back to 2002.\n\n\"My Lego Network\" is a social networking site that involves items, blueprints, ranks, badges which are earned for completing certain tasks, trading and trophies called masterpieces which allow users to progress to go to the next rank. The website has a built in inbox which allows users to send pre written messages to one another. The Lego Network includes automated non-player characters within called \"Networkers\", who are able to do things which normal users cannot do, sending custom messages, and selling masterpieces and blueprints. The site also has modules which are set up on the user's page that give the user items, or that display picture compositions. Before My Lego Network, there were Lego Club Pages, which essentially held the same purpose, although the design lacked complex interaction.\n\nMerlin Entertainments operates seven Legoland amusement parks, the original in Billund, Denmark, the second in Windsor, England, the third in Günzburg, Germany, the fourth in Carlsbad, California, the fifth in Winter Haven, Florida, the sixth in Nusajaya, Malaysia, the seventh in Dubai, United Arab Emirates, and the eighth in Shanghai, China. On 13 July 2005, the control of 70% of the Legoland parks was sold for $460 million to the Blackstone Group of New York while the remaining 30% is still held by Lego Group. There are also eight Legoland Discovery Centres, two in Germany, four in the United States, one in Japan and one in the United Kingdom. Two Legoland Discovery Centres opened in 2013: one at the Westchester Ridge Hill shopping complex in Yonkers, New York, and one at the Vaughan Mills in Vaughan, Ontario, Canada. Another has opened at the Meadowlands complex in East Rutherford, New Jersey, in 2014.\n\nLego operates 132 so-called \"Lego Store\" retail shops. There are stores at the Downtown Disney shopping complexes at Disneyland and Walt Disney World Resorts as well as in Mall of America in Bloomington, Minnesota. The opening of each store is celebrated with weekend-long event in which a Master Model Builder creates, with the help of volunteers—most of whom are children—a larger-than-life Lego statue, which is then displayed at the new store for several weeks.\n\nSince around 2000, the Lego Group has been promoting \"Lego Serious Play\", a form of business consultancy fostering creative thinking, in which team members build metaphors of their organizational identities and experiences using Lego bricks. Participants work through imaginary scenarios using visual three-dimensional Lego constructions, imaginatively exploring possibilities in a serious form of play.\n\nLego branched out into the video game market in 1997 by founding Lego Media International Limited, and \"Lego Island\" was released that year by Mindscape. After this Lego released titles such as \"Lego Creator\" and \"Lego Racers\".\n\nAfter Lego closed down their publishing subsidiary, they moved on to a partnership with Traveller's Tales, and went on to make games like \"\", \"\", \"\", and many more including the very well-received \"Lego Marvel Super Heroes\" game, featuring New York City as the overworld and including Marvel characters from the Avengers, the Fantastic Four, the X-Men, and more. More recently, Lego has created a game based on \"The Lego Movie\", due to its popularity.\n\nLego Games launched in 2009, was a series of Lego-themed board games designed by Cephas Howard and Reiner Knizia in which the players usually build the playing board out of Lego bricks and then play with Lego-style players. Examples of the games include \"Minotaurus\", in which players roll dice to move characters within a brick-build labyrinth, \"Creationary\", in which players must build something which appears on a card, or \"Ramses Pyramid\", in which players collect gems and climb up a customisable pyramid. Like many board games, the games use dice. In Lego Games, the dice are Lego, with Lego squares with symbols on Lego studs on the dice, surrounded by rubber. The games vary from simple to complex, some are similar to \"traditional\" board games, while others are completely different.\n\nSeveral straight-to-DVD computer animated Bionicle and Hero Factory movies were produced, and \"\" was released on DVD in February 2010, a computer-animated film made by Tinseltown Toons.\n\n\"The Lego Movie\", a feature film based on Lego toys, was released by Warner Bros. in February 2014. It featured Chris Pratt in the lead role, with substantial supporting characters voiced by Will Arnett, Morgan Freeman, Liam Neeson, Alison Brie, Will Ferrell and Nick Offerman. A contest was held for contestants to submit designs for vehicles to be used in the film. After the release of \"The Lego Movie\", independent Canadian toy retailers reported issues with shortages of Lego products and cited cancellations of Lego pre-orders without warning as a motive to stock compatible, rival products.\n\nA spin-off of \"The Lego Movie\", entitled \"The Lego Batman Movie\", directed by Chris McKay was released in the US in February 2017.\n\nIn June 2013, it was reported that Warner Bros. was developing a feature film adaptation of Lego Ninjago. Brothers Dan Hageman and Kevin Hageman were attached to write the adaptation, while Dan Lin and Roy Lee, along with Phil Lord and Chris Miller, were announced as producers. The film, \"The Lego Ninjago Movie\", was released in September 2017. A computer-generated animated series based on \"\" began in 2011, and another based on \"Legends of Chima\" began in 2013. A television series of \"Lego City\" has also been announced.\n\nLego has an ongoing deal with publisher Dorling Kindersley (DK), who are producing a series of illustrated hardback books looking at different aspects of the construction toy. The first was \"The Ultimate Lego Book\", published in 1999. More recently, in 2009, the same publisher produced \"The LEGO Book\", which was sold within a slipcase along with \"Standing Small: A celebration of 30 years of the LEGO minifigure\", a smaller book focused on the minifigure. In 2012, a revised edition was published. Also in 2009, DK also published books on Lego Star Wars and a range of Lego-based sticker books.\n\nAlthough no longer being published in the United States by Scholastic, books covering events in the Bionicle storyline are written by Greg Farshtey. They are still being published in Europe by AMEET. Bionicle comics, also written by Farshtey, are compiled into graphic novels and were released by Papercutz. This series ended in 2009, after nine years.\n\nThere is also the Lego Club and Brickmaster magazine, the latter discontinued in 2011.\n\nSince 1993, LEGOwear Clothes have been produced and marketed by a Danish company called Kabooki under licence from Lego Group. The clothes are for boys and girls from 0 to 12 years old and the partnership also ties in with other Lego products such as 'Ninjago', 'Hero Factory' and the new 'Friends' theme for girls.\n\n\n"}
{"id": "18364", "url": "https://en.wikipedia.org/wiki?curid=18364", "title": "Li people", "text": "Li people\n\nThe Li, Lizu, or Hlai are a Kra–Dai speaking ethnic group, one of the 56 ethnic groups officially recognized by the People's Republic of China. The vast majority live off the southern coast of China on Hainan Island, where they are the largest minority ethnic group. Divided into the five branches of the Qi (Gei), Ha, Run (Zwn), Sai (Tai, Jiamao), and Meifu (Moifau), the Li have their own distinctive culture and customs.\nLi is the Chinese transcription of their native name, which is \"Hlai\". They are sometimes also known as the \"Sai\" or \"Say\". During China's Sui Dynasty, they were known by the name Liliao.\n\nThe Li are believed to be descendants of the Kra-Dai speaking part of the Yue tribes of ancient China, who settled on the island thousands of years ago. DNA analysis carried out amongst the modern Li population indicate a close relationship with populations in the southern Chinese province of Guangxi.\n\nDuring the Japanese occupation of Hainan (1939–1945), the Li suffered particularly heavily due to their communist resistance activities especially in the western Hainan. Li villages were frequently targetted for extermination and rape by Japanese soldiers. In four towns alone, the Japanese slaugtered more than 10,000 Li people. Some minor atrocities include the 17 March 1939 one where Japanese entered ethnic Li Houshi village (后石村) in Sanya and raped and killed more than 80 Li people . The Japanese also killed 2,180 Miao civilians in Baisha and Baoting counties. They are held in high esteem by the Beijing government because they fought on the side of the CPC against Chinese Nationalist rule during the Chinese Civil War. Hainan Li-Miao Autonomous Prefecture was created in 1952 (abolished in 1988).\n\nThe Li speak the Hlai languages, a member of the Kra–Dai language family, but most can understand or speak Hainanese and Standard Chinese. The language spoken natively by the Sai (also known as Tai or Jiamao) subgroup has been noted for its dissimilarity to the dialects or languages spoken by the other subgroups of the Li.\n\nThe Li play a traditional wind instrument called \"kǒuxiāo\" (口箫), and another called \"lìlāluó\" (利拉罗).\n"}
{"id": "18365", "url": "https://en.wikipedia.org/wiki?curid=18365", "title": "Luminance", "text": "Luminance\n\nLuminance is a photometric measure of the luminous intensity per unit area of light travelling in a given direction. It describes the amount of light that passes through, is emitted or reflected from a particular area, and falls within a given solid angle. The SI unit for luminance is candela per square metre (cd/m). A non-SI term for the same unit is the nit. The CGS unit of luminance is the stilb, which is equal to one candela per square centimetre or 10 kcd/m.\n\nLuminance is often used to characterize emission or reflection from flat, diffuse surfaces. The luminance indicates how much luminous power will be detected by an eye looking at the surface from a particular angle of view. Luminance is thus an indicator of how bright the surface will appear. In this case, the solid angle of interest is the solid angle subtended by the eye's pupil. Luminance is used in the video industry to characterize the brightness of displays. A typical computer display emits between 50 and . The sun has a luminance of about at noon.\n\nLuminance is invariant in geometric optics. This means that for an ideal optical system, the luminance at the output is the same as the input luminance. For real, passive, optical systems, the output luminance is \"at most\" equal to the input. As an example, if one uses a lens to form an image that is smaller than the source object, the luminous power is concentrated into a smaller area, meaning that the illuminance is higher at the image. The light at the image plane, however, fills a larger solid angle so the luminance comes out to be the same assuming there is no loss at the lens. The image can never be \"brighter\" than the source.\n\nThe luminance of a specified point of a light source, in a specified direction, is defined by the derivative\n\nwhere\n\nIf light travels through a lossless medium, the luminance does not change along a given light ray. As the ray crosses an arbitrary surface \"S\", the luminance is given by\n\nwhere\n\nMore generally, the luminance along a light ray can be defined as\n\nwhere\n\nThe luminance of a reflecting surface is related to the illuminance it receives:\n\nwhere the integral covers all the directions of emission , and\n\nIn the case of a perfectly diffuse reflector (also called a Lambertian reflector), the luminance is isotropic, per Lambert's cosine law. Then the relationship is simply\n\nA variety of units have been used for luminance, besides the candela per square metre.\n\nOne candela per square metre is equal to:\n\nRetinal damage can occur when the eye is exposed to high luminance. Damage can occur due to local heating of the retina. Photochemical effects can also cause damage, especially at short wavelengths.\n\nA luminance meter is a device used in photometry that can measure the luminance in a particular direction and with a particular solid angle. The simplest devices measure the luminance in a single direction while imaging luminance meters measure luminance in a way similar to the way a digital camera records color images.\n\n\n"}
{"id": "18366", "url": "https://en.wikipedia.org/wiki?curid=18366", "title": "Lycos", "text": "Lycos\n\nLycos, Inc., is a web search engine and web portal established in 1994, spun out of Carnegie Mellon University. Lycos also encompasses a network of email, webhosting, social networking, and entertainment websites. The company is based in Waltham, Massachusetts and currently a subsidiary of Kakao.\n\nThe word \"Lycos\" comes from the Latin word for \"wolf spider\". However its standard American English pronounciation is like \"lie-cose\".\n\nLycos is a university spin-off that began as a research project by Michael Loren Mauldin of Carnegie Mellon University's main Pittsburgh campus in May 1994. Lycos Inc. was formed with approximately US$2 million in venture capital funding from CMGI. Bob Davis became the CEO and first employee of the new company in 1995, and concentrated on building the company into an advertising-supported web portal. Lycos enjoyed several years of growth during the 1990s and became the most visited online destination in the world in 1999, with a global presence in more than 40 countries.\n\nIn April 1996, the company completed the fastest initial public offering from inception to offering in NASDAQ (LCOS) history, ending its first day with a market value of $300 million. It also became the first search engine to go public, before its big rivals Yahoo! and Excite. In 1997, it became one of the first profitable Internet businesses in the world. In 1998, Lycos paid $58 million for Tripod.com in an attempt to \"break into the portal market.\" Over the course of the next few years, Lycos acquired nearly two dozen Internet brands including Gamesville, WhoWhere, Wired News (eventually sold to Wired), HotBot, Quote.com, Angelfire, Matchmaker.com, and RagingBull.com.\n\nLycos started offering e-mail services in October 1997.\n\nLycos Europe was a joint venture between Lycos and the Bertelsmann transnational media corporation, but it has always been a distinct corporate entity. Although Lycos Europe remains the largest of Lycos's overseas ventures, several other Lycos subsidiaries also entered into joint venture agreements including Lycos Canada, Lycos Korea and Lycos Asia.\n\nLycos was one of the most popular websites on the internet, ranking 8th in 1997, and peaking at 4th in both 1999 and 2001.\nNear the peak of the dot-com bubble on May 16, 2000, Lycos announced its intent to be acquired by Terra Networks, the Internet arm of the Spanish telecommunications giant Telefónica, for $12.5 billion. The acquisition price represented a return of nearly 3,000 times the company's initial venture capital investment and about 20 times its initial public offering valuation. The transaction closed in October 2000 and the merged company was renamed Terra Lycos, although the Lycos brand continued to be used in the United States. Overseas, the company continued to be known as Terra Networks.\n\nSet back by the dot-com bubble burst, in late 2001 Lycos abandoned its own search crawler and started using FAST.\n\nOn August 2, 2004, Terra announced that it was selling Lycos to Seoul, South Korea-based Daum Communications Corporation, now Kakao, for $95.4 million in cash, less than 2% of Terra's initial multibillion-dollar investment. In October 2004, the transaction closed for sale of half of the business and the company name was changed back to Lycos Inc. The remaining Terra half was reacquired by Telefónica.\n\nUnder new ownership, Lycos began to refocus its strategy. In 2005, the company moved away from a search-centric portal and toward a community destination for broadband entertainment content. With a new management team in place, Lycos also began divesting properties that were not core to its new strategy. In July 2006, Wired News, which had been part of Lycos since the purchase of Wired Digital in 1998, was sold to Condé Nast Publications and re-merged with \"Wired Magazine\". The Lycos Finance division, best known for Quote.com and RagingBull.com, was sold to FT Interactive Data Corporation in February 2006, while its online dating site, Matchmaker.com, was sold to Date.com. In 2006, Lycos regained ownership of the Lycos trademark from Carnegie Mellon University.\n\nDuring 2006, Lycos introduced several media services, including Lycos Phone which combined video chat, real-time video on demand, and an MP3 player. In November 2006, Lycos began to roll out applications centered on social media, including its video application, Lycos Cinema, that featured simultaneous watch and chat functionality. In February 2007, Lycos MIX was launched, allowing users to pull video clips from YouTube, Google Video, Yahoo! Video and MySpace Video. Lycos MIX also allowed users to create playlists where other users could add video comments and chat in real-time.\n\nAs part of a corporate restructuring to focus on mobile, social networks and location-based services, Daum sold Lycos for $36 million in August 2010 to Ybrant Digital, an Internet marketing company based in Hyderabad, India. Ybrant Digital paid $20 million at signing and there has been a legal dispute over magnitude of the second installment between Ybrant and Daum. In 2018, a New York court ruled in favor of Daum and appointed Daum (by then merged with Kakao) as receiver of Ybrant's 56% ownership interest in Lycos.\n\nIn May 2012, Lycos announced the appointment of former employee Rob Balazy as CEO of Media division of Lycos.\n\nIn September 2014, Ed Noel was appointed in place of Rob and manages the operations under the title of General Manager of Lycos Media.\n\nIn June 2015, Lycos announced a pear of wearable devices, called Band and Ring.\n\n\n\n\n"}
{"id": "18367", "url": "https://en.wikipedia.org/wiki?curid=18367", "title": "Luton Town F.C.", "text": "Luton Town F.C.\n\nLuton Town Football Club () is a professional association football club based in the town of Luton, Bedfordshire, England, that competes in League One, the third tier of the English football league system. Founded in 1885, it is nicknamed \"the Hatters\" and affiliated to the Bedfordshire County Football Association. The team plays its home matches at Kenilworth Road, where it has been based since 1905. The club's history includes major trophy wins, several financial crises, numerous promotions and relegations, and some spells of sustained success. It was perhaps most prominent between 1982 and 1992, when it was a member of English football's top division, at that time the First Division; the team won its only major honour, the Football League Cup, in 1988.\n\nThe club was the first in southern England to turn professional, making payments to players as early as 1890 and turning fully professional a year later. It joined the Football League before the 1897–98 season, left in 1900 because of financial problems, and rejoined in 1920. Luton reached the First Division in 1955–56 and contested a major final for the first time when playing Nottingham Forest in the 1959 FA Cup Final. The team was then relegated from the top division in 1959–60, and demoted twice more in the following five years, playing in the Fourth Division from the 1965–66 season. However, it was promoted back to the top level by 1974–75.\n\nLuton Town's most recent successful period began in 1981–82, when the club won the Second Division, and thereby gained promotion to the First. Luton defeated Arsenal 3–2 in the 1988 Football League Cup Final and remained in the First Division until relegation at the end of the 1991–92 season. Between 2007 and 2009, financial difficulties caused the club to fall from the second tier of English football to the fifth in successive seasons. The last of these relegations came during the 2008–09 season, when 30 points were docked from Luton's record for various financial irregularities. Luton thereafter spent five seasons in non-League football before winning the Conference Premier in 2013–14, securing promotion back into the Football League.\n\nLuton Town Football Club was formed on 11 April 1885. Before this there were many clubs in the town, the most prominent of which were Luton Wanderers and Luton Excelsior. A Wanderers player, George Deacon, came up with the idea of a \"Town\" club which would include all the best players in Luton. Wanderers secretary Herbert Spratley seized upon Deacon's idea and arranged a secret meeting on 13 January 1885 at the St Matthews school rooms in High Town. The Wanderers committee resolved to rename the club Luton Town—which was not well received by the wider community. The local newspapers referred to the club as \"Luton Town (late Wanderers)\". When George Deacon and John Charles Lomax then arranged a public meeting with the purpose of forming a \"Luton Town Football Club\", Spratley protested, saying there was already a Luton Town club; and the atmosphere was tense when the meeting convened in the town hall on the 11 April 1885. The meeting, attended by most football lovers in the town, heard about Spratley's secret January meeting and voted down his objections. The motion to form a \"Luton Town Football Club\", put forward by G H Small and seconded by E H Lomax, was carried. A club committee was elected by ballot and the team colours were agreed to be pink and dark blue shirts and caps.\n\nInitially based at Excelsior's Dallow Lane ground, Luton Town began making payments to certain individual players in 1890. The following year, Luton became the first club in southern England to be fully professional. The club was a founder member of the Southern Football League in the 1894–95 season and finished as runners-up in its first two seasons. It then left to help form the United League and came second in that league's inaugural season before joining the Football League (then based mostly in northern and central England) for 1897–98, concurrently moving to a new ground at Dunstable Road. The club continued to enter a team to the United League for two more seasons, and won the title in 1897–98. Poor attendance, high wages and the high travel and accommodation costs that resulted from Luton's distance from the northern heartlands of the Football League crippled the club financially, and made it too expensive to compete in that league. A return to the Southern League was therefore arranged for the 1900–01 season.\n\nEight years after arriving at Dunstable Road, Luton moved again, settling at their current ground, Kenilworth Road, in 1905. Captain and left winger Bob Hawkes became Luton's first international player when he was picked to play for England against Ireland on 16 February 1907. A poor 1911–12 season saw Luton relegated to the Southern League's Second Division; the club won promotion back two years later. After the First World War broke out, Luton took part in The London Combination during 1915–16, and afterwards filled each season with friendly matches. A key player of the period was Ernie Simms, a forward. Simms was invalided back to England after being wounded on the Italian front, but recovered enough to regain his place in the Luton team and scored 40 goals during the 1916–17 season.\n\nThe Luton side first played in the white and black colours which it has retained for much of its history during the 1920–21 season, when the club rejoined the Football League; the players had previously worn an assortment of colour combinations, most permanently sky blue shirts with white shorts and navy socks. Such was the quality of Luton's team at this time that despite playing in the third tier, a fixture between Ireland and England at Windsor Park on 22 October 1921 saw three Luton players on the pitch—Louis Bookman and Allan Mathieson for Ireland, and the club's top goalscorer, Simms, for England. However, after Luton finished fourth in the division, the squad was broken up as Simms, Bookman and Mathieson joined South Shields, Port Vale and Exeter City respectively. Luton stayed in the Third Division South until 1936–37, when the team finished top and won promotion to the Second Division, at that time the second tier of English football. During the promotion season, striker Joe Payne scored 55 goals in 39 games; during the previous season he had scored 10 in one match against Bristol Rovers, which remains a Football League record today.\n\nDuring the early 1950s, one of Luton's greatest sides emerged under manager Dally Duncan. The team included Gordon Turner, who went on to become Luton's all-time top goalscorer, Bob Morton, who holds the record for the most club appearances, and Syd Owen, an England international. During this period, Luton sides also featured two England international goalkeepers, Ron Baynham and Bernard Streten, as well as Irish internationals Seamus Dunne, Tom Aherne and George Cummins. This team reached the top flight for the first time in 1955–56, after finishing the season in second place behind Birmingham City on goal average. A few years of success followed, including an FA Cup Final appearance against Nottingham Forest in 1958–59; at the end of the season, Owen was voted FWA Footballer of the Year. However, the club was relegated the following season and, by 1964–65, was playing in the fourth tier.\n\nIn yo-yo club fashion, Luton were to return. A team including Bruce Rioch, John Moore and Graham French won the Fourth Division championship in 1967–68 under the leadership of former player Allan Brown; two years later Malcolm Macdonald's goals helped them to another promotion, while comedian Eric Morecambe became a director of the club. Luton Town won promotion back to the First Division in 1973–74, but were relegated the following season by a solitary point. Former Luton player David Pleat was made manager in 1978, and by 1982–83 the team was back in the top flight. The team which Pleat assembled at Kenilworth Road was notable at the time for the number of black players it included; during an era when many English squads were almost entirely white, Luton often fielded a mostly black team. Talented players such as Ricky Hill, Brian Stein and Emeka Nwajiobi made key contributions to the club's success during this period, causing it to accrue \"a richer history of black stars than any in the country\", in the words of journalist Gavin Willacy.\n\nOn the last day of the 1982–83 season, the club's first back in the top tier, it narrowly escaped relegation: playing Manchester City at Maine Road, Luton needed to win to stay up, while City could escape with a draw. A late winner by Yugoslavian substitute Raddy Antić saved the team and prompted Pleat to dance across the pitch performing a \"jig of joy\", an image that has become iconic. The club achieved its highest ever league position, seventh, under John Moore in 1986–87, and, managed by Ray Harford, won the Football League Cup a year later with a 3–2 win over Arsenal. With ten minutes left on the clock and Arsenal 2–1 ahead, a penalty save from stand-in goalkeeper Andy Dibble sparked a late Luton rally: Danny Wilson equalised, before Brian Stein scored the winner with the last kick of the match. The club reached the League Cup Final once more in 1988–89, but lost 3–1 to Nottingham Forest.\n\nThe club was relegated from the top division at the end of the 1991–92 season, and sank to the third tier four years later. Luton stayed in the third-tier Second Division until relegation at the end of the 2000–01 season. Under the management of Joe Kinnear, who had arrived halfway through the previous season, the team won promotion from the fourth tier at the first attempt. \"Controversial\" owner John Gurney unsettled the club in 2003, terminating Kinnear's contract on his arrival in May; Gurney replaced Kinnear with Mike Newell before leaving Luton as the club entered administration. Newell's team finished as champions of the rebranded third-tier Football League One in 2004–05.\n\nWhile Newell's place was taken first by Kevin Blackwell and later former player Mick Harford, the team was then relegated twice in a row, starting in 2006–07, and spent the latter part of the 2007–08 season in administration, thus incurring a ten-point deduction from that season's total. The club then had a total of 30 points docked from its 2008–09 record by the Football Association and the Football League for financial irregularities dating back several years. These deductions proved to be too large an obstacle to overcome, but Luton came from behind in the final of the Football League Trophy to win the competition for the first time.\n\nRelegation meant that 2009–10 saw Luton playing in the Conference Premier, a competition in which the club had never before participated. The club unsuccessfully contested the promotion play-offs three times in four seasons during their time as a non-League club, employing five different managers. In the 2012–13 FA Cup fourth round, Luton won their away tie against Premier League club Norwich City 1–0 and, in doing so, became the first non-League team to beat a side from England's top division since 1989. In the 2013–14 season, under the management of John Still, Luton won the Conference Premier title with three games to spare, and thereby secured a return to the Football League from 2014–15. Another promotion followed three years later, putting Luton back in League One from the start of the 2018–19 campaign.\n\nThe club's nickname, \"the Hatters\", reflects Luton's historical connection with the hat making trade, which has been prominent there since the 17th century. The nickname was originally a variant on the now rarely seen straw-plaiters. Supporters of the club are also called Hatters.\n\nThe club is associated with two very different colour schemes—white and black (first permanently adopted in 1920), and orange, navy and white (first used in 1973, and worn by the team as of the 2015–16 season). Luton mainly wore a combination of light blue and white before 1920, when white shirts and black shorts were first adopted. These colours were retained for over half a century, with the colour of the socks varying between white and black, until Luton changed to orange, navy and white at the start of the 1973–74 season. Luton began playing in white shirts, shorts and socks in 1979, with the orange and navy motif reduced to trim; navy shorts were adopted in 1984. This palette was retained until the 1999–2000 season, when the team played in orange shirts and blue shorts. From 2000 to 2008, Luton returned to white shirts and black shorts; orange was included as trim until 2007. The white, navy and orange palette favoured in the 1980s was brought back in 2008, following the results of a club poll, but a year later the colours were changed yet again, this time to a predominantly orange strip with white shorts. Navy shorts were readopted in 2011. Luton are wearing orange shirts, navy shorts and white socks during the 2015–16 season.\n\nLuton Town have traditionally used the town's crest as its own in a manner similar to many other teams. The club's first badge was a white eight-pointed star, which was emblazoned across the team's shirts (then a deep cochineal red) in 1892. Four years later a crest comprising the club's initials intertwined was briefly adopted. The shirts were thereafter plain until 1933, when Luton first adopted a badge depicting a straw boater, which appeared on Luton shirts. The letters \"LTFC\" were added in 1935, and this basic design remained until 1947. The club then played without a badge until 1970, when the club began to wear the town crest regularly, having first done so in the 1959 FA Cup Final.\n\nIn 1973, concurrently with the club's switch to the orange kit, a new badge was introduced featuring the new colours. The new emblem depicted a stylised orange football, bearing the letters \"Lt\", surrounded by the club's name in navy blue text. In 1987, the club switched back to a derivative of the town emblem, with the shield portion of the heraldic crest becoming the team's badge; the only similarity with the previous design was the inclusion of the club name around the shield in navy blue. The \"rainbow\" badge, introduced in 1994, featured the town crest below an orange and blue bow which curved around to meet two footballs, positioned on either side of the shield, with the club name underneath. This badge was used until 2005, when a replacement very similar to the 1987 version was adopted, featuring black text rather than blue and a straw boater in place of the outstretched arm depicted in the older design. The club's founding year, 1885, was added in 2008. The badge was altered once more during the 2009–10 pre-season, with the red of the town crest being replaced with orange to better reflect the club colours.\n\nThe first sponsor to appear on a Luton Town shirt was Tricentrol, a local motor company based in Dunstable, who sponsored the club from March 1980 to 1982; the deal was worth £50,000. Subsequent sponsors have been Bedford Trucks (1982 to 1990), Vauxhall (1990 to 1991), Universal Salvage Auctions (1991 to 1999), SKF (1999 to 2003), Travel Extras (2003 to 2005), Electrolux (2005 to 2008), Carbrini Sportswear (2008 to 2009), EasyJet and NICEIC (concurrently, 2009 to 2015), and Barnfield College and NICEIC (concurrently, 2015 to 2016). Since June 2016, the club's kit has been sponsored by NICEIC and SsangYong Motor UK.\n\nThe club released the song \"Hatters, Hatters\", a collaboration between the Luton team and the Bedfordshire-based musical comedy group the Barron Knights, in 1974. Eight years later another song featuring vocals by the Luton players, \"We're Luton Town\", was released to celebrate the club's promotion to the First Division.\n\nLuton Town's first ground was at Dallow Lane, the former ground of Excelsior. The ground was next to the Dunstable to Luton railway line, and players regularly claimed to have trouble seeing the ball because of smoke from the trains. A damaging financial loss during 1896–97 forced Luton to sell the stadium to stay afloat and, as a result, the club moved across the tracks to a stadium between the railway and Dunstable Road. The Dunstable Road ground was opened by Herbrand Russell, 11th Duke of Bedford, who also donated £50 towards the £800 building costs. When the site was sold for housing in 1905, the club was forced to move again at short notice, to its present Kenilworth Road site, in time for the start of the 1905–06 season.\n\nThe 10,356 capacity all-seater stadium is in the Bury Park area of Luton, and named after the road that runs along one end of it, although the official address of the club is 1 Maple Road. Opposite the eponymous Kenilworth Stand is the Oak Road End, which has evolved from a stand first used exclusively by Luton supporters, then later by away supporters, and now used by both except in times of high ticket demand from away clubs. The Main Stand is flanked by the David Preece Stand, and opposite them stands a row of executive boxes. These boxes replaced the Bobbers Stand in 1986, as the club sought to maximise income.\n\nThe original Main Stand burnt down in 1921, and was replaced by the current stand before the 1922–23 season. The ground underwent extensive redevelopment during the 1930s, and the capacity by the start of the Second World War was 30,000. Floodlights were installed before the 1953–54 season, but it was 20 years before any further modernisation was carried out. In 1973 the Bobbers Stand became all-seated, and in 1985 the grass pitch was replaced with an artificial playing surface; it quickly became unpopular and was derided as \"the plastic pitch\".\n\nA serious incident involving hooliganism before, during and after a match against Millwall in 1985 caused the club's then chairman, Conservative MP David Evans, to introduce a scheme effective from the start of 1986–87 banning all visiting supporters from the ground, and requiring home fans to carry identity cards when attending matches. Conversion to an all-seater ground also began in 1986. Away fans returned for 1990–91, and grass a year later. The David Preece Stand was erected in 1991, and the conversion of the Kenilworth Stand to an all-seater was completed in 2005.\n\nThe club first stated its intent to leave Kenilworth Road in 1955. Even then the ground was small compared to rival stadia, and its location made significant redevelopment difficult. The team has since made several attempts to relocate. Leaving Luton for the nearby new town of Milton Keynes was unsuccessfully proposed several times, most notably in the 1980s. The club sold Kenilworth Road to Luton Council in 1989, and has since leased it. A planning application for a new ground, the \"Kohlerdome\" proposed by chairman David Kohler in 1995, was turned down by the Secretary of State in 1998, and Kohler left soon after.\n\nIn 2007, the club's then-owners proposed a controversial plan to relocate to a site near Junction 12 of the M1 motorway, near Harlington and Toddington. A planning application was made on the club's behalf by former chairman Cliff Bassett, but the application was withdrawn almost immediately following the club's takeover in 2008. In 2009, the club began an independent feasibility study to determine a viable location to move to. The club did not rule out redeveloping Kenilworth Road and, in October 2012, entered talks to buy the stadium back from Luton Borough Council. By 2015, these plans had been dropped in favour of a move to a new location, with managing director Gary Sweet confirming that the club was in a position to \"buy land, secure the best possible professional advice ... and to see the [planning] application process through to the receipt of consent.\"\n\nIn April 2016, the club announced its intention to build and move into a 17,500-capacity stadium on the Power Court site in central Luton. Planning permission for this ground, with potential to expand to 23,000 seats, was granted by Luton Borough Council on 16 January 2019..\n\nDuring the 2014–15 season, Luton Town had an average home league attendance of 8,702—the second highest in League Two behind only Portsmouth. In the 2013–14 season, when the club were in the Conference Premier, the club had significantly higher support than the other clubs in its league, with an average home attendance of 7,387; more than twice compared to the second highest of 3,568. Average attendances at Kenilworth Road fell with the installation of seats and the club's reduction in stature, dropping from 13,452 in 1982–83 to their 2014–15 level—a slump of 35% over 32 years. A supporters' trust, Trust in Luton, owns shares in the club and elects a representative to the club's board. The club's official supporters' group, Luton Town Supporters' Club, merged with Trust in Luton in 2014. The club is associated with another supporters' group, the breakaway Loyal Luton Supporters Club. Trust in Luton has, since March 2014, held the legal right to veto any changes to the club's identity, including name, nickname, colours, club crest and mascot.\n\nLuton Town supporters maintain a bitter rivalry with Hertfordshire-based Watford. Watford have remained the higher ranked team at the end of every season since 1997. However, overall Luton still hold the superior record in the fixture between the two clubs; out of 118 competitive matches there have been 53 Luton victories and 36 for Watford, with 29 draws. A survey taken in 2003 showed that there was also animosity between Luton Town fans and those of west London club Queens Park Rangers.\n\nThe club produces an official match programme for home games, \"Talk of the Town\". A character known as Happy Harry, a smiling man wearing a straw boater, serves as the team's mascot and appears on the Kenilworth Road pitch before matches. In December 2014, after the seafront statue of Eric Morecambe in his birthplace Morecambe was restored, Luton and Morecambe F.C. jointly announced that the winners of future Luton–Morecambe fixtures would be awarded the \"Eric Morecambe Trophy\".\n\nThe record for the most appearances for Luton is held by Bob Morton, who turned out for Luton 562 times in all competitions. Morton also holds the record for the most Football League appearances for the club, with 495. Fred Hawkes holds the record for the most league appearances for Luton, having played in 509 league matches. Six players, Gordon Turner, Andy Rennie, Brian Stein, Ernie Simms, Herbert Moody and Steve Howard, have scored more than 100 goals for Luton.\n\nThe first player to be capped while playing for Luton was left winger Robert Hawkes, who took to the field for England against Ireland at Goodison Park on 16 February 1907. The most capped player is Mal Donaghy, who earned 58 Northern Ireland caps while at the club. The first player to score in an international match was Joe Payne, who scored twice in his only game for England against Finland on 20 May 1937. Payne also holds the Football League record for the most goals in a game—he hit 10 past Bristol Rovers on 13 April 1936.\n\nThe club's largest wins have been a 15–0 victory over Great Yarmouth Town on 21 November 1914 in the FA Cup and a 12–0 win over Bristol Rovers in the Third Division South on 13 April 1936. Luton's heaviest loss was a 9–0 defeat against Small Heath in the Second Division on 12 November 1898.\n\nLuton's highest home attendances are 30,069 against Blackpool in the FA Cup on 4 March 1959 and 27,911 against Wolverhampton Wanderers in the First Division on 5 November 1955.\n\nThe highest transfer fee received for a Luton Town player is the £3 million West Bromwich Albion paid for Curtis Davies on 31 August 2005. The most expensive player Luton Town have ever bought was Lars Elstrup, who cost £850,000 from Odense Boldklub on 21 August 1989.\n\nThe youngest player to make a first-team appearance for Luton Town is Connor Tomlinson at 15 years and 199 days old in the EFL Trophy, replacing Zane Banton as a 92nd-minute substitute in a 2–1 win over Gillingham on 30 August 2016, after the club were given permission for him to play from his headteacher.\n\nThe club operates a Development Squad, made up of contracted senior players, youth team scholars and trialists, which plays in the Southern Division of The Central League. The club also fields an under-18 team in the Football League Youth Alliance South East Conference. Luton's youth set-up consists of ten Soccer Centres across Bedfordshire and North Hertfordshire, two Centres of Excellence (one in Luton, one in Dunstable), and an Academy in Baldock that caters for players in the under-9 to under-16 age groups.\n\n\n\nBibliography\n\n"}
{"id": "18369", "url": "https://en.wikipedia.org/wiki?curid=18369", "title": "Lunar calendar", "text": "Lunar calendar\n\nA lunar calendar is a calendar based upon the monthly cycles of the Moon's phases (synodic months), in contrast to solar calendars, whose annual cycles are based only directly upon the solar year. The most commonly used calendar, the Gregorian calendar, is a solar calendar system that originally evolved out of a lunar calendar system. A purely lunar calendar is also distinguished from a lunisolar calendar, whose lunar months are brought into alignment with the solar year through some process of intercalation. The details of when months begin varies from calendar to calendar, with some using new, full, or crescent moons and others employing detailed calculations.\n\nSince each lunation is approximately  days (29 days, 12 hours, 44 minutes, 3 seconds, or days), it is common for the months of a lunar calendar to alternate between 29 and 30 days. Since the period of twelve such lunations, a lunar year, is only 354 days, 8 hours, 48 minutes, 34 seconds ( days), purely lunar calendars lose around 11 days per year relative to the Gregorian calendar. In purely lunar calendars like the Islamic calendar, the lack of intercalation causes the lunar months to cycle through all the seasons of the Gregorian year over the course of a 33 lunar-year cycle.\n\nAlthough the Gregorian calendar is in common and legal use in most countries, traditional lunar and lunisolar calendars continue to be used throughout the Old World to determine religious festivals and national holidays. Examples of such holidays include Ramadan (Islamic calendar); Easter, the Chinese, Japanese, Korean, Vietnamese, and Mongolian New Year (Chinese, Japanese, Korean, Vietnamese, and Mongolian calendars); the Nepali New Year (Nepali calendar); the Mid-Autumn Festival and Chuseok (Chinese and Korean calendars); Loi Krathong (Thai calendar); Sunuwar calendar; Vesak/Buddha's Birthday (Buddhist calendar); Diwali (Hindu calendars); and Rosh Hashanah (Hebrew calendar).\n\nThe earliest known lunar calendar was found at Warren Field in Scotland and has been dated to , during its Mesolithic period. Some scholars argue for lunar calendars still further back—Rappenglück in the marks on a  year-old cave painting at Lascaux and Marshack in the marks on a  year-old bone baton—but their findings remain controversial.\n\nMost calendars referred to as \"lunar\" calendars are in fact lunisolar calendars. Their months are based on observations of the lunar cycle, with intercalation being used to bring them into general agreement with the solar year. The solar \"civic calendar\" that was used in ancient Egypt showed traces of its origin in the earlier lunar calendar, which continued to be used alongside it for religious and agricultural purposes. Present-day lunisolar calendars include the Chinese, Hindu, and Thai calendars.\n\nSynodic months are 29 or 30 days in length, making a lunar year of 12 months about 11 days shorter than a solar year. Some lunar calendars do not use intercalation, such as most Islamic calendars. For those that do, such as the Hebrew calendar, the most common form of intercalation is to add an additional month every second or third year. Some lunisolar calendars are also calibrated by annual natural events which are affected by lunar cycles as well as the solar cycle. An example of this is the lunar calendar of the Banks Islands, which includes three months in which the edible palolo worm mass on the beaches. These events occur at the last quarter of the lunar month, as the reproductive cycle of the palolos is synchronized with the moon.\n\nLunar and lunisolar calendars differ as to which day is the first day of the month. In some lunisolar calendars, such as the Chinese calendar, the first day of a month is the day when an astronomical new moon occurs in a particular time zone. In others, such as some Hindu calendars, each month begins on the day after the full moon or the new moon. Others were based in the past on the first sighting of a lunar crescent, such as the Hebrew calendar and the Hijri calendar.\n\nThe length of each lunar cycle varies slightly from the average value. In addition, observations are subject to uncertainty and weather conditions. Thus to avoid uncertainty about the calendar, there have been attempts to create fixed arithmetical rules to determine the start of each calendar month.\n\nThe average length of the synodic month is days. Thus it is convenient if months generally alternate between 29 and 30 days (sometimes termed respectively “\"hollow\"” and “\"full\"”). The distribution of \"hollow\" and \"full\" months can be determined using continued fractions, and examining successive approximations for the length of the month in terms of fractions of a day. In the list below, after the number of days listed in the numerator, an integer number of months as listed in the denominator have been completed:\n\nThese fractions can be used to construct a lunar calendar, or in combination with a solar calendar to produce a lunisolar calendar. A 49-month cycle was proposed as the basis of an alternative Easter computation by Isaac Newton around 1700. The tabular Islamic calendar's 360-month cycle is equivalent to 24×15 months, minus a correction of one day.\n\n\n\n"}
{"id": "18372", "url": "https://en.wikipedia.org/wiki?curid=18372", "title": "Mount Lykaion", "text": "Mount Lykaion\n\nMount Lykaion (, \"Lýkaion Óros\"; ) is a mountain in Arcadia, Greece. Lykaion has two peaks: \"Stefani\" to the north and St. Ilias (, \"Agios Īlías\") to the south where the altar of Zeus is located.\n\nThe northern peak is higher, 1,421 m, than the southern, 1,382 m (). Mount Lykaion was sacred to Zeus Lykaios, who was said to have been born and brought up on it, and was the home of Pelasgus and his son Lycaon, who were said to have founded the ritual of Zeus practiced on its summit. This seems to have involved a human sacrifice and a feast in which the man who received the portion of a human victim was changed to a wolf, as Lycaon had been after sacrificing a child. The altar of Zeus consists of a great mound of ashes with a retaining wall. It was said that no shadows fell within the precincts and that any who entered it died within the year. The sanctuary of Zeus played host to athletic games held every four years, the \"Lykaia\".\n\nArchaeological excavations were first carried out in 1897 by K. Kontopoulos for the Greek Archaeological Service, followed by K. Kourouniotes between 1902 and 1909.\n\nThe Mt. Lykaion Excavation and Survey Project, a joint effort of the University of Pennsylvania and the University of Arizona began work at the site in 2004, with the aim of continuing the topographical survey begun in 1996 and carrying out a full topographical and architectural analysis not only of the altar and \"temenos\", but of the nearby valley where the Lykaian Games were held. The detailed digital records and drawings of every architectural stone block. To date, a complete map of the area has been made, including not only the Ash Altar and \"temenos\", but also two fountains, including the Hagno fountain mentioned by Pausanias, the hippodrome, the stadium, a building that was probably a bathhouse, the \"xenon\" (hotel), a stoa, several rows of seats, and a group of statue bases.\n\nMany of these buildings seem to have been planned in relation to each other: the baths at the northern end of the hippodrome are on the same alignment as it is, and the stoa, the \"xenon\", the lower fountain, and the rows of seats all appear to have been built in an intentionally similar alignment. Just to the north of the stoa four rows of seats were excavated, with the remains of a group of stelae and statue bases nearby. These would have bordered the hippodrome's southern edge, and correspond to an earlier excavated row of seats on the south-eastern edge of the racetrack. The majority of the spectators of events in the hippodrome, however, would have sat on the surrounding hills.\n\nMt. Lykaion, its religious significance, and its quadrennial athletic games appear with some frequency in the ancient literary sources. The 2nd-century Greek geographer Pausanias provides the greatest amount of information in the eighth book of his \"Description of Greece\", where he discusses Lykaion’s mythological, historical, and physical characteristics in detail. More isolated references occur, however, in sources ranging from Plato to Virgil.\n\nPausanias states that the Arcadians claimed Cretea atop Mt. Lykaion as the birthplace of Zeus, although tradition had handed down at least two other locations for Zeus’ birth.\n\nLycaon, son of Pelasgus, the mythical founder of the Greek race, is said to have instituted the worship of Zeus at Mt. Lykaion, giving the god the epithet Lykaios and establishing games in his honor. The \"Bibliotheca\", a Roman-era mythological compendium, adds the story that Lycaon attempted to test Zeus’ omniscience by tricking him into eating a sacrifice mixed with human flesh. In punishment, Zeus slew Lycaon and his fifty sons. Other sources, including the Roman poet Ovid, claim instead that Lycaon’s punishment was transformation into a wolf, an early example of lycanthropy.\n\nAccording to Pausanias and the Greek historian Polybius, an inscribed pillar (\"stele\") was erected near the altar of Zeus on Mt. Lykaion during the Second Messenian War, a revolt against the Spartans. The inscription supposedly commemorated the execution of Aristocrates of Arcadia, who had betrayed the Messenian hero Aristomenes at the battle of the Great Trench.\n\nThucydides, a Greek historian of the Peloponnesian War, writes that the Spartan king Pleistoanax lived on Mt. Lykaion while in exile from the mid-440s BC until 427, where he built a house straddling the sacred region (\"temenos\") of Zeus to avoid further persecution.\n\nIn his \"Stratagems\", the 2nd-century Macedonian rhetorician Polyaenus describes a battle between the Spartans and Demetrius of Macedon in 294 BC. Mt. Lykaion extended between the camps of the two sides, causing some consternation among the Macedonians due to their unfamiliarity with the terrain. Nevertheless, Demetrius’ forces won the battle with relative ease.\n\nPolybius and Plutarch, a Greek author writing under the Roman empire, cite a battle at Mt. Lykaion in 227 BC between the Achaean League under Aratus and the Spartans under Cleomenes III. Although the details are vague, both authors make it clear that the Achaeans were defeated and that Aratus was killed shortly thereafter.\n\nMt. Lykaion was an important site of religious worship in ancient Greece. Pausanias describes a sanctuary of Pan surrounded by a grove of trees. At the sanctuary were bases of statues, which by Pausanias’ time had been deprived of the statues themselves, as well as a hippodrome, where the athletic games had once been held. References to Lykaian Pan are especially abundant in Latin poetry, as for instance in Virgil’s epic, the \"Aeneid\": “\"Lupercal / Parrhasio dictum Panos de more Lycaei\",” “...the Lupercal, named after the Parrhasian worship of Lykaian Pan,” and in Horace’s Odes: “\"Velox amoenum saepe Lucretilem / mutat Lycaeo Faunus\",” “Often swift Faunus [Pan] exchanges Lykaion for pleasant Lucretilis.”\n\nPausanias records the presence of a mound of earth on the highest point of the mountain, an altar to Zeus Lykaios. He describes two pillars near the altar which had once been topped by golden eagles. Although Pausanias alludes to secret sacrifices which took place on this altar, he explains that he was reluctant to inquire into these rites due to their extreme antiquity. Pausanias also discusses the \"temenos\" of Zeus, a sacred precinct which humans were forbidden to enter. He notes the common belief that any person entering the \"temenos\" would die within a year, along with the legend that all creatures, human and animal alike, cast no shadow while inside the sacred area.\n\nThe athletic competitions at Lykaion, held every four years, receive occasional mention in the literary record. Authors are in disagreement as to when exactly the games were first instituted: Aristotle is said to have ranked the Lykaion games fourth in order of institution after the Eleusinia, the Panathenaia, and the Argive games, while Pausanias argues for the Lykaian competition’s priority to the Panathenaia. Pliny the Elder, an imperial Roman polymath, states that the games at Lykaion were the first to introduce gymnastic competition. The ancient Greek lyric poet Pindar records the victories of several athletes in his \"Victory Odes\", and two inscribed \"stelae\" recently excavated from the Lykaian hippodrome provide information about the events, participants, and winners at the games.\n\nAfter 1832, when Greece had gained independence from the Ottoman Empire, European travelers and scholars began to systematically tour Sparta and the Peloponnese. Ernst Curtius, Charles Beulé, and Guillaume Blouet published scholarly studies of the area, and discussions of the region appeared in German and British travelogues as well. Many of these writers used Pausanias as their guide to the geography and sights of the region, but were also concerned to correlate modern Greek place-names with ancient evidence.\n\nBeulé described the hippodrome and surrounding area, including large stones that he assumed formed had formed the seats of the judges and magistrates, and the remains of a building he called a temple to Pan, but which probably corresponds to the stoa of the modern excavations. The German writer Ross described the bathhouse and its ancient but still-visible cisterns, which site he noted the locals called the Skaphidia.\n\nMt. Lykaion was initially excavated by the Greek Archaeological Service, first in 1897 by archaeologist K. Kontopoulos and again in 1902 by K. Kourouniotes. Kontopoulos dug several trial trenches near the hippodrome and the altar. Kourouniotes’s excavations of the altar and surrounding area (the \"temenos\") were particularly informative; he learned that the altar consisted of a raised mound of blackened earth as described by Pausanias. Excavation of the earth of the altar yielded burnt stones, small animal (cow and pig) bones, tiny pottery fragments, iron knives, clay figures, coins from Aegina, a clay figure of a bird, and two small bronze tripods. Further trenches dug in the \"temenos\" produced several bronze figures, some iron objects, and roof tiles. In 1909 Kourouniotes excavated an area at the east of the mountain and beneath the summit, the site of the hippodrome, stadium, and bathhouse.\n\nSince Kourouniotes’s excavation, anthropologists and scholars of Arcadian religion have studied the site in terms of its development as a sanctuary, but there was no further systematic or scientific investigation until 1996, when Dr. David Gilman Romano of the University of Pennsylvania conducted a topographical and architectural survey of the site. Romano continued his work with the Mt. Lykaion Excavation and Survey Project under the auspices of the University of Pennsylvania and the University of Arizona. A preliminary planning phase of cleaning and surveying took place in 2004 and 2005, and was followed by a five-year excavation program beginning in June 2006. A two-year period during which the findings will be studied is scheduled to begin in the summer of 2011.\n\nThe hippodrome at Mount Lykaion, located in a valley below and to the north of the altar, is the only extant hippodrome from Greek antiquity, and is therefore crucial to our understanding of Greek athletic festivals. The hippodrome was constructed on roughly a north-south orientation with a retaining wall of about 140 meters along the eastern side curving around the northern end. Modern excavations have discovered portions tapering column drums that may belonged to the turning posts at either end of the race-course, from whose location it appears that the hippodrome could have had a length of 320 meters and a width of 140. A bath building is being excavated about 35 meters to the northeast of the hippodrome; a large portion of it appears to have been dedicated to a cistern, and large stone basins from the middle of the structure have been uncovered\n\nThe Lykaian hippodrome is further unique in apparently having encompassed the stadium racecourse. The early 20th century excavator of Lykaion, Kouriouniotis discovered stone blocks in the middle of the hippodrome that would have formed the starting line of the stadium. The topological survey of 1996 confirmed 6 starting line blocks, four of which were grouped together and were thus possibly found near their original orientation and position. From this, archaeologist David Romano speculated that a stadium racecourse of 170–180 meters would have been enclosed within the hippodrome. The apparently double-use of the space is particularly interesting because inscriptional evidence concerning the Lykaian Games of the 4th century BCE indicates that horse and foot-races were held during the same festivals, and possibly on the same day.\n\nTwo inscriptions were uncovered in the excavations of Kouriouniotis that give the names of winning athletes in the various contests of the Lykaian Games that were held every four years between 320 and 304 BCE. These contests included footraces for men and for boys, various chariot races with teams of adult and juvenile horses, boxing, wrestling, and a pentathlon.\n\nA circular altar of blackened earth about 1.5 meters in height and 30 meters in diameter seems to date from before the migration of Indo-European peoples into the area. The excavations of Kourouniotes in 1903 of the altar and its nearby \"temenos\" determined definite cult activity at the Lykaion altar from the late 7th century b.c.e, including animals bones, miniature tripods, knives, and statuettes of Zeus holding an eagle and a lightning bolt. These objects were primarily found in the \"temenos\". The earth-altar may correspond to a Linear B mention of an \"open-fire altar\"; Linear B (14th-13th centuries BCE) inscriptions also give the first mentions of offerings to Zeus and of the sacred precinct (temenos) near the altar, such as has been excavated at Lykaion.\n\nExcavation in 2007 revealed pottery fragments and signs of activity in the ash altar believed to have been used as early as 3000 BCE. Nearby Olympia (only 22 miles away) has a similar ash altar, and both settlements held ancient athletic games. The extremely early date of activity at Lykaion could suggest that these customs originated there. Stratigraphic analysis from the most recent excavations showed prehistoric human activity at the altar site, which seems to have been in continuous use from the Late Neolithic period through to the Hellenistic era. A number of drinking vessels and bones of sheep and goats from the Late Helladic period indicates that the altar was the site of Mycenean drinking and feasting rituals, probably in honor of Zeus. An especially interesting discovery was a seal ring from the Late Minoan period (1500-1400 BCE), which could indicate some interaction between Mt. Lykaion and Crete, both of which are given as the birthplace of Zeus by ancient sources.\n\nRecent excavations of a 30-meter ash altar on Mount Lykaion in Greece, once worshipped as the birthplace of Zeus, have revealed a 3000-year-old skeleton of an adolescent boy thought to be a human sacrifice, The Boston Globe reports. The altar is not a cemetery, the researchers note, and the skeleton was lined with stones, showing that it was not a typical human burial. Plato and other ancient writers linked Mount Lykaion specifically to human sacrifices to Zeus—the legends say a sacrificed boy would be cooked with sacrificed animal meat and those who consumed the human portion would become a wolf for 9 years.\n\n"}
{"id": "18374", "url": "https://en.wikipedia.org/wiki?curid=18374", "title": "Lake Eyre", "text": "Lake Eyre\n\nLake Eyre ( ), officially known as Kati Thanda–Lake Eyre, contains the lowest natural point in Australia, at approximately below sea level (AHD), and, on the rare occasions that it fills, is the largest lake in Australia covering . The shallow endorheic lake is the depocentre of the vast Lake Eyre basin and is found in Northern South Australia, some north of Adelaide.\n\nWhen the lake is full, it has the same salinity level as the sea, but as the lake dries up and the water evaporates, salinity increases.\n\nThe lake was named by Europeans in honour of Edward John Eyre, who was the first European to see it, in 1840. The lake's official name was changed in December 2012 to combine the name \"Lake Eyre\" with the indigenous name, Kati Thanda. The native title over the lake and surrounding region is held by the Arabana people.\n\nKati Thanda–Lake Eyre is in the deserts of central Australia, in northern South Australia. The Lake Eyre Basin is a large endorheic system surrounding the lakebed, the lowest part of which is filled with the characteristic salt pan caused by the seasonal expansion and subsequent evaporation of the trapped waters. Even in the dry season there is usually some water remaining in Kati Thanda–Lake Eyre, normally collecting in over 200 smaller sub-lakes within its margins. The lake was formed by aeolian processes after tectonic upwarping occurred to the south subsequent to the end of the Pleistocene epoch.\n\nDuring the rainy season, rivers from the north-east part of the Lake Eyre Basin (in outback (south-west and central) Queensland) flow towards the lake through the Channel Country. The amount of water from the monsoon determines whether water will reach the lake and if it does, how deep the lake will get. The average rainfall in the area of the lake is per year.\n\nThe altitude usually attributed to Kati Thanda–Lake Eyre refers to the deepest parts of the lake floor, in Belt Bay and the Madigan Gulf. The shoreline lies at . The lake is the area of maximum deposition of sediment in the Lake Eyre Basin.\n\nLake Eyre is divided into two sections which are joined by the Goyder Channel. These are known as Lake Eyre North, which is in length and wide, and Lake Eyre South, which measures . The salt crusts are thickest (up to ) in the southern Belt Bay, Jackboot Bay and Madigan Gulf sub-basins of Lake Eyre North.\n\nSince 1883, proposals have been made to flood Lake Eyre with seawater brought to the basin via a canal or pipeline. The purpose was, in part, to increase evaporation and thereby increase rainfall in the region downwind of an enlarged Lake Eyre. The added rainfall has been modeled as small. Due to the basin's low elevation below sea level and the region's high annual evaporation rate (between ), such schemes have generally been considered impractical as it is likely that accumulation of salt deposits would rapidly block the engineered channel. At a rate of evaporation per day, a viaduct flowing a would supply enough water to create a sea. If brine water was not sent back to the ocean, it would precipitate of salt every year.\n\nThe salinity in the lake increases as the salt crust dissolves over a period of six months of a major flood resulting in a massive fish kill. When over deep the lake is no more salty than the sea, but salinity increases as the water evaporates, with saturation occurring at about a depth. The lake takes on a pink hue when saturated due to the presence of beta-carotene pigment caused by the algae \"Dunaliella salina\".\n\nTypically a flood occurs every three years, a flood every decade, and a fill or near fill a few times a century. The water in the lake soon evaporates with a minor or medium flood drying by the end of the following summer. Most of the water entering the lakes arrives via Warburton River.\n\nIn strong La Niña years the lake can fill. Since 1885 this has occurred in 1886–1887, 1889–1890, 1916–1917, 1950, 1955, 1974–1977, and 1999–2001, with the highest flood of in 1974. Local rain can also fill Kati Thanda–Lake Eyre to as occurred in 1984 and 1989. Torrential rain in January 2007 took about six weeks to reach the lake but only placed a small amount of water into it.\n\nWhen recently flooded the lake is almost fresh and native freshwater fish, including bony bream (\"Nematolosa erebi\"), the Lake Eyre Basin sub-species of golden perch (\"Macquaria ambigua\") and various small hardyhead species (\"Craterocephalus\" spp.) can survive in it. \n\nThe 2009 Lake Eyre flood peaked at deep in late May, which is a quarter of its maximum recorded depth of . of water crossed the Queensland–South Australian border with most of it coming from massive floods in the Georgina River. However, owing to the very low rainfall in the lower reaches of these rivers (contrasting with heavy rainfall in the upper catchments) the greater proportion soaked into the desert or evaporated en route to the lake, leaving less than in the lake which covered an area of or 12% of the total. As the flood did not start filling the lake's deepest point (Belt Bay) until late March, little bird life appeared preferring instead to nest in the upper reaches of the Lake Eyre Basin, north of Birdsville, where large lakes appeared in January as a result of monsoonal rain.\n\nThe high rainfall in summer 2010 sent flood water into the Diamantina, Georgina and Cooper Creek catchments of the Lake Eyre basin, with the Cooper Creek reaching the lake for the first time since 1990. The higher rainfall has prompted many different birds to migrate back to the area for breeding.\n\nHeavy local rain in early March 2011 in the Stuart Creek and Warriner catchments filled Lake Eyre South, with Lake Eyre North about 75 per cent covered with water firstly from the Neales and Macumba Rivers, and later from the Warburton River.\n\nIn late 2015, water began flowing into Lake Eyre following heavy rain in the north-east of the state.\n\nThe Lake Eyre Yacht Club is a dedicated group of sailors who sail on the lake's floods, including recent trips in 1997, 2000, 2001, 2004, 2007 and 2009. A number of trailer sailers sailed on Kati Thanda–Lake Eyre in 1975, 1976, and 1984 when the flood depth reached . In July 2010 The Yacht Club held its first regatta since 1976 and its first on Lake Killamperpunna, a freshwater lake on Cooper Creek. The Cooper had reached Kati Thanda–Lake Eyre for the first time since 1990.\n\nWhen the lake is full, a notable phenomenon is that around midday the surface can often become very flat. The surface then reflects the sky in a way that leaves both the horizon and water surface virtually impossible to see. The commodore of the Lake Eyre Yacht Club has stated that sailing during this time has the appearance of sailing in the sky.\n\nKati Thanda–Lake Eyre has been a site for various land speed record attempts on its salt flats, especially those by Donald Campbell with the Bluebird-Proteus CN7.\n\nPhytoplankton in the lake includes \"Nodularia spumigena\" and a number of species of \"Dunaliella\".\n\nBirds such as pelicans and banded stilts are drawn to a filled lake from southern coastal regions of Australia, and from as far afield as Papua New Guinea. During the 1989–1990 flood it was estimated that 200,000 pelicans, 80% of Australia's total population, came to feed & roost at Lake Eyre. Scientists are presently unable to determine how such birds appear able to detect the filling of the lake, even when hundreds or thousands of kilometres away from the basin.\n\nThe extent of the lake is covered by two protected areas declared by the Government of South Australia - the Kati Thanda-Lake Eyre National Park and the Elliot Price Conservation Park.\n\nLake Eyre is on the list of wetlands of national importance known as A Directory of Important Wetlands in Australia.\n\nLake Eyre has been identified by BirdLife International as an Important Bird Area (IBA) known as the Lake Eyre Important Bird Area because, when flooded, it supports major breeding events of the Banded stilt and Australian pelican, as well as over 1% of the world populations of Red-necked avocets, Sharp-tailed sandpipers, Red-necked stints, Silver gulls and Caspian terns.\n\n\n"}
{"id": "18375", "url": "https://en.wikipedia.org/wiki?curid=18375", "title": "Locksmithing", "text": "Locksmithing\n\nLocksmithing is the science and art of making and defeating locks.\n\nLocksmithing is a traditional trade and in most countries requires completion of an apprenticeship. The level of formal education required varies from country to country, from a simple training certificate awarded by an employer, to a full diploma from an engineering college (such as in Australia) in addition to time spent working as an apprentice.\n\nA lock is a mechanism that secures buildings, rooms, cabinets, objects, or other storage facilities. A \"smith\" of any type is one who shapes metal pieces, often using a forge or mould, into useful objects or to be part of a more complex structure. Locksmithing, as its name implies, is the assembly and designing of locks and their respective keys.\n\nLocks have been constructed for over 2500 years, initially out of wood and later out of metal. Historically, locksmiths would make the entire lock, working for hours hand cutting screws and doing much file-work. Lock designs became significantly more complicated in the 18th century, and locksmiths often specialized in repairing or designing locks.\n\nAfter the rise of cheap mass production, the vast majority of locks are repaired by swapping of parts or like-for-like replacement, or upgraded to modern mass-production items. Until more recently, safes and strongboxes were the exception to this, and to this day large vaults are custom designed and built at great cost, as the cost of this is lower than the very limited scope for mass production would allow, and the risk of a copy being obtained and defeated as practice is removed.\n\nAlthough fitting of keys to replace lost keys to automobiles and homes and the changing of keys for homes and businesses to maintain security are still an important part of locksmithing, locksmiths today are primarily involved in the installation of higher quality lock-sets and the design, implementation and management of keying and key control systems. Most locksmiths also do electronic lock servicing, such as making keys for transponder-equipped vehicles and the implementation and application of access control systems protecting individuals and assets for many large institutions.\n\nIn terms of physical security, a locksmith's work frequently involves making a determination of the level of risk to an individual or institution and then recommending and implementing appropriate combinations of equipment and policies to create \"security layers\" which exceed the reasonable gain to an intruder or attacker. The more different security layers are implemented, the more the requirement for additional skills and knowledge and tools to defeat them all. But because each layer comes at an expense to the customer, the application of appropriate levels without exceeding reasonable costs to the customer is often very important and requires a skilled and knowledgeable locksmith to determine.\n\nLocksmiths may be commercial (working out of a storefront), mobile (working out of a vehicle), institutional (employed by an institution) or investigational (forensic locksmiths) or may specialize in one aspect of the skill, such as an automotive lock specialist, a master key system specialist or a safe technician. Many are also security consultants, but not every security consultant has the skills and knowledge of a locksmith. Locksmiths are frequently certified in specific skill areas or to a level of skill within the trade. This is separate from certificates of completion of training courses. In determining skill levels, certifications from manufacturers or locksmith associations are usually more valid criteria than certificates of completion. Some locksmiths decide to call themselves \"Master Locksmiths\" whether they are fully trained or not, and some training certificates appear quite authoritative.\n\nThe majority of locksmiths also work on any existing door hardware, not just locking mechanisms. This includes door closers, door hinges, electric strikes, frame repairs and other door hardware.\n\nThe issue of full disclosure was first raised in the context of locksmithing, in a 19th-century controversy regarding whether weaknesses in lock systems should be kept secret in the locksmithing community, or revealed to the public.\n\nAccording to A. C. Hobbs:\nA commercial, and in some respects a social doubt has been started within the last year or two, whether or not it is right to discuss so openly the security or insecurity of locks. Many well-meaning persons suppose that the discussion respecting the means for baffling the supposed safety of locks offers a premium for dishonesty, by showing others how to be dishonest. This is a fallacy. Rogues are very keen in their profession, and know already much more than we can teach them respecting their several kinds of roguery.\n\nRogues knew a good deal about lock-picking long before locksmiths discussed it among themselves, as they have lately done. If a lock, let it have been made in whatever country, or by whatever maker, is not so inviolable as it has hitherto been deemed to be, surely it is to the interest of honest persons to know this fact, because the dishonest are tolerably certain to apply the knowledge practically;and the spread of the knowledge is necessary to give fair play to those who might suffer by ignorance.\n\nIt cannot be too earnestly urged that an acquaintance with real facts will, in the end, be better for all parties. Some time ago, when the reading public was alarmed at being told how London milk is adulterated, timid persons deprecated the exposure, on the plea that it would give instructions in the art of adulterating milk; a vain fear, milkmen knew all about it before, whether they practiced it or not; and the exposure only taught purchasers the necessity of a little scrutiny and caution, leaving them to obey this necessity or not, as they pleased.\n\n\n\n"}
{"id": "18376", "url": "https://en.wikipedia.org/wiki?curid=18376", "title": "Loran-C", "text": "Loran-C\n\nLoran-C was a \"hyperbolic\" radio navigation system which allowed a receiver to determine its position by listening to low frequency radio signals transmitted by fixed land-based radio beacons. Loran-C combined two different techniques to provide a signal that was both long-range and highly accurate, traits that had formerly been at odds. The downside was the expense of the equipment needed to interpret the signals, which meant that Loran-C was used primarily by militaries after it was first introduced in 1957.\n\nBy the 1970s the electronics needed to implement Loran-C had been dramatically reduced due to the introduction of solid state radio electronics, and especially the use of early microcontrollers to interpret the signal. Low-cost and easy-to-use Loran-C units became common from the late 1970s, especially in the early 1980s, leading to the earlier LORAN system being turned off in favour of installing more Loran-C stations around the world. Loran-C became one of the most common and widely used navigation systems for large areas of North America, Europe, Japan and the entire Atlantic and Pacific areas. The Soviet Union operated a nearly identical system, CHAYKA.\n\nThe introduction of civilian satellite navigation in the 1990s led to a very rapid drop-off in Loran-C use. Discussions about the future of Loran-C began in the 1990s, and several turn-off dates were announced and then cancelled. In 2010 the US and Canadian systems were shut down, along with shared Loran-C/CHAYKA stations with Russia. Several other chains remained active, and some had been upgraded for continued use. At the end of 2015, navigation chains in most of Europe were turned off. In December 2015 in the US, there was also renewed discussion of funding an eLoran system and NIST was offering to fund development of a microchip-sized eLoran receiver for distribution of timing signals.\n\nRecent U.S. legislation, such as the National Timing Resilience and Security Act of 2017 and other bills, has been introduced which may resurrect Loran.\n\nThe original LORAN was proposed by Alfred Lee Loomis at a meeting of the Microwave Committee. The US Army Air Corps was interested in the concept for aircraft navigation, and after some discussion they returned a requirement for a system offering accuracy of about at a range of , and a maximum range as great as for high-flying aircraft. The Microwave Committee, by this time organized into what would become the Radiation Laboratory, took up development as Project 3. During the initial meetings, a member of the UK liaison team, Taffy Bowen, mentioned that he was aware the British were also working on a similar concept, but had no information on its performance.\n\nThe development team, led by Loomis, made rapid progress on the transmitter design and tested several systems during 1940 before settling on a 3 MHz design. Extensive signal-strength measurements were made by mounting a conventional radio receiver in a station wagon and driving around the eastern states. However, the custom receiver design and its associated cathode ray tube displays proved to be a bigger problem. In spite of several efforts to design around the problem, instability in the display prevented accurate measurements.\n\nBy this time the team had become much more familiar with the British Gee system, and were aware of their related work on \"strobes\", a time base generator that produced well-positioned \"pips\" on the display that could be used for accurate measurement. They met with the Gee team in 1941, and immediately adopted this solution. But this meeting also revealed that Project 3 and Gee called for almost identical systems, with similar performance, range and accuracy. But Gee had already completed basic development and was entering into initial production, making Project 3 superfluous.\n\nIn response, the Project 3 team told the Army Air Force to adopt Gee, and realigned their own efforts to provide long-range navigation on the oceans. This led to US Navy interest, and a series of experiments quickly demonstrated that systems using the basic Gee concept but operating at a lower frequency around 2 MHz would offer reasonable accuracy on the order of a few miles over distances on the order of , at least at night when signals of this frequency range were able to skip off the ionosphere. Rapid development followed, and a system covering the western Atlantic was operational in 1943. Additional stations followed, first covering the European side of the Atlantic, and then a massive expansion in the Pacific. By the end of the war, there were 72 operational LORAN stations and as many as 75,000 receivers.\n\nIn 1958 the operation of the LORAN system was handed over to the US Coast Guard, which renamed the system \"Loran-A\", the lower-case name being introduced at that time.\n\nThere are two ways to implement the timing measurements needed for a hyperbolic navigation system, pulse timing systems like Gee and LORAN, and phase-timing systems like the Decca Navigator System.\n\nThe former requires sharp pulses of signal, and their accuracy is generally limited to how rapidly the pulses can be turned on and off, which is a function of the carrier frequency. There is an ambiguity in the signal; the same measurements can be valid at two locations relative to the broadcasters, but in normal operation, they are hundreds of kilometres apart, so one possibility can be eliminated.\n\nThe second system uses constant signals (\"continuous wave\") and takes measurements by comparing the phase of two signals. This system is easy to use even at very low frequencies. However, its signal is ambiguous over the distance of a wavelength, meaning there are hundreds of locations that will return the same signal. Decca referred to these ambiguous locations as \"cells\" in Decca. This demands some other navigation method to be used in conjunction to pick which cell the receiver is within, and then using the phase measurements to place the receiver accurately within the cell.\n\nNumerous efforts were made to provide some sort of secondary low-accuracy system that could be used with a phase-comparison system like Decca in order to resolve the ambiguity. Among the many methods were a directional broadcast systems known as POPI, and a variety of systems combining pulse-timing for low-accuracy navigation and then using phase-comparison for fine adjustment. Decca themselves had set aside one frequency, \"9f\", for testing this concept, but did not have the chance to do so until much later. Similar concepts were also used in the experimental Navarho system in the US.\n\nIt was known from the start of the LORAN project that the same CRT displays that showed the LORAN pulses could, when suitably magnified, also show the individual waves of the intermediate frequency. This meant that pulse-matching could be used to get a rough fix, and then the operator could gain additional timing accuracy by lining up the individual waves within the pulse, like Decca. This could either be used to greatly increase the accuracy of LORAN, or alternately, offer similar accuracy using much lower carrier frequencies, and thus greatly extend range. This would require the transmitter stations to be synchronized both in time and phase, but much of this problem had been solved by Decca engineers.\n\nThe long-range option was of considerable interest to the Coast Guard, who set up an experimental system known as LF LORAN in 1945. This operated at much lower frequencies than the original LORAN, at 180 kHz, and required very long balloon-borne antennas. Testing was carried out throughout the year, including several long-distance flights as far as Brazil. The experimental system was then sent to Canada where it was used during Operation Muskox in the Arctic. Accuracy was found to be at , a significant advance over LORAN. With the ending of Muskox it was decided to keep the system running under what became known as \"Operation Musk Calf\", run by a group consisting of the US Air Force, Royal Canadian Air Force, Royal Canadian Navy and Royal Corps of Signals. The system ran until September 1947.\n\nThis led to another major test series, this time by the newly formed USAF, known as Operation Beetle. Beetle was located in the far north, on the Canada-Alaska border, and used new guy-stayed steel towers, replacing the earlier system's balloon-lofted cable antennas. The system became operational in 1948 and ran for two years until February 1950. Unfortunately, the stations proved poorly sited, as the radio transmission over the permafrost was much shorter than expected and synchronization of the signals between the stations using groundwaves proved impossible. The tests also showed that the system was extremely difficult to use in practice; it was easy for the operator to select the wrong sections of the waveforms on their display, leading to significant real-world inaccuracy.\n\nIn 1946 the Rome Air Development Center sent out contracts for longer-ranged and more-accurate navigation systems that would be used for long-range bombing navigation. As the US Army Air Force was moving towards smaller crews, only three in the Boeing B-47 Stratojet for instance, a high degree of automation was desired. Two contracts were accepted; Sperry Gyroscope proposed the CYCLAN system (CYCLe matching LorAN) which was broadly similar to LF LORAN but with additional automation, and Sylvania proposed Whyn using continuous wave navigation like Decca, but with additional coding using frequency modulation. In spite of great efforts, Whyn could never be made to work, and was abandoned.\n\nCYCLAN operated by sending the same LF LORAN-like signals on two frequencies, LF LORAN's 180 kHz and again on 200 kHz. The associated equipment would look for a rising amplitude that indicated the start of the signal pulse, and then use sampling gates to extract the carrier phase. Using two receivers solved the problem of mis-aligning the pulses, because the phases would only align properly between the two copies of the signal when the same pulses were being compared. None of this was trivial; using the era's tube-based electronics, the experimental CYCLAN system filled much of a semi-trailer.\n\nCYCLAN proved highly successful, so much so that it became increasingly clear that the problems that led the engineers to use two frequencies were simply not as bad as expected. It appeared that a system using a single frequency would work just as well, given the right electronics. This was especially good news, as the 200 kHz frequency was interfering with existing broadcasts, and had to be moved to 160 kHz during testing.\n\nThrough this period the issue of radio spectrum use was becoming a major concern, and had led to international efforts to decide on a frequency band suitable for long-range navigation. This process eventually settled on the band from 90 to 100 kHz. CYCLAN appeared to suggest that accuracy at even lower frequencies was not a problem, and the only real concern was the expense of the equipment involved.\n\nThe success of the CYCLAN system led to a further contract with Sperry in 1952 for a new system with the twin goals of working in the 100 kHz range while being equally accurate, less complex and less expensive. These goals would normally be contradictory, but the CYCLAN system gave all involved the confidence that these could be met. The resulting system was known as Cytac.\n\nTo solve the complexity problem, a new circuit was developed to properly time the sampling of the signal. This consisted of a circuit to extract the envelope of the pulse, another to extract the derivative of the envelope, and finally another that subtracted the derivative from the envelope. The result of this final operation would become negative during a very specific and stable part of the rising edge of the pulse, and this zero-crossing was used to trigger a very short-time sampling gate. This system replaced the complex system of clocks used in CYCLAN. By simply measuring the time between the zero-crossings of the master and slave, pulse-timing was extracted.\n\nThe output of the envelope sampler was also sent to a phase-shifter that adjusted the output of a local clock that locked to the master carrier using a phase-locked loop. This retained the phase of the master signal long enough for the slave signal to arrive. Gating on the slave signal was then compared to this master signal in a phase detector, and a varying voltage was produced depending on the difference in phase. This voltage represented the fine-positioning measurement.\n\nThe system was generally successful during testing through 1953, but there were concerns raised about the signal power at long ranges, and the possibility of jamming. This led to further modifications of the basic signal. The first was to broadcast a series of pulses instead of just one, broadcasting more energy during a given time and improving the ability of the receivers to tune in a useful signal. They also added a fixed 45° phase shift to every pulse, so simple continuous-wave jamming signals could be identified and rejected.\n\nThe Cytac system underwent an enormous series of tests across the United States and offshore. Given the potential accuracy of the system, even minor changes to the groundwave synchronization were found to cause errors that could be eliminated - issues such as the number of rivers the signal crossed caused predictable delays that could be measured and then factored into navigation solutions. This led to a series of \"correction contours\" that could be added to the received signal to adjust for these concerns, and these were printed on the Cytac charts. Using prominent features on dams as target points, a series of tests demonstrated that the uncorrected signals provided accuracy on the order of 100 yards, while adding the correction contour adjustments reduced this to the order of ten yards.\n\nIt was at this moment that the US Air Force (having taken over these efforts while moving from the USAAF) dropped their interest in the project. Although the reasons are not well recorded, it appears the idea of a fully automated bombing system using radio aids was no longer considered possible. The AAF had been involved in missions covering about 1000 km (the distance from London to Berlin) and the Cytac system would work well at these ranges. But as the mission changed to trans-polar missions of 5,000 km or more, even Cytac did not offer the range and accuracy needed. They turned their attention to the use of inertial platforms and Doppler radar systems, cancelling work on Cytac as well as a competing system known as Navarho.\n\nAround this period the Navy began work on a similar system using combined pulse and phase comparison, but based on the existing LORAN frequency of 200 kHz. By this time the Navy had handed operational control of the LORAN system to the Coast Guard, and it was assumed the same arrangement would be true for any new system as well. Thus the Coast Guard was given the choice of naming the systems, and decided to rename the existing system Loran-A, and the new system Loran-B.\n\nWith Cytac fully developed and its test system on the US east coast mothballed, the Navy also decided to re-commission Cytac for tests in the long-range role. An extensive series of tests across the Atlantic were carried out by the USCGC \"Androscoggin\" (WHEC-68) starting in April 1956. Meanwhile, Loran-B proved to have serious problems keeping their transmitters in phase, and that work was abandoned. Minor changes were made to the Cytac systems to further simplify it, including a reduction in the pulse-chain spacing from 1200 to 1000 µs, the pulse rate changed to 20 pps to match the existing Loran-A system, and the phase-shifting between pulses to an alternating 0, 180 degree shift instead of 45 degrees at every pulse within the chain.\n\nThe result was Loran-C. Testing of the new system was intensive, and over water flights around Bermuda demonstrated that 50% of fixes lay within a circle. This was a dramatic improvement over the original Loran-A, meeting the accuracy of the Gee system but at much greater range. The first chain were set up using the original experimental Cytac system, along with a second in the Mediterranean in 1957. Further chains covering the North Atlantic and large areas of the Pacific followed. At the time global charts were printed with shaded sections representing the area where a accurate fix could be obtained under most operational conditions.\n\nLoran-C had originally been designed to be highly automated, allowing the system to be operated more rapidly than the original LORAN's multi-minute measurement. It was also operated in \"chains\" of linked stations, allowing a fix to be made by simultaneously comparing two slaves to a single master. The downside of this approach was that the required electronic equipment, built using 1950s-era tube technology, was very large. Looking for companies with knowledge of seaborne, multi-channel phase-comparison electronics led, ironically, to Decca, who built the AN/SPN-31, the first widely used Loran-C receiver. The AN/SPN-31 weighed over and had 52 controls.\n\nAirborne units followed, and an adapted AN/SPN-31 was tested in an Avro Vulcan in 1963. By the mid-1960s, units with some transistorization were becoming more common, and a chain was set up in Viet Nam to support the US war efforts there. A number of commercial airline operators experimented with the system as well, using it for navigation on the great circle route between North America and Europe. However, inertial platforms ultimately became more common in this role.\n\nIn 1969, Decca sued the Navy for patent infringement, producing ample documentation of their work on the basic concept as early as 1944, along with the \"missing\" 9f frequency at 98 kHz that had been set aside for experiments using this system. Decca won the initial suit, but the judgement was overturned on appeal when the Navy claimed \"wartime expediency\".\n\nWhen Loran-C became widespread, the USAF once again became interested in using it as a guidance system. They proposed a new system layered on top of Loran-C, using it as the coarse guidance signal in much the same way that pulses were the coarse guidance and phase-comparison used for fine. To provide an extra-fine guidance signal, Loran-D interleaved another train of eight pulses immediately after the signals from one of the existing Loran-C stations, folding the two signals together. This technique became known as \"Supernumary Interpulse Modulation\" (SIM). These were broadcast from low-power portable transmitters, offering relatively short-range service of high accuracy.\n\nLoran-D was used only experimentally during war-games in the 1960s from a transmitter set in the UK. The system was also used in a limited fashion during the Vietnam War, combined with the Pave Spot laser designator system, a combination known as Pave Nail. Using mobile transmitters, the AN/ARN-92 LORAN navigation receiver could achieve accuracy on the order of , which the Spot system improved to about . The SIM concept became a system for sending additional data.\n\nAt about the same time, Motorola proposed a new system using pseudo-random pulse-chains. This mechanism ensures that no two chains within a given period (on the order of many seconds) will have the same pattern, making it easy to determine if the signal is a groundwave from a recent transmission or a multi-hop signal from a previous one. The system, Multi-User Tactical Navigation Systems (MUTNS) was used briefly but it was found that Loran-D met the same requirements but had the added advantage of being a standard Loran-C signal as well. Although MUTNS was unrelated to the Loran systems, it was sometimes referred to as Loran-F.\n\nIn spite of its many advantages, the high cost of implementing a Loran-C receiver made it uneconomical for many users. Additionally, as military users upgraded from Loran-A to Loran-C, large numbers of surplus Loran-A receivers were dumped on the market. This made Loran-A popular in spite of being less accurate and fairly difficult to operate. By the early 1970s the introduction of integrated circuits combining a complete radio receiver began to greatly reduce the complexity of Loran-A measurements, and fully automated units the size of a stereo receiver became common. For those users requiring higher accuracy, Decca had considerable success with their Decca Navigator system, and produced units that combined both receivers, using Loran to eliminate the ambiguities in Decca.\n\nThe same rapid development of microelectronics that made Loran-A so easy to operate worked equally well on the Loran-C signals, and the obvious desire to have a long-range system that could also provide enough accuracy for lake and harbour navigation led to the \"opening\" of the Loran-C system to public use in 1974. Civilian receivers quickly followed, and dual-system A/C receivers were also common for a time. The switch from A to C was extremely rapid, due largely to rapidly falling prices which led to many users' first receiver being Loran-C. By the late 1970s the Coast Guard decided to turn off Loran-A, in favour of adding additional Loran-C stations to cover gaps is its coverage. The original Loran-A network was shut down in 1979 and 1980, with a few units used in the Pacific for some time. Given the widespread availability of Loran-A charts, many Loran-C receivers included a system for converting coordinates between A and C units.\n\nOne of the reasons for Loran-C's opening to the public was the move from Loran to new forms of navigation, including INS, Transit and OMEGA, meant that the security of Loran was no longer as stringent as it was as a primary form of navigation. As these newer systems gave way to GPS through the 1980s and 90s, this process repeated itself, but this time the military was able to separate GPS's signals in such a way that it could provide both secure military and insecure civilian signals at the same time. GPS was more difficult to receive and decode, but by the 1990s the required electronics were already as small and inexpensive as Loran-C, leading to rapid adoption that has become largely universal.\n\nAlthough Loran-C was largely redundant by 2000, it has not universally disappeared due to a number of concerns. One is that the GPS system can be jammed through a variety of means; although the same is true of Loran-C, the transmitters are close-at-hand and can be adjusted if need be. More importantly, there are effects that might cause the GPS system to become unusable over wide areas, notably space weather events and potential EMP events. Loran, located entirely under the atmosphere, offers more resilience to these sorts of issues. There has been considerable debate about the relative merits of keeping the Loran-C system operational as a result of considerations like these.\n\nIn November 2009, the USCG announced that Loran-C is not needed by the U.S. for maritime navigation. This decision left the fate of LORAN and eLORAN in the U.S. to the Secretary of the Department of Homeland Security. Per a subsequent announcement, the U.S. Coast Guard, in accordance with the DHS Appropriations Act, terminated the transmission of all U.S. LORAN-C signals on 8 February 2010. On 1 August 2010 the U.S. transmission of the Russian American signal was terminated, and on 3 August 2010 all Canadian signals were shut down by the USCG and the CCG.\n\nThe European Union had decided that the potential security advantages of Loran are worthy not only of keeping the system operational, but upgrading it and adding new stations. This is part of the wider Eurofix system which combines GPS, Galileo and nine Loran stations into a single integrated system.\n\nHowever, in 2014, Norway and France both announced that all of their remaining transmitters, which make up a significant part of the Eurofix system, would be shut down on 31 December 2015. The two remaining transmitters in Europe (Anthorn, UK and Sylt, Germany) would no longer be able to sustain a positioning and navigation Loran service, with the result that the UK announced its trial eLoran service would be discontinued from the same date.\n\nIn conventional navigation, measuring one's location, or \"taking a fix\", is accomplished by taking two measurements against well known locations. In optical systems this is typically accomplished by measuring the angle to two landmarks, and then drawing lines on a nautical chart at those angles, producing an intersection that reveals the ship's location. Radio methods can also use the same concept with the aid of a radio direction finder, but due to the nature of radio propagation, such instruments are subject to significant errors, especially at night. More accurate radio navigation can be made using pulse timing or phase comparison techniques, which rely on the time-of-flight of the signals. In comparison to angle measurements, these remain fairly steady over time, and most of the effects that change these values are fixed objects like rivers and lakes that can be accounted for on charts.\n\nTiming systems can reveal the absolute distance to an object, as is the case in radar. The problem in the navigational case is that the receiver has to know when the original signal was sent. In theory, one could synchronize an accurate clock to the signal before leaving port, and then use that to compare the timing of the signal during the voyage. However, in the 1940s no suitable system was available that could hold an accurate signal over the time span of an operational mission.\n\nInstead, radio navigation systems adopted the \"multilateration\" concept. which is based on the difference in times (or phase) instead of the absolute time. The basic idea is that it is relatively easy to synchronize two ground stations, using a signal shared over a phone line for instance, so one can be sure that the signals received were sent at exactly the same time. They will not be received at exactly the same time, however, as the receiver will receive the signal from the closer station first. Timing the difference between two signals can be easily accomplished, first by physically measuring them on a cathode ray tube, or simple electronics in the case of phase comparison.\n\nThe difference in signal timing does not reveal the location by itself. Instead, it determines a series of locations where that timing is possible. For instance, if the two stations are 300 km apart and the receiver measures no difference in the two signals, that implies that the receiver is somewhere along a line equidistant between the two. If the signal from one is received exactly 100 µs, then the receiver is closer to one station than the other. Plotting all the locations where one station is 30 km closer than the other produces a curved line. Taking a fix is accomplished by making two such measurements with different pairs of stations, and then looking up both curves on a navigational chart. The curves are known as \"lines of position\" or LOP.\n\nIn practice, radio navigation systems normally use a \"chain\" of three or four stations, all synchronized to a \"master\" signal that is broadcast from one of the stations. The others, the \"secondaries\", are positioned so their LOPs cross at acute angles, which increases the accuracy of the fix. So for instance, a given chain might have four stations with the master in the center, allowing a receiver to pick the signals from two secondaries that are currently as close to right angles as possible given their current location. Modern systems, which know the locations of all the broadcasters, can automate which stations to pick.\n\nIn the case of LORAN, one station remains constant in each application of the principle, the \"primary\", being paired up separately with two other \"secondary\" stations. Given two secondary stations, the time difference (TD) between the primary and first secondary identifies one curve, and the time difference between the primary and second secondary identifies another curve, the intersections of which will determine a geographic point in relation to the position of the three stations. These curves are referred to as \"TD lines\".\n\nIn practice, LORAN is implemented in integrated regional arrays, or \"chains\", consisting of one \"primary\" station and at least two (but often more) \"secondary\" stations, with a uniform \"group repetition interval\" (GRI) defined in microseconds. The amount of time before transmitting the next set of pulses is defined by the distance between the start of transmission of primary to the next start of transmission of primary signal.\n\nThe secondary stations receive this pulse signal from the primary, then wait a preset number of milliseconds, known as the \"secondary coding delay\", to transmit a response signal. In a given chain, each secondary's coding delay is different, allowing for separate identification of each secondary's signal. (In practice, however, modern LORAN receivers do not rely on this for secondary identification.)\n\nEvery LORAN chain in the world uses a unique Group Repetition Interval, the number of which, when multiplied by ten, gives how many microseconds pass between pulses from a given station in the chain. (In practice, the delays in many, but not all, chains are multiples of 100 microseconds.) LORAN chains are often referred to by this designation (e.g., GRI 9960, the designation for the LORAN chain serving the Northeast United States).\n\nDue to the nature of hyperbolic curves, a particular combination of a primary and two secondary stations can possibly result in a \"grid\" where the grid lines intersect at shallow angles. For ideal positional accuracy, it is desirable to operate on a navigational grid where the grid lines are closer to right angles (orthogonal) to each other. As the receiver travels through a chain, a certain selection of secondaries whose TD lines initially formed a near-orthogonal grid can become a grid that is significantly skewed. As a result, the selection of one or both secondaries should be changed so that the TD lines of the new combination are closer to right angles. To allow this, nearly all chains provide at least three, and as many as five, secondaries.\n\nWhere available, common marine nautical charts include visible representations of TD lines at regular intervals over water areas. The TD lines representing a given primary-secondary pairing are printed with distinct colors, and note the specific time difference indicated by each line. On a nautical chart, the denotation for each Line of Position from a receiver, relative to axis and color, can be found at the bottom of the chart. The color on official charts for stations and the timed-lines of position follow no specific conformance for the purpose of the International Hydrographic Organization (IHO). However, local chart producers may color these in a specific conformance to their standard. Always consult the chart notes, administrations Chart1 reference, and information given on the chart for the most accurate information regarding surveys, datum, and reliability.\n\nThere are three major factors when considering signal delay and propagation in relation to LORAN-C:\n\nThe chart notes should indicate whether ASF corrections have been made (Canadian Hydrographic Service (CHS) charts, for example, include them). Otherwise, the appropriate correction factors must be obtained before use.\n\nDue to interference and propagation issues suffered from land features and artificial structures such as tall buildings, the accuracy of the LORAN signal can be degraded considerably in inland areas (see Limitations). As a result, nautical charts will not show TD lines in those areas, to prevent reliance on LORAN-C for navigation.\nTraditional LORAN receivers display the time difference between each pairing of the primary and one of the two selected secondary stations, which is then used to find the appropriate TD line on the chart. Modern LORAN receivers display latitude and longitude coordinates instead of time differences, and, with the advent of time difference comparison and electronics, provide improved accuracy and better position fixing, allowing the observer to plot their position on a nautical chart more easily. When using such coordinates, the datum used by the receiver (usually WGS84) must match that of the chart, or manual conversion calculations must be performed before the coordinates can be used.\n\nEach LORAN station is equipped with a suite of specialized equipment to generate the precisely timed signals used to modulate / drive the transmitting equipment. Up to three commercial cesium atomic clocks are used to generate 5 MHz and pulse per second (or 1 Hz) signals that are used by timing equipment to generate the various GRI-dependent drive signals for the transmitting equipment.\n\nWhile each U.S.-operated LORAN station is supposed to be synchronized to within 100 ns of UTC, the actual accuracy achieved as of 1994 was within 500 ns.\n\nLORAN-C transmitters operate at peak powers of 100–4,000 kilowatts, comparable to longwave broadcasting stations. Most use 190–220 metre tall mast radiators, insulated from ground. The masts are inductively lengthened and fed by a loading coil (see: electrical lengthening). A well known-example of a station using such an antenna is Rantum. Free-standing tower radiators in this height range are also used. Carolina Beach uses a free-standing antenna tower. Some LORAN-C transmitters with output powers of 1,000 kW and higher used supertall 412 metre mast radiators (see below). Other high power LORAN-C stations, like George, used four T-antennas mounted on four guyed masts arranged in a square.\n\nAll LORAN-C antennas are designed to radiate an omnidirectional pattern. Unlike longwave broadcasting stations, LORAN-C stations cannot use backup antennas because the exact position of the antenna is a part of the navigation calculation. The slightly different physical location of a backup antenna would produce Lines of Position different from those of the primary antenna.\n\nLORAN suffers from electronic effects of weather and the ionospheric effects of sunrise and sunset. The most accurate signal is the groundwave that follows the Earth's surface, ideally over seawater. At night the indirect skywave, bent back to the surface by the ionosphere, is a problem as multiple signals may arrive via different paths (multipath interference). The ionosphere's reaction to sunrise and sunset accounts for the particular disturbance during those periods. Magnetic storms have serious effects as with any radio based system.\n\nLORAN uses ground-based transmitters that only cover certain regions. Coverage is quite good in North America, Europe, and the Pacific Rim.\n\nThe absolute accuracy of LORAN-C varies from . Repeatable accuracy is much greater, typically from .\n\nLORAN Data Channel (LDC) is a project underway between the FAA and USCG to send low bit rate data using the LORAN system. Messages to be sent include station identification, absolute time, and position correction messages. In 2001, data similar to Wide Area Augmentation System (WAAS) GPS correction messages were sent as part of a test of the Alaskan LORAN chain. As of November 2005, test messages using LDC were being broadcast from several U.S. LORAN stations.\n\nIn recent years, LORAN-C has been used in Europe to send differential GPS and other messages, employing a similar method of transmission known as EUROFIX.\n\nA system called SPS (Saudi Positioning System), similar to EUROFIX, is in use in Saudi Arabia. GPS differential corrections and GPS integrity information are added to the LORAN signal. A combined GPS/LORAN receiver is used, and if a GPS fix is not available it automatically switches over to LORAN.\n\nAs LORAN systems are maintained and operated by governments, their continued existence is subject to public policy. With the evolution of other electronic navigation systems, such as satellite navigation systems, funding for existing systems is not always assured.\n\nCritics, who have called for the elimination of the system, state that the LORAN system has too few users, lacks cost-effectiveness, and that GNSS signals are superior to LORAN. Supporters of continued and improved LORAN operation note that LORAN uses a strong signal, which is difficult to jam, and that LORAN is an independent, dissimilar, and complementary system to other forms of electronic navigation, which helps ensure availability of navigation signals.\n\nOn 26 February 2009, the U.S. Office of Management and Budget released the first blueprint for the Financial Year 2010 budget. This document identified the LORAN-C system as \"outdated\" and supported its termination at an estimated savings of $36 million in 2010 and $190 million over five years.\n\nOn 21 April 2009 the U.S. Senate Committee on Commerce, Science and Transportation and the Committee on Homeland Security and Governmental Affairs released inputs to the FY 2010 Concurrent Budget Resolution with backing for the continued support for the LORAN system, acknowledging the investment already made in infrastructure upgrades and recognizing the studies performed and multi-departmental conclusion that eLORAN is the best backup to GPS.\n\nSenator Jay Rockefeller, Chairman of the Committee on Commerce, Science and Transportation, wrote that the committee recognized the priority in \"Maintaining LORAN-C while transitioning to eLORAN\" as means of enhancing the national security, marine safety and environmental protection missions of the Coast Guard.\n\nSenator Collins, the ranking member on the Committee on Homeland Security and Governmental Affairs wrote that the President's budget overview proposal to terminate the LORAN-C system is inconsistent with the recent investments, recognized studies and the mission of the U.S. Coast Guard. The committee also recognizes the $160 million investment already made toward upgrading the LORAN-C system to support the full deployment of eLORAN.\n\nFurther, the Committees also recognize the many studies which evaluated GPS backup systems and concluded both the need to back up GPS and identified eLORAN as the best and most viable backup. \"This proposal is inconsistent with the recently released (January 2009) Federal Radionavigation Plan (FRP), which was jointly prepared by DHS and the Departments of Defense (DOD) and Transportation (DOT). The FRP proposed the eLORAN program to serve as a Position, Navigation and Timing (PNT) backup to GPS (Global Positioning System).\"\n\nOn 7 May 2009, President Barack Obama proposed cutting funding (approx. $35 million/year) for LORAN, citing its redundancy alongside GPS. In regard to the pending Congressional bill, H.R. 2892, it was subsequently announced that \"[t]he Administration supports the Committee's aim to achieve an orderly termination through a phased decommissioning beginning in January 2010, and the requirement that certifications be provided to document that the LORAN-C termination will not impair maritime safety or the development of possible GPS backup capabilities or needs.\"\n\nAlso on 7 May 2009, the U.S. General Accounting Office (GAO), the investigative arm of Congress, released a report citing the very real potential for the GPS system to degrade or fail in light of program delays which have resulted in scheduled GPS satellite launches slipping by up to three years.\n\nOn 12 May 2009 the March 2007 Independent Assessment Team (IAT) report on LORAN was released to the public. In its report the ITA stated that it \"unanimously recommends that the U.S. government complete the eLORAN upgrade and commit to eLORAN as the national backup to GPS for 20 years.\" The release of the report followed an extensive Freedom Of Information Act (FOIA) battle waged by industry representatives against the federal government. Originally completed 20 March 2007 and presented to the co-sponsoring Department of Transportation and Department of Homeland Security (DHS) Executive Committees, the report carefully considered existing navigation systems, including GPS. The unanimous recommendation for keeping the LORAN system and upgrading to eLORAN was based on the team's conclusion that LORAN is operational, deployed and sufficiently accurate to supplement GPS. The team also concluded that the cost to decommission the LORAN system would exceed the cost of deploying eLORAN, thus negating any stated savings as offered by the Obama administration and revealing the vulnerability of the U.S. to GPS disruption.\n\nIn November 2009, the U.S. Coast Guard announced that the LORAN-C stations under its control would be closed down for budgetary reasons after 4 January 2010 provided the Secretary of the Department of Homeland Security certified that LORAN is not needed as a backup for GPS.\n\nOn 7 January 2010, Homeland Security published a notice of the permanent discontinuation of LORAN-C operation. Effective 2000 UTC 8 February 2010, the United States Coast Guard terminated all operation and broadcast of LORAN-C signals in the USA. The U.S. Coast Guard transmission of the Russian American CHAYKA signal was terminated on 1 August 2010. The transmission of Canadian LORAN-C signals was terminated on 3 August 2010.\n\nWith the potential vulnerability of GNSS systems, and their own propagation and reception limitations, renewed interest in LORAN applications and development has appeared. Enhanced LORAN, also known as eLORAN or E-LORAN, comprises an advancement in receiver design and transmission characteristics which increase the accuracy and usefulness of traditional LORAN. With reported accuracy as good as ± 8 meters, the system becomes competitive with unenhanced GPS. eLORAN also includes additional pulses which can transmit auxiliary data such as DGPS corrections. eLORAN receivers now use \"all in view\" reception, incorporating signals from all stations in range, not solely those from a single GRI, incorporating time signals and other data from up to 40 stations. These enhancements in LORAN make it adequate as a substitute for scenarios where GPS is unavailable or degraded. \nIn recent years the US Coast Guard has reported several episodes of GPS interference in the Black Sea. South Korea has claimed that North Korea has jammed GPS near the border, interfering with airplanes and ships. By 2018, the United States will build a new eLoran system as a complement to and backup for the GPS system. And the South Korean government has already pushed plans to have three eLoran beacons active by 2019, which is enough to provide accurate corrections for all shipments in the region if North Korea (or anyone else) tries to block GPS again.\n\nOn 31 May 2007, the UK Department for Transport (DfT), via the General Lighthouse Authorities (GLA), awarded a 15-year contract to provide a state-of-the-art enhanced LORAN (eLORAN) service to improve the safety of mariners in the UK and Western Europe. The service contract will operate in two phases, with development work and further focus for European agreement on eLORAN service provision from 2007 through 2010, and full operation of the eLORAN service from 2010 through 2022. The first eLORAN transmitter is situated at Anthorn radio station Cumbria, UK, and is operated by Babcock International (previously Babcock Communications).\n\neLORAN: The UK government has granted approval for seven differential eLoran ship-positioning technology stations to be built along the south and east coasts of the UK to help counter the threat of jamming of global positioning systems. They are set to reach initial operational capability by summer 2014. The General Lighthouse Authorities (GLAs) of the UK and Ireland announced 31 October the initial operational capability of UK maritime eLoran. Seven differential reference stations now provide additional position, navigation, and timing (PNT) information via low-frequency pulses to ships fitted with eLoran receivers. The service will help ensure they can navigate safely in the event of GPS failure in one of the busiest shipping regions in the world, with expected annual traffic of 200,000 vessels by 2020.\n\nDespite these plans, in light of the decision by France and Norway to cease Loran transmissions on 31 December 2015, the UK announced at the start of that month that its eLoran service would be discontinued on the same day.\n\nA list of LORAN-C transmitters. Stations with an antenna tower taller than 300 metres (984 feet) are shown in bold.\n\n\n\n"}
{"id": "18377", "url": "https://en.wikipedia.org/wiki?curid=18377", "title": "Lunatic", "text": "Lunatic\n\nLunatic is an antiquated term referring to a person who is considered as mentally ill, dangerous, foolish, unpredictable, or crazy—conditions once attributed to lunacy. The word derives from \"lunaticus\" meaning \"of the moon\" or \"moonstruck\". The term was once commonly used in law.\n\nThe term \"lunatic\" derives from the Latin word \"lunaticus\", which originally referred mainly to epilepsy and madness, as diseases thought to be caused by the moon. KJV records \"lunatick\" in Mt 17:15 and Mt 4:24. By the fourth and fifth centuries astrologers were commonly using the term to refer to neurological and psychiatric diseases. Philosophers such as Aristotle and Pliny the Elder argued that the full moon induced insane individuals with bipolar disorder by providing light during nights which would otherwise have been dark, and affecting susceptible individuals through the well-known route of sleep deprivation. Until at least 1700, it was also a common belief that the moon influenced fevers, rheumatism, episodes of epilepsy and other diseases.\n\nIn the jurisdiction of England and Wales the Lunacy Acts 1890–1922 referred to \"lunatics\", but the Mental Treatment Act 1930 changed the legal term to \"person of unsound mind\", an expression which was replaced under the Mental Health Act 1959 by \"mental illness\". \"Person of unsound mind\" was the term used in 1950 in the English version of the European Convention on Human Rights as one of the types of person who could be deprived of liberty by a judicial process. The 1930 Act also replaced the term \"asylum\" with \"mental hospital\". Criminal lunatics became Broadmoor patients in 1948 under the National Health Service Act 1946.\n\nOn December 5, 2012, the US House of Representatives passed legislation approved earlier by the US Senate removing the word \"lunatic\" from all federal laws in the United States. President Barack Obama signed this legislation into law on December 28, 2012.\n\n\"Of unsound mind\" or \"non compos mentis\" are alternatives to \"lunatic\", the most conspicuous term used for insanity in the law in the late 19th century.\n\nThe term \"lunatic\" was sometimes used to describe those who sought to discover a reliable method of determining longitude (before John Harrison developed the marine chronometer method of determining longitude, the main theory was the Method of Lunar Distances, advanced by Astronomer Royal Nevil Maskelyne). The artist William Hogarth portrayed a \"longitude lunatic\" in the eight scene of his 1733 work A Rake's Progress. Twenty years later, though, Hogarth described John Harrison's H-1 chronometer as \"one of the most exquisite movements ever made.\"\n\nLater, members of the Lunar Society of Birmingham called themselves \"lunaticks\". In an age with little street lighting, the society met on or near the night of the full moon.\n\n\n"}
{"id": "18379", "url": "https://en.wikipedia.org/wiki?curid=18379", "title": "Linear timecode", "text": "Linear timecode\n\nLinear (or Longitudinal) Timecode (LTC) is an encoding of SMPTE timecode data in an audio signal, as defined in SMPTE 12M specification. The audio signal is commonly recorded on a VTR track or other storage media. The bits are encoded using the biphase mark code (also known as \"FM\"): a 0 bit has a single transition at the start of the bit period. A 1 bit has two transitions, at the beginning and middle of the period. This encoding is self-clocking. Each frame is terminated by a 'sync word' which has a special predefined sync relationship with any video or film content.\n\nA special bit in the linear timecode frame, the \"biphase mark correction\" bit, ensures that there are an even number of AC transitions in each timecode frame.\n\nThe sound of linear timecode is a jarring and distinctive noise and has been used as a sound-effects shorthand to imply \"telemetry\" or \"computers\".\n\nIn broadcast video situations, the LTC generator should be tied into house black burst, as should all devices using timecode, to ensure correct color framing and correct synchronization of all digital clocks. When synchronizing multiple clock-dependent digital devices together with video, such as digital audio recorders, the devices must be connected to a common word clock signal that is derived from the house black burst signal. This can be accomplished by using a generator that generates both black burst and video-resolved word clock, or by synchronizing the master digital device to video, and synchronizing all subsequent devices to the word clock output of the master digital device (and to LTC).\n\nMade up of 80 bits per frame, where there may be 24, 25 or 30 frames per second, LTC timecode varies from 960 Hz (binary zeros at 24 frames/s) to 2400 Hz (binary ones at 30 frames/s), and thus is comfortably in the audio frequency range. LTC can exist as either a balanced or unbalanced signal, and can be treated as an audio signal in regards to distribution. Like audio, LTC can be distributed by standard audio wiring, connectors, distribution amplifiers, and patchbays, and can be ground-isolated with audio transformers. It can also be distributed via 75 ohm video cable and video distribution amplifiers, although the voltage attenuation caused by using a 75 ohm system may cause the signal to drop to a level that can not be read by some equipment.\n\nCare has to be taken with analog audio to avoid audible 'breakthrough' (aka \"crosstalk\") from the LTC track to the audio tracks.\n\nLTC care:\n\n\nLongitudinal SMPTE timecode should be played back at a middle-level when recorded on an audio track, as both low and high levels will introduce distortion.\n\nThe basic format is an 80-bit code that gives the time of day to the second, and the frame number within the second. Values are stored in binary-coded decimal, least significant bit first.\nThere are thirty-two bits of user data, usually used for a reel number and date.\n\n\n"}
{"id": "18381", "url": "https://en.wikipedia.org/wiki?curid=18381", "title": "John William Strutt, 3rd Baron Rayleigh", "text": "John William Strutt, 3rd Baron Rayleigh\n\nJohn William Strutt, 3rd Baron Rayleigh, (; 12 November 1842 – 30 June 1919), was a British scientist who made extensive contributions to both theoretical and experimental physics. He spent all of his academic career at the University of Cambridge. Among many honours, he received the 1904 Nobel Prize in Physics \"for his investigations of the densities of the most important gases and for his discovery of argon in connection with these studies.\" He served as President of the Royal Society from 1905 to 1908 and as Chancellor of the University of Cambridge from 1908 to 1919.\n\nRayleigh provided the first theoretical treatment of the elastic scattering of light by particles much smaller than the light's wavelength, a phenomenon now known as \"Rayleigh scattering\", which notably explains why the sky is blue. He studied and described transverse surface waves in solids, now known as \"Rayleigh waves\". He contributed extensively to fluid dynamics, with concepts such as the Rayleigh number (a dimensionless number associated with natural convection), Rayleigh flow, the Rayleigh–Taylor instability, and Rayleigh's criterion for the stability of Taylor–Couette flow. He also formulated the circulation theory of aerodynamic lift. In optics, Rayleigh proposed a well known criterion for angular resolution. His derivation of the Rayleigh–Jeans law for classical black-body radiation later played an important role in birth of quantum mechanics (see Ultraviolet catastrophe). Rayleigh's textbook \"The Theory of Sound\" (1877) is still used today by acousticians and engineers.\n\nStrutt was born on 12 November 1842 at Langford Grove in Maldon, Essex. In his early years he suffered from frailty and poor health. He attended Eton College and Harrow School (each for only a short period), before going on to the University of Cambridge in 1861 where he studied mathematics at Trinity College, Cambridge. He obtained a Bachelor of Arts degree (Senior Wrangler and 1st Smith's Prize) in 1865, and a Master of Arts in 1868. He was subsequently elected to a Fellowship of Trinity. He held the post until his marriage to Evelyn Balfour, daughter of James Maitland Balfour, in 1871. He had three sons with her. In 1873, on the death of his father, John Strutt, 2nd Baron Rayleigh, he inherited the Barony of Rayleigh.\n\nHe was the second Cavendish Professor of Physics at the University of Cambridge (following James Clerk Maxwell), from 1879 to 1884. He first described dynamic soaring by seabirds in 1883, in the British journal \"Nature\". From 1887 to 1905 he was Professor of Natural Philosophy at the Royal Institution.\n\nAround the year 1900 Rayleigh developed the \"duplex\" (combination of two) theory of human sound localisation using two binaural cues, interaural phase difference (IPD) and interaural level difference (ILD) (based on analysis of a spherical head with no external pinnae). The theory posits that we use two primary cues for sound lateralisation, using the difference in the phases of sinusoidal components of the sound and the difference in amplitude (level) between the two ears.\n\nIn 1919, Rayleigh served as President of the Society for Psychical Research. As an advocate that simplicity and theory be part of the scientific method, Rayleigh argued for the principle of similitude.\n\nRayleigh was elected Fellow of the Royal Society on 12 June 1873, and served as president of the Royal Society from 1905 to 1908. From time to time Rayleigh participated in the House of Lords; however, he spoke up only if politics attempted to become involved in science.\n\nHe died on 30 June 1919, in Witham, Essex. He was succeeded, as the 4th Lord Rayleigh, by his son Robert John Strutt, another well-known physicist. Lord Rayleigh was buried in the graveyard of All Saints' Church in Terling in Essex.\n\nThe rayl unit of acoustic impedance is named after him.\n\nRayleigh was an Anglican. Though he did not write about the relationship of science and religion, he retained a personal interest in spiritual matters. When his scientific papers were to be published in a collection by the Cambridge University Press, Strutt wanted to include a religious quotation from the Bible, but he was discouraged from doing so, as he later reported:\n\nStill, he had his wish and the quotation was printed in the five-volume collection of scientific papers.\n\nIn a letter to a family member, he wrote about his rejection of materialism and spoke of Jesus Christ as a moral teacher:\n\nHe held an interest in parapsychology and was an early member of the Society for Psychical Research (SPR). He was not convinced of spiritualism but remained open to the possibility of supernatural phenomena. Rayleigh was the president of the SPR in 1919. He gave a presidential address in the year of his death but did not come to any definite conclusions.\n\nThe lunar crater \"Rayleigh\" as well as the Martian crater \"Rayleigh\" were named in his honour. The asteroid 22740 Rayleigh was named after him on 1 June 2007. A type of surface waves are known as Rayleigh waves. The rayl, a unit of specific acoustic impedance, is also named for him. Rayleigh was also awarded with (in chronological order):\n\nLord Rayleigh was among the original recipients of the Order of Merit (OM) in the 1902 Coronation Honours list published on 26 June 1902, and received the order from King Edward VII at Buckingham Palace on 8 August 1902.\n\nHe received the degree of \"Doctor mathematicae (honoris causa)\" from the Royal Frederick University on 6 September 1902, when they celebrated the centennial of the birth of mathematician Niels Henrik Abel.\n\nSir William Ramsay, his co-worker in the investigation to discover Argon described Rayleigh as \"the greatest man alive\" while speaking to Lady Ramsay during his last illness.\n\nH. M. Hyndmann said of Rayleigh that \"no man ever showed less consciousness of great genius\".\n\n\n"}
{"id": "18382", "url": "https://en.wikipedia.org/wiki?curid=18382", "title": "Lunisolar calendar", "text": "Lunisolar calendar\n\nA lunisolar calendar is a calendar in many cultures whose date indicates both the moon phase and the time of the solar year. If the solar year is defined as a tropical year, then a lunisolar calendar will give an indication of the season; if it is taken as a sidereal year, then the calendar will predict the constellation near which the full moon may occur. As with all calendars which divide the year into months there is an additional requirement that the year have a whole number of months. In this case ordinary years consist of twelve months but every second or third year is an embolismic year, which adds a thirteenth intercalary, embolismic, or leap month.\n\nThe Hebrew, Jain, Buddhist, Hindu and Kurdish as well as the traditional Burmese, Chinese, Japanese, Tibetan, Vietnamese, Mongolian and Korean calendars (in the east Asian cultural sphere), plus the ancient Hellenic, Coligny, and Babylonian calendars are all lunisolar. Also, some of the ancient pre-Islamic calendars in south Arabia followed a lunisolar system. The Chinese, Coligny and\nHebrew lunisolar calendars track more or less the tropical year whereas the Buddhist and Hindu lunisolar calendars track the sidereal year. Therefore, the first three give an idea of the seasons whereas the last two give an idea of the position among the constellations of the full moon. The Tibetan calendar was influenced by both the Chinese and Buddhist calendars. The Germanic peoples also used a lunisolar calendar before their conversion to Christianity.\n\nThe Islamic calendar is lunar, but not a lunisolar calendar because its date is not related to the sun. The civil versions of the Julian and Gregorian calendars are solar, because their dates do not indicate the moon phase — however, both the Gregorian and Julian calendars include undated lunar calendars that allow them to calculate the Christian celebration of Easter, so both are lunisolar calendars in that respect.\n\nA rough idea of the frequency of the intercalary or leap month in all lunisolar calendars can be obtained by the following calculation, using approximate lengths of months and years in days:\n\nIntercalation of leap months is frequently controlled by the \"epact\", which is the difference between the lunar and solar years (approximately 11 days). The Metonic cycle, used in the Hebrew calendar and the Julian and Gregorian ecclesiastical calendars, adds seven months during every nineteen-year period. The classic Metonic cycle can be reproduced by assigning an initial epact value of 1 to the last year of the cycle and incrementing by 11 each year. Between the last year of one cycle and the first year of the next the increment is 12. This adjustment, the \"saltus lunae\", causes the epacts to repeat every 19 years. When the epact goes above 29 an intercalary month is added and 30 is subtracted. The intercalary years are numbers 3, 6, 8, 11, 14, 17 and 19. Both the Hebrew calendar and the Julian calendar use this sequence.\n\nThe Buddhist and Hebrew calendars restrict the leap month to a single month of the year; the number of common months between leap months is, therefore, usually 36, but occasionally only 24 months. Because the Chinese and Hindu lunisolar calendars allow the leap month to occur after or before (respectively) any month but use the true motion of the sun, their leap months do not usually occur within a couple of months of perihelion, when the apparent speed of the sun along the ecliptic is fastest (now about 3 January). This increases the usual number of common months between leap months to roughly 34 months when a doublet of common years occurs, while reducing the number to about 29 months when only a common singleton occurs.\n\nAn alternative way of dealing with the fact that a solar year does not contain an integer number of months is by including uncounted time in the year that does not belong to any month. Some Coast Salish peoples used a calendar of this kind. For instance, the Chehalis began their count of lunar months from the arrival of spawning chinook salmon (in Gregorian calendar October), and counted 10 months, leaving an uncounted period until the next chinook salmon run.\n\nThe Gregorian calendar has a lunisolar calendar, which is used to determine the date of Easter. The rules are in the Computus.\n\nThe following is a list of lunisolar calendars:\n\n\n\n"}
{"id": "18383", "url": "https://en.wikipedia.org/wiki?curid=18383", "title": "Leonids", "text": "Leonids\n\nThe Leonids ( ) are a prolific meteor shower associated with the comet Tempel–Tuttle. The Leonids get their name from the location of their radiant in the constellation Leo: the meteors appear to radiate from that point in the sky. Their proper Greek name should be Leon\"t\"ids (Λεοντίδαι, \"Leontídai\"), but the word was initially constructed as a Greek/Latin hybrid and it has been used since. They peak in the month of November.\n\nEarth moves through the meteoroid stream of particles left from the passages of a comet. The stream comprises solid particles, known as meteoroids, ejected by the comet as its frozen gases evaporate under the heat of the Sun when it is close enough – typically closer than Jupiter's orbit. The Leonids are a fast moving stream which encounter the path of Earth and impact at 72 km/s. Larger Leonids which are about 10 mm across have a mass of half a gram and are known for generating bright (apparent magnitude −1.5) meteors. An annual Leonid shower may deposit 12 or 13 tons of particles across the entire planet.\n\nThe meteoroids left by the comet are organized in trails in orbits similar to though different from that of the comet. They are differentially disturbed by the planets, in particular Jupiter and to a lesser extent by radiation pressure from the sun, the Poynting–Robertson effect, and the Yarkovsky effect. These trails of meteoroids cause meteor showers when Earth encounters them. Old trails are spatially not dense and compose the meteor shower with a few meteors per minute. In the case of the Leonids, that tends to peak around November 18, but some are spread through several days on either side and the specific peak changes every year. Conversely, young trails are spatially very dense and the cause of meteor outbursts when the Earth enters one. Meteor storms (large outbursts) exceed 1000 meteors per hour, to be compared to the sporadic background (5 to 8 meteors per hour) and the shower background (several per hour).\n\nThe Leonids are famous because their meteor showers, or storms, can be among the most spectacular. Because of the storm of 1833 and the recent developments in scientific thought of the time (see for example the identification of Halley's Comet) the Leonids have had a major effect on the development of the scientific study of meteors, which had previously been thought to be atmospheric phenomena. Though it has been suggested the meteor shower-storm has been noted in ancient times it was the meteor storm of 1833 that broke into people's modern day awareness – it was of truly superlative strength. One estimate is over one hundred thousand meteors an hour, but another, done as the storm abated, estimated in excess of 240,000 meteors during the nine hours of the storm over the entire region of North America east of the Rocky Mountains.\n\nIt was marked by several nations of Native Americans: the Cheyenne established a peace treaty and the Lakota calendar was reset. Abolitionists including Harriet Tubman and Frederick Douglass as well as slave-owners took note and others. The New York Evening Post carried a series of articles on the event including reports from Canada to Jamaica, it made news in several states beyond New York and though it appeared in North America was talked about in Europe. The journalism of the event tended to rise above the partisan debates of the time and reviewed facts as they could be sought out. Abraham Lincoln commented on it years later. Near Independence, Missouri, in Clay County, a refugee Mormon community watched the meteor shower on the banks of the Missouri River after having been driven from their homes by local settlers. The founder and first leader of Mormonism, Joseph Smith, afterwards noted in his journal his belief that this event was a literal fulfillment of the word of God and a sure sign that the coming of Christ was close at hand. Though it was noted in the midwest and eastern areas it was also noted in the far west.\n\nDenison Olmsted explained the event most accurately. After spending the last weeks of 1833 collecting information, he presented his findings in January 1834 to the \"American Journal of Science and Arts\", published in January–April 1834, and January 1836. He noted the shower was of short duration and was not seen in Europe, and that the meteors radiated from a point in the constellation of Leo and he speculated the meteors had originated from a cloud of particles in space. Accounts of the 1866 repeat of the Leonids counted hundreds per minute/a few thousand per hr in Europe. The Leonids were again seen in 1867, when moonlight reduced the rates to 1000 per hour. Another strong appearance of the Leonids in 1868 reached an intensity of 1000 per hour in dark skies. It was in 1866–67 that information on Comet Tempel-Tuttle was gathered pointing it out as the source of the meteor shower. When the storms failed to return in 1899, it was generally thought that the dust had moved on and storms were a thing of the past.\n\nThen, in 1966, a spectacular storm was seen over the Americas. Historical notes were gathered thus noting the Leonids back to 900AD. Radar studies showed the 1966 storm included a relatively high percentage of smaller particles while 1965's lower activity had a much higher proportion of larger particles. In 1981 Donald K. Yeomans of the Jet Propulsion Laboratory reviewed the history of meteor showers for the Leonids and the history of the dynamic orbit of Comet Tempel-Tuttle. A graph from it was adapted and re-published in Sky and Telescope. It showed relative positions of the Earth and Tempel-Tuttle and marks where Earth encountered dense dust. This showed that the meteoroids are mostly behind and outside the path of the comet, but paths of the Earth through the cloud of particles resulting in powerful storms were very near paths of nearly no activity. But overall the 1998 Leonids were in a favorable position so interest was rising.\n\nLeading up to the 1998 return, an airborne observing campaign was organized to mobilize modern observing techniques by Peter Jenniskens at NASA Ames Research Center. There were also efforts to observe impacts of meteoroids, as an example of transient lunar phenomenon, on the Moon in 1999. A particular reason to observe the Moon is that our vantage from a location on Earth sees only meteors coming into the atmosphere relatively close to us while impacts on the Moon would be visible from across the Moon in a single view. The sodium tail of the Moon tripled just after the 1998 Leonid shower which was composed of larger meteoroids (which in the case of the Earth was witnessed as fireballs.) However, in 1999 the sodium tail of the Moon did not change from the Leonid impacts.\n\nResearch by Kondrat'eva, Reznikov and colleagues at Kazan University had shown how meteor storms could be accurately predicted, but for some years the worldwide meteor community remained largely unaware of these results. The work of David J. Asher, Armagh Observatory and Robert H. McNaught, Siding Spring Observatory and independently by Esko Lyytinen in 1999, following on from the Kazan research, is considered by most meteor experts as the breakthrough in modern analysis of meteor storms. Whereas previously it was hazardous to guess if there would be a storm or little activity, the predictions of Asher and McNaught timed bursts in activity down to ten minutes by narrowing down the clouds of particles to individual streams from each passage of the comet, and their trajectories amended by subsequent passage near planets. However, whether a specific meteoroid trail will be primarily composed of small or large particles, and thus the relative brightness of the meteors, was not understood. But McNaught did extend the work to examine the placement of the Moon with trails and saw a large chance of a storm impacting in 1999 from a trail while there were less direct impacts from trails in 2000 and 2001 (successive contact with trails through 2006 showed no hits.)\n\nViewing campaigns resulted in spectacular footage from the 1999, 2001 and 2002, storms producing up to 3,000 Leonid meteors per hour. Predictions for the Moon's Leonid impacts also noted that in 2000 the side of the Moon facing the stream was away from the Earth but that impacts should be in number enough to raise a cloud of particles kicked off the Moon by impacts would cause a detectable increase in the sodium tail of the Moon. Research using the explanation of meteor trails/streams have explained the storms of the past. The 1833 storm was not due to the recent passage of the comet, but from a direct impact with the previous 1800 dust trail. The meteoroids from the 1733 passage of Comet Tempel-Tuttle resulted in the 1866 storm and the 1966 storm was from the 1899 passage of the comet. The double spikes in Leonid activity in 2001 and in 2002 were due to the passage of the comet's dust ejected in 1767 and 1866. This ground breaking work was soon applied to other meteor showers – for example the 2004 June Bootids. Peter Jenniskens has published predictions for the next 50 years. However, a close encounter with Jupiter is expected to perturb the comet's path, and many streams, making storms of historic magnitude unlikely for many decades. Recent work tries to take into account the roles of differences in parent bodies and the specifics of their orbits, ejection velocities off the solid mass of the core of a comet, radiation pressure from the sun, the Poynting–Robertson effect, and the Yarkovsky effect on the particles of different sizes and rates of rotation to explain differences between meteor showers in terms of being predominantly fireballs or small meteors.\nPredictions until the end of the 21st century have been published by Mikhail Maslov.\n\nTwo appearances of the Leonids frame the story of the novel Blood Meridian by Cormac McCarthy.\n\nThe 1833 shower is referenced in the fourth section of William Faulkner's short story \"The Bear,\" as published in his novel Go Down, Moses. As Ike reads the entries chronicling the slaves owned by his family, the recording for Tomy lists her death as June 1833, \"Yr stars fell.\"\n\nIn \"Pokémon Omega Ruby and Alpha Sapphire\", the Leonid is referenced as the Litleonids meteor shower (named after the Pokémon species Litleo). This has a big impact in an event in its post game named \"The Delta Episode\" in which one of the meteors contain Deoxys.\n\nThe shower is part of the plot in the first episode of The Brokenwood Mysteries, a New Zealand crime series.\n\n\n\n"}
{"id": "18384", "url": "https://en.wikipedia.org/wiki?curid=18384", "title": "Labarum", "text": "Labarum\n\nThe labarum () was a \"vexillum\" (military standard) that displayed the \"Chi-Rho\" symbol ☧, a christogram formed from the first two Greek letters of the word \"Christ\" (, or Χριστός) — \"Chi\" (χ) and \"Rho\" (ρ). It was first used by the Roman emperor Constantine the Great. Since the vexillum consisted of a flag suspended from the crossbar of a cross, it was ideally suited to symbolize the crucifixion of Christ.\n\nAncient sources draw an unambiguous distinction between the two terms \"labarum\" and \"Chi-Rho\", even though later usage sometimes regards the two as synonyms. The name labarum was applied both to the original standard used by Constantine the Great and to the many standards produced in imitation of it in the Late Antique world, and subsequently.\n\nBeyond its derivation from Latin \"labarum\", the etymology of the word is unclear. The Oxford English Dictionary offers no further derivation from within Latin. Some derive it from Latin /labāre/ 'to totter, to waver' (in the sense of the \"waving\" of a flag in the breeze) or \"laureum [vexillum]\" (\"laurel standard\"). An origin as a loan into Latin from a Celtic language or Basque has also been postulated. There is a traditional Basque symbol called the lauburu; though the name is only attested from the 19th century onwards the motif occurs in engravings dating as early as the 2nd century AD.\n\nOn the evening of October 27, 312 AD, with his army preparing for the Battle of the Milvian Bridge, the emperor Constantine I claimed to have had a vision which led him to believe he was fighting under the protection of the Christian God.\n\nLactantius states that, in the night before the battle, Constantine was commanded in a dream to \"delineate the heavenly sign on the shields of his soldiers\". Obeying this command, \"he marked on their shields the letter X, with a perpendicular line drawn through it and turned round thus at the top, being the cipher of Christ\". Having had their shields marked in this fashion, Constantine's troops readied themselves for battle.\n\nFrom Eusebius, two accounts of a battle survive. The first, shorter one in the \"Ecclesiastical History\" leaves no doubt that God helped Constantine but does not mention any vision. In his later \"Life of Constantine\", Eusebius gives a detailed account of a vision and stresses that he had heard the story from the emperor himself. According to this version, Constantine with his army was marching somewhere (Eusebius does not specify the actual location of the event, but it clearly is not in the camp at Rome) when he looked up to the sun and saw a cross of light above it, and with it the Greek words \"Ἐν Τούτῳ Νίκα\". The traditionally employed Latin translation of the Greek is \"in hoc signo vinces\"— literally \"In this sign, you will conquer.\" However, a direct translation from the original Greek text of Eusebius into English gives the phrase \"By this, conquer!\"\n\nAt first he was unsure of the meaning of the apparition, but the following night he had a dream in which Christ explained to him that he should use the sign against his enemies. Eusebius then continues to describe the labarum, the military standard used by Constantine in his later wars against Licinius, showing the Chi-Rho sign.\n\nThose two accounts have been merged in popular notion into Constantine seeing the Chi-Rho sign on the evening before the battle. Both authors agree that the sign was not readily understandable as denoting Christ, which corresponds with the fact that there is no certain evidence of the use of the letters chi and rho as a Christian sign before Constantine. Its first appearance is on a Constantinian silver coin from c. 317, which proves that Constantine did use the sign at that time. He made extensive use of the Chi-Rho and the labarum later in the conflict with Licinius.\n\nThe vision has been interpreted in a solar context (e.g. as a solar halo phenomenon), which would have been reshaped to fit with the Christian beliefs of the later Constantine.\n\nAn alternate explanation of the intersecting celestial symbol has been advanced by George Latura, which claims that Plato's visible god in \"Timaeus\" is in fact the intersection of the Milky Way and the Zodiacal Light, a rare apparition important to pagan beliefs that Christian bishops reinvented as a Christian symbol.\n\n\"A Description of the Standard of the Cross, which the Romans now call the Labarum.\"\n\"Now it was made in the following manner. A long spear, overlaid with gold, formed the figure of the cross by means of a transverse bar laid over it. On the top of the whole was fixed a wreath of gold and precious stones; and within this, the symbol of the Saviour’s name, two letters indicating the name of Christ by means of its initial characters, the letter P being intersected by X in its centre: and these letters the emperor was in the habit of wearing on his helmet at a later period. From the cross-bar of the spear was suspended a cloth, a royal piece, covered with a profuse embroidery of most brilliant precious stones; and which, being also richly interlaced with gold, presented an indescribable degree of beauty to the beholder. This banner was of a square form, and the upright staff, whose lower section was of great length, of the pious emperor and his children on its upper part, beneath the trophy of the cross, and immediately above the embroidered banner.\"\n\n\"The emperor constantly made use of this sign of salvation as a safeguard against every adverse and hostile power, and commanded that others similar to it should be carried at the head of all his armies.\"\n\nThe labarum does not appear on any of several standards depicted on the Arch of Constantine, which was erected just three years after the battle. If Eusebius' oath-confirmed account of Constantine's vision and the role it played in his victory and conversion can be trusted, then a grand opportunity for the kind of political propaganda that the Arch was built to present was missed. Many historians have argued that in the early years after the battle, the Emperor had not yet decided to give clear public support to Christianity, whether from a lack of personal faith or because of fear of religious friction. The arch's inscription does say that the Emperor had saved the \"res publica\" (\"by greatness of mind and by instinct [or impulse] of divinity\"). Continuing the iconography of his predecessors, Constantine's coinage at the time was inscribed with solar symbolism, interpreted as representing \"Sol Invictus\" (the Unconquered Sun), Helios, Apollo, or Mithras, but in 325 and thereafter the coinage ceases to be explicitly pagan, and Sol Invictus disappears. And although Eusebius' \"Historia Ecclesiae\" further reports that Constantine had a statue of himself \"holding the sign of the Savior [the cross] in his right hand\" erected after his victorious entry into Rome, there are no other reports to confirm such a monument.\n\nHistorians still dispute whether Constantine was the first Christian Emperor to support a peaceful transition to Christianity during his rule, or an undecided pagan believer until middle age, and also how strongly influenced he was in his political-religious decisions by his Christian mother St. Helena.\n\nAs for the labarum itself, there is little evidence for its use before 317. In the course of Constantine's second war against Licinius in 324, the latter developed a superstitious dread of Constantine's standard. During the attack of Constantine's troops at the Battle of Adrianople the guard of the labarum standard were directed to move it to any part of the field where his soldiers seemed to be faltering. The appearance of this talismanic object appeared to embolden Constantine's troops and dismay those of Licinius. At the final battle of the war, the Battle of Chrysopolis, Licinius, though prominently displaying the images of Rome's pagan pantheon on his own battle line, forbade his troops from actively attacking the labarum, or even looking at it directly.\n\nConstantine felt that both Licinius and Arius were agents of Satan, and associated them with the serpent described in the Book of Revelation (). Constantine represented Licinius as a snake on his coins.\n\nEusebius stated that in addition to the singular labarum of Constantine, other similar standards (labara) were issued to the Roman army. This is confirmed by the two labara depicted being held by a soldier on a coin of Vetranio (illustrated) dating from 350.\n\nA later Byzantine manuscript indicates that a jewelled labarum standard believed to have been that of Constantine was preserved for centuries, as an object of great veneration, in the imperial treasury at Constantinople. The labarum, with minor variations in its form, was widely used by the Christian Roman emperors who followed Constantine.\n\nA miniature version of the labarum became part of the imperial regalia of Byzantine rulers, who were often depicted carrying it in their right hands.\n\nThe term \"labarum\" can be generally applied to any ecclesiastical banner, such as those carried in religious processions.\n\n\"The Holy Lavaro\" were a set of early national Greek flags, blessed by the Greek Orthodox Church. Under these banners the Greeks united throughout the Greek Revolution (1821), a war of liberation waged against the Ottoman Empire.\n\nLabarum also gives its name (Labaro) to a suburb of Rome adjacent to Prima Porta, one of the sites where the 'Vision of Constantine' is placed by tradition.\n\n\n"}
{"id": "18385", "url": "https://en.wikipedia.org/wiki?curid=18385", "title": "Lactantius", "text": "Lactantius\n\nLucius Caecilius Firmianus Lactantius (c. 250 – c. 325) was an early Christian author who became an advisor to the first Christian Roman emperor, Constantine I, guiding his religious policy as it developed, and a tutor to his son Crispus. His most important work is the \"Institutiones Divinae\" (\"The Divine Institutes\"), an apologetic treatise intended to establish the reasonableness and truth of Christianity to pagan critics.\n\nLactantius, a Latin-speaking North African of Berber origin, was not born into a Christian family. He was a pupil of Arnobius who taught at Sicca Veneria, an important city in Numidia. In his early life, he taught rhetoric in his native town, which may have been Cirta in Numidia, where an inscription mentions a certain \"L. Caecilius Firmianus\".\n\nLactantius had a successful public career at first. At the request of the Roman Emperor Diocletian, he became an official professor of rhetoric in Nicomedia; the voyage from Africa is described in his poem \"Hodoeporicum\" (now lost). There, he associated in the imperial circle with the administrator and polemicist Sossianus Hierocles and the pagan philosopher Porphyry; he first met Constantine, and Galerius, whom he cast as villain in the persecutions. Having converted to Christianity, he resigned his post before Diocletian's purging of Christians from his immediate staff and before the publication of Diocletian's first \"Edict against the Christians\" (February 24, 303).\n\nAs a Latin \"rhetor\" in a Greek city, he subsequently lived in poverty according to Saint Jerome and eked out a living by writing until Constantine I became his patron. The persecution forced him to leave Nicomedia and from the outbreak of hostilities until perhaps 311 or 313 he had to live elsewhere. The Emperor Constantine appointed the elderly Lactantius Latin tutor to his son Crispus. Lactantius followed Crispus to Trier in 317, when Crispus was made Caesar (lesser co-emperor) and sent to the city. Crispus was put to death by order of his father Constantine I in 326, but when Lactantius died and under what circumstances are unknown.\n\nLike so many of the early Christian authors, Lactantius depended on classical models. The early humanists called him the \"Christian Cicero\" (\"Cicero Christianus\"). A translator of the \"Divine Institutes\" wrote: \"Lactantius has always held a very high place among the Christian Fathers, not only on account of the subject-matter of his writings, but also on account of the varied erudition, the sweetness of expression, and the grace and elegance of style, by which they are characterized.\"\n\nHe wrote apologetic works explaining Christianity in terms that would be palatable to educated people who still practiced the traditional religions of the Empire. He defended Christian beliefs against the criticisms of Hellenistic philosophers. His \"Divinae Institutiones\" (\"Divine Institutes\") were an early example of a systematic presentation of Christian thought.\n\nHe was considered somewhat heretical after his death, but Renaissance humanists took a renewed interest in him, more for his elaborately rhetorical Latin style than for his theology. His works were copied in manuscript several times in the 15th century and were first printed in 1465 by the Germans Arnold Pannartz and Konrad Sweynheim at the Abbey of Subiaco. This edition was the first book printed in Italy to have a date of printing, as well as the first use of a Greek alphabet font anywhere, which was apparently produced in the course of printing, as the early pages leave Greek text blank. It was probably the fourth book ever printed in Italy. A copy of this edition was sold at auction in 2000 for more than $1 million.\n\nLike many writers in the first few centuries of the early church, Lactantius took a premillennialist view, holding that the second coming of Christ will precede a millennium or a thousand-year reign of Christ on earth. According to Charles E. Hill, \"With Lactantius in the early fourth century we see a determined attempt to revive a more “genuine” form of chiliasm.\" Lactantius quoted the Sibyls extensively (although the Sibylline Oracles are now known to be pseudepigrapha). Book VII of \"The Divine Institutes\" indicates a familiarity with Jewish, Christian, Egyptian and Iranian apocalyptic material.\n\nNone of the fathers thus far had been more verbose on the subject of the millennial kingdom than Lactantius or more particular in describing the times and events preceding and following. He held to the literalist interpretation of the millennium, that the millennium originates with the second advent of Christ and marks the destruction of the wicked, the binding of the devil and the raising of the righteous dead.\n\nHe depicted Jesus reigning with the resurrected righteous on this earth during the seventh thousand years prior to the general judgment. In the end, the devil, having been bound during the thousand years, is loosed; the enslaved nations rebel against the righteous, who hide underground until the hosts, attacking the Holy City, are overwhelmed by fire and brimstone and mutual slaughter and buried altogether by an earthquake: rather unnecessarily, it would seem, since the wicked are thereupon raised again to be sent into eternal punishment. Next, God renews the earth, after the punishment of the wicked, and the Lord alone is thenceforth worshiped in the renovated earth.\n\nLactantius confidently stated that the beginning of the end would be the fall, or breakup, of the Roman Empire. However, this view fell out of favor with the conversion of Constantine and the improved lot of Christians: \"Many Christians felt that any expectation of the downfall of the empire was as disloyal to God as it was to Rome.\"\n\nAttempts to determine the time of the End were viewed as in contradiction to Acts 1:7: \"It is not for you to know the times or seasons that the Father has established by his own authority,\" and Mark 13:32: \"But of that day or hour, no one knows, neither the angels in heaven, nor the Son, but only the Father.\"\n\n\n\n\n"}
{"id": "18386", "url": "https://en.wikipedia.org/wiki?curid=18386", "title": "Laconia", "text": "Laconia\n\nLaconia (, \"Lakonía\", ) is a region of Greece in the southeastern part of the Peloponnese peninsula. Its administrative capital is Sparta. The word \"laconic\" is derived from the name of the region by analogy—to speak in a concise way, as the Spartans were reputed by the Athenians to do.\n\nLaconia is bordered by Messenia to the west and Arcadia to the north and is surrounded by the Myrtoan Sea to the east and by the Laconian Gulf and the Mediterranean Sea to the south. It encompasses Cape Malea and Cape Tainaron and a large part of the Mani Peninsula. The Mani Peninsula is in the west region of Lakonia. The islands of Kythira and Antikythera lie to the south, but they administratively belong to the Attica regional unit of islands. The island, Elafonisos, situated between the Laconian mainland and Kythira, is part of Laconia.\n\nThe Eurotas is the longest river in the prefecture. The valley of the Eurotas is predominantly an agricultural region that contains many citrus groves, olive groves, and pasture lands. It is the location of the largest orange production in the Peloponnese and probably in all of Greece. Lakonia, a brand of orange juice, is based in Amykles.\n\nThe main mountain ranges are the Taygetus (2,407 m) in the west and the Parnon (1,961 m) in the northeast. Taygetus, known as Pentadaktylos (\"five-fingers\") throughout the Middle Ages, is west of Sparta and the Eurotas valley. It is the highest mountain in Laconia and the Peloponnese and is mostly covered with pine trees. Two roads join the Messenia and Laconia prefectures: one is a tortuous mountain pass through Taygetus and the other bypasses the mountain via the Mani district to the south.\n\nThe stalactite cave, Dirou, a major tourist attraction, is located south of Areopolis in the southwest of Laconia.\n\nLaconia has a Mediterranean climate with warm winters and hot summers. Snow is rare on the coast throughout the winter but is very common in the mountains.\n\nEvidence of Neolithic settlement in southern Laconia has been found during excavations of the Alepotrypa cave site. In ancient Greece, this was the principal region of the Spartan state. For much of classical antiquity the Spartan sphere of influence expanded to Messenia, whose inhabitants (the Helots) were enslaved. Significant archaeological recovery exists at the Vaphio-tomb site in Laconia. Found here is advanced Bronze Age art as well as evidence of cultural associations with the contemporaneous Minoan culture on Crete. Laconia was at war with the Kingdom of Macedonia and saw several battles; at the end of the Mycenaean period, the population of Laconia sharply declined. From the early-2nd century BC until 395 AD, it was a part of the Roman Empire.\n\nIn the medieval period, Laconia formed part of the Byzantine Empire. Following the Fourth Crusade, it was gradually conquered by the Frankish Principality of Achaea. In the 1260s, however, the Byzantines recovered Mystras and other fortresses in the region and managed to evict the Franks from Laconia, which became the nucleus of a new Byzantine province. By the mid-14th century, this evolved into the Despotate of Morea, held by the last Greek ruling dynasty, the Palaiologoi. With the fall of the Despotate to the Ottomans in 1460, Laconia was conquered as well.\n\nWith the exception of a 30-year interval of Venetian rule, Laconia remained under Ottoman control until the outbreak of the Greek War of Independence of 1821. Following independence, Sparta was selected as the capital of the modern prefecture, and its economy and agriculture expanded. With the incorporation of the British-ruled Ionian Islands into Greece in 1864, Elafonissos became part of the prefecture. After World War II and the Greek Civil War, its population began to somewhat decline, as people moved from the villages toward the larger cities of Greece and abroad.\n\nIn 1992, a devastating fire ruined the finest olive crops in the northern part of the prefecture, and affected the area of Sellasia along with Oinountas and its surrounding areas. Firefighters, helicopters and planes battled for days to put out the horrific fire.\n\nThe Mani portion along with Gytheio became famous in Greece for filming episodes of \"Vendetta\", broadcast on Mega Channel throughout Greece and abroad on Mega Cosmos.\n\nIn early 2006, flooding ruined olive and citrus crops as well as properties and villages along the Eurotas river. In the summer 2006, a terrible fire devastated a part of the Mani Peninsula, ruining forests, crops, and numerous villages.\n\nThe regional unit, Laconia, is subdivided into five municipalities. These are (number as in the map in the infobox):\n\nAs a part of the 2011 Kallikratis government reform, regional unit Laconia was created out of the former prefecture Laconia (). The prefecture had the same territory as the present regional unit. At the same time, the municipalities were reorganised, according to the table below.\n\n\"Note:\" Provinces no longer hold any legal status in Greece.\n\n\nThe main cities and towns of Laconia are (ranked by 2011 census population):\n\n\n\n\n\n"}
{"id": "18387", "url": "https://en.wikipedia.org/wiki?curid=18387", "title": "Lanista", "text": "Lanista\n\nLanista is a genus of African bush-crickets (Orthoptera: Tettigoniidae) in the subfamily Conocephalinae.\n\n"}
{"id": "18388", "url": "https://en.wikipedia.org/wiki?curid=18388", "title": "Laocoön", "text": "Laocoön\n\nLaocoön (; , ), the son of Acoetes, is a figure in Greek and Roman mythology and the Epic Cycle. He was a Trojan priest who was attacked, with his two sons, by giant serpents sent by the gods. The story of Laocoön has been the subject of numerous artists, both in ancient and in more contemporary times.\n\nThe most detailed description of Laocoön's grisly fate was provided by Quintus Smyrnaeus in \"Posthomerica\", a later, literary version of events following the \"Iliad\". According to Quintus, Laocoön begged the Trojans to set fire to the horse to ensure it was not a trick. Athena, angry with him and the Trojans, shook the ground around Laocoön's feet and painfully blinded him. The Trojans, watching this unfold, assumed Laocoön was punished for the Trojans' mutilating and doubting Sinon, the undercover Greek soldier sent to convince the Trojans to let him and the horse inside their city walls. Thus, the Trojans wheeled the great wooden Horse in. Laocoön did not give up trying to convince the Trojans to burn the horse, and Athena made him pay even further. She sent two giant sea serpents to strangle and kill him and his two sons. In another version of the story, it was said that Poseidon sent the sea serpents to strangle and kill Laocoön and his two sons. \nAccording to Apollodorus, it was Apollo who sent the two sea serpents. Laocoön had insulted Apollo by sleeping with his wife in front of the \"divine image\".\n\nVirgil used the story in the \"Aeneid.\" According to Virgil, Laocoön advised the Trojans to not receive the horse from the Greeks. They disregarded Laocoön's advice and were taken in by the deceitful testimony of Sinon. The enraged Laocoön threw his spear at the Horse in response. Minerva then sent sea-serpents to strangle Laocoön and his two sons, Antiphantes and Thymbraeus, for his actions. \"Laocoön, ostensibly sacrificing a bull to Neptune on behalf of the city (lines 201ff.), becomes himself the tragic victim, as the simile (lines 223–24) makes clear. In some sense, his death must be symbolic of the city as a whole,\" S. V. Tracy notes. According to the Hellenistic poet Euphorion of Chalcis, Laocoön is in fact punished for procreating upon holy ground sacred to Poseidon; only unlucky timing caused the Trojans to misinterpret his death as punishment for striking the Horse, which they bring into the city with disastrous consequences. The episode furnished the subject of Sophocles' lost tragedy, \"Laocoön\".\n\nIn \"Aeneid\", Virgil describes the circumstances of Laocoön's death:\n\nThe story of Laocoön is not mentioned by Homer, but it had been the subject of a tragedy, now lost, by Sophocles and was mentioned by other Greek writers, though the events around the attack by the serpents vary considerably. The most famous account of these is now in Virgil's \"Aeneid\" where Laocoön was a priest of Poseidon (or Neptune for the Romans), who was killed with both his sons after attempting to expose the ruse of the Trojan Horse by striking it with a spear.\nVirgil gives Laocoön the famous line \"Equō nē crēdite, Teucrī / Quidquid id est, timeō Danaōs et dōna ferentēs\", or \"Do not trust the Horse, Trojans / Whatever it is, I fear the Greeks even bearing gifts.\" This line is the source of the saying: \"Beware of Greeks bearing gifts.\"\n\nIn Sophocles, however, he was a priest of Apollo who should have been celibate but had married. The serpents killed only the two sons, leaving Laocoön himself alive to suffer. In other versions he was killed for having committed an impiety by making love with his wife in the presence of a cult image in a sanctuary, or simply making a sacrifice in the temple with his wife present. In this second group of versions, the snakes were sent by Poseidon and in the first by Poseidon and Athena, or Apollo, and the deaths were interpreted by the Trojans as proof that the horse was a sacred object. The two versions have rather different morals: Laocoön was either punished for doing wrong, or for being right.\n\nThe death of Laocoön was famously depicted in a much-admired marble \"Laocoön and His Sons\", attributed by Pliny the Elder to the Rhodian sculptors Agesander, Athenodoros, and Polydorus, which stands in the Vatican Museums, Rome. Copies have been executed by various artists, notably Baccio Bandinelli. These show the complete sculpture (with conjectural reconstructions of the missing pieces) and can be seen in Rhodes, at the Palace of the Grand Master of the Knights of Rhodes, Rome, the Uffizi Gallery in Florence and in front of the Archaeological Museum, Odessa, Ukraine, amongst others.\n\nThe marble Laocoön provided the central image for Lessing's \"Laocoön\", 1766, an aesthetic polemic directed against Winckelmann and the comte de Caylus. Daniel Albright reengages the role of the figure of Laocoön in aesthetic thought in his book \"Untwisting the Serpent: Modernism in Literature, Music, and Other Arts\". [cite El Greco painting]\n\nIn addition to other literary references, John Barth employs a bust of Laocoön in his novella, \"The End of the Road\". The R.E.M. song \"Laughing\" references Laocoön, rendering him female (\"Laocoön and her two sons\"). The marble's pose is parodied in the comic book \"Asterix and the Laurel Wreath\". American author Joyce Carol Oates also references Laocoön in her 1989 novel \"American Appetites\". In Stave V of \"A Christmas Carol\", by Charles Dickens (1843), Scrooge awakes on Christmas morning, \"making a perfect Laocoon of himself with his stockings\". Barbara Tuchman's \"The March of Folly\" begins with an extensive analysis of the Laocoön story. The American feminist poet and author Marge Piercy includes a poem titled, \"Laocoön is the name of the figure\", in her collection \"Stone, Paper, Knife\" (1983), relating love lost and beginning.\n\nIn Hector Berlioz's opera \"Les Troyens\", the death of Laocoon is a pivotal moment of the first act after Aeneas' entrance, sung by eight singers and a double choir (\"ottetto et double chœur\"). It begins with the verse \"Châtiment effroyable\" (\"frightful punishment\").\n\n\n\nCompiled by Tracy, 1987:452 note 3, which also mentions a fragmentary line possibly by Nicander.\n\n"}
{"id": "18389", "url": "https://en.wikipedia.org/wiki?curid=18389", "title": "Limburg an der Lahn", "text": "Limburg an der Lahn\n\nLimburg an der Lahn (officially abbreviated \"Limburg a. d. Lahn\") is the district seat of Limburg-Weilburg in Hesse, Germany.\n\nLimburg lies in western Hessen between the Taunus and the Westerwald on the river Lahn.\n\nThe town lies roughly centrally in a basin within the Rhenish Slate Mountains which is surrounded by the low ranges of the Taunus and Westerwald and called the Limburg Basin (\"Limburger Becken\"). Owing to the favourable soil and climate, the Limburg Basin stands as one of Hesse's richest agricultural regions and moreover, with its convenient Lahn crossing, it has been of great importance to transport since the Middle Ages. Within the basin, the Lahn's otherwise rather narrow lower valley broadens out noticeably, making Limburg's mean elevation only 117 m above sea level.\n\nLimburg forms, together with the town of Diez, a middle centre (in terms of Central place theory) but partially functions as an upper centre to western Middle Hesse.\n\nLimburg's residential neighbourhoods reach beyond the town limits; the neighbouring centres of Elz and Diez run seamlessly together.\n\nSurrounding towns and communities are the community of Elz and the town of Hadamar in the north, the community of Beselich in the northeast, the town of Runkel in the east, the communities of Villmar and Brechen in the southeast, the community of Hünfelden in the south (all in Limburg-Weilburg), the community of Holzheim in the southwest, and the town of Diez and the communities of Aull and Gückingen in the west (all in the Rhein-Lahn-Kreis in Rhineland-Palatinate).\n\nThe nearest major cities are Wetzlar and Gießen to the north east, Wiesbaden and Frankfurt to the south and Koblenz to the west.\n\nThe town consists of eight formerly autonomous \"Ortsteile\" or villages, listed here by population.\n\n\nBlumenrod is also often called a constituent community, although this is actually only a big residential neighbourhood in the main town’s south end. Its landmark is the \"Domäne Blumenrod\", a former manor house that has been restored and remodelled by the Limburg Free Evangelical community.\n\nLimburg’s biggest outlying centre is Lindenholzhausen (3,329 residents as of June 2006); the second biggest is Linter.\n\nThe derivation of the name “Limburg” is not quite clear and may well hearken back to a castle built here (\"Burg\" means \"castle\" in German). In 910 the town was first mentioned as \"Lintpurc\". Two of the popular theories are:\n\nAbout 800 A.D., the first castle buildings arose on the Limburg crags. This was probably designed for the protection of a ford over the river Lahn. In the decades that followed, the town developed under the castle's protection. Limburg is first mentioned in documents in 910 under the name of \"Lintpurc\" when Louis the Child granted Konrad Kurzbold an estate in the community on which he was to build a church. Konrad Kurzbold laid the foundation stone for Saint George's Monastery Church, where he was also buried. The community soon increased in importance with the monastery's founding and profited from the lively goods trade on the \"Via Publica\".\n\nIn 1150, a wooden bridge was built across the Lahn. The long-distance road from Cologne to Frankfurt am Main subsequently ran through Limburg. In the early 13th century, Limburg Castle was built in its current form. Shortly afterwards, the town passed into the ownership of the Lords of Ysenburg. In 1214, the community was granted town rights. Remains of the fortification wall from the years 1130, 1230 and 1340 with a maximum length of roughly one thousand metres indicate to this day the blossoming town's quick development in the Middle Ages. There is proof of a mint in Limburg in 1180.\n\nOne line of the Lords of Ysenburg resided from 1258 to 1406 at Limburg Castle and took their name from their seat, Limburg. From this line came the House of Limburg-Stirum and also Imagina of Isenburg-Limburg, German King Adolf's wife.\n\nThe ruling class among the mediaeval townsfolk were rich merchant families whose houses stood right near the castle tower and were surrounded by the first town wall once it was built. The area of today's Rossmarkt (\"Horse Market\"), in which many simple craftsmen lived, was only brought within the fortifications once the second town wall was built. The inhabitants there, however, unlike the merchant élite, were accorded no entitlement to a voice in town affairs and were not allowed to send representatives to the town council. Nevertheless, they had to bear the main financial burden of running the town. Only in 1458 were they allowed to send two representatives to town council.\n\nSaint George's Cathedral (\"Sankt-Georgs-Dom\") built on the old monastery church's site, and also called \"Georgsdom\", was consecrated in 1235. On 14 May 1289, a devastating fire wiped out great parts of the inner town, although these were subsequently rebuilt. One of the houses built at that time was the Römer 2-4-6, which is today one of Germany's oldest half-timbered houses. In 1337, Limburg's Jews were expelled from the town. Only in 1341 were they once again able to settle in the town, by royal decree. In 1344 a half share of the town was pledged to the Electorate of Trier, and in 1420, the town passed wholly into the ownership of Trier. This event, along with another town fire in 1342, the Black Death in 1349, 1356 and 1365, but above all the rise of the Territorial Princes, led to a gradual decline. In 1315 and 1346, the old stone Lahn Bridge was built (presumably in two sections).\n\nAgainst the background of the German Peasants' War, unrest also arose among the townsfolk in 1525. After the Elector of Trier had demanded that the townsmen turn a Lutheran preacher out of the town, a board made up of townsmen who were ineligible for council functions handed the council a 30-point comprehensive list of demands on 24 May. It dealt mainly with financial participation and equality in taxation, trade and building issues with the merchant class. In the days that followed, these demands were reduced in negotiations between the council and the board to 16 points, which were likely also taken up with the Elector afterwards. On 5 August, however, Archbishop Richard ordered the council to overturn all concessions to the townsmen. Furthermore, a ban on assembly was decreed, and the ineligible townsmen were stripped of their right to send two representatives to council.\n\nIn 1806, Limburg came into the possession of the newly founded Duchy of Nassau. In 1818 the town wall was torn down. In 1827 the town was raised to a Catholic episcopal seat. In 1866 the Duchy and with it Limburg passed to Prussia in the wake of the Austro-Prussian War. As of 1862, Limburg became a railway hub and from 1886 a district seat. In 1892, the Pallottines settled in town, but only the men; the women came in 1895.\n\nDuring World War I there was a major prisoner of war camp at Limburg an der Lahn. Many Irish members of the British Army were interned there until the end of the war and at one stage they were visited by the Irish republican leader Roger Casement in an attempt to win recruits for the forthcoming Irish rebellion.\n\nFrom 1919 to 1923, Limburg was the \"capital\" of a short-lived state called Free State Bottleneck (or \"Freistaat Flaschenhals\" in German) because it was the nearest unoccupied town to the Weimar Republic.\n\nThe municipal election held on 6 March 2016 yielded the following results:\nThe town's mayor is currently Marius Hahn (SPD).\n\n\nIn 1956, a \"Patenschaft\" – roughly, a sponsorship – was undertaken for Sudeten Germans driven out of the town of Mährisch Neustadt in the Sternberg district.\n\nLimburg is a traditional transport hub. Already in the Middle Ages, the \"Via Publica\" crossed the navigable Lahn here. Today the A 3 (Emmerich–Oberhausen–Cologne–Frankfurt–Nuremberg–Passau) and \"Bundesstraße\" 8, which both follow the \"Via Publica's\" alignment as closely as possible, run through the town. \"Bundesstraße\" 49 links Limburg to Koblenz towards the west and Wetzlar and Gießen towards the east. The section between Limburg and Wetzlar is currently being widened to four lanes. This section as far as Obertiefenbach is also known as \"Die lange Meil\" (\"The Long Mile\"). \"Bundesstraße\" 54 links Limburg on the one hand with Siegen to the north and on the other by way of Diez with Wiesbaden, which may likewise be reached over \"Bundesstraße\" 417 (\"Hühnerstraße\").\n\nAs early as 1248, a wooden bridge spanned the Lahn, but was replaced after the flooding in 1306 by a stone bridge, the \"Alte Lahnbrücke\". Other road bridges are the \"Lahntalbrücke Limburg\" (1964) on the A 3, the \"Lahnbrücke\" near Staffel and the \"Neue Lahnbrücke\" from 1968, over which run the \"Bundesstraßen\" before they cross under the inner town through the \"Schiedetunnel\", a bypass tunnel.\n\nOnce the \"Lahntalbahn\" had been built, Limburg was joined to the railway network in 1862. Limburg railway station developed into a transport hub. Eschhofen station is also in Limburg. Other railway lines are the \"Unterwesterwaldbahn\", the \"Oberwesterwaldbahn\" and the Main-Lahn Railway. At Niedernhausen station on the \"Main-Lahn Railway\", transfer to the \"Ländchesbahn\" to Wiesbaden is possible. With the exception of the upper section of the \"Lahntalbahn\" and express lines to Koblenz and Frankfurt, which are still served by Deutsche Bahn, all railway lines are run by Vectus Verkehrsgesellschaft mbH, based in Limburg.\n\nOnce the InterCityExpress Cologne-Frankfurt high-speed rail line had been built, Limburg acquired an ICE station. It is the only railway station in Germany at which exclusively ICE trains stop. The high-speed rail line crosses the Lahn over the \"Lahntalbrücke\" and then dives into the \"Limburger Tunnel\".\n\nThe nearest airport is Frankfurt Airport, 63 km away on the A 3. Travel time there on the ICE is roughly 20 minutes. Cologne Bonn Airport is 110 km away and can be reached on the ICE in 44 minutes.\n\nThe Lahn between Lahnstein and Wetzlar is a \"Bundeswasserstraße\" (\"Federal waterway\"). Since the \"Lahntalbahn's\" expansion, however, the waterway's importance has been declining. It is used mainly by tourists with small motorboats, canoes and rowboats. Limburg is the landing site of the tourboat \"Wappen von Limburg\".\n\n\nLimburg has four schools which lead to, among other qualifications, the Abitur:\n\nProfessional training schools:\n\nHauptschulen and Realschulen:\n\nLibraries:\n\nThe hospital perched on the Schafsberg overlooking the town has at its disposal 433 beds and 15 specialist departments.\n\nIn Limburg there are various sport clubs; some are even represented in \"Bundesligen\", and even at the world level.\n\nThe Evangelical Church offers with its \"Jugendfreizeitstätte Limburg\" (JFS for short, meaning \"Youth Leisure Place\") a meeting place for youth with many events. With table football, Internet café and many events, this institution is not only church-based, with two staff and a \"Zivildienstleistender\" supporting the visitors not only with their problems.\n\nThe \"Mütterzentrum Limburg\" is a family meeting place for those with or without children on Hospitalstraße. The club is supported by the town of Limburg and the \"Bundesland\" of Hesse and offers among other things a parents' service that looks after children, a broad array of course offerings for children and adults, a miniature kindergarten and a café.\n\n\nThe cabaret troupe \"Thing\", founded more than 25 years ago, moved after a short time from its initial home in the outlying centre of Staffel to the Josef-Kohlmaier-Halle, a civic event hall, where its stage can now be found in the hall's club rooms. The troupe is run by an independent acting club. On the programme are chanson, cabaret, literature and jazz as well as folk, Rock and performances by singer-songwriters. It makes a point of furthering young artists. Each month, three or four events are staged.\n\nThe dedication of \"Thing\" was recognized on 6 December 2003 when the \"Kulturpreis Mittelhessen\" (\"Middle Hesse Culture Prize\") was awarded to it.\n\nLimburg Cathedral has a famous boys' choir, the \"Limburger Domsingknaben\", although they are actually based at the \"Musical Boarding School\" in Hadamar just outside Limburg.\n\nIn Limburg there are several museums. The most important are:\n\nOnly a few towns, like Limburg, have been able to keep a full set of nearly unscathed mediaeval buildings. The formerly walled town core between St. George’s Cathedral, Grabenstraße (a street marking the old town moat) and the 600-year-old Lahn Bridge thus stands today as a whole under monumental protection.\n\nThe \"Altstadt\" (\"Old Town\") boasts a fine cathedral and is full of narrow streets with timber-frame houses, dating mainly from the 17th and 18th centuries. That's why it is located on the German Timber-Frame Road.\n\n(limited to those featuring in Wikipedia (EN) \n\n\n\n\n"}
{"id": "18390", "url": "https://en.wikipedia.org/wiki?curid=18390", "title": "Lavrentiy Beria", "text": "Lavrentiy Beria\n\nLavrentiy Pavlovich Beria (; ; , ; 29 March [17 March old style] 1899 – 23 December 1953) was a Soviet politician, Marshal of the Soviet Union and state security administrator, chief of the Soviet security and secret police apparatus (NKVD) under Joseph Stalin during World War II, and promoted to deputy premier under Stalin from 1941. He later officially joined the Politburo in 1946.\n\nBeria was the longest-lived and most influential of Stalin's secret police chiefs, wielding his most substantial influence during and after World War II. Following the Soviet invasion of Poland in 1939 he was responsible for organizing the Katyn massacre. He simultaneously administered vast sections of the Soviet state and acted as the \"de facto\" Marshal of the Soviet Union in command of NKVD field units responsible for barrier troops and Soviet partisan intelligence and sabotage operations on the Eastern Front during World War II. Beria administered the vast expansion of the Gulag labor camps and was primarily responsible for overseeing the secret detention facilities for scientists and engineers known as \"sharashkas\".\n\nHe attended the Yalta Conference with Stalin, who introduced him to U.S. President Franklin D. Roosevelt as \"our Himmler\". After the war, he organized the Communist takeover of the state institutions in Central Europe and Eastern Europe and political repressions in these countries. Beria's uncompromising ruthlessness in his duties and skill at producing results culminated in his success in overseeing the Soviet atomic bomb project. Stalin gave it absolute priority and the project was completed in under five years, having been accelerated by Soviet espionage against the West.\n\nAfter Stalin's death in March 1953, Lavrentiy Beria became First Deputy Premier of the Soviet Union and head of the Ministry of Internal Affairs. In this dual capacity, he formed a troika alongside Georgy Malenkov and Vyacheslav Molotov that briefly led the country in Stalin’s place. However, in a coup d'état launched by Nikita Khrushchev on June 1953, Beria was ultimately removed from power and subsequently arrested on charges of treason. He was sentenced to death and was executed by Pavel Batitsky on December 23, 1953.\n\nBeria was born in Merkheuli, near Sukhumi, in the Sukhum Okrug of the Kutais Governorate (now Gulripshi District, de facto Republic of Abkhazia, then part of the Russian Empire). He was from the Mingrelian ethnic group and grew up in a Georgian Orthodox family. Beria's mother, Marta Jaqeli (1868–1955), was deeply religious and church-going (she spent much time in church and died in a church building). She was previously married and widowed before marrying Beria's father, Pavel Khukhaevich Beria (1872–1922), a landowner from Abkhazia. Beria also had a brother (name unknown), and a deaf sister named Anna.\n\nIn his autobiography, Lavrentiy Beria mentioned only his sister and his niece, implying that his brother was (or any other siblings were) dead or had no relationship with Beria after he left Merkheuli. Beria attended a technical school in Sukhumi, and joined the Bolsheviks in March 1917 while a student in the Baku Polytechnicum (subsequently known as the Azerbaijan State Oil Academy). As a student, Beria distinguished himself in mathematics and the sciences. The Polytechnicum's curriculum concentrated on the petroleum industry.\n\nBeria also worked for the anti-Bolshevik Mussavatists in Baku. After the Red Army captured the city on 28 April 1920, Beria was saved from execution because there was not enough time to arrange his shooting and replacement, and Sergei Kirov possibly intervened. While in prison, he formed a connection with Nina Gegechkori (1905–10 June 1991) his cellmate's niece, and they eloped on a train. She was 17, a trained scientist from an aristocratic family.\nIn 1919, at the age of twenty, Beria started his career in state security when the security service of the Azerbaijan Democratic Republic hired him while still a student at the Polytechnicum. In 1920 or 1921 (accounts vary) Beria joined the Cheka, the original Bolshevik secret police. At that time, a Bolshevik revolt took place in the Menshevik-controlled Democratic Republic of Georgia, and the Red Army subsequently invaded. The Cheka became heavily involved in the conflict, which resulted in the defeat of the Mensheviks and the formation of the Georgian SSR. By 1922, Beria was deputy head of the Georgian branch of Cheka's successor, the OGPU.\n\nIn 1924, he led the repression of a Georgian nationalist uprising, after which up to 10,000 people were executed. For this display of \"Bolshevik ruthlessness,\" Beria was appointed head of the \"secret-political division\" of the Transcaucasian OGPU and was awarded the Order of the Red Banner.\n\nIn 1926, Beria became head of the Georgian OGPU; Sergo Ordzhonikidze, head of the Transcaucasian party, introduced him to fellow-Georgian Iosef Dzhughashvili, later known as Joseph Stalin. As a result, Beria became an ally in Stalin's rise to power. During his years at the helm of the Georgian OGPU, Beria effectively destroyed the intelligence networks that Turkey and Iran had developed in the Soviet Caucasus, while successfully penetrating the governments of these countries with his agents. He also took over Stalin's holiday security.\n\nBeria was appointed Secretary of the Communist Party in Georgia in 1931, and for the whole Transcaucasian region in 1932. He became a member of the Central Committee of the Communist Party of the Soviet Union in 1934. During this time, he began to attack fellow members of the Georgian Communist Party, particularly Gaioz Devdariani, who served as Minister of Education of the Georgian SSR. Beria ordered the executions of Devdariani's brothers George and Shalva, who held important positions in the Cheka and the Communist Party respectively.\n\nHe reportedly won Stalin's favour in the early 1930s, after faking a conspiracy to assassinate the Soviet leader that he then claimed to have foiled. By 1935, Beria had become one of Stalin's most trusted subordinates. He cemented his place in Stalin's entourage with a lengthy oration titled, \"On the History of the Bolshevik Organisations in Transcaucasia\" (later published as a book), which emphasized Stalin's role. When Stalin's purge of the Communist Party and government began in 1934 after the assassination of Leningrad party boss Sergei Kirov (1 December 1934), Beria ran the purges in Transcaucasia. He used the opportunity to settle many old scores in the politically turbulent Transcaucasian republics.\n\nIn June 1937, he said in a speech, \"Let our enemies know that anyone who attempts to raise a hand against the will of our people, against the will of the party of Lenin and Stalin, will be mercilessly crushed and destroyed.\"\n\nIn August 1938, Stalin brought Beria to Moscow as deputy head of the People's Commissariat for Internal Affairs (NKVD), the ministry which oversaw the state security and police forces. Under Nikolai Yezhov, the NKVD carried out the Great Purge: the imprisonment or execution of millions of people throughout the Soviet Union as alleged \"enemies of the people.\" By 1938, however, the oppression had become so extensive that it was damaging the infrastructure, economy and even the armed forces of the Soviet state, prompting Stalin to wind the purge down. Stalin had voted to appoint Georgy Malenkov as head of the NKVD, but he was overruled. In September, Beria was appointed head of the Main Administration of State Security (GUGB) of the NKVD, and in November he succeeded Yezhov as NKVD head. Yezhov was executed in 1940 and one account says he was personally strangled by Beria. The NKVD was purged next, with half of its personnel replaced by Beria loyalists, many of them from the Caucasus. \n\nAlthough Beria's name is closely identified with the Great Purge because of his activities while deputy head of the NKVD, his leadership of the organisation marked an easing of the repression begun under Yezhov. Over 100,000 people were released from the labour camps. The government officially admitted that there had been some injustice and \"excesses\" during the purges, which were blamed entirely on Yezhov. The liberalisation was only relative: arrests and executions continued, and in 1940, as war approached, the pace of the purges again accelerated. During this period, Beria supervised deportations of people identified as political enemies from Poland and the Baltic states after Soviet occupation of those regions.\n\nIn March 1939, Beria became a candidate member of the Communist Party's Politburo. Although he did not become a full member until 1946, he was already one of the senior leaders of the Soviet state. In 1941, Beria was made a Commissar General of State Security, the highest quasi-military rank within the Soviet police system of that time, effectively comparable to a Marshal of the Soviet Union.\n\nOn 5 March 1940, after the Gestapo–NKVD Third Conference was held in Zakopane, Beria sent a note (no. 794/B) to Stalin in which he stated that the Polish prisoners of war kept at camps and prisons in western Belarus and Ukraine were enemies of the Soviet Union, and recommended their execution. Most of them were military officers, but there were also intelligentsia, doctors, priests, and others in a total of more than 22,000 people. With Stalin's approval, Beria's NKVD executed them in what became known as the Katyn massacre.\n\nFrom October 1940 to February 1942, the NKVD under Beria carried out a new purge of the Red Army and related industries. In February 1941, Beria became Deputy Chairman of the Council of People's Commissars, and in June, following Nazi Germany's invasion of the Soviet Union, he became a member of the State Defense Committee (GKO). During World War II, he took on major domestic responsibilities and mobilized the millions of people imprisoned in NKVD Gulag camps into wartime production. He took control of the manufacture of armaments, and (with Georgy Malenkov) aircraft and aircraft engines. This was the beginning of Beria's alliance with Malenkov, which later became of central importance.\n\nIn 1944, as the Germans were driven from Soviet soil, Beria was in charge of dealing with the various ethnic minorities accused of anti-sovietism and/or collaboration with the invaders, including the Balkars, the Karachays, the Chechens, the Ingush, the Crimean Tatars, the Pontic Greeks and the Volga Germans. All these groups were deported to Soviet Central Asia (see \"Population transfer in the Soviet Union.\")\n\nIn December 1944, Beria's NKVD was assigned to supervise the Soviet atomic bomb project (\"Task No. 1\"), which built and tested a bomb by 29 August 1949. The project was extremely labour-intensive. At least 330,000 people, including 10,000 technicians, were involved. The Gulag system provided tens of thousands of people for work in uranium mines and for the construction and operation of uranium processing plants. They also constructed test facilities, such as those at Semipalatinsk and in the Novaya Zemlya archipelago. The NKVD also ensured the necessary security for the project.\n\nIn July 1945, as Soviet police ranks were converted to a military uniform system, Beria's rank was officially converted to that of Marshal of the Soviet Union. Although he had never held a traditional military command, Beria made a significant contribution to the victory of the Soviet Union in World War II through his organization of wartime production and his use of partisans. Stalin personally never thought much of it, and neither commented publicly on his performance nor awarded him recognition (i.e. Order of Victory), as he did for most other Soviet Marshals.\n\nAbroad, Beria had met with Kim Il-sung, the future leader of North Korea, several times when the Soviet troops had declared war on Japan and occupied the northern half of Korea from August 1945. Beria recommended that Stalin install a communist leader in the occupied territories.\n\nWith Stalin nearing 70, a concealed struggle for succession amongst his entourage dominated Kremlin politics in the post-war years. At the end of the war, Andrei Zhdanov seemed the most likely candidate. Zhdanov had served as the Communist Party leader in Leningrad during the war, and by 1946 had charge of all cultural matters. After 1946, Beria formed an alliance with Malenkov to counter Zhdanov's rise.\n\nIn January 1946, Beria resigned as chief of the NKVD while retaining general control over national security matters as Deputy Prime Minister and Curator of the Organs of State Security under Stalin. However, the new NKVD chief, Sergei Kruglov, was not a Beria man. Also, by the summer of 1946, Beria's man Vsevolod Nikolayevich Merkulov was replaced as head of the Ministry for State Security (MGB) by Viktor Abakumov. Abakumov had headed SMERSH from 1943 to 1946; his relationship with Beria involved close collaboration (since Abakumov owed his rise to Beria's support and esteem), but also rivalry. Stalin had begun to encourage Abakumov to form his own network inside the MGB to counter Beria's dominance of the power ministries. Kruglov and Abakumov moved expeditiously to replace Beria's men in the security apparatus leadership with new people. Very soon, Deputy Minister Stepan Mamulov of the Soviet Ministry of Internal Affairs was the only close Beria ally left outside foreign intelligence, on which Beria kept a grip. In the following months, Abakumov started carrying out important operations without consulting Beria, often working in tandem with Zhdanov, and on Stalin's direct orders. These operations were aimed by Stalin—initially tangentially, but with time more directly–at Beria.\n\nOne of the first such moves involved the Jewish Anti-Fascist Committee affair, which commenced in October 1946 and eventually led to the murder of Solomon Mikhoels and the arrest of many other members. This affair damaged Beria; not only had he championed the creation of the committee in 1942, but his own entourage included a substantial number of Jews.\n\nAfter Zhdanov died suddenly in August 1948, Beria and Malenkov consolidated their power by means of a purge of Zhdanov's associates in the so-called \"Leningrad Affair\". Those executed included Zhdanov's deputy, Alexey Kuznetsov; the economic chief, Nikolai Voznesensky; the Party head in Leningrad, Pyotr Popkov; and the Prime Minister of the Russian Republic, Mikhail Rodionov.\n\nDuring the postwar years, Beria supervised installation of Communist regimes in the countries of Eastern Europe and hand-picked the Soviet-backed leaders. Starting in 1948, Abakumov initiated several investigations against these leaders, which culminated with the arrest in November 1951 of Rudolf Slánský, Bedřich Geminder, and others in Czechoslovakia. These men were frequently accused of Zionism, \"rootless cosmopolitanism\", and providing weapons to Israel. Such charges deeply disturbed Beria, as he had directly ordered the sale of large amounts of Czech arms to Israel. Altogether, 14 Czechoslovak Communist leaders, 11 of them Jewish, were tried, convicted, and executed (see Slánský trial). Similar investigations in Poland and other Soviet satellite countries occurred at the same time.\n\nIn 1951, Abakumov was replaced by Semyon Ignatyev, who further intensified the anti-Semitic campaign. On 13 January 1953, the biggest anti-semitic affair in the Soviet Union started with an article in \"Pravda\" – it began what became known as the Doctors' plot, in which a number of the country's prominent Jewish physicians were accused of poisoning top Soviet leaders and arrested. Concurrently, the Soviet press began an anti-semitic propaganda campaign, euphemistically termed the \"struggle against rootless cosmopolitanism\". Initially, 37 men were arrested, but the number quickly grew into hundreds. Scores of Soviet Jews were dismissed from their jobs, arrested, sent to the Gulag, or executed. The \"Doctors' plot\" was presumably invented by Stalin as an excuse to dismiss Beria and replace him with Ignatiev or some other MGB functionary. A few days after Stalin's death on 5 March 1953, Beria freed all the arrested doctors, announced that the entire matter was fabricated, and arrested the MGB functionaries directly involved.\n\nIn other international issues, Beria (along with Mikoyan) correctly foresaw the victory (1949–1950) of Mao Zedong in the Chinese Civil War and greatly helped the Chinese Communists by letting them use Soviet-occupied Manchuria as a staging area and arranging large weapons shipments to the People's Liberation Army, mainly from the recently captured equipment of the Japanese Kwantung Army.\n\nAt Beria's trial in 1953, it became known that he had committed numerous rapes during the years he was NKVD chief. Simon Sebag-Montefiore, a biographer of Stalin, concluded the information \"reveals a sexual predator who used his power to indulge himself in obsessive depravity.\"\n\nHis case files in the Soviet archives contained the official testimony from Colonel Rafael Semyonovich Sarkisov and Colonel Sardion Nikolaevich Nadaraia, two of Beria's most senior NKVD bodyguards. They stated that, on warm nights during the war years, Beria was often driven slowly through the streets of Moscow in his armored Packard limousine. He would point out young women to be detained and escorted to his mansion, where wine and a feast awaited them. After dining, Beria would take the women into his soundproofed office and rape them. Beria's bodyguards reported that their duties included handing each victim a flower bouquet as she left Beria's house. Accepting it implied that the sex had been consensual; refusal would mean arrest. In one incident, his chief bodyguard, Sarkisov, reported that a woman who had been brought to Beria rejected his advances and ran out of his office; Sarkisov mistakenly handed her the flowers anyway, prompting the enraged Beria to declare, \"Now it's not a bouquet, it's a wreath! May it rot on your grave!\" The NKVD arrested the woman the next day.\n\nWomen also submitted to Beria's sexual advances in exchange for the promise of freeing their relatives from the Gulag. In one case, Beria picked up Tatiana Okunevskaya, a well-known Soviet actress, under the pretence of bringing her to perform for the Politburo. Instead he took her to his dacha, where he offered to free her father and grandmother from NKVD prison if she submitted. He then raped her, telling her: \"Scream or not, it doesn't matter.\" Beria, however, already knew that her relatives had been executed months earlier. Okunevskaya was arrested shortly afterwards and sentenced to solitary confinement in the Gulag, which she survived.\n\nBeria's sexually predatory nature was well known to the Politburo, and though Stalin took an indulgent viewpoint (considering Beria's wartime importance), he said, \"I don't trust Beria.\" In one instance, when Stalin learned his daughter was alone with Beria at his house, he telephoned her and told her to leave immediately. When Beria complimented Alexander Poskrebyshev's daughter on her beauty, Poskrebyshev quickly pulled her aside and instructed her, \"Don't ever accept a lift from Beria.\" After taking an interest in Marshal Kliment Voroshilov's daughter-in-law during a party at their summer dacha, Beria shadowed their car closely all the way back to the Kremlin, terrifying Voroshilov's wife.\n\nPrior to and during the war, Beria directed Sarkisov to keep a running list of the names and phone numbers of his sexual encounters. Eventually, he ordered Sarkisov to destroy the list as a security risk, but the colonel retained a secret handwritten copy. When Beria's fall from power began, Sarkisov passed the list to Viktor Abakumov, the former wartime head of SMERSH and now chief of the MGB – the successor to the NKVD. Abakumov was already aggressively building a case against Beria. Stalin, who was also seeking to undermine Beria, was thrilled by the detailed records kept by Sarkisov, demanding: \"Send me everything this asshole writes down!\" Sarkisov reported that Beria's sexual appetite had led to him contracting syphilis during the war, for which he was secretly treated without the knowledge of Stalin or the Politburo (a fact Beria later admitted during his interrogation). Although the Russian government acknowledged Sarkisov's handwritten list of Beria's victims on 17 January 2003, the victims' names will not be released until 2028.\n\nEvidence suggests that not only did Beria abduct and rape women, but that some were also murdered. His villa in Moscow is now the Tunisian Embassy (at ). In the mid 1990s, routine work in the grounds turned up the bone remains of several young women buried in the gardens. According to Martin Sixsmith, in a BBC documentary, \"Beria spent his nights having teenagers abducted from the streets and brought here for him to rape. Those who resisted were strangled and buried in his wife's rose garden.\"\n\nThe testimony of Sarkisov and Nadaraia has been partially corroborated by Edward Ellis Smith, an American who served in the U.S. embassy in Moscow after the war. According to historian Amy Knight, \"Smith noted that Beria's escapades were common knowledge among embassy personnel because his house was on the same street as a residence for Americans, and those who lived there saw girls brought to Beria's house late at night in a limousine.\"\n\nKhrushchev wrote in his memoirs that Beria had, immediately after Stalin's stroke, gone about \"spewing hatred against [Stalin] and mocking him.\" When Stalin showed signs of consciousness, Beria dropped to his knees and kissed his hand. When Stalin fell unconscious again, Beria immediately stood and spat.\n\nStalin's aide Vasili Lozgachev reported that Beria and Malenkov were the first members of the Politburo to see Stalin's condition when he was found unconscious. They arrived at Stalin's dacha at Kuntsevo at 03:00 on 2 March, after being called by Khrushchev and Bulganin. The latter two did not want to risk Stalin's wrath by checking themselves. Lozgachev tried in futility to explain to Beria that the then-unconscious Stalin (still in his soiled clothing) was \"sick and needed medical attention.\" Beria angrily dismissed his claims as panic-mongering and quickly left, ordering him, \"Don't bother us, don't cause a panic and don't disturb Comrade Stalin!\" Calling a doctor was deferred for a full 12 hours after Stalin was rendered paralyzed, incontinent, and unable to speak. This decision is noted as \"extraordinary\" by the historian Simon Sebag-Montefiore, but also consistent with the standard Stalinist policy of deferring all decision-making (no matter how necessary or obvious) without official orders from higher authority.\n\nBeria's decision to avoid immediately calling a doctor was tacitly supported (or at least not opposed) by the rest of the Politburo, which was rudderless without Stalin's micromanagement and paralyzed by a legitimate fear he would suddenly recover and wreak violent reprisal on anyone who had dared to act without his orders. Stalin's suspicion of doctors in the wake of the Doctors' Plot was well known. At the time of his sickness, his private physician was already being tortured in the basement of the Lubyanka for suggesting the leader required more bed rest.\n\nAfter Stalin's death, Beria claimed to have killed him. This aborted a final purge of Old Bolsheviks Mikoyan and Molotov, for which Stalin had been laying the groundwork in the year prior to his death. Shortly after Stalin's death, Beria announced triumphantly to the Politburo that he had \"done [Stalin] in\" and \"saved [us] all\", according to Molotov's memoirs. The assertion that Stalin was poisoned by Beria's associates has been supported by Edvard Radzinsky and other authors.\n\nAfter Stalin's death, Beria's ambitions sprang into full force. In the uneasy silence following the cessation of Stalin's last agonies, Beria was the first to dart forward to kiss his lifeless form (a move likened by Sebag-Montefiore to \"wrenching a dead King's ring off his finger\"). While the rest of Stalin's inner circle (even Molotov, saved from certain liquidation) stood sobbing unashamedly over the body, Beria reportedly appeared \"radiant\", \"regenerated\", and \"glistening with ill-concealed relish.\" When Beria left the room, he broke the somber atmosphere by shouting loudly for his driver, his voice echoing with what Stalin's daughter Svetlana Alliluyeva called \"the ring of triumph unconcealed.\" Alliluyeva noticed how the Politburo seemed openly frightened of Beria and unnerved by his bold display of ambition. \"He's off to take power,\" Mikoyan recalled muttering to Khrushchev. That prompted a \"frantic\" dash for their own limousines to intercept him at the Kremlin.\n\nAfter Stalin's death, Beria was appointed First Deputy Premier and reappointed head of the MVD, which he merged with the MGB. His close ally Malenkov was the new Prime Minister and initially the most powerful man in the post-Stalin leadership. Beria was second most powerful, and given Malenkov's personal weakness, was poised to become the power behind the throne and ultimately leader himself. Khrushchev became Party Secretary. Voroshilov became Chairman of the Presidium of the Supreme Soviet (i.e., the head of state).\n\nGiven his record, it is not surprising that the other Party leaders were suspicious of Beria's motives. Khrushchev opposed the alliance between Beria and Malenkov, but he was initially unable to challenge them. His opportunity came in June 1953 when a spontaneous uprising against the East German Communist regime broke out in East Berlin.\n\nBased on Beria's own statements, other leaders suspected that in the wake of the uprising, he might be willing to trade the reunification of Germany and the end of the Cold War for massive aid from the United States, as had been received in World War II. The cost of the war still weighed heavily on the Soviet economy. Beria craved the vast financial resources that another (more sustained) relationship with the United States could provide. For example, Beria gave Estonia, Latvia and Lithuania serious prospects of national autonomy, possibly similarly to other Soviet satellite states in Europe. Regarding East Germany Beria said, \"It's not even a real state but one kept in being only by Soviet troops.\"\n\nThe East German uprising convinced Molotov, Malenkov, and Nikolai Bulganin that Beria's policies were dangerous and destabilizing to Soviet power. Within days of the events in Germany, Khrushchev persuaded the other leaders to support a Party \"coup\" against Beria; Beria's principal ally Malenkov abandoned him.\n\nOn 26 June 1953, Beria was arrested and held in an undisclosed location near Moscow. Accounts of Beria's fall vary considerably. By the most likely account, Khrushchev prepared an elaborate ambush, convening a meeting of the Presidium on 26 June, where he suddenly launched a scathing attack on Beria, accusing him of being a traitor and spy in the pay of British intelligence. Beria was taken completely by surprise. He asked, \"What's going on, Nikita Sergeyevich? Why are you picking fleas in my trousers?\" Molotov and others quickly spoke against Beria one after the other, followed by a motion by Khrushchev for his instant dismissal.\n\nWhen Beria finally realized what was happening and plaintively appealed to Malenkov to speak for him, his old friend and crony silently hung his head and refused to meet his gaze. Malenkov pressed a button on his desk as the pre-arranged signal to Marshal Georgy Zhukov and a group of armed officers in a nearby room who burst in and arrested Beria.\n\nBeria was taken first to the Moscow guardhouse and then to the bunker of the headquarters of Moscow Military District. Defence Minister Nikolai Bulganin ordered the Kantemirovskaya Tank Division and Tamanskaya Motor Rifle Division to move into Moscow to prevent security forces loyal to Beria from rescuing him. Many of Beria's subordinates, proteges and associates were also arrested, among them Vsevolod Merkulov, Bogdan Kobulov, Sergey Goglidze, Vladimir Dekanozov, Pavel Meshik, and Lev Vlodzimirskiy. \"Pravda\" did not announce Beria's arrest until 10 July, crediting it to Malenkov and referring to Beria's \"criminal activities against the Party and the State.\"\n\nBeria and the others were tried by a special session (\"spetsialnoye sudebnoye prisutstvie\" ) of the Supreme Court of the Soviet Union on 23 December 1953 with no defense counsel and no right of appeal. Marshal Ivan Konev was the chairman of the court.\n\nBeria was found guilty of:\n\nBeria and all the other defendants were sentenced to death on 23 December 1953. When the death sentence was carried out, Beria pleaded on his knees for mercy before collapsing to the floor and wailing and crying, but to no avail. The other six defendants were executed by firing squad on the same day the trial ended. Beria was executed separately. He was shot through the forehead by General Pavel Batitsky who had to stuff a rag into Beria's mouth to silence him. His final moments bore great similarity to those of his own predecessor, NKVD Chief Nikolai Yezhov, who begged for his life before his execution in 1940. His body was subsequently cremated and the remains buried in a forest near Moscow.\n\nBeria is the central character in \"Good Night, Uncle Joe\" by Canadian playwright David Elendune. The play is a fictionalised account of the events leading up to Stalin's death.\n\nGeorgian film director Tengiz Abuladze based the character of dictator Varlam Aravidze on Beria in his 1984 film \"Repentance\". Although banned in the Soviet Union for its semi-allegorical critique of Stalinism, it premiered at the 1987 Cannes Film Festival, winning the FIPRESCI Prize, Grand Prize of the Jury, and the Prize of the Ecumenical Jury.\n\nBritish actor Bob Hoskins played Beria in the 1991 film \"Inner Circle\". He was portrayed by Roshan Seth in the 1992 film \"Stalin\" and, with an Irish accent, by David Suchet in \"Red Monarch\".\n\nSimon Russell Beale played Beria in the 2017 satirical film \"The Death of Stalin\".\n\nIn the 1958 CBS production of \"The Plot to Kill Stalin\" for Playhouse 90, Beria was portrayed by E. G. Marshall.\n\nBeria appears in the third episode (\"Superbomb\") of the four-part 2007 BBC docudrama series \"Nuclear Secrets\", played by Boris Isarov. In the 2008 BBC documentary series \"\", Beria was portrayed by Polish actor .\n\nHe was also an important character in the 2013 Russian mini-series \"Kill Stalin\", produced by Star Media.\n\nRichard Condon's 1959 novel \"The Manchurian Candidate\" describes brainwashed Raymond Shaw, the \"perfectly prefabricated assassin,\" as \"this dream by Lavrenti Beria.\"\n\nIn the 1964 science fiction novel by Arkady and Boris Strugatsky, \"Hard to Be a God\", Beria is personified in the character Don Reba who serves as the king's minister of defence.\n\nAt the opening of Kingsley Amis' \"The Alteration\", Lavrentiy Beria figures as \"Monsignor Laurentius\", paired with the similarly black-clad cleric \"Monsignor Henricus\" of the Holy Office (i.e., the Inquisition); the one to whom Beria was compared by Stalin in our own timeline: Heinrich Himmler. In the novel, both men are on the same side, serving an alternate-world Catholic Empire.\n\nBeria is a significant character in the alternate history/alien invasion novel series Worldwar by Harry Turtledove as well as the \"Axis of Time\" series by John Birmingham\n\nBeria is a significant character in the opening chapters of the 1998 novel \"Archangel\" by British novelist Robert Harris.\n\nBeria is a minor character in the 2009 novel \"The Hundred-Year-Old Man Who Climbed Out the Window and Disappeared\" by Jonas Jonasson. Beria is described as the boss of the Soviet state's security and is in attendance at a meal with the main character and Stalin.\n\nIn 2012, his alleged personal diary from 1938 to 1953 was published in Russia.\n\n\n\n"}
{"id": "18391", "url": "https://en.wikipedia.org/wiki?curid=18391", "title": "Lyonel Feininger", "text": "Lyonel Feininger\n\nLyonel Charles Feininger (July 17, 1871January 13, 1956) was a German-American painter, and a leading exponent of Expressionism. He also worked as a caricaturist and comic strip artist. He was born and grew up in New York City, traveling to Germany at 16 to study and perfect his art. He started his career as a cartoonist in 1894 and met with much success in this area. He was also a commercial caricaturist for 20 years for magazines and newspapers in the USA and Germany. At the age of 36, he started to work as a fine artist. He also produced a large body of photographic works between 1928 and the mid 1950s, but he kept these primarily within his circle of friends. He was also a pianist and composer, with several piano compositions and fugues for organ extant.\n\nLyonel Feininger was born to German-American violinist and composer Karl Feininger and American singer Elizabeth Feininger. He was born and grew up in New York City, but traveled to Germany at the age of 16 in 1887 to study. In 1888, he moved to Berlin and studied at the Königliche Akademie Berlin under Ernst Hancke. He continued his studies at art schools in Berlin with Karl Schlabitz, and in Paris with sculptor Filippo Colarossi. He started as a caricaturist for several magazines including \"Harper's Round Table\", \"Harper's Young People\", \"Humoristische Blätter\", \"Lustige Blätter\", \"Das Narrenschiff\", \"Berliner Tageblatt\" and \"Ulk\".\n\nIn 1900, he met Clara Fürst, daughter of the painter Gustav Fürst. He married her in 1901, and they had two daughters. In 1905, he separated from his wife after meeting Julia Berg. He married Berg in 1908 and the couple had three boys.\n\nThe artist was represented with drawings at the exhibitions of the annual Berlin Secession in the years 1901 through 1903.\n\nFeininger's career as cartoonist started in 1894. He was working for several German, French and American magazines. In February 1906, when a quarter of Chicago's population was of German descent, James Keeley, editor of The \"Chicago Tribune\" traveled to Germany to procure the services of the most popular humor artists. He recruited Feininger to illustrate two comic strips \"The Kin-der-Kids\" and \"Wee Willie Winkie's World\" for the \"Chicago Tribune\". The strips were noted for their fey humor and graphic experimentation. He also worked as a commercial caricaturist for 20 years for various newspapers and magazines in both the United States and Germany. Later, Art Spiegelman wrote in \"The New York Times Book Review,\" that Feininger's comics have \"achieved a breathtaking formal grace unsurpassed in the history of the medium.\"\n\nFeininger started working as a fine artist at the age of 36. He was a member of the \"Berliner Sezession\" in 1909, and he was associated with German expressionist groups: Die Brücke, the Novembergruppe, Gruppe 1919, the Blaue Reiter circle and Die Blaue Vier (The Blue Four). His first solo exhibit was at Sturm Gallery in Berlin, 1917. When Walter Gropius founded the Bauhaus in Germany in 1919, Feininger was his first faculty appointment, and became the master artist in charge of the printmaking workshop.\nFrom 1909 until 1921, Feininger spent summer vacations on the island of Usedom to recover and to get new inspiration. Typical of works from this period were marine settings from the shores of the Baltic See (Ostsee). He continued to create paintings and drawings of Benz for the rest of his life, even after returning to live in the United States. A tour of the sites appearing in the works of Feininger follows a path with markers in the ground to guide visitors.\n\nHe designed the cover for the Bauhaus 1919 manifesto: an expressionist woodcut 'cathedral'. He taught at the Bauhaus for several years. Among the students who attended his workshops were Ludwig Hirschfeld Mack (German/Australian (1893–1965), Hans Friedrich Grohs (German 1892 - 1981), and Margarete Koehler-Bittkow (German/American, 1898–1964).\n\nWhen the Nazi Party came to power in 1933, the situation became unbearable for Feininger and his wife. The Nazi Party declared his work to be \"degenerate\". They moved to America after his work was exhibited in the 'degenerate art' (\"Entartete Kunst\") in 1936, but before the 1937 exhibition in Munich. He taught at Mills College before returning to New York. He was elected to the American Academy of Arts and Letters in 1955.\n\nIn addition to drawing, Feininger created art with painted toy figures being photographed in front of drawn backgrounds.\n\nFeininger produced a large body of photographic works between 1928 and the mid-1950s. He kept his photographic work within his circle of friends, and it was not shared with the public in his lifetime. He gave some prints away to his colleagues Walter Gropius and Alfred H. Barr Jr..\n\nFeininger also had intermittent activity as a pianist and composer, with several piano compositions and fugues for organ extant.\n\nHis sons, Andreas Feininger and T. Lux Feininger, both became noted artists, the former as a photographer and the latter as a photographer and painter. T. Lux Feininger died July 7, 2011 at the age of 101.\n\nA major retrospective exhibition of Lyonel Feininger's work, initially at the Whitney Museum of American Art during June 30 October 16, 2011, was subsequently due to run at the Montreal Museum of Fine Arts during January 20–May 13, 2012. The exhibition is described as \"the first in Feininger’s native country in more than forty-five years, and the first ever to include the full breadth of his art\" and as \"accompanied by a richly illustrated monograph with a feature essay that provides a broad overview of Feininger’s career...\" Many critics have argued that the artist's work was at its most mature around 1910 in works in which the power of Feininger as illustrator balance his abstract side; however, we have to consider the possibility that Feininger used cubism as a more artistically succinct tool to establish his version of the concept known as the objective correlative. In tandem with the Whitney retrospective, the American Symphony Orchestra under Leon Botstein, at Carnegie Hall on 21 October 2011, performed three orchestral fugues written by Feininger. Barbara Haskell, curator of the Whitney exhibit, wrote that for his entire life, Feininger credited Bach with having been his \"master in painting.\" \n\nAt a 2001 Christie's auction in London, Feininger's painting \"The Green Bridge\" (1909) was sold for £2.42 million.\n\nAt a 2017 Sotheby's auction in New York, Feininger's oil painting \"Fin de séance\" (1910) sold for $5,637,500.\n\n\n\n\n"}
{"id": "18393", "url": "https://en.wikipedia.org/wiki?curid=18393", "title": "Life", "text": "Life\n\nLife is a characteristic that distinguishes physical entities that have biological processes, such as signaling and self-sustaining processes, from those that do not, either because such functions have ceased (they have died), or because they never had such functions and are classified as inanimate. Various forms of life exist, such as plants, animals, fungi, protists, archaea, and bacteria. The criteria can at times be ambiguous and may or may not define viruses, viroids, or potential synthetic life as \"living\". Biology is the science concerned with the study of life.\n\nThere is currently no consensus regarding the definition of life. One popular definition is that organisms are open systems that maintain homeostasis, are composed of cells, have a life cycle, undergo metabolism, can grow, adapt to their environment, respond to stimuli, reproduce and evolve. However, several other definitions have been proposed, and there are some borderline cases of life, such as viruses or viroids.\n\nAbiogenesis attempts to describe the natural process of life arising from non-living matter, such as simple organic compounds. The prevailing scientific hypothesis is that the transition from non-living to living entities was not a single event, but a gradual process of increasing complexity. Life on Earth first appeared as early as 4.28 billion years ago, soon after ocean formation 4.41 billion years ago, and not long after the formation of the Earth 4.54 billion years ago. The earliest known life forms are microfossils of bacteria. Earth's current life may have descended from an RNA world, although RNA-based life may not have been the first. The mechanism by which life began on Earth is unknown, though many hypotheses have been formulated and are often based on the Miller–Urey experiment. \n\nSince its primordial beginnings, life on Earth has changed its environment on a geologic time scale, but it has also adapted to survive in most ecosystems and conditions. Some microorganisms, called extremophiles, thrive in physically or geochemically extreme environments that are detrimental to most other life on Earth. The cell is considered the structural and functional unit of life. There are two kinds of cells, prokaryotic and eukaryotic, both of which consist of cytoplasm enclosed within a membrane and contain many biomolecules such as proteins and nucleic acids. Cells reproduce through a process of cell division, in which the parent cell divides into two or more daughter cells.\n\nIn the past, there have been many attempts to define what is meant by \"life\" through obsolete concepts such as odic force, hylomorphism, spontaneous generation and vitalism, that have now been disproved by biological discoveries. Aristotle was the first person to classify organisms. Later, Carl Linnaeus introduced his system of binomial nomenclature for the classification of species. Eventually new groups and categories of life were discovered, such as cells and microorganisms, forcing dramatic revisions of the structure of relationships between living organisms. Though currently only known on Earth, life need not be restricted to it, and many scientists speculate in the existence of extraterrestrial life. Artificial life is a computer simulation or man-made reconstruction of any aspect of life, which is often used to examine systems related to natural life. \n\nDeath is the permanent termination of all biological functions which sustain an organism, and as such, is the end of its life. Extinction is the term describing the dying out of a group or taxon, usually a species. Fossils are the preserved remains or traces of organisms.\n\nThe definition of life has long been a challenge for scientists and philosophers, with many varied definitions put forward. This is partially because life is a process, not a substance. This is complicated by a lack of knowledge of the characteristics of living entities, if any, that may have developed outside of Earth. Philosophical definitions of life have also been put forward, with similar difficulties on how to distinguish living things from the non-living. Legal definitions of life have also been described and debated, though these generally focus on the decision to declare a human dead, and the legal ramifications of this decision.\n\nSince there is no unequivocal definition of life, most current definitions in biology are descriptive. Life is considered a characteristic of something that preserves, furthers or reinforces its existence in the given environment. This characteristic exhibits all or most of the following traits:\n\nThese complex processes, called physiological functions, have underlying physical and chemical bases, as well as signaling and control mechanisms that are essential to maintaining life.\n\nFrom a physics perspective, living beings are thermodynamic systems with an organized molecular structure that can reproduce itself and evolve as survival dictates. Thermodynamically, life has been described as an open system which makes use of gradients in its surroundings to create imperfect copies of itself. Hence, life is a self-sustained chemical system capable of undergoing Darwinian evolution. A major strength of this definition is that it distinguishes life by the evolutionary process rather than its chemical composition.\n\nOthers take a systemic viewpoint that does not necessarily depend on molecular chemistry. One systemic definition of life is that living things are self-organizing and autopoietic (self-producing). Variations of this definition include Stuart Kauffman's definition as an autonomous agent or a multi-agent system capable of reproducing itself or themselves, and of completing at least one thermodynamic work cycle. This definition is extended by the apparition of novel functions over time.\n\nWhether or not viruses should be considered as alive is controversial. They are most often considered as just replicators rather than forms of life. They have been described as \"organisms at the edge of life\" because they possess genes, evolve by natural selection, and replicate by creating multiple copies of themselves through self-assembly. However, viruses do not metabolize and they require a host cell to make new products. Virus self-assembly within host cells has implications for the study of the origin of life, as it may support the hypothesis that life could have started as self-assembling organic molecules.\n\nTo reflect the minimum phenomena required, other biological definitions of life have been proposed, with many of these being based upon chemical systems. Biophysicists have commented that living things function on negative entropy. In other words, living processes can be viewed as a delay of the spontaneous diffusion or dispersion of the internal energy of biological molecules towards more potential microstates. In more detail, according to physicists such as John Bernal, Erwin Schrödinger, Eugene Wigner, and John Avery, life is a member of the class of phenomena that are open or continuous systems able to decrease their internal entropy at the expense of substances or free energy taken in from the environment and subsequently rejected in a degraded form.\n\nLiving systems are open self-organizing living things that interact with their environment. These systems are maintained by flows of information, energy, and matter.\n\nSome scientists have proposed in the last few decades that a general living systems theory is required to explain the nature of life. Such a general theory would arise out of the ecological and biological sciences and attempt to map general principles for how all living systems work. Instead of examining phenomena by attempting to break things down into components, a general living systems theory explores phenomena in terms of dynamic patterns of the relationships of organisms with their environment.\n\nThe idea that the Earth is alive is found in philosophy and religion, but the first scientific discussion of it was by the Scottish scientist James Hutton. In 1785, he stated that the Earth was a superorganism and that its proper study should be physiology. Hutton is considered the father of geology, but his idea of a living Earth was forgotten in the intense reductionism of the 19th century. The Gaia hypothesis, proposed in the 1960s by scientist James Lovelock, suggests that life on Earth functions as a single organism that defines and maintains environmental conditions necessary for its survival. This hypothesis served as one of the foundations of the modern Earth system science.\n\nThe first attempt at a general living systems theory for explaining the nature of life was in 1978, by American biologist James Grier Miller. Robert Rosen (1991) built on this by defining a system component as \"a unit of organization; a part with a function, i.e., a definite relation between part and whole.\" From this and other starting concepts, he developed a \"relational theory of systems\" that attempts to explain the special properties of life. Specifically, he identified the \"nonfractionability of components in an organism\" as the fundamental difference between living systems and \"biological machines.\"\n\nA systems view of life treats environmental fluxes and biological fluxes together as a \"reciprocity of influence,\" and a reciprocal relation with environment is arguably as important for understanding life as it is for understanding ecosystems. As Harold J. Morowitz (1992) explains it, life is a property of an ecological system rather than a single organism or species. He argues that an ecosystemic definition of life is preferable to a strictly biochemical or physical one. Robert Ulanowicz (2009) highlights mutualism as the key to understand the systemic, order-generating behavior of life and ecosystems.\n\nComplex systems biology (CSB) is a field of science that studies the emergence of complexity in functional organisms from the viewpoint of dynamic systems theory. The latter is also often called systems biology and aims to understand the most fundamental aspects of life. A closely related approach to CSB and systems biology called relational biology is concerned mainly with understanding life processes in terms of the most important relations, and categories of such relations among the essential functional components of organisms; for multicellular organisms, this has been defined as \"categorical biology\", or a model representation of organisms as a category theory of biological relations, as well as an algebraic topology of the functional organization of living organisms in terms of their dynamic, complex networks of metabolic, genetic, and epigenetic processes and signaling pathways. Alternative but closely related approaches focus on the interdependance of constraints, where constraints can be either molecular, such as enzymes, or macroscopic, such as the geometry of a bone or of the vascular system.\n\nIt has also been argued that the evolution of order in living systems and certain physical systems obeys a common fundamental principle termed the Darwinian dynamic. The Darwinian dynamic was formulated by first considering how macroscopic order is generated in a simple non-biological system far from thermodynamic equilibrium, and then extending consideration to short, replicating RNA molecules. The underlying order-generating process was concluded to be basically similar for both types of systems.\n\nAnother systemic definition called the operator theory proposes that \"life is a general term for the presence of the typical closures found in organisms; the typical closures are a membrane and an autocatalytic set in the cell\" and that an organism is any system with an organisation that complies with an operator type that is at least as complex as the cell. Life can also be modeled as a network of inferior negative feedbacks of regulatory mechanisms subordinated to a superior positive feedback formed by the potential of expansion and reproduction.\n\nSome of the earliest theories of life were materialist, holding that all that exists is matter, and that life is merely a complex form or arrangement of matter. Empedocles (430 BC) argued that everything in the universe is made up of a combination of four eternal \"elements\" or \"roots of all\": earth, water, air, and fire. All change is explained by the arrangement and rearrangement of these four elements. The various forms of life are caused by an appropriate mixture of elements.\n\nDemocritus (460 BC) thought that the essential characteristic of life is having a soul (\"psyche\"). Like other ancient writers, he was attempting to explain what makes something a \"living\" thing. His explanation was that fiery atoms make a soul in exactly the same way atoms and void account for any other thing. He elaborates on fire because of the apparent connection between life and heat, and because fire moves.\n\nThe mechanistic materialism that originated in ancient Greece was revived and revised by the French philosopher René Descartes, who held that animals and humans were assemblages of parts that together functioned as a machine. In the 19th century, the advances in cell theory in biological science encouraged this view. The evolutionary theory of Charles Darwin (1859) is a mechanistic explanation for the origin of species by means of natural selection.\n\nHylomorphism is a theory first expressed by the Greek philosopher Aristotle (322 BC). The application of hylomorphism to biology was important to Aristotle, and biology is extensively covered in his extant writings. In this view, everything in the material universe has both matter and form, and the form of a living thing is its soul (Greek \"psyche\", Latin \"anima\"). There are three kinds of souls: the \"vegetative soul\" of plants, which causes them to grow and decay and nourish themselves, but does not cause motion and sensation; the \"animal soul\", which causes animals to move and feel; and the \"rational soul\", which is the source of consciousness and reasoning, which (Aristotle believed) is found only in man. Each higher soul has all of the attributes of the lower ones. Aristotle believed that while matter can exist without form, form cannot exist without matter, and that therefore the soul cannot exist without the body.\n\nThis account is consistent with teleological explanations of life, which account for phenomena in terms of purpose or goal-directedness. Thus, the whiteness of the polar bear's coat is explained by its purpose of camouflage. The direction of causality (from the future to the past) is in contradiction with the scientific evidence for natural selection, which explains the consequence in terms of a prior cause. Biological features are explained not by looking at future optimal results, but by looking at the past evolutionary history of a species, which led to the natural selection of the features in question.\n\nSpontaneous generation was the belief that living organisms can form without descent from similar organisms. Typically, the idea was that certain forms such as fleas could arise from inanimate matter such as dust or the supposed seasonal generation of mice and insects from mud or garbage.\n\nThe theory of spontaneous generation was proposed by Aristotle, who compiled and expanded the work of prior natural philosophers and the various ancient explanations of the appearance of organisms; it held sway for two millennia. It was decisively dispelled by the experiments of Louis Pasteur in 1859, who expanded upon the investigations of predecessors such as Francesco Redi. Disproof of the traditional ideas of spontaneous generation is no longer controversial among biologists.\n\nVitalism is the belief that the life-principle is non-material. This originated with Georg Ernst Stahl (17th century), and remained popular until the middle of the 19th century. It appealed to philosophers such as Henri Bergson, Friedrich Nietzsche, and Wilhelm Dilthey, anatomists like Marie François Xavier Bichat, and chemists like Justus von Liebig. Vitalism included the idea that there was a fundamental difference between organic and inorganic material, and the belief that organic material can only be derived from living things. This was disproved in 1828, when Friedrich Wöhler prepared urea from inorganic materials. This Wöhler synthesis is considered the starting point of modern organic chemistry. It is of historical significance because for the first time an organic compound was produced in inorganic reactions.\n\nDuring the 1850s, Hermann von Helmholtz, anticipated by Julius Robert von Mayer, demonstrated that no energy is lost in muscle movement, suggesting that there were no \"vital forces\" necessary to move a muscle. These results led to the abandonment of scientific interest in vitalistic theories, although the belief lingered on in pseudoscientific theories such as homeopathy, which interprets diseases and sickness as caused by disturbances in a hypothetical vital force or life force.\n\nThe age of the Earth is about 4.54 billion years. Evidence suggests that life on Earth has existed for at least 3.5 billion years, with the oldest physical traces of life dating back 3.7 billion years; however, some theories, such as the Late Heavy Bombardment theory, suggest that life on Earth may have started even earlier, as early as 4.1–4.4 billion years ago, and the chemistry leading to life may have begun shortly after the Big Bang, 13.8 billion years ago, during an epoch when the universe was only 10–17 million years old.\n\nMore than 99% of all species of life forms, amounting to over five billion species, that ever lived on Earth are estimated to be extinct.\n\nAlthough the number of Earth's catalogued species of lifeforms is between 1.2 million and 2 million, the total number of species in the planet is uncertain. Estimates range from 8 million to 100 million, with a more narrow range between 10 and 14 million, but it may be as high as 1 trillion (with only one-thousandth of one percent of the species described) according to studies realized in May 2016. The total number of related DNA base pairs on Earth is estimated at 5.0 x 10 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon). In July 2016, scientists reported identifying a set of 355 genes from the Last Universal Common Ancestor (LUCA) of all organisms living on Earth.\n\nAll known life forms share fundamental molecular mechanisms, reflecting their common descent; based on these observations, hypotheses on the origin of life attempt to find a mechanism explaining the formation of a universal common ancestor, from simple organic molecules via pre-cellular life to protocells and metabolism. Models have been divided into \"genes-first\" and \"metabolism-first\" categories, but a recent trend is the emergence of hybrid models that combine both categories.\n\nThere is no current scientific consensus as to how life originated. However, most accepted scientific models build on the Miller–Urey experiment and the work of Sidney Fox, which show that conditions on the primitive Earth favored chemical reactions that synthesize amino acids and other organic compounds from inorganic precursors, and phospholipids spontaneously form lipid bilayers, the basic structure of a cell membrane.\n\nLiving organisms synthesize proteins, which are polymers of amino acids using instructions encoded by deoxyribonucleic acid (DNA). Protein synthesis entails intermediary ribonucleic acid (RNA) polymers. One possibility for how life began is that genes originated first, followed by proteins; the alternative being that proteins came first and then genes.\n\nHowever, because genes and proteins are both required to produce the other, the problem of considering which came first is like that of the chicken or the egg. Most scientists have adopted the hypothesis that because of this, it is unlikely that genes and proteins arose independently.\n\nTherefore, a possibility, first suggested by Francis Crick, is that the first life was based on RNA, which has the DNA-like properties of information storage and the catalytic properties of some proteins. This is called the RNA world hypothesis, and it is supported by the observation that many of the most critical components of cells (those that evolve the slowest) are composed mostly or entirely of RNA. Also, many critical cofactors (ATP, Acetyl-CoA, NADH, etc.) are either nucleotides or substances clearly related to them. The catalytic properties of RNA had not yet been demonstrated when the hypothesis was first proposed, but they were confirmed by Thomas Cech in 1986.\n\nOne issue with the RNA world hypothesis is that synthesis of RNA from simple inorganic precursors is more difficult than for other organic molecules. One reason for this is that RNA precursors are very stable and react with each other very slowly under ambient conditions, and it has also been proposed that living organisms consisted of other molecules before RNA. However, the successful synthesis of certain RNA molecules under the conditions that existed prior to life on Earth has been achieved by adding alternative precursors in a specified order with the precursor phosphate present throughout the reaction. This study makes the RNA world hypothesis more plausible.\n\nGeological findings in 2013 showed that reactive phosphorus species (like phosphite) were in abundance in the ocean before 3.5 Ga, and that Schreibersite easily reacts with aqueous glycerol to generate phosphite and glycerol 3-phosphate. It is hypothesized that Schreibersite-containing meteorites from the Late Heavy Bombardment could have provided early reduced phosphorus, which could react with prebiotic organic molecules to form phosphorylated biomolecules, like RNA.\n\nIn 2009, experiments demonstrated Darwinian evolution of a two-component system of RNA enzymes (ribozymes) \"in vitro\". The work was performed in the laboratory of Gerald Joyce, who stated \"This is the first example, outside of biology, of evolutionary adaptation in a molecular genetic system.\"\n\nPrebiotic compounds may have originated extraterrestrially. NASA findings in 2011, based on studies with meteorites found on Earth, suggest DNA and RNA components (adenine, guanine and related organic molecules) may be formed in outer space.\n\nIn March 2015, NASA scientists reported that, for the first time, complex DNA and RNA organic compounds of life, including uracil, cytosine and thymine, have been formed in the laboratory under outer space conditions, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe, may have been formed in red giants or in interstellar dust and gas clouds, according to the scientists.\n\nAccording to the panspermia hypothesis, microscopic life—distributed by meteoroids, asteroids and other small Solar System bodies—may exist throughout the universe.\n\nThe diversity of life on Earth is a result of the dynamic interplay between genetic opportunity, metabolic capability, environmental challenges, and symbiosis. For most of its existence, Earth's habitable environment has been dominated by microorganisms and subjected to their metabolism and evolution. As a consequence of these microbial activities, the physical-chemical environment on Earth has been changing on a geologic time scale, thereby affecting the path of evolution of subsequent life. For example, the release of molecular oxygen by cyanobacteria as a by-product of photosynthesis induced global changes in the Earth's environment. Because oxygen was toxic to most life on Earth at the time, this posed novel evolutionary challenges, and ultimately resulted in the formation of Earth's major animal and plant species. This interplay between organisms and their environment is an inherent feature of living systems.\n\nThe biosphere is the global sum of all ecosystems. It can also be termed as the zone of life on Earth, a closed system (apart from solar and cosmic radiation and heat from the interior of the Earth), and largely self-regulating. By the most general biophysiological definition, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere, geosphere, hydrosphere, and atmosphere.\n\nLife forms live in every part of the Earth's biosphere, including soil, hot springs, inside rocks at least deep underground, the deepest parts of the ocean, and at least high in the atmosphere. Under certain test conditions, life forms have been observed to thrive in the near-weightlessness of space and to survive in the vacuum of outer space. Life forms appear to thrive in the Mariana Trench, the deepest spot in the Earth's oceans. Other researchers reported related studies that life forms thrive inside rocks up to below the sea floor under of ocean off the coast of the northwestern United States, as well as beneath the seabed off Japan. In August 2014, scientists confirmed the existence of life forms living below the ice of Antarctica. According to one researcher, \"You can find microbes everywhere—they're extremely adaptable to conditions, and survive wherever they are.\"\n\nThe biosphere is postulated to have evolved, beginning with a process of biopoesis (life created naturally from non-living matter, such as simple organic compounds) or biogenesis (life created from living matter), at least some 3.5 billion years ago. The earliest evidence for life on Earth includes biogenic graphite found in 3.7 billion-year-old metasedimentary rocks from Western Greenland and microbial mat fossils found in 3.48 billion-year-old sandstone from Western Australia. More recently, in 2015, \"remains of biotic life\" were found in 4.1 billion-year-old rocks in Western Australia. In 2017, putative fossilized microorganisms (or microfossils) were announced to have been discovered in hydrothermal vent precipitates in the Nuvvuagittuq Belt of Quebec, Canada that were as old as 4.28 billion years, the oldest record of life on earth, suggesting \"an almost instantaneous emergence of life\" after ocean formation 4.4 billion years ago, and not long after the formation of the Earth 4.54 billion years ago. According to biologist Stephen Blair Hedges, \"If life arose relatively quickly on Earth ... then it could be common in the universe.\"\n\nIn a general sense, biospheres are any closed, self-regulating systems containing ecosystems. This includes artificial biospheres such as Biosphere 2 and BIOS-3, and potentially ones on other planets or moons.\n\nThe inert components of an ecosystem are the physical and chemical factors necessary for life—energy (sunlight or chemical energy), water, heat, atmosphere, gravity, nutrients, and ultraviolet solar radiation protection. In most ecosystems, the conditions vary during the day and from one season to the next. To live in most ecosystems, then, organisms must be able to survive a range of conditions, called the \"range of tolerance.\" Outside that are the \"zones of physiological stress,\" where the survival and reproduction are possible but not optimal. Beyond these zones are the \"zones of intolerance,\" where survival and reproduction of that organism is unlikely or impossible. Organisms that have a wide range of tolerance are more widely distributed than organisms with a narrow range of tolerance.\n\nTo survive, selected microorganisms can assume forms that enable them to withstand freezing, complete desiccation, starvation, high levels of radiation exposure, and other physical or chemical challenges. These microorganisms may survive exposure to such conditions for weeks, months, years, or even centuries. Extremophiles are microbial life forms that thrive outside the ranges where life is commonly found. They excel at exploiting uncommon sources of energy. While all organisms are composed of nearly identical molecules, evolution has enabled such microbes to cope with this wide range of physical and chemical conditions. Characterization of the structure and metabolic diversity of microbial communities in such extreme environments is ongoing.\n\nMicrobial life forms thrive even in the Mariana Trench, the deepest spot in the Earth's oceans. Microbes also thrive inside rocks up to below the sea floor under of ocean.\n\nInvestigation of the tenacity and versatility of life on Earth, as well as an understanding of the molecular systems that some organisms utilize to survive such extremes, is important for the search for life beyond Earth. For example, lichen could survive for a month in a simulated Martian environment.\n\nAll life forms require certain core chemical elements needed for biochemical functioning. These include carbon, hydrogen, nitrogen, oxygen, phosphorus, and sulfur—the elemental macronutrients for all organisms—often represented by the acronym CHNOPS. Together these make up nucleic acids, proteins and lipids, the bulk of living matter. Five of these six elements comprise the chemical components of DNA, the exception being sulfur. The latter is a component of the amino acids cysteine and methionine. The most biologically abundant of these elements is carbon, which has the desirable attribute of forming multiple, stable covalent bonds. This allows carbon-based (organic) molecules to form an immense variety of chemical arrangements. Alternative hypothetical types of biochemistry have been proposed that eliminate one or more of these elements, swap out an element for one not on the list, or change required chiralities or other chemical properties.\n\nDeoxyribonucleic acid is a molecule that carries most of the genetic instructions used in the growth, development, functioning and reproduction of all known living organisms and many viruses. DNA and RNA are nucleic acids; alongside proteins and complex carbohydrates, they are one of the three major types of macromolecule that are essential for all known forms of life. Most DNA molecules consist of two biopolymer strands coiled around each other to form a double helix. The two DNA strands are known as polynucleotides since they are composed of simpler units called nucleotides. Each nucleotide is composed of a nitrogen-containing nucleobase—either cytosine (C), guanine (G), adenine (A), or thymine (T)—as well as a sugar called deoxyribose and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. According to base pairing rules (A with T, and C with G), hydrogen bonds bind the nitrogenous bases of the two separate polynucleotide strands to make double-stranded DNA. The total amount of related DNA base pairs on Earth is estimated at 5.0 x 10, and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).\n\nDNA stores biological information. The DNA backbone is resistant to cleavage, and both strands of the double-stranded structure store the same biological information. Biological information is replicated as the two strands are separated. A significant portion of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences.\n\nThe two strands of DNA run in opposite directions to each other and are therefore anti-parallel. Attached to each sugar is one of four types of nucleobases (informally, \"bases\"). It is the sequence of these four nucleobases along the backbone that encodes biological information. Under the genetic code, RNA strands are translated to specify the sequence of amino acids within proteins. These RNA strands are initially created using DNA strands as a template in a process called transcription.\n\nWithin cells, DNA is organized into long structures called chromosomes. During cell division these chromosomes are duplicated in the process of DNA replication, providing each cell its own complete set of chromosomes. Eukaryotic organisms (animals, plants, fungi, and protists) store most of their DNA inside the cell nucleus and some of their DNA in organelles, such as mitochondria or chloroplasts. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm. Within the chromosomes, chromatin proteins such as histones compact and organize DNA. These compact structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.\n\nDNA was first isolated by Friedrich Miescher in 1869. Its molecular structure was identified by James Watson and Francis Crick in 1953, whose model-building efforts were guided by X-ray diffraction data acquired by Rosalind Franklin.\n\nThe first known attempt to classify organisms was conducted by the Greek philosopher Aristotle (384–322 BC), who classified all living organisms known at that time as either a plant or an animal, based mainly on their ability to move. He also distinguished animals with blood from animals without blood (or at least without red blood), which can be compared with the concepts of vertebrates and invertebrates respectively, and divided the blooded animals into five groups: viviparous quadrupeds (mammals), oviparous quadrupeds (reptiles and amphibians), birds, fishes and whales. The bloodless animals were also divided into five groups: cephalopods, crustaceans, insects (which included the spiders, scorpions, and centipedes, in addition to what we define as insects today), shelled animals (such as most molluscs and echinoderms), and \"zoophytes\" (animals that resemble plants). Though Aristotle's work in zoology was not without errors, it was the grandest biological synthesis of the time and remained the ultimate authority for many centuries after his death.\n\nThe exploration of the Americas revealed large numbers of new plants and animals that needed descriptions and classification. In the latter part of the 16th century and the beginning of the 17th, careful study of animals commenced and was gradually extended until it formed a sufficient body of knowledge to serve as an anatomical basis for classification. \n\nIn the late 1740s, Carl Linnaeus introduced his system of binomial nomenclature for the classification of species. Linnaeus attempted to improve the composition and reduce the length of the previously used many-worded names by abolishing unnecessary rhetoric, introducing new descriptive terms and precisely defining their meaning. The Linnaean classification has eight levels: domains, kingdoms, phyla, class, order, family, genus, and species.\n\nThe fungi were originally treated as plants. For a short period Linnaeus had classified them in the taxon Vermes in Animalia, but later placed them back in Plantae. Copeland classified the Fungi in his Protoctista, thus partially avoiding the problem but acknowledging their special status. The problem was eventually solved by Whittaker, when he gave them their own kingdom in his five-kingdom system. Evolutionary history shows that the fungi are more closely related to animals than to plants.\n\nAs new discoveries enabled detailed study of cells and microorganisms, new groups of life were revealed, and the fields of cell biology and microbiology were created. These new organisms were originally described separately in protozoa as animals and protophyta/thallophyta as plants, but were united by Haeckel in the kingdom Protista; later, the prokaryotes were split off in the kingdom Monera, which would eventually be divided into two separate groups, the Bacteria and the Archaea. This led to the six-kingdom system and eventually to the current three-domain system, which is based on evolutionary relationships. However, the classification of eukaryotes, especially of protists, is still controversial.\n\nAs microbiology, molecular biology and virology developed, non-cellular reproducing agents were discovered, such as viruses and viroids. Whether these are considered alive has been a matter of debate; viruses lack characteristics of life such as cell membranes, metabolism and the ability to grow or respond to their environments. Viruses can still be classed into \"species\" based on their biology and genetics, but many aspects of such a classification remain controversial.\n\nIn May 2016, scientists reported that 1 trillion species are estimated to be on Earth currently with only one-thousandth of one percent described. \n\nThe original Linnaean system has been modified over time as follows:\nIn the 1960s cladistics emerged: a system arranging taxa based on clades in an evolutionary or phylogenetic tree.\n\nCells are the basic unit of structure in every living thing, and all cells arise from pre-existing cells by division. Cell theory was formulated by Henri Dutrochet, Theodor Schwann, Rudolf Virchow and others during the early nineteenth century, and subsequently became widely accepted. The activity of an organism depends on the total activity of its cells, with energy flow occurring within and between them. Cells contain hereditary information that is carried forward as a genetic code during cell division.\n\nThere are two primary types of cells. Prokaryotes lack a nucleus and other membrane-bound organelles, although they have circular DNA and ribosomes. Bacteria and Archaea are two domains of prokaryotes. The other primary type of cells are the eukaryotes, which have distinct nuclei bound by a nuclear membrane and membrane-bound organelles, including mitochondria, chloroplasts, lysosomes, rough and smooth endoplasmic reticulum, and vacuoles. In addition, they possess organized chromosomes that store genetic material. All species of large complex organisms are eukaryotes, including animals, plants and fungi, though most species of eukaryote are protist microorganisms. The conventional model is that eukaryotes evolved from prokaryotes, with the main organelles of the eukaryotes forming through endosymbiosis between bacteria and the progenitor eukaryotic cell.\n\nThe molecular mechanisms of cell biology are based on proteins. Most of these are synthesized by the ribosomes through an enzyme-catalyzed process called protein biosynthesis. A sequence of amino acids is assembled and joined together based upon gene expression of the cell's nucleic acid. In eukaryotic cells, these proteins may then be transported and processed through the Golgi apparatus in preparation for dispatch to their destination.\n\nCells reproduce through a process of cell division in which the parent cell divides into two or more daughter cells. For prokaryotes, cell division occurs through a process of fission in which the DNA is replicated, then the two copies are attached to parts of the cell membrane. In eukaryotes, a more complex process of mitosis is followed. However, the end result is the same; the resulting cell copies are identical to each other and to the original cell (except for mutations), and both are capable of further division following an interphase period.\n\nMulticellular organisms may have first evolved through the formation of colonies of identical cells. These cells can form group organisms through cell adhesion. The individual members of a colony are capable of surviving on their own, whereas the members of a true multi-cellular organism have developed specializations, making them dependent on the remainder of the organism for survival. Such organisms are formed clonally or from a single germ cell that is capable of forming the various specialized cells that form the adult organism. This specialization allows multicellular organisms to exploit resources more efficiently than single cells. In January 2016, scientists reported that, about 800 million years ago, a minor genetic change in a single molecule, called GK-PID, may have allowed organisms to go from a single cell organism to one of many cells.\n\nCells have evolved methods to perceive and respond to their microenvironment, thereby enhancing their adaptability. Cell signaling coordinates cellular activities, and hence governs the basic functions of multicellular organisms. Signaling between cells can occur through direct cell contact using juxtacrine signalling, or indirectly through the exchange of agents as in the endocrine system. In more complex organisms, coordination of activities can occur through a dedicated nervous system.\n\nThough life is confirmed only on Earth, many think that extraterrestrial life is not only plausible, but probable or inevitable. Other planets and moons in the Solar System and other planetary systems are being examined for evidence of having once supported simple life, and projects such as SETI are trying to detect radio transmissions from possible alien civilizations. Other locations within the Solar System that may host microbial life include the subsurface of Mars, the upper atmosphere of Venus, and subsurface oceans on some of the moons of the giant planets.\nBeyond the Solar System, the region around another main-sequence star that could support Earth-like life on an Earth-like planet is known as the habitable zone. The inner and outer radii of this zone vary with the luminosity of the star, as does the time interval during which the zone survives. Stars more massive than the Sun have a larger habitable zone, but remain on the Sun-like \"main sequence\" of stellar evolution for a shorter time interval. Small red dwarfs have the opposite problem, with a smaller habitable zone that is subject to higher levels of magnetic activity and the effects of tidal locking from close orbits. Hence, stars in the intermediate mass range such as the Sun may have a greater likelihood for Earth-like life to develop. The location of the star within a galaxy may also affect the likelihood of life forming. Stars in regions with a greater abundance of heavier elements that can form planets, in combination with a low rate of potentially habitat-damaging supernova events, are predicted to have a higher probability of hosting planets with complex life. The variables of the Drake equation are used to discuss the conditions in planetary systems where civilization is most likely to exist. Use of the equation to predict the amount of extraterrestrial life, however, is difficult; because many of the variables are unknown, the equation functions as more of a mirror to what its user already thinks. As a result, the number of civilizations in the galaxy can be estimated as low as 9.1 x 10 or as high as 156 million; for the calculations, see Drake equation.\n\nArtificial life is the simulation of any aspect of life, as through computers, robotics, or biochemistry. The study of artificial life imitates traditional biology by recreating some aspects of biological phenomena. Scientists study the logic of living systems by creating artificial environments—seeking to understand the complex information processing that defines such systems. While life is, by definition, alive, artificial life is generally referred to as data confined to a digital environment and existence.\n\nSynthetic biology is a new area of biotechnology that combines science and biological engineering. The common goal is the design and construction of new biological functions and systems not found in nature. Synthetic biology includes the broad redefinition and expansion of biotechnology, with the ultimate goals of being able to design and build engineered biological systems that process information, manipulate chemicals, fabricate materials and structures, produce energy, provide food, and maintain and enhance human health and the environment.\n\nDeath is the permanent termination of all vital functions or life processes in an organism or cell. It can occur as a result of an accident, medical conditions, biological interaction, malnutrition, poisoning, senescence, or suicide. After death, the remains of an organism re-enter the biogeochemical cycle. Organisms may be consumed by a predator or a scavenger and leftover organic material may then be further decomposed by detritivores, organisms that recycle detritus, returning it to the environment for reuse in the food chain.\n\nOne of the challenges in defining death is in distinguishing it from life. Death would seem to refer to either the moment life ends, or when the state that follows life begins. However, determining when death has occurred is difficult, as cessation of life functions is often not simultaneous across organ systems. Such determination therefore requires drawing conceptual lines between life and death. This is problematic, however, because there is little consensus over how to define life. The nature of death has for millennia been a central concern of the world's religious traditions and of philosophical inquiry. Many religions maintain faith in either a kind of afterlife or reincarnation for the soul, or resurrection of the body at a later date.\n\nExtinction is the process by which a group of taxa or species dies out, reducing biodiversity. The moment of extinction is generally considered the death of the last individual of that species. Because a species' potential range may be very large, determining this moment is difficult, and is usually done retrospectively after a period of apparent absence. Species become extinct when they are no longer able to survive in changing habitat or against superior competition. In Earth's history, over 99% of all the species that have ever lived are extinct; however, mass extinctions may have accelerated evolution by providing opportunities for new groups of organisms to diversify.\n\nFossils are the preserved remains or traces of animals, plants, and other organisms from the remote past. The totality of fossils, both discovered and undiscovered, and their placement in fossil-containing rock formations and sedimentary layers (strata) is known as the \"fossil record\". A preserved specimen is called a fossil if it is older than the arbitrary date of 10,000 years ago. Hence, fossils range in age from the youngest at the start of the Holocene Epoch to the oldest from the Archaean Eon, up to 3.4 billion years old.\n\n\n"}
{"id": "18398", "url": "https://en.wikipedia.org/wiki?curid=18398", "title": "La Espero", "text": "La Espero\n\n\"La Espero\" () is a poem written by Polish-Jewish doctor L. L. Zamenhof (1859–1917), the initiator of the Esperanto language. The song is often used as the anthem of Esperanto, and is now usually sung to a triumphal march composed by Félicien Menu de Ménil in 1909 (although there is an earlier, less martial tune created in 1891 by Claes Adelsköld, as well as a number of others less well-known). It is sometimes referred to as the hymn of the Esperanto movement.\n\nSome Esperantists object to the use of terms like \"hymn\" or \"anthem\" for \"La Espero\", arguing that these terms have religious and nationalist overtones respectively.\n\n"}
{"id": "18400", "url": "https://en.wikipedia.org/wiki?curid=18400", "title": "Loonie", "text": "Loonie\n\nThe loonie (), formally the Canadian one-dollar coin, is a gold-coloured coin that was introduced in 1987 and is produced by the Royal Canadian Mint at its facility in Winnipeg. The most prevalent versions of the coin show a common loon, a bird found throughout Canada, on the reverse and Queen Elizabeth II, the nation's head of state, on the obverse. Various commemorative and specimen-set editions of the coin with special designs replacing the loon on the reverse have been minted over the years.\n\nThe coin's outline is an 11-sided curve of constant width. Its diameter of 26.5 mm and its 11-sidedness matched that of the already-circulating Susan B. Anthony dollar in the United States, and its thickness of 1.95 mm was a close match to the latter's 2.0 mm. Its gold colour differed from the silver-coloured Anthony dollar; however, the succeeding Sacagawea and Presidential dollars matched the loonie's overall hue. Other coins using a curve of constant width include the 7-sided British twenty pence and fifty pence coins (the latter of which has similar size and value to the loonie, but is silver in colour).\n\nAfter its introduction, the coin became the symbol of the Canadian dollar: media often discuss the rate at which the \"loonie\" is trading against other currencies. The nickname \"loonie\" became so widely recognized that in 2006, the Royal Canadian Mint secured the rights to it. When the Canadian two-dollar coin was introduced in 1996, it was in turn nicknamed the \"toonie\" (a portmanteau of \"two\" and \"loonie\").\n\nCanada first minted a silver dollar coin in 1935 to celebrate the 25th anniversary of George V's reign as king. The voyageur dollar, so named because it featured an Indigenous person and a French voyageur paddling a canoe on the reverse, was minted in silver until 1967, after which it was composed primarily of nickel. The coins did not see wide circulation, mainly due to their size and weight; the nickel version weighed and was in diameter, and was itself smaller than the silver version.\n\nBy 1982, the Royal Canadian Mint had begun work on a new composition for the dollar coin that it hoped would lead to increased circulation. At the same time, vending machine operators and transit systems were lobbying the Government of Canada to replace the dollar banknotes with wider circulating coins. A Commons committee recommended in 1985 that the dollar bill be eliminated despite a lack of evidence that Canadians would support the move. The government argued that it would save between $175 million and $250 million over 20 years by switching from bills that had a lifespan of less than a year to coins that would last two decades.\n\nThe government announced on March 25, 1986, that the new dollar coin would be launched the following year as a replacement for the dollar bill, which would be phased out. It was expected to cost $31.8 million to produce the first 300 million coins, but through seigniorage (the difference between the cost of production and the coin's value), expected to make up to $40 million a year on the coins. From the proceeds, a total of $60 million over five years was dedicated toward funding the 1988 Winter Olympics in Calgary.\n\nThe failure of the Susan B. Anthony dollar coin in the United States had been considered and it was believed Americans refused to support the coin due to its similarity to their quarter coin and its lack of esthetic appeal. In announcing the new Canadian dollar coin, the government stated it would be the same overall size as the Susan B. Anthony coin – slightly larger than a quarter – to allow for compatibility with American manufactured vending machines, but would be eleven-sided and gold-coloured.\n\nIt was planned that the coin would continue using the voyageur theme of its predecessor, but the master dies that had been struck in Ottawa were lost in transit en route to the Mint's facility at Winnipeg. A Commons committee struck to investigate the loss discovered that the Mint had no documented procedures for transport of master dies and that it had shipped them via a local courier in a bid to save $43.50. It was also found to be the third time that the Mint had lost master dies within five years. An internal review by the Royal Canadian Mint argued that while a policy existed to ship the obverse and reverse dies separately, the new coin dies were packaged separately but were part of the same shipment. The Mint also disagreed with the Royal Canadian Mounted Police's contention that the dies were simply lost in transit, believing instead that they were stolen. The dies were never recovered.\n\nFearing the possibility of counterfeiting, the government approved a new design for the reverse, replacing the voyageur with a Robert-Ralph Carmichael design of a common loon floating in water. The coin was immediately nicknamed the \"loonie\" across English Canada, and became known as a \"huard\", French for \"loon\", in Quebec. The loonie entered circulation on June 30, 1987, as 40 million coins were introduced into major cities across the country. Over 800 million loonies had been struck by the coin's 20th anniversary.\n\nTwo years after the loonie's introduction, the Bank of Canada ceased production of the dollar banknote. The final dollar bills were printed on June 30, 1989. Initial support for the coin was mixed, but withdrawing the banknote forced acceptance of the coin.\n\nThe loonie has subsequently gained iconic status within Canada, and is now regarded as a national symbol. The term \"loonie\" has since become synonymous with the Canadian dollar itself. The town of Echo Bay, Ontario, home of Robert-Ralph Carmichael, erected a large loonie monument in his honour in 1992 along the highway, similar to Sudbury's 'Big Nickel'.\n\nOfficials for the 2002 Salt Lake Winter Olympics invited the National Hockey League's ice making consultant, Dan Craig, to oversee the city's E Center arena, where the ice hockey tournament was being held. Craig invited a couple of members from the ice crew in his hometown of Edmonton to assist. One of them, Trent Evans, secretly placed a loonie at centre ice. He originally placed a dime, but added the loonie after the smaller coin quickly vanished as the ice surface was built up. He placed the coins after realizing there was no target at centre ice for referees to aim for when dropping the puck for a faceoff. A thin yellow dot was painted on the ice surface over the coins, though the loonie was faintly visible to those who knew to look for it.\n\nKeeping the coin a secret, Evans told only a few people of its placement and swore them to secrecy. Among those told were the players of the men's and women's teams. Both Canadian teams went on to win gold medals. Several members of the women's team kissed the spot where the coin was buried following their victory. After the men won their final, the coin was dug up and given to Wayne Gretzky, the team's executive-director, who revealed the existence of the \"lucky loonie\" at a post-game press conference.\n\nThe lucky loonie quickly became a piece of Canadian lore. The original lucky loonie was donated to the Hockey Hall of Fame, and Canadians have subsequently hidden loonies at several international competitions. Loonies were buried in the foundations of facilities built for the 2010 Winter Olympics in Vancouver.\n\nCapitalizing on the tradition, the Royal Canadian Mint has released a commemorative edition \"lucky loonie\" for each Olympic Games since 2004.\n\nThe weight of the coin was originally specified as 108 grains, equivalent to 6.998 grams. The coin's diameter is 26.5mm.\n\nWhen introduced, loonie coins were made of Aureate, a bronze-electroplated nickel combination. Beginning in 2007, some loonie blanks also began to be produced with a cyanide-free brass plating process. In the spring of 2012, the composition switched to multi-ply brass-plated steel. As a result, the weight dropped from 7.00 to 6.27 grams. This has resulted in the 2012 loonie not being accepted in some vending machines. The Toronto Parking Authority estimates that at about $345 per machine, it will cost about $1 million to upgrade almost 3,000 machines to accept the new coins. The Mint states that multi-ply plated steel technology, already used in Canada's smaller coinage, produces an electromagnetic signature that is harder to counterfeit than that for regular alloy coins; also, using steel provides cost savings and avoids fluctuations in price or supply of nickel.\n\nOn April 10, 2012, the Royal Canadian Mint announced design changes to the loonie and toonie, which include new security features.\n\nAlongside the regular minting of the loonie with the standard image of the common loon on the coin's reverse, the Royal Canadian Mint has also released commemorative editions of the one-dollar coin for a variety of occasions. These coins have a circulation-grade finish and have been made available to the public in five-coin packs and in 25-coin rolls in addition to being released directly into circulation.\n\nIn 1997, 2002, and each year since 2004, the Royal Canadian Mint has issued a one-dollar coin that depicts a different and unique image of a bird on the coin's reverse. These special loonies have limited mintages and are available only in the six-coin specimen sets.\n\n\nFootnotes\nBibliography\n\n"}
{"id": "18401", "url": "https://en.wikipedia.org/wiki?curid=18401", "title": "Laminar flow", "text": "Laminar flow\n\nIn fluid dynamics, laminar flow (or streamline flow) occurs when a fluid flows in parallel layers, with no disruption between the layers. At low velocities, the fluid tends to flow without lateral mixing, and adjacent layers slide past one another like playing cards. There are no cross-currents perpendicular to the direction of flow, nor eddies or swirls of fluids. In laminar flow, the motion of the particles of the fluid is very orderly with particles close to a solid surface moving in straight lines parallel to that surface.\nLaminar flow is a flow regime characterized by high momentum diffusion and low momentum convection.\n\nWhen a fluid is flowing through a closed channel such as a pipe or between two flat plates, either of two types of flow may occur depending on the velocity and viscosity of the fluid: laminar flow or turbulent flow. Laminar flow tends to occur at lower velocities, below a threshold at which it becomes turbulent. Turbulent flow is a less orderly flow regime that is characterised by eddies or small packets of fluid particles, which result in lateral mixing. In non-scientific terms, laminar flow is \"smooth\", while turbulent flow is \"rough\".\n\nThe type of flow occurring in a fluid in a channel is important in fluid-dynamics problems and subsequently affects heat and mass transfer in fluid systems. The dimensionless Reynolds number is an important parameter in the equations that describe whether fully developed flow conditions lead to laminar or turbulent flow. The Reynolds number is the ratio of the inertial force to the shearing force of the fluid: how fast the fluid is moving relative to how viscous it is, irrespective of the scale of the fluid system. Laminar flow generally occurs when the fluid is moving slowly or the fluid is very viscous. As the Reynolds number increases, such as by increasing the flow rate of the fluid, the flow will transition from laminar to turbulent flow at a specific range of Reynolds numbers, the laminar–turbulent transition range depending on small disturbance levels in the fluid or imperfections in the flow system. If the Reynolds number is very small, much less than 1, then the fluid will exhibit Stokes, or creeping, flow, where the viscous forces of the fluid dominate the inertial forces.\n\nThe specific calculation of the Reynolds number, and the values where laminar flow occurs, will depend on the geometry of the flow system and flow pattern. The common example is flow through a pipe, where the Reynolds number is defined as\n\nwhere:\n\nFor such systems, laminar flow occurs when the Reynolds number is below a critical value of approximately 2,040, though the transition range is typically between 1,800 and 2,100.\n\nFor fluid systems occurring on external surfaces, such as flow past objects suspended in the fluid, other definitions for Reynolds numbers can be used to predict the type of flow around the object. The particle Reynolds number Re would be used for particle suspended in flowing fluids, for example. As with flow in pipes, laminar flow typically occurs with lower Reynolds numbers, while turbulent flow and related phenomena, such as vortex shedding, occur with higher Reynolds numbers.\n\nA common application of laminar flow is in the smooth flow of a viscous liquid through a tube or pipe. In that case, the velocity of flow varies from zero at the walls to a maximum along the cross-sectional centre of the vessel. The flow profile of laminar flow in a tube can be calculated by dividing the flow into thin cylindrical elements and applying the viscous force to them.\n\nAnother example is the flow of air over an aircraft wing. The boundary layer is a very thin sheet of air lying over the surface of the wing (and all other surfaces of the aircraft). Because air has viscosity, this layer of air tends to adhere to the wing. As the wing moves forward through the air, the boundary layer at first flows smoothly over the streamlined shape of the airfoil. Here, the flow is laminar and the boundary layer is a laminar layer. Prandtl applied the concept of the laminar boundary layer to airfoils in 1904.\n\nLaminar airflow is used to separate volumes of air, or prevent airborne contaminants from entering an area. Laminar flow hoods are used to exclude contaminants from sensitive processes in science, electronics and medicine. Air curtains are frequently used in commercial settings to keep heated or refrigerated air from passing through doorways. A laminar flow reactor (LFR) is a reactor that uses laminar flow to study chemical reactions and process mechanisms.\n\n\n"}
{"id": "18402", "url": "https://en.wikipedia.org/wiki?curid=18402", "title": "Luanda", "text": "Luanda\n\nLuanda, formerly named São Paulo da Assunção de Loanda, is the capital and largest city in Angola, and the country's most populous and important city, primary port and major industrial, cultural and urban centre. Located on Angola's coast with the Atlantic Ocean, Luanda is both Angola's chief seaport and its administrative centre. It is also the capital city of Luanda Province and the second most populous Portuguese-speaking capital city in the world, after Brasília.\n\nThe city is currently undergoing a major reconstruction, with many large developments taking place that will alter its cityscape significantly.\n\nPortuguese explorer Paulo Dias de Novais founded Luanda on 25 January 1576 as \"São Paulo da Assumpção de Loanda\", with one hundred families of settlers and four hundred soldiers. In 1618, the Portuguese built the fortress called \"Fortaleza São Pedro da Barra\", and they subsequently built two more: Fortaleza de São Miguel (1634) and Forte de São Francisco do Penedo (1765-6). Of these, the Fortaleza de São Miguel is the best preserved.\n\nLuanda was Portugal's bridgehead from 1627, except during the Dutch rule of Luanda, from 1640 to 1648, as Fort Aardenburgh. The city served as the centre of slave trade to Brazil from circa 1550 to 1836. The slave trade was conducted mostly with the Portuguese colony of Brazil; Brazilian ships were the most numerous in the port of Luanda. This slave trade also involved local merchants and warriors who profited from the trade. During this period, no large scale territorial conquest was intended by the Portuguese; only a few minor settlements were established in the immediate hinterland of Luanda, some on the last stretch of the Kwanza River.\n\nIn the 17th century, the Imbangala became the main rivals of the Mbundu in supplying slaves to the Luanda market. In the 1750s, between 5,000 and 10,000 slaves were annually sold. By this time, Angola, a Portuguese colony, was in fact like a colony of Brazil, paradoxically another Portuguese colony. A strong degree of Brazilian influence was noted in Luanda until the Independence of Brazil in 1822. In the 19th century, still under Portuguese rule, Luanda experienced a major economic revolution. The slave trade was abolished in 1836, and in 1844, Angola's ports were opened to foreign shipping. By 1850, Luanda was one of the greatest and most developed Portuguese cities in the vast Portuguese Empire outside Continental Portugal, full of trading companies, exporting (together with Benguela) palm and peanut oil, wax, copal, timber, ivory, cotton, coffee, and cocoa, among many other products. Maize, tobacco, dried meat, and cassava flour are also produced locally. The Angolan bourgeoisie was born by this time.\n\nIn 1889, Governor Brito Capelo opened the gates of an aqueduct which supplied the city with water, a formerly scarce resource, laying the foundation for major growth. Like most of Portuguese Angola, the cosmopolitan city of Luanda was not affected by the Portuguese Colonial War (1961–1974); economic growth and development in the entire region reached record highs during this period. In 1972, a report called Luanda the \"Paris of Africa\". Throughout Portugal's Estado Novo period, Luanda grew from a town of 61,208 with 14.6% of those inhabitants being white in 1940, to a wealthy cosmopolitan major city of 475,328 in 1970 with 124,814 Europeans (26.3%) and around 50,000 mixed race inhabitants. Luanda has also become one of the world's most expensive cities.\n\nBy the time of Angolan independence in 1975, Luanda was a modern city. The majority of its population was African, but it was dominated by a strong minority of white Portuguese origin. After the Carnation Revolution in Lisbon on April 25, 1974, with the advent of independence and the start of the Angolan Civil War (1975–2002), most of the white Portuguese Luandans left as refugees, principally for Portugal, with many travelling overland to South Africa. There was an immediate crisis, however, as the local African population lacked the skills and knowledge needed to run the city and maintain its well-developed infrastructure. The large numbers of skilled technicians among the force of Cuban soldiers sent in to support the Popular Movement for the Liberation of Angola (MPLA) government in the Angolan Civil War were able to make a valuable contribution to restoring and maintaining basic services in the city. In the following years, however, slums called \"musseques\" — which had existed for decades — began to grow out of proportion and stretched several kilometres beyond Luanda's former city limits as a result of the decades-long civil war, and because of the rise of deep social inequalities due to large-scale migration of civil war refugees from other Angolan regions. For decades, Luanda's facilities were not adequately expanded to handle this huge increase in the city's population. After 2002, with the end of the civil war and high economic growth rates fuelled by the wealth provided by the increasing oil and diamond production, major reconstruction started.\n\nLuanda is divided into two parts, the \"Baixa de Luanda\" (lower Luanda, the old city) and the \"Cidade Alta\" (upper city or the new part). The \"Baixa de Luanda\" is situated next to the port, and has narrow streets and old colonial buildings. However, vast new constructions have by now covered large areas beyond these traditional limits, and a number of previously independent nuclei — like Viana — were incorporated into the city.\n\nSince 2016, Luanda Province is divided into 9 municipalities:\n\n\nAll of the municipalities except those transferred from Bengo Province in 2011; namely Icolo e Bengo, and Quiçama, may be considered part of Greater Luanda. They comprise the 2,417 km2 area that was formerly the limits of Luanda Province before the transfers.\n\nThe city of Luanda is divided in seven urban districts: Ingombota, Kilamba Kiaxi, Maianga, Ngola Kiluanj, Rangel, Samba e Sambizanga.\n\nA completely new satellite city, called Luanda Sul has been built. In Camama, Zango and Kilamba Kiaxi, more high-rise developments are to be built. The capital Luanda is growing constantly - and in addition, increasingly beyond the official city limits and even provincial boundaries.\n\nLuanda is the seat of a Roman Catholic archbishop. It is also the location of most of Angola's educational institutions, including the private Catholic University of Angola and the public University of Agostinho Neto. It is also the home of the colonial Governor's Palace and the Estádio da Cidadela (the \"Citadel Stadium\"), Angola's main stadium, with a total seating capacity of 60,000.\n\nLuanda Sul is a satellite city of Luanda. A small stream flows in southern Luanda Sul, starting near the Quatro de Fevereiro Airport and emptying into the Atlantic Ocean. Luanda International School is in Viana.\n\nLuanda has a hot semi-arid climate (Köppen climate classification: \"BSh\"). The climate is warm to hot but surprisingly dry, owing to the cool Benguela Current, which prevents moisture from easily condensing into rain. Frequent fog prevents temperatures from falling at night even during the completely dry months from June to October. Luanda has an annual rainfall of , but the variability is among the highest in the world, with a co-efficient of variation above 40 percent. Observed records since 1858 range from in 1958 to in 1916. The short rainy season in March and April depends on a northerly counter current bringing moisture to the city: it has been shown clearly that weakness in the Benguela current can increase rainfall about sixfold compared with years when that current is strong.\n\nThe inhabitants of Luanda are primarily members of African ethnic groups, mainly Ambundu, Ovimbundu, and Bakongo. The official and the most widely used language is Portuguese, although several Bantu languages are also used, chiefly Kimbundu, Umbundu, and Kikongo. There is a sizable minority population of European origin, especially Portuguese (about 260,000), as well as Brazilians and other Latin Americans. Over the last decades, a significant Chinese community has formed, as has a much smaller Vietnamese community. There is a sprinkling of immigrants from other African countries as well, including a small expatriate South African community. A small number of people of Luanda are of mixed race — European/Portuguese and native African. In recent years, mainly since the mid-2000s, immigration from Portugal has increased due to Portugal's recession and poor economic situation.\n\nThe population of Luanda has grown dramatically in recent years, due in large part to war-time migration to the city, which is safe compared to the rest of the country. Luanda, however, in 2006 saw an increase in violent crime, particularly in the shanty towns that surround the colonial urban core.\n\nAround one-third of Angolans live in Luanda, 53% of whom live in poverty. Living conditions in Luanda are poor for most of the people, with essential services such as safe drinking water and electricity still in short supply, and severe shortcomings in traffic conditions. On the other hand, luxury constructions for the benefit of the wealthy minority are booming. Luanda is one of the world's most expensive cities for resident foreigners.\n\nNew import tariffs imposed in March 2014 made Luanda even more expensive. As an example, a half-litre tub of vanilla ice-cream at the supermarket was reported to cost US$31. The higher import tariffs applied to hundreds of items, from garlic to cars. The stated aim was to try to diversify the heavily oil-dependent economy and nurture farming and industry, sectors which have remained weak. These tariffs have caused much hardship in a country where the average salary was US$260 in 2010, the latest year for which data was available. However, the average salary in the booming oil industry was over 20 times higher at US$5,400.\n\nManufacturing includes processed foods, beverages, textiles, cement and other building materials, plastic products, metalware, cigarettes, and shoes/clothes. Petroleum (found in nearby off-shore deposits) is refined in the city, although this facility was repeatedly damaged during the Angolan Civil War of 1975–2002. Luanda has an excellent natural harbour; the chief exports are coffee, cotton, sugar, diamonds, iron, and salt. The city also has a thriving building industry, an effect of the nationwide economic boom experienced since 2002, when political stability returned with the end of the civil war. Economic growth is largely supported by oil extraction activities, although great diversification is taking place. Large investment (domestic and international), along with strong economic growth, has dramatically increased construction of all economic sectors in the city of Luanda. In 2007, the first modern shopping mall in Angola was established in the city at Belas Shopping mall.\n\nLuanda is the starting point of the Luanda railway that goes due east to Malanje. The civil war left the railway non-functional, but the railway has been restored up to Dondo and Malanje.\n\nThe main airport of Luanda is Quatro de Fevereiro Airport, which is the largest in the country. Currently, a new international airport, Angola International Airport is under construction southeast of the city, a few kilometres from Viana, which was expected to be opened in 2011. However, as the Angolan government did not continue to make the payments due to the Chinese enterprise in charge of the construction, the firm suspended its work in 2010.\n\nThe port of Luanda serves as the largest port of Angola, and connects Angola to the rest of the world. Major expansion of this port is also taking place. In 2014, a new port is being developed at Dande, about 30 km to the north.\n\nLuanda's roads are in a poor state of repair, but are currently undergoing an extensive reconstruction process by the government in order to relieve traffic congestion in the city. Major road repairs can be found taking place in nearly every neighbourhood, including a major 6-lane highway connected Luanda to Viana.\n\nPublic transit is provided by the suburban services of the Luanda Railway, by the public company TCUL, and by a large fleet of privately owned collective taxis as white-blue painted minibuses called \"Candongueiro\".\n\nCandongueiros are usually Toyota Hiace vans, that are built to carry 12 people, although the candongueiros usually carry at least 15 people. They charge from 100 to 200 kwanzas per trip. They are known to disobey traffic rules, for example not stopping at signs and driving over pavements and aisles. Their stop points, known as \"paragens\" are often the places cause significant traffic because they often double park.\n\nThere is also a private bus company Transportes Urbanos Rodoviarios de Angola - TURA, working routes in Luanda.\n\nThe central government supposedly allocates funds to all regions of the country, but the capital region receives the bulk of these funds. Since the end of the Angolan Civil War (1975–2002), stability has been widespread in the country, and major reconstruction has been going on since 2002 in those parts of the country that were damaged during the civil war. Luanda has been of major concern because its population had multiplied and had far outgrown the capacity of the city, especially because much of its infrastructure (water, electricity, roads etc.) had become obsolete and degraded.\n\nLuanda has been undergoing major road reconstruction in the 21st century, and new highways are planned to improve connections to Cacuaco, Viana, Samba, and the new airport.\n\nMajor social housing is also being constructed to house those who reside in slums, which dominate the landscape of Luanda. A large Chinese firm has been given a contract to construct the majority of replacement housing in Luanda. The Angolan minister of health recently stated poverty in Angola will be overcome by an increase in jobs and the housing of every citizen.\n\nUniversities:\n\nInternational schools in Luanda:\n\nIn 2013 Luanda together with Namibe, today's Moçâmedes, hosted the 2013 FIRS Men's Roller Hockey World Cup, the first time that a World Cup of roller hockey was held in Africa. The city is home to the Desportivo do Bengo football club.\n\nLuanda makes widespread use of an unusual variant of the median U-turn type intersection. This eliminates the need for traffic lights and encourages free flow traffic on many main roads around the city. The intersection operates by not permitting the left turn at intersections. Angola drives on the right. A driver entering from a minor road wanting to turn left is required to join the main road traffic and proceed a u-turn and then backtrack in the opposite direction and then make a safe right turn.\n\nThe advantages: \n\nDisadvantages:\n\nThe Government of Angola takes a bold view of property rights and has been known to relocate property owners at short notice, where the land is required to make space for the bulged u-turns.\n\nIt is unclear whether this intersection design has been in use prior or since the civil war.\n\nThe Luanda traffic is notoriously congested with gridlock and so arguably this intersection worsens the situation by lengthening the routes.\n\nLuanda is twinned with:\n\n"}
{"id": "18403", "url": "https://en.wikipedia.org/wiki?curid=18403", "title": "Logical positivism", "text": "Logical positivism\n\nLogical positivism and logical empiricism, which together formed neopositivism, was a movement in Western philosophy whose central thesis was verificationism, a theory of knowledge which asserted that only statements verifiable through empirical observation are cognitively meaningful. The movement flourished in the 1920s and 1930s in several European centers. \n\nEfforts to convert philosophy to this new \"scientific philosophy\", shared with empirical sciences' best examples, such as Albert Einstein's general theory of relativity, sought to prevent confusion rooted in unclear language and unverifiable claims. \n\nThe Berlin Circle and Vienna Circle—groups of philosophers, scientists, and mathematicians in Berlin and Vienna—propounded logical positivism, starting in the late 1920s.\n\nLogical positivists culled from Ludwig Wittgenstein's early philosophy of language the verifiability principle or criterion of meaningfulness. As in Ernst Mach's phenomenalism, whereby the mind knows only actual or potential sensory experience, verificationists took all sciences' basic content to be only sensory experience. And some influence came from Percy Bridgman's musings that others proclaimed as operationalism, whereby a physical theory is understood by what laboratory procedures scientists perform to test its predictions. In verificationism, only the \"verifiable\" was scientific, and thus meaningful (or \"cognitively meaningful\"), whereas the unverifiable, being unscientific, were meaningless \"pseudostatements\" (just \"emotively meaningful\"). Unscientific discourse, as in ethics and metaphysics, would be unfit for discourse by philosophers, newly tasked to organize knowledge, not develop new knowledge.\n\nLogical positivism is sometimes stereotyped as forbidding talk of unobservables, such as microscopic entities or such notions as causality and general principles, but that is an exaggeration. Rather, most neopositivists viewed talk of unobservables as metaphorical or elliptical: direct observations phrased abstractly or indirectly. So \"theoretical terms\" would garner meaning from \"observational terms\" via \"correspondence rules\", and thereby \"theoretical laws\" would be reduced to \"empirical laws\". Via Bertrand Russell's logicism, reducing mathematics to logic, physics' mathematical formulas would be converted to symbolic logic. Via Russell's logical atomism, ordinary language would break into discrete units of meaning. Rational reconstruction, then, would convert ordinary statements into standardized equivalents, all networked and united by a logical syntax. A scientific theory would be stated with its method of verification, whereby a logical calculus or empirical operation could verify its falsity or truth.\n\nIn the late 1930s, logical positivists fled Germany and Austria for Britain and the United States. By then, many had replaced Mach's phenomenalism with Otto Neurath's physicalism, whereby science's content is not actual or potential sensations, but instead is entities publicly observable. Rudolf Carnap, who had sparked logical positivism in the Vienna Circle, had sought to replace \"verification\" with simply \"confirmation\". With World War II's close in 1945, logical positivism became milder, \"logical empiricism\", led largely by Carl Hempel, in America, who expounded the covering law model of scientific explanation. Logical positivism became a major underpinning of analytic philosophy, and dominated philosophy in the English-speaking world, including philosophy of science, while influencing sciences, but especially social sciences, into the 1960s. Yet the movement failed to resolve its central problems, and its doctrines were increasingly criticized, most trenchantly by Willard Van Orman Quine, Norwood Hanson, Karl Popper, Thomas Kuhn, and Carl Hempel.\n\n\"Tractatus Logico-Philosophicus\", by the young Ludwig Wittgenstein, introduced the view of philosophy as \"critique of language\", offering the possibility of a theoretically principled distinction of intelligible versus nonsensical discourse. \"Tractatus\" adhered to a correspondence theory of truth (versus a coherence theory of truth). Wittgenstein's influence also shows in some versions of the verifiability principle. In tractarian doctrine, truths of logic are tautologies, a view widely accepted by logical positivists who were also influenced by Wittgenstein's interpretation of probability although, according to Neurath, some logical positivists found \"Tractatus\" to contain too much metaphysics.\n\nGottlob Frege began the program of reducing mathematics to logic, continued it with Bertrand Russell, but lost interest in this logicism, and Russell continued it with Alfred North Whitehead in their \"Principia Mathematica\", inspiring some of the more mathematical logical posivists, such as Hans Hahn and Rudolf Carnap. Carnap's early anti-metaphysical works employed Russell's theory of types. Carnap envisioned a universal language that could reconstruct mathematics and thereby encode physics. Yet Kurt Gödel's incompleteness theorem showed this impossible except in trivial cases, and Alfred Tarski's undefinability theorem shattered all hopes of reducing mathematics to logic. Thus, a universal language failed to stem from Carnap's 1934 work \"Logische Syntax der Sprache\" (\"Logical Syntax of Language\"). Still, some logical positivists, including Carl Hempel, continued support of logicism.\n\nIn Germany, Hegelian metaphysics was a dominant movement, and Hegelian successors such as F H Bradley explained reality by postulating metaphysical entities lacking empirical basis, drawing reaction in the form of positivism. Starting in the late 19th century, there was a \"back to Kant\" movement. Ernst Mach's positivism and phenomenalism were a major influence.\n\nThe Vienna Circle, gathering around University of Vienna and Café Central, was led principally by Moritz Schlick. Schlick had held a neo-Kantian position, but later converted, via Carnap's 1928 book \"Der logische Aufbau der Welt\", that is, \"The Logical Structure of the World\". A 1929 pamphlet written by Otto Neurath, Hans Hahn, and Rudolf Carnap summarized the Vienna Circle's positions. Another member of Vienna Circle to later prove very influential was Carl Hempel. A friendly but tenacious critic of the Circle was Karl Popper, whom Neurath nicknamed the \"Official Opposition\".\n\nCarnap and other Vienna Circle members, including Hahn and Neurath, saw need for a weaker criterion of meaningfulness than verifiability. A radical \"left\" wing—led by Neurath and Carnap—began the program of \"liberalization of empiricism\", and they also emphasized fallibilism and pragmatics, which latter Carnap even suggested as empiricism's basis. A conservative \"right\" wing—led by Schlick and Waismann—rejected both the liberalization of empiricism and the epistemological nonfoundationalism of a move from phenomenalism to physicalism. As Neurath and somewhat Carnap posed science toward social reform, the split in Vienna Circle also reflected political views.\n\nThe Berlin Circle was led principally by Hans Reichenbach.\n\nBoth Moritz Schlick and Rudolf Carnap had been influenced by and sought to define logical positivism versus the neo-Kantianism of Ernst Cassirer—the then leading figure of Marburg school, so called—and against Edmund Husserl's phenomenology. Logical positivists especially opposed Martin Heidegger's obscure metaphysics, the epitome of what logical positivism rejected. In the early 1930s, Carnap debated Heidegger over \"metaphysical pseudosentences\". Despite its revolutionary aims, logical positivism was but one view among many vying within Europe, and logical positivists initially spoke their language.\n\nAs the movement's first emissary to the New World, Moritz Schlick visited Stanford University in 1929, yet otherwise remained in Vienna and was murdered at the University, reportedly by a deranged student, in 1936. That year, a British attendee at some Vienna Circle meetings since 1933, A. J. Ayer saw his \"Language, Truth and Logic\", written in English, import logical positivism to the English-speaking world. By then, the Nazi Party's 1933 rise to power in Germany had triggered flight of intellectuals. In exile in England, Otto Neurath died in 1945. Rudolf Carnap, Hans Reichenbach, and Carl Hempel—Carnap's protégé who had studied in Berlin with Reichenbach—settled permanently in America. Upon Germany's annexation of Austria in 1938, remaining logical positivists, many of whom were also Jewish, were targeted and continued flight. Logical positivism thus became dominant in the English-speaking world.\n\nConcerning reality, the necessary is a state true in all possible worlds—mere logical validity—whereas the contingent hinges on the way the particular world is. Concerning knowledge, the \"a priori\" is knowable before or without, whereas the \"a posteriori\" is knowable only after or through, relevant experience. Concerning statements, the \"analytic\" is true via terms' arrangement and meanings, thus a tautology—true by logical necessity but uninformative about the world—whereas the \"synthetic\" adds reference to a state of facts, a contingency.\n\nIn 1739, David Hume cast a fork aggressively dividing \"relations of ideas\" from \"matters of fact and real existence\", such that all truths are of one type or the other. By Hume's fork, truths by relations among ideas (abstract) all align on one side (analytic, necessary, \"a priori\"), whereas truths by states of actualities (concrete) always align on the other side (synthetic, contingent, \"a posteriori\"). Of any treatises containing neither, Hume orders, \"Commit it then to the flames, for it can contain nothing but sophistry and illusion\".\n\nThus awakened from \"dogmatic slumber\", Immanuel Kant quested to answer Hume's challenge—but by explaining how metaphysics is possible. Eventually, in his 1781 work, Kant crossed the tines of Hume's fork to identify another range of truths by necessity—synthetic \"a priori\", statements claiming states of facts but known true before experience—by arriving at transcendental idealism, attributing the mind a constructive role in phenomena by arranging sense data into the very experience \"space\", \"time\", and \"substance\". Thus, Kant saved Newton's law of universal gravitation from Hume's problem of induction by finding uniformity of nature to be \"a priori\" knowledge. Logical positivists rejected Kant's synthethic \"a priori\", and staked Hume's fork, whereby a statement is either analytic and \"a priori\" (thus necessary and verifiable logically) or synthetic and \"a posteriori\" (thus contingent and verifiable empirically).\n\nEarly, most logical positivists proposed that all knowledge is based on logical inference from simple \"protocol sentences\" grounded in observable facts. In the 1936 and 1937 papers \"Testability and meaning\", individual terms replace sentences as the units of meaning. Further, theoretical terms no longer need to acquire meaning by explicit definition from observational terms: the connection may be indirect, through a system of implicit definitions. Carnap also provided an important, pioneering discussion of disposition predicates.\n\nThe logical positivists' initial stance was that a statement is \"cognitively meaningful\" only if some finite procedure conclusively determines its truth. By this verifiability principle, only statements verifiable either by their analyticity or by empiricism were \"cognitively meaningful\". Metaphysics, ontology, as well as much of ethics failed this criterion, and so were found \"cognitively meaningless\". Moritz Schlick, however, did not view ethical or aesthetic statements as cognitively meaningless. \"Cognitive meaningfulness\" was variously defined: having a truth value; corresponding to a possible state of affairs; intelligible or understandable as are scientific statements.\n\nEthics and aesthetics were subjective preferences, while theology and other metaphysics contained \"pseudostatements\", neither true nor false. This meaningfulness was cognitive, although other types of meaningfulness—for instance, emotive, expressive, or figurative—occurred in metaphysical discourse, dismissed from further review. Thus, logical positivism indirectly asserted Hume's law, the principle that \"is\" statements cannot justify \"ought\" statements, but are separated by an unbridgeable gap. A. J. Ayer's 1936 book asserted an extreme variant—the boo/hooray doctrine—whereby all evaluative judgments are but emotional reactions.\n\nIn an important pair of papers in 1936 and 1937, \"Testability and meaning\", Carnap replaced \"verification\" with \"confirmation\", on the view that although universal laws cannot be verified they can be confirmed. Later, Carnap employed abundant logical and mathematical methods in researching inductive logic while seeking to provide an account of probability as \"degree of confirmation\", but was never able to formulate a model. In Carnap's inductive logic, every universal law's degree of confirmation is always zero. In any event, the precise formulation of what came to be called the \"criterion of cognitive significance\" took three decades (Hempel 1950, Carnap 1956, Carnap 1961).\n\nCarl Hempel became a major critic within the logical positivism movement. Hempel elucidated the paradox of confirmation.\n\nThe second edition of A. J. Ayer's book arrived in 1946, and discerned \"strong\" versus \"weak\" forms of verification. Ayer concluded, \"A proposition is said to be verifiable, in the strong sense of the term, if, and only if, its truth could be conclusively established by experience\", but is verifiable in the weak sense \"if it is possible for experience to render it probable\". And yet, \"no proposition, other than a tautology, can possibly be anything more than a probable hypothesis\". Thus, all are open to weak verification.\n\nUpon the global defeat of Nazism, and the removal from philosophy of rivals for radical reform—Marburg neo-Kantianism, Husserlian phenomenology, Heidegger's \"existential hermeneutics\"—and while hosted in the climate of American pragmatism and commonsense empiricism, the neopositivists shed much of their earlier, revolutionary zeal. No longer crusading to revise traditional philosophy into a new \"scientific philosophy\", they became respectable members of a new philosophy subdiscipline, \"philosophy of science\". Receiving support from Ernest Nagel, logical empiricists were especially influential in the social sciences.\n\nComtean positivism had viewed science as \"description\", whereas the logical positivists posed science as \"explanation\", perhaps to better realize the envisioned unity of science by covering not only fundamental science—that is, fundamental physics—but the special sciences, too, for instance biology, anthropology, psychology, sociology, and economics. The most widely accepted concept of scientific explanation, held even by neopositivist critic Karl Popper, was the deductive-nomological model (DN model). Yet DN model received its greatest explication by Carl Hempel, first in his 1942 article \"The function of general laws in history\", and more explicitly with Paul Oppenheim in their 1948 article \"Studies in the logic of explanation\".\n\nIn the DN model, the stated phenomenon to be explained is the \"explanandum\"—which can be an event, law, or theory—whereas premises stated to explain it are the \"explanans\". Explanans must be true or highly confirmed, contain at least one law, and entail the explanandum. Thus, given initial conditions \"C, C . . . C\" plus general laws \"L, L . . . L\", event \"E\" is a deductive consequence and scientifically explained. In the DN model, a law is an unrestricted generalization by conditional proposition—\"If A, then B\"—and has empirical content testable. (Differing from a merely true regularity—for instance, \"George always carries only $1 bills in his wallet\"—a law suggests what \"must\" be true, and is consequent of a scientific theory's axiomatic structure.)\n\nBy the Humean empiricist view that humans observe sequences of events, (not cause and effect, as causality and causal mechanisms are unobservable), the DN model neglects causality beyond mere constant conjunction, first event \"A\" and then always event \"B\". Hempel's explication of the DN model held natural laws—empirically confirmed regularities—as satisfactory and, if formulated realistically, approximating causal explanation. In later articles, Hempel defended the DN model and proposed a probabilistic explanation, inductive-statistical model (IS model). the DN and IS models together form the \"covering law model\", as named by a critic, William Dray. Derivation of statistical laws from other statistical laws goes to deductive-statistical model (DS model). Georg Henrik von Wright, another critic, named it \"subsumption theory\", fitting the ambition of theory reduction.\n\nLogical positivists were generally committed to \"Unified Science\", and sought a common language or, in Neurath's phrase, a \"universal slang\" whereby all scientific propositions could be expressed. The adequacy of proposals or fragments of proposals for such a language was often asserted on the basis of various \"reductions\" or \"explications\" of the terms of one special science to the terms of another, putatively more fundamental. Sometimes these reductions consisted of set-theoretic manipulations of a few logically primitive concepts (as in Carnap's \"Logical Structure of the World\", 1928). Sometimes, these reductions consisted of allegedly analytic or \"a priori\" deductive relationships (as in Carnap's \"Testability and meaning\"). A number of publications over a period of thirty years would attempt to elucidate this concept.\n\nAs in Comtean positivism's envisioned unity of science, neopositivists aimed to network all special sciences through the covering law model of scientific explanation. And ultimately, by supplying boundary conditions and supplying bridge laws within the covering law model, all the special sciences' laws would reduce to fundamental physics, the fundamental science.\n\nAfter World War II, key tenets of logical positivism, including its atomistic philosophy of science, the verifiability principle, and the fact/value gap, drew escalated criticism. It was clear that empirical claims cannot be verified to be universally true. Thus, as initially stated, the verifiability criterion made universal statements meaningless, and even made statements beyond empiricism for technological but not conceptual reasons meaningless, which would pose significant problems for science. These problems were recognized within the movement, which hosted attempted solutions—Carnap's move to \"confirmation\", Ayer's acceptance of \"weak verification\"—but the program drew sustained criticism from a number of directions by the 1950s. Even philosophers disagreeing among themselves on which direction general epistemology ought to take, as well as on philosophy of science, agreed that the logical empiricist program was untenable, and it became viewed as self-contradictory. The verifiability criterion of meaning was itself unverified. Notable critics included Nelson Goodman, Willard Van Orman Quine, Norwood Hanson, Karl Popper, Thomas Kuhn, J L Austin, Peter Strawson, Hilary Putnam, and Richard Rorty.\n\nAlthough quite empiricist, American logician Willard Van Orman Quine published the 1951 paper \"Two Dogmas of Empiricism\", which challenged conventional empiricist presumptions. Quine attacked the analytic/synthetic division, which the verificationist program had been hinged upon in order to entail, by consequence of Hume's fork, both necessity and apriocity. Quine's ontological relativity explained that every term in any statement has its meaning contingent on a vast network of knowledge and belief, the speaker's conception of the entire world. Quine later proposed naturalized epistemology.\n\nIn 1958, Norwood Hanson's \"Patterns of Discovery\" undermined the division of observation versus theory, as one can predict, collect, prioritize, and assess data only via some horizon of expectation set by a theory. Thus, any dataset—the direct observations, the scientific facts—is laden with theory.\n\nAn early, tenacious critic was Karl Popper whose 1934 book \"Logik der Forschung\", arriving in English in 1959 as \"The Logic of Scientific Discovery\", directly answered verificationism. Popper heeded the problem of induction as rendering empirical verification logically impossible, and the deductive fallacy of affirming the consequent reveals any phenomenon's capacity to host more than one logically possible explanation. Accepting scientific method as hypotheticodeduction, whose inference form is denying the consequent, Popper finds scientific method unable to proceed without falsifiable predictions. Popper thus identifies falsifiability to demarcate not \"meaningful\" from \"meaningless\" but simply \"scientific\" from \"unscientific\"—a label not in itself unfavorable.\n\nPopper finds virtue in metaphysics, required to develop new scientific theories. And an unfalsifiable—thus unscientific, perhaps metaphysical—concept in one era can later, through evolving knowledge or technology, become falsifiable, thus scientific. Popper also found science's quest for truth to rest on values. Popper disparages the \"pseudoscientific\", which occurs when an unscientific theory is proclaimed true and coupled with seemingly scientific method by \"testing\" the unfalsifiable theory—whose predictions are confirmed by necessity—or when a scientific theory's falsifiable predictions are strongly falsified but the theory is persistently protected by \"immunizing stratagems\", such as the appendage of \"ad hoc\" clauses saving the theory or the recourse to increasingly speculative hypotheses shielding the theory.\n\nPopper's \"scientific\" epistemology is falsificationism, which finds that no number, degree, and variety of empirical successes can either verify or confirm scientific theory. Falsificationism finds science's aim as \"corroboration\" of scientific theory, which strives for scientific realism but accepts the maximal status of strongly corroborated verisimilitude (\"truthlikeness\"). Explicitly denying the positivist view that all knowledge is scientific, Popper developed the \"general\" epistemology critical rationalism, which finds human knowledge to evolve by \"conjectures and refutations\". Popper thus acknowledged the value of the positivist movement, driving evolution of human understanding, but claimed that he had \"killed positivism\".\n\nWith his landmark, \"The Structure of Scientific Revolutions\" (1962), Thomas Kuhn critically destabilized the verificationist program, which was presumed to call for foundationalism. (Actually, even in the 1930s, Otto Neurath had argued for nonfoundationalism via coherentism by likening science to a boat (Neurath's boat) that scientists must rebuild at sea.) Although Kuhn's thesis itself was attacked even by opponents of neopositivism, in the 1970 postscript to \"Structure\", Kuhn asserted, at least, that there was no algorithm to science—and, on that, even most of Kuhn's critics agreed.\n\nPowerful and persuasive, Kuhn's book, unlike the vocabulary and symbols of logic's formal language, was written in natural language open to the layperson. Ironically, Kuhn's book was first published in a volume of \"Encyclopedia of Unified Science\"—a project begun by logical positivists—and some sense unified science, indeed, but by bringing it into the realm of historical and social assessment, rather than fitting it to the model of physics. Kuhn's ideas were rapidly adopted by scholars in disciplines well outside natural sciences, and, as logical empiricists were extremely influential in the social sciences, ushered academia into postpositivism or postempiricism.\n\nThe \"received view\" operates on the \"correspondence rule\" that states, \"The observational terms are taken as referring to specified phenomena or phenomenal properties, and the only interpretation given to the theoretical terms is their explicit definition provided by the correspondence rules\". According to Hilary Putnam, a former student of Reichenbach and of Carnap, the dichotomy of observational terms versus theoretical terms introduced a problem within scientific discussion that was nonexistent until this dichotomy was stated by logical positivists. Putnam's four objections:\n\n\nPutnam also alleged that positivism was actually a form of metaphysical idealism by its rejecting scientific theory's ability to garner knowledge about nature's unobservable aspects. With his \"no miracles\" argument, posed in 1974, Putnam asserted scientific realism, the stance that science achieves true—or approximately true—knowledge of the world as it exists independently of humans' sensory experience. In this, Putnam opposed not only the positivism but other instrumentalism—whereby scientific theory is but a human tool to predict human observations—filling the void left by positivism's decline.\n\nBy the late 1960s, logical positivism had become exhausted. Interviewed in the late 1970s, A. J. Ayer supposed that \"the most important\" defect \"was that nearly all of it was false\". After some laughter, he says that \"it was true in spirit.\" Although logical positivism tends to be recalled as a pillar of scientism, Carl Hempel was key in establishing the philosophy subdiscipline philosophy of science where Thomas Kuhn and Karl Popper brought in the era of postpositivism. John Passmore found logical positivism to be \"dead, or as dead as a philosophical movement ever becomes\".\n\nLogical positivism's fall reopened debate over the metaphysical merit of scientific theory, whether it can offer knowledge of the world beyond human experience (scientific realism) versus whether it is but a human tool to predict human experience (instrumentalism). Meanwhile, it became popular among philosophers to rehash the faults and failures of logical positivism without investigation of it. Thereby, logical positivism has been generally misrepresented, sometimes severely. Arguing for their own views, often framed versus logical positivism, many philosophers have reduced logical positivism to simplisms and stereotypes, especially the notion of logical positivism as a type of foundationalism. In any event, the movement helped anchor analytic philosophy in the English-speaking world, and returned Britain to empiricism. Without the logical positivists, who have been tremendously influential outside philosophy, especially in psychology and social sciences, intellectual life of the 20th century would be unrecognizable.\n\n\n\n\nArticles by logical positivists\n\nArticles on logical positivism\n\nArticles on related philosophical topics\n"}
{"id": "18404", "url": "https://en.wikipedia.org/wiki?curid=18404", "title": "Lorentz transformation", "text": "Lorentz transformation\n\nIn physics, the Lorentz transformations are a one-parameter family of linear transformations from a coordinate frame in space time to another frame that moves at a constant velocity, the parameter, within the former. The transformations are named after the Dutch physicist Hendrik Lorentz. The respective inverse transformation is then parametrized by the negative of this velocity.\n\nThe most common form of the transformation, parametrized by the real constant formula_1 representing a velocity confined to the -direction, is expressed as \nwhere and are the coordinates of an event in two frames, where the primed frame is seen from the unprimed frame as moving with speed along the -axis, is the speed of light, and formula_3 is the Lorentz factor.\n\nExpressing the speed as formula_4 an equivalent form of the transformation is\n\nFrames of reference can be divided into two groups: inertial (relative motion with constant velocity) and non-inertial (accelerating, moving in curved paths, rotational motion with constant angular velocity, etc.). The term \"Lorentz transformations\" only refers to transformations between \"inertial\" frames, usually in the context of special relativity. \n\nIn each reference frame, an observer can use a local coordinate system (most exclusively Cartesian coordinates in this context) to measure lengths, and a clock to measure time intervals. An observer is a real or imaginary entity that can take measurements, say humans, or any other living organism—or even robots and computers. An event is something that happens at a point in space at an instant of time, or more formally a point in spacetime. The transformations connect the space and time coordinates of an event as measured by an observer in each frame.\n\nThey supersede the Galilean transformation of Newtonian physics, which assumes an absolute space and time (see Galilean relativity). The Galilean transformation is a good approximation only at relative speeds much smaller than the speed of light. Lorentz transformations have a number of unintuitive features that do not appear in Galilean transformations. For example, they reflect the fact that observers moving at different velocities may measure different distances, elapsed times, and even different orderings of events, but always such that the speed of light is the same in all inertial reference frames. The invariance of light speed is one of the postulates of special relativity.\n\nHistorically, the transformations were the result of attempts by Lorentz and others to explain how the speed of light was observed to be independent of the reference frame, and to understand the symmetries of the laws of electromagnetism. The Lorentz transformation is in accordance with special relativity, but was derived before special relativity.\n\nThe Lorentz transformation is a linear transformation. It may include a rotation of space; a rotation-free Lorentz transformation is called a Lorentz boost. In Minkowski space, the mathematical model of spacetime in special relativity, the Lorentz transformations preserve the spacetime interval between any two events. This property is the defining property of a Lorentz transformation. They describe only the transformations in which the spacetime event at the origin is left fixed. They can be considered as a hyperbolic rotation of Minkowski space. The more general set of transformations that also includes translations is known as the Poincaré group.\n\nMany physicists—including Woldemar Voigt, George FitzGerald, Joseph Larmor, and Hendrik Lorentz himself—had been discussing the physics implied by these equations since 1887. Early in 1889, Oliver Heaviside had shown from Maxwell's equations that the electric field surrounding a spherical distribution of charge should cease to have spherical symmetry once the charge is in motion relative to the aether. FitzGerald then conjectured that Heaviside’s distortion result might be applied to a theory of intermolecular forces. Some months later, FitzGerald published the conjecture that bodies in motion are being contracted, in order to explain the baffling outcome of the 1887 aether-wind experiment of Michelson and Morley. In 1892, Lorentz independently presented the same idea in a more detailed manner, which was subsequently called FitzGerald–Lorentz contraction hypothesis. Their explanation was widely known before 1905.\n\nLorentz (1892–1904) and Larmor (1897–1900), who believed the luminiferous aether hypothesis, also looked for the transformation under which Maxwell's equations are invariant when transformed from the aether to a moving frame. They extended the FitzGerald–Lorentz contraction hypothesis and found out that the time coordinate has to be modified as well (\"local time\"). Henri Poincaré gave a physical interpretation to local time (to first order in \"v\"/\"c\", the relative velocity of the two reference frames normalized to the speed of light) as the consequence of clock synchronization, under the assumption that the speed of light is constant in moving frames. Larmor is credited to have been the first to understand the crucial time dilation property inherent in his equations.\n\nIn 1905, Poincaré was the first to recognize that the transformation has the properties of a mathematical group,\nand named it after Lorentz.\nLater in the same year Albert Einstein published what is now called special relativity, by deriving the Lorentz transformation under the assumptions of the principle of relativity and the constancy of the speed of light in any inertial reference frame, and by abandoning the mechanistic aether as unnecessary.\n\nAn \"event\" is something that happens at a certain point in spacetime, or more generally, the point in spacetime itself. In any inertial frame an event is specified by a time coordinate \"ct\" and a set of Cartesian coordinates to specify position in space in that frame. Subscripts label individual events.\n\nFrom Einstein's second postulate of relativity follows\n\nin all inertial frames for events connected by \"light signals\". The quantity on the left is called the \"spacetime interval\" between events and . The interval between \"any two\" events, not necessarily separated by light signals, is in fact invariant, i.e., independent of the state of relative motion of observers in different inertial frames, as is shown using homogeneity and isotropy of space. The transformation sought after thus must possess the property that\n\nwhere are the spacetime coordinates used to define events in one frame, and are the coordinates in another frame. First one observes that is satisfied if an arbitrary -tuple of numbers are added to events and . Such transformations are called \"spacetime translations\" and are not dealt with further here. Then one observes that a \"linear\" solution preserving the origin of the simpler problem\n\nsolves the general problem too. (A solution satisfying the left formula automatically satisfies the right formula, see polarization identity.) Finding the solution to the simpler problem is just a matter of look-up in the theory of classical groups that preserve bilinear forms of various signature.. First equation in can be written more compactly as\n\nwhere refers to the bilinear form of signature on exposed by the right hand side formula in . The alternative notation defined on the right is referred to as the \"relativistic dot product\". Spacetime mathematically viewed as endowed with this bilinear form is known as Minkowski space . The Lorentz transformation is thus an element of the group Lorentz group , the Lorentz group or, for those that prefer the other metric signature, (also called the Lorentz group). One has\n\nwhich is precisely preservation of the bilinear form which implies (by linearity of and bilinearity of the form) that is satisfied. The elements of the Lorentz group are rotations and \"boosts\" and mixes thereof. If the spacetime translations are included, then one obtains the \"inhomogeneous Lorentz group\" or the Poincaré group.\n\nThe relations between the primed and unprimed spacetime coordinates are the Lorentz transformations, each coordinate in one frame is a linear function of all the coordinates in the other frame, and the inverse functions are the inverse transformation. Depending on how the frames move relative to each other, and how they are oriented in space relative to each other, other parameters that describe direction, speed, and orientation enter the transformation equations.\n\nTransformations describing relative motion with constant (uniform) velocity and without rotation of the space coordinate axes are called \"boosts\", and the relative velocity between the frames is the parameter of the transformation. The other basic type of Lorentz transformations is rotations in the spatial coordinates only, these are also inertial frames since there is no relative motion, the frames are simply tilted (and not continuously rotating), and in this case quantities defining the rotation are the parameters of the transformation (e.g., axis–angle representation, or Euler angles, etc.). A combination of a rotation and boost is a \"homogeneous transformation\", which transforms the origin back to the origin.\n\nThe full Lorentz group also contains special transformations that are neither rotations nor boosts, but rather reflections in a plane through the origin. Two of these can be singled out; spatial inversion in which the spatial coordinates of all events are reversed in sign and temporal inversion in which the time coordinate for each event gets its sign reversed.\n\nBoosts should not be conflated with mere displacements in spacetime; in this case, the coordinate systems are simply shifted and there is no relative motion. However, these also count as symmetries forced by special relativity since they leave the spacetime interval invariant. A combination of a rotation with a boost, followed by a shift in spacetime, is an \"inhomogeneous Lorentz transformation\", an element of the Poincaré group, which is also called the inhomogeneous Lorentz group.\n\nA \"stationary\" observer in frame defines events with coordinates . Another frame moves with velocity relative to , and an observer in this \"moving\" frame defines events using the coordinates .\n\nThe coordinate axes in each frame are parallel (the and axes are parallel, the and axes are parallel, and the and axes are parallel), remain mutually perpendicular, and relative motion is along the coincident axes. At , the origins of both coordinate systems are the same, . In other words, the times and positions are coincident at this event. If all these hold, then the coordinate systems are said to be in standard configuration, or synchronized.\n\nIf an observer in records an event , then an observer in records the \"same\" event with coordinates\n\nwhere is the relative velocity between frames in the -direction, is the speed of light, and\n\n(lowercase gamma) is the Lorentz factor.\n\nHere, is the \"parameter\" of the transformation, for a given boost it is a constant number, but can take a continuous range of values. In the setup used here, positive relative velocity is motion along the positive directions of the axes, zero relative velocity is no relative motion, while negative relative velocity is relative motion along the negative directions of the axes. The magnitude of relative velocity cannot equal or exceed , so only subluminal speeds are allowed. The corresponding range of is .\n\nThe transformations are not defined if is outside these limits. At the speed of light () is infinite, and faster than light () is a complex number, each of which make the transformations unphysical. The space and time coordinates are measurable quantities and numerically must be real numbers.\n\nAs an active transformation, an observer in F′ notices the coordinates of the event to be \"boosted\" in the negative directions of the axes, because of the in the transformations. This has the equivalent effect of the \"coordinate system\" F′ boosted in the positive directions of the axes, while the event does not change and is simply represented in another coordinate system, a passive transformation.\n\nThe inverse relations ( in terms of ) can be found by algebraically solving the original set of equations. A more efficient way is to use physical principles. Here is the \"stationary\" frame while is the \"moving\" frame. According to the principle of relativity, there is no privileged frame of reference, so the transformations from to must take exactly the same form as the transformations from to . The only difference is moves with velocity relative to (i.e., the relative velocity has the same magnitude but is oppositely directed). Thus if an observer in notes an event , then an observer in notes the \"same\" event with coordinates\n\nand the value of remains unchanged. This \"trick\" of simply reversing the direction of relative velocity while preserving its magnitude, and exchanging primed and unprimed variables, always applies to finding the inverse transformation of every boost in any direction.\n\nSometimes it is more convenient to use (lowercase beta) instead of , so that\n\nwhich shows much more clearly the symmetry in the transformation. From the allowed ranges of and the definition of , it follows . The use of and is standard throughout the literature.\n\nThe Lorentz transformations can also be derived in a way that resembles circular rotations in 3d space using the hyperbolic functions. For the boost in the direction, the results are\n\nwhere (lowercase zeta) is a parameter called \"rapidity\" (many other symbols are used, including ). Given the strong resemblance to rotations of spatial coordinates in 3d space in the Cartesian xy, yz, and zx planes, a Lorentz boost can be thought of as a hyperbolic rotation of spacetime coordinates in the xt, yt, and zt Cartesian-time planes of 4d Minkowski space. The parameter is the hyperbolic angle of rotation, analogous to the ordinary angle for circular rotations. This transformation can be illustrated with a Minkowski diagram.\n\nThe hyperbolic functions arise from the \"difference\" between the squares of the time and spatial coordinates in the spacetime interval, rather than a sum. The geometric significance of the hyperbolic functions can be visualized by taking or in the transformations. Squaring and subtracting the results, one can derive hyperbolic curves of constant coordinate values but varying , which parametrizes the curves according to the identity\n\nConversely the and axes can be constructed for varying coordinates but constant . The definition\n\nprovides the link between a constant value of rapidity, and the slope of the axis in spacetime. A consequence these two hyperbolic formulae is an identity that matches the Lorentz factor\n\nComparing the Lorentz transformations in terms of the relative velocity and rapidity, or using the above formulae, the connections between , , and are\n\nTaking the inverse hyperbolic tangent gives the rapidity\n\nSince , it follows . From the relation between and , positive rapidity is motion along the positive directions of the axes, zero rapidity is no relative motion, while negative rapidity is relative motion along the negative directions of the axes.\n\nThe inverse transformations are obtained by exchanging primed and unprimed quantities to switch the coordinate frames, and negating rapidity since this is equivalent to negating the relative velocity. Therefore,\n\nThe inverse transformations can be similarly visualized by considering the cases when and .\n\nSo far the Lorentz transformations have been applied to \"one event\". If there are two events, there is a spatial separation and time interval between them. It follows from the linearity of the Lorentz transformations that two values of space and time coordinates can be chosen, the Lorentz transformations can be applied to each, then subtracted to get the Lorentz transformations of the differences;\n\nwith inverse relations\n\nwhere (uppercase delta) indicates a difference of quantities; e.g., for two values of coordinates, and so on.\n\nThese transformations on \"differences\" rather than spatial points or instants of time are useful for a number of reasons:\n\n\nA critical requirement of the Lorentz transformations is the invariance of the speed of light, a fact used in their derivation, and contained in the transformations themselves. If in the equation for a pulse of light along the direction is , then in the Lorentz transformations give , and vice versa, for any .\n\nFor relative speeds much less than the speed of light, the Lorentz transformations reduce to the Galilean transformation\n\nin accordance with the correspondence principle. It is sometimes said that nonrelativistic physics is a physics of \"instantaneous action at a distance\".\n\nThree counterintuitive, but correct, predictions of the transformations are:\n\nThe use of vectors allows positions and velocities to be expressed in arbitrary directions compactly. A single boost in any direction depends on the full relative velocity vector with a magnitude that cannot equal or exceed , so that .\n\nOnly time and the coordinates parallel to the direction of relative motion change, while those coordinates perpendicular do not. With this in mind, split the spatial position vector as measured in , and as measured in , each into components perpendicular (⊥) and parallel ( ‖ ) to ,\n\nthen the transformations are\n\nwhere · is the dot product. The Lorentz factor retains its definition for a boost in any direction, since it depends only on the magnitude of the relative velocity. The definition with magnitude is also used by some authors.\n\nIntroducing a unit vector in the direction of relative motion, the relative velocity is with magnitude and direction , and vector projection and rejection give respectively\n\nAccumulating the results gives the full transformations,\n\n\\end{align}</math>\n\nThe projection and rejection also applies to . For the inverse transformations, exchange and to switch observed coordinates, and negate the relative velocity (or simply the unit vector since the magnitude is always positive) to obtain\n\n\\end{align}</math>\n\nThe unit vector has the advantage of simplifying equations for a single boost, allows either or to be reinstated when convenient, and the rapidity parametrization is immediately obtained by replacing and . It is not convenient for multiple boosts.\n\nThe vectorial relation between relative velocity and rapidity is\n\nand the \"rapidity vector\" can be defined as\n\neach of which serves as a useful abbreviation in some contexts. The magnitude of is the absolute value of the rapidity scalar confined to , which agrees with the range .\n\nDefining the coordinate velocities and Lorentz factor by\n\ntaking the differentials in the coordinates and time of the vector transformations, then dividing equations, leads to\n\nThe velocities and are the velocity of some massive object. They can also be for a third inertial frame (say \"F\"′′), in which case they must be \"constant\". Denote either entity by X. Then X moves with velocity relative to F, or equivalently with velocity relative to F′, in turn F′ moves with velocity relative to F. The inverse transformations can be obtained in a similar way, or as with position coordinates exchange and , and change to .\n\nThe transformation of velocity is useful in stellar aberration, the Fizeau experiment, and the relativistic Doppler effect.\n\nThe Lorentz transformations of acceleration can be similarly obtained by taking differentials in the velocity vectors, and dividing these by the time differential.\n\nIn general, given four quantities and and their Lorentz-boosted counterparts and , a relation of the form\n\nimplies the quantities transform under Lorentz transformations similar to the transformation of spacetime coordinates;\n\nThe decomposition of (and ) into components perpendicular and parallel to is exactly the same as for the position vector, as is the process of obtaining the inverse transformations (exchange and to switch observed quantities, and reverse the direction of relative motion by the substitution ).\n\nThe quantities collectively make up a \"four vector\", where is the \"timelike component\", and the \"spacelike component\". Examples of and are the following:\n\nFor a given object (e.g., particle, fluid, field, material), if or correspond to properties specific to the object like its charge density, mass density, spin, etc., its properties can be fixed in the rest frame of that object. Then the Lorentz transformations give the corresponding properties in a frame moving relative to the object with constant velocity. This breaks some notions taken for granted in non-relativistic physics. For example, the energy of an object is a scalar in non-relativistic mechanics, but not in relativistic mechanics because energy changes under Lorentz transformations; its value is different for various inertial frames. In the rest frame of an object, it has a rest energy and zero momentum. In a boosted frame its energy is different and it appears to have a momentum. Similarly, in non-relativistic quantum mechanics the spin of a particle is a constant vector, but in relativistic quantum mechanics spin depends on relative motion. In the rest frame of the particle, the spin pseudovector can be fixed to be its ordinary non-relativistic spin with a zero timelike quantity , however a boosted observer will perceive a nonzero timelike component and an altered spin.\n\nNot all quantities are invariant in the form as shown above, for example orbital angular momentum does not have a timelike quantity, and neither does the electric field nor the magnetic field . The definition of angular momentum is , and in a boosted frame the altered angular momentum is . Applying this definition using the transformations of coordinates and momentum leads to the transformation of angular momentum. It turns out transforms with another vector quantity related to boosts, see relativistic angular momentum for details. For the case of the and fields, the transformations cannot be obtained as directly using vector algebra. The Lorentz force is the definition of these fields, and in it is while in it is . A method of deriving the EM field transformations in an efficient way which also illustrates the unit of the electromagnetic field uses tensor algebra, given below.\n\nThroughout, italic non-bold capital letters are 4×4 matrices, while non-italic bold letters are 3×3 matrices.\n\nWriting the coordinates in column vectors and the Minkowski metric as a square matrix\n\nthe spacetime interval takes the form (T denotes transpose)\n\nand is invariant under a Lorentz transformation\n\nwhere Λ is a square matrix which can depend on parameters.\n\nThe set of all Lorentz transformations Λ in this article is denoted formula_29. This set together with matrix multiplication forms a group, in this context known as the \"Lorentz group\". Also, the above expression is a quadratic form of signature (3,1) on spacetime, and the group of transformations which leaves this quadratic form invariant is the indefinite orthogonal group O(3,1), a Lie group. In other words, the Lorentz group is O(3,1). As presented in this article, any Lie groups mentioned are matrix Lie groups. In this context the operation of composition amounts to matrix multiplication.\n\nFrom the invariance of the spacetime interval it follows\n\nand this matrix equation contains the general conditions on the Lorentz transformation to ensure invariance of the spacetime interval. Taking the determinant of the equation using the product rule gives immediately\n\nWriting the Minkowski metric as a block matrix, and the Lorentz transformation in the most general form,\n\ncarrying out the block matrix multiplications obtains general conditions on to ensure relativistic invariance. Not much information can be directly extracted from all the conditions, however one of the results\n\nis useful; always so it follows that\n\nThe negative inequality may be unexpected, because multiplies the time coordinate and this has an effect on time symmetry. If the positive equality holds, then is the Lorentz factor.\n\nThe determinant and inequality provide four ways to classify Lorentz Transformations (\"herein LTs for brevity\"). Any particular LT has only one determinant sign \"and\" only one inequality. There are four sets which include every possible pair given by the intersections (\"n\"-shaped symbol meaning \"and\") of these classifying sets.\n\nwhere \"+\" and \"−\" indicate the determinant sign, while \"↑\" for ≥ and \"↓\" for ≤ denote the inequalities.\n\nThe full Lorentz group splits into the union (\"u\"-shaped symbol meaning \"or\") of four disjoint sets\n\nA subgroup of a group must be closed under the same operation of the group (here matrix multiplication). In other words, for two Lorentz transformations and from a particular set, the composite Lorentz transformations and must be in the same set as and . This will not always be the case; it can be shown that the composition of \"any\" two Lorentz transformations always has the positive determinant and positive inequality, a proper orthochronous transformation. The sets formula_36, formula_37, formula_38, and formula_39 all form subgroups. The other sets involving the improper and/or antichronous properties (i.e. formula_40, formula_41, formula_42) do not form subgroups, because the composite transformation always has a positive determinant or inequality, whereas the original separate transformations will have negative determinants and/or inequalities.\n\nThe Lorentz boost is\n\nwhere the boost matrix is\n\nThe boosts along the Cartesian directions can be readily obtained, for example the unit vector in the x direction has components and .\n\nThe matrices make one or more successive transformations easier to handle, rather than rotely iterating the transformations to obtain the result of more than one transformation. If a frame is boosted with velocity relative to frame , and another frame is boosted with velocity relative to , the separate boosts are\nand the composition of the two boosts connects the coordinates in and ,\nSuccessive transformations act on the left. If and are collinear (parallel or antiparallel along the same line of relative motion), the boost matrices commute: and this composite transformation happens to be another boost.\n\nIf and are not collinear but in different directions, the situation is considerably more complicated. Lorentz boosts along different directions do not commute: and are not equal. Also, each of these compositions is \"not\" a single boost, but still a Lorentz transformation as each boost still preserves invariance of the spacetime interval. It turns out the composition of any two Lorentz boosts is equivalent to a boost followed or preceded by a rotation on the spatial coordinates, in the form of or . The and are composite velocities, while and are rotation parameters (e.g. axis-angle variables, Euler angles, etc.). The rotation in block matrix form is simply\n\nwhere is a 3d rotation matrix, which rotates any 3d vector in one sense (active transformation), or equivalently the coordinate frame in the opposite sense (passive transformation). It is \"not\" simple to connect and (or and ) to the original boost parameters and . In a composition of boosts, the matrix is named the Wigner rotation, and gives rise to the Thomas precession. These articles give the explicit formulae for the composite transformation matrices, including expressions for .\n\nIn this article the axis-angle representation is used for . The rotation is about an axis in the direction of a unit vector , through angle (positive anticlockwise, negative clockwise, according to the right-hand rule). The \"axis-angle vector\"\nwill serve as a useful abbreviation.\n\nSpatial rotations alone are also Lorentz transformations they leave the spacetime interval invariant. Like boosts, successive rotations about different axes do not commute. Unlike boosts, the composition of any two rotations is equivalent to a single rotation. Some other similarities and differences between the boost and rotation matrices include:\n\n\nThe most general proper Lorentz transformation includes a boost and rotation together, and is a nonsymmetric matrix. As special cases, and . An explicit form of the general Lorentz transformation is cumbersome to write down and will not be given here. Nevertheless, closed form expressions for the transformation matrices will be given below using group theoretical arguments. It will be easier to use the rapidity parametrization for boosts, in which case one writes and .\n\nThe set of transformations\n\nwith matrix multiplication as the operation of composition forms a group, called the \"restricted Lorentz group\", and is the special indefinite orthogonal group SO(3,1). (The plus sign indicates that it preserves the orientation of the temporal dimension).\n\nFor simplicity, look at the infinitesimal Lorentz boost in the x direction (examining a boost in any other direction, or rotation about any axis, follows an identical procedure). The infinitesimal boost is a small boost away from the identity, obtained by the Taylor expansion of the boost matrix to first order about ,\n\nwhere the higher order terms not shown are negligible because is small, and is simply the boost matrix in the \"x\" direction. The derivative of the matrix is the matrix of derivatives (of the entries, with respect to the same variable), and it is understood the derivatives are found first then evaluated at ,\n\nFor now, is defined by this result (its significance will be explained shortly). In the limit of an infinite number of infinitely small steps, the finite boost transformation in the form of a matrix exponential is obtained\n\nwhere the limit definition of the exponential has been used (see also characterizations of the exponential function). More generally\n\nThe axis-angle vector and rapidity vector are altogether six continuous variables which make up the group parameters (in this particular representation), and the generators of the group are and , each vectors of matrices with the explicit forms\n\nThese are all defined in an analogous way to above, although the minus signs in the boost generators are conventional. Physically, the generators of the Lorentz group correspond to important symmetries in spacetime: are the \"rotation generators\" which correspond to angular momentum, and are the \"boost generators\" which correspond to the motion of the system in spacetime. The derivative of any smooth curve with in the group depending on some group parameter with respect to that group parameter, evaluated at , serves as a definition of a corresponding group generator , and this reflects an infinitesimal transformation away from the identity. The smooth curve can always be taken as an exponential as the exponential will always map smoothly back into the group via for all ; this curve will yield again when differentiated at .\n\nExpanding the exponentials in their Taylor series obtains\n\nwhich compactly reproduce the boost and rotation matrices as given in the previous section.\n\nIt has been stated that the general proper Lorentz transformation is a product of a boost and rotation. At the \"infinitesimal\" level the product\n\nis commutative because only linear terms are required (products like and count as higher order terms and are negligible). Taking the limit as before leads to the finite transformation in the form of an exponential\n\nThe converse is also true, but the decomposition of a finite general Lorentz transformation into such factors is nontrivial. In particular,\n\nbecause the generators do not commute. For a description of how to find the factors of a general Lorentz transformation in terms of a boost and a rotation \"in principle\" (this usually does not yield an intelligible expression in terms of generators and ), see Wigner rotation. If, on the other hand, \"the decomposition is given\" in terms of the generators, and one wants to find the product in terms of the generators, then the Baker–Campbell–Hausdorff formula applies.\n\nLorentz generators can be added together, or multiplied by real numbers, to obtain more Lorentz generators. In other words, the set of all Lorentz generators\n\ntogether with the operations of ordinary matrix addition and multiplication of a matrix by a number, forms a vector space over the real numbers. The generators form a basis set of \"V\", and the components of the axis-angle and rapidity vectors, , are the coordinates of a Lorentz generator with respect to this basis.\n\nThree of the commutation relations of the Lorentz generators are\n\nwhere the bracket is known as the \"commutator\", and the other relations can be found by taking cyclic permutations of x, y, z components (i.e. change x to y, y to z, and z to x, repeat).\n\nThese commutation relations, and the vector space of generators, fulfill the definition of the Lie algebra formula_63. In summary, a Lie algebra is defined as a vector space \"V\" over a field of numbers, and with a binary operation [ , ] (called a Lie bracket in this context) on the elements of the vector space, satisfying the axioms of bilinearity, alternatization, and the Jacobi identity. Here the operation [ , ] is the commutator which satisfies all of these axioms, the vector space is the set of Lorentz generators \"V\" as given previously, and the field is the set of real numbers.\n\nLinking terminology used in mathematics and physics: A group generator is any element of the Lie algebra. A group parameter is a component of a coordinate vector representing an arbitrary element of the Lie algebra with respect to some basis. A basis, then, is a set of generators being a basis of the Lie algebra in the usual vector space sense.\n\nThe exponential map from the Lie algebra to the Lie group,\n\nprovides a one-to-one correspondence between small enough neighborhoods of the origin of the Lie algebra and neighborhoods of the identity element of the Lie group. It the case of the Lorentz group, the exponential map is just the matrix exponential. Globally, the exponential map is not one-to-one, but in the case of the Lorentz group, it is surjective (onto). Hence any group element can be expressed as an exponential of an element of the Lie algebra.\n\nLorentz transformations also include parity inversion\n\nwhich negates all the spatial coordinates only, and time reversal\n\nwhich negates the time coordinate only, because these transformations leave the spacetime interval invariant. Here is the 3d identity matrix. These are both symmetric, they are their own inverses (see involution (mathematics)), and each have determinant −1. This latter property makes them improper transformations.\n\nIf is a proper orthochronous Lorentz transformation, then is improper antichronous, is improper orthochronous, and is proper antichronous.\n\nTwo other spacetime symmetries have not been accounted for. For the spacetime interval to be invariant, it can be shown that it is necessary and sufficient for the coordinate transformation to be of the form\n\nwhere \"C\" is a constant column containing translations in time and space. If \"C\" ≠ 0, this is an inhomogeneous Lorentz transformation or Poincaré transformation. If \"C\" = 0, this is a homogeneous Lorentz transformation. Poincaré transformations are not dealt further in this article.\n\nWriting the general matrix transformation of coordinates as the matrix equation\n\nallows the transformation of other physical quantities that cannot be expressed as four-vectors; e.g., tensors or spinors of any order in 4d spacetime, to be defined. In the corresponding tensor index notation, the above matrix expression is\n\nwhere lower and upper indices label covariant and contravariant components respectively, and the summation convention is applied. It is a standard convention to use Greek indices that take the value 0 for time components, and 1, 2, 3 for space components, while Latin indices simply take the values 1, 2, 3, for spatial components. Note that the first index (reading left to right) corresponds in the matrix notation to a \"row index\". The second index corresponds to the column index.\n\nThe transformation matrix is universal for all four-vectors, not just 4-dimensional spacetime coordinates. If is any four-vector, then in tensor index notation\n\nAlternatively, one writes\n\nin which the primed indices denote the indices of A in the primed frame. This notation cuts risk of exhausting the Greek alphabet roughly in half.\n\nFor a general -component object one may write\n\nwhere is the appropriate representation of the Lorentz group, an matrix for every . In this case, the indices should \"not\" be thought of as spacetime indices (sometimes called Lorentz indices), and they run from to . E.g., if is a bispinor, then the indices are called \"Dirac indices\".\n\nThere are also vector quantities with covariant indices. They are generally obtained from their corresponding objects with contravariant indices by the operation of \"lowering an index\"; e.g.,\n\nwhere is the metric tensor. (The linked article also provides more information about what the operation of raising and lowering indices really is mathematically.) The inverse of this transformation is given by\n\nwhere, when viewed as matrices, is the inverse of . As it happens, . This is referred to as \"raising an index\". To transform a covariant vector , first raise its index, then transform it according to the same rule as for contravariant -vectors, then finally lower the index;\n\nBut\n\nI. e., it is the -component of the \"inverse\" Lorentz transformation. One defines (as a matter of notation),\n\nand may in this notation write\n\nNow for a subtlety. The implied summation on the right hand side of\n\nis running over \"a row index\" of the matrix representing . Thus, in terms of matrices, this transformation should be thought of as the \"inverse transpose\" of acting on the column vector . That is, in pure matrix notation,\n\nThis means exactly that covariant vectors (thought of as column matrices) transform according to the dual representation of the standard representation of the Lorentz group. This notion generalizes to general representations, simply replace with .\n\nIf and are linear operators on vector spaces and , then a linear operator may be defined on the tensor product of and , denoted according to\n\nFrom this it is immediately clear that if and are a four-vectors in , then transforms as\n\nThe second step uses the bilinearity of the tensor product and the last step defines a 2-tensor on component form, or rather, it just renames the tensor .\n\nThese observations generalize in an obvious way to more factors, and using the fact that a general tensor on a vector space can be written as a sum of a coefficient (component!) times tensor products of basis vectors and basis covectors, one arrives at the transformation law for any tensor quantity . It is given by\n\n_\\mu {\\Lambda^{\\beta'}}_\\nu \\cdots {\\Lambda^{\\zeta'}}_\\rho\n</math>               \n\nwhere is defined above. This form can generally be reduced to the form for general -component objects given above with a single matrix () operating on column vectors. This latter form is sometimes preferred; e.g., for the electromagnetic field tensor.\n\nLorentz transformations can also be used to illustrate that the magnetic field and electric field are simply different aspects of the same force — the electromagnetic force, as a consequence of relative motion between electric charges and observers. The fact that the electromagnetic field shows relativistic effects becomes clear by carrying out a simple thought experiment.\n\nThe electric and magnetic fields transform differently from space and time, but exactly the same way as relativistic angular momentum and the boost vector.\n\nThe electromagnetic field strength tensor is given by\n\nin SI units. In relativity, the Gaussian system of units is often preferred over SI units, even in texts whose main choice of units is SI units, because in it the electric field and the magnetic induction have the same units making the appearance of the electromagnetic field tensor more natural. Consider a Lorentz boost in the -direction. It is given by\n\nwhere the field tensor is displayed side by side for easiest possible reference in the manipulations below.\n\nThe general transformation law becomes\n\nFor the magnetic field one obtains\n\nFor the electric field results\n\nHere, is used. These results can be summarized by\n\nand are independent of the metric signature. For SI units, substitute . refer to this last form as the view as opposed to the \"geometric view\" represented by the tensor expression\nand make a strong point of the ease with which results that are difficult to achieve using the view can be obtained and understood. Only objects that have well defined Lorentz transformation properties (in fact under \"any\" smooth coordinate transformation) are geometric objects. In the geometric view, the electromagnetic field is a six-dimensional geometric object in \"spacetime\" as opposed to two interdependent, but separate, 3-vector fields in \"space\" and \"time\". The fields (alone) and (alone) do not have well defined Lorentz transformation properties. The mathematical underpinnings are equations and that immediately yield . One should note that the primed and unprimed tensors refer to the \"same event in spacetime\". Thus the complete equation with spacetime dependence is\n\nLength contraction has an effect on charge density and current density , and time dilation has an effect on the rate of flow of charge (current), so charge and current distributions must transform in a related way under a boost. It turns out they transform exactly like the space-time and energy-momentum four-vectors,\n\nor, in the simpler geometric view,\n\nOne says that charge density transforms as the time component of a four-vector. It is a rotational scalar. The current density is a 3-vector.\n\nThe Maxwell equations are invariant under Lorentz transformations.\n\nEquation hold unmodified for any representation of the Lorentz group, including the bispinor representation. In one simply replaces all occurrences of by the bispinor representation ,\n\nThe above equation could, for instance, be the transformation of a state in Fock space describing two free electrons.\n\nA general \"noninteracting\" multi-particle state (Fock space state) in quantum field theory transforms according to the rule\nwhere is the Wigner rotation and is the representation of .\n\n\n\n\n\n\n"}
{"id": "18406", "url": "https://en.wikipedia.org/wiki?curid=18406", "title": "Luminiferous aether", "text": "Luminiferous aether\n\nLuminiferous aether or ether (\"luminiferous\", meaning \"light-bearing\"), was the postulated medium for the propagation of light. It was invoked to explain the ability of the apparently wave-based light to propagate through empty space, something that waves should not be able to do. The assumption of a spatial plenum of luminiferous aether, rather than a spatial vacuum, provided the theoretical medium that was required by wave theories of light.\n\nThe aether hypothesis was the topic of considerable debate throughout its history, as it required the existence of an invisible and infinite material with no interaction with physical objects. As the nature of light was explored, especially in the 19th century, the physical qualities required of an aether became increasingly contradictory. By the late 1800s, the existence of the aether was being questioned, although there was no physical theory to replace it.\n\nThe negative outcome of the Michelson–Morley experiment (1887) suggested that the aether did not exist, a finding that was confirmed in subsequent experiments through the 1920s. This led to considerable theoretical work to explain the propagation of light without an aether. A major breakthrough was the theory of relativity, which could explain why the experiment failed to see aether, but was more broadly interpreted to suggest that it was not needed. The Michelson-Morley experiment, along with the blackbody radiator and photoelectric effect, was a key experiment in the development of modern physics, which includes both relativity and quantum theory, the latter of which explains the wave-like nature of light.\n\nIn the 17th century, Robert Boyle was a proponent of an aether hypothesis. According to Boyle, the aether consists of subtle particles, one sort of which explains the absence of vacuum and the mechanical interactions between bodies, and the other sort of which explains phenomena such as magnetism (and possibly gravity) that are, otherwise, inexplicable on the basis of purely mechanical interactions of macroscopic bodies, \"though in the ether of the ancients there was nothing taken notice of but a diffused and very subtle substance; yet we are at present content to allow that there is always in the air a swarm of steams moving in a determinate course between the north pole and the south\".\n\nChristiaan Huygens hypothesized that light is a wave propagating through an aether. He and Isaac Newton could only envision light waves as being longitudinal, propagating like sound and other mechanical waves in fluids. However, longitudinal waves necessarily have only one form for a given propagation direction, rather than two polarizations like transverse wave. Thus, longitudinal waves can not explain birefringence, in which two polarizations of light are refracted differently by a crystal. In addition, Newton rejected light as waves in a medium because such a medium would have to extend everywhere in space, and would thereby \"disturb and retard the Motions of those great Bodies\" (the planets and comets) and thus \"as it is of no use, and hinders the Operation of Nature, and makes her languish, so there is no evidence for its Existence, and therefore it ought to be rejected\".\n\nIsaac Newton contended that light is made up of numerous small particles. This can explain such features as light's ability to travel in straight lines and reflect off surfaces. Newton imagined that light particles as non-spherical \"corpuscles\", with different \"sides\" that give rise to birefringence. But the particle theory of light can not satisfactorily explain refraction and diffraction. To explain refraction, Newton's \"Opticks\" (1704) postulated an \"Aethereal Medium\" transmitting vibrations faster than light, by which light, when overtaken, is put into \"Fits of easy Reflexion and easy Transmission\", which caused refraction and diffraction. Newton believed that these vibrations were related to heat radiation:\n\nIs not the Heat of the warm Room convey'd through the vacuum by the Vibrations of a much subtiler Medium than Air, which after the Air was drawn out remained in the Vacuum? And is not this Medium the same with that Medium by which Light is refracted and reflected, and by whose Vibrations Light communicates Heat to Bodies, and is put into Fits of easy Reflexion and easy Transmission?\n\nIn contrast to the modern understanding that heat radiation and light are both electromagnetic radiation, Newton viewed heat and light as two different phenomena. He believed heat vibrations to be excited \"when a Ray of Light falls upon the Surface of any pellucid Body\". He wrote, \"I do not know what this Aether is\", but that if it consists of particles then they must be exceedingly smaller than those of Air, or even than those of Light: The exceeding smallness of its Particles may contribute to the greatness of the force by which those Particles may recede from one another, and thereby make that Medium exceedingly more rare and elastic than Air, and by consequence exceedingly less able to resist the motions of Projectiles, and exceedingly more able to press upon gross Bodies, by endeavoring to expand itself.\n\nIn 1720, James Bradley carried out a series of experiments attempting to measure stellar parallax by taking measurements of stars at different times of the year. As the Earth moves around the sun, the apparent angle to a given distant spot changes. By measuring those angles the distance to the star can be calculated based on the known orbital circumference of the Earth around the sun. He failed to detect any parallax, thereby placing a lower limit on the distance to stars.\n\nDuring these experiments, Bradley also discovered a related effect; the apparent positions of the stars did change over the year, but not as expected. Instead of the apparent angle being maximized when the Earth was at either end of its orbit with respect to the star, the angle was maximized when the Earth was at its fastest sideways velocity with respect to the star. This effect is now known as stellar aberration.\n\nBradley explained this effect in the context of Newton's corpuscular theory of light, by showing that the aberration angle was given by simple vector addition of the Earth's orbital velocity and the velocity of the corpuscles of light, just as vertically falling raindrops strike a moving object at an angle. Knowing the Earth's velocity and the aberration angle, this enabled him to estimate the speed of light.\n\nExplaining stellar aberration in the context of an aether-based theory of light was regarded as more problematic. As the aberration relied on relative velocities, and the measured velocity was dependent on the motion of the Earth, the aether had to be remaining stationary with respect to the star as the Earth moved through it. This meant that the Earth could travel through the aether, a physical medium, with no apparent effect – precisely the problem that led Newton to reject a wave model in the first place.\n\nA century later, Thomas Young and Augustin-Jean Fresnel revived the wave theory of light when they pointed out that light could be a transverse wave rather than a longitudinal wave – the polarization of a transverse wave (like Newton's \"sides\" of light) could explain birefringence, and in the wake of a series of experiments on diffraction the particle model of Newton was finally abandoned. Physicists assumed, moreover, that like mechanical waves, light waves required a medium for propagation, and thus required Huygens's idea of an aether \"gas\" permeating all space.\n\nHowever, a transverse wave apparently required the propagating medium to behave as a solid, as opposed to a gas or fluid. The idea of a solid that did not interact with other matter seemed a bit odd, and Augustin-Louis Cauchy suggested that perhaps there was some sort of \"dragging\", or \"entrainment\", but this made the aberration measurements difficult to understand. He also suggested that the \"absence\" of longitudinal waves suggested that the aether had negative compressibility. George Green pointed out that such a fluid would be unstable. George Gabriel Stokes became a champion of the entrainment interpretation, developing a model in which the aether might be (by analogy with pine pitch) rigid at very high frequencies and fluid at lower speeds. Thus the Earth could move through it fairly freely, but it would be rigid enough to support light.\n\nIn 1856, Wilhelm Eduard Weber and Rudolf Kohlrausch measured the numerical value of the ratio of the electromagnetic unit of charge to the electrostatic unit of charge. They found that the ratio equals the product of the speed of light and the square root of two. The following year, Gustav Kirchhoff wrote a paper in which he showed that the speed of a signal along an electric wire was equal to the speed of light. These are the first recorded historical links between the speed of light and electromagnetic phenomena.\n\nJames Clerk Maxwell began working on Michael Faraday's lines of force. In his 1861 paper \"\" he modelled these magnetic lines of force using a sea of molecular vortices that he considered to be partly made of aether and partly made of ordinary matter. He derived expressions for the dielectric constant and the magnetic permeability in terms of the transverse elasticity and the density of this elastic medium. He then equated the ratio of the dielectric constant to the magnetic permeability with a suitably adapted version of Weber and Kohlrausch's result of 1856, and he substituted this result into Newton's equation for the speed of sound. On obtaining a value that was close to the speed of light as measured by Hippolyte Fizeau, Maxwell concluded that light consists in undulations of the same medium that is the cause of electric and magnetic phenomena.\n\nMaxwell had, however, expressed some uncertainties surrounding the precise nature of his molecular vortices and so he began to embark on a purely dynamical approach to the problem. He wrote another paper in 1864, entitled \"A Dynamical Theory of the Electromagnetic Field\", in which the details of the luminiferous medium were less explicit. Although Maxwell did not explicitly mention the sea of molecular vortices, his derivation of Ampère's circuital law was carried over from the 1861 paper and he used a dynamical approach involving rotational motion within the electromagnetic field which he likened to the action of flywheels. Using this approach to justify the electromotive force equation (the precursor of the Lorentz force equation), he derived a wave equation from a set of eight equations which appeared in the paper and which included the electromotive force equation and Ampère's circuital law. Maxwell once again used the experimental results of Weber and Kohlrausch to show that this wave equation represented an electromagnetic wave that propagates at the speed of light, hence supporting the view that light is a form of electromagnetic radiation.\n\nThe apparent need for a propagation medium for such Hertzian waves can be seen by the fact that they consist of orthogonal electric (E) and magnetic (B or H) waves. The E waves consist of undulating dipolar electric fields, and all such dipoles appeared to require separated and opposite electric charges. Electric charge is an inextricable property of matter, so it appeared that some form of matter was required to provide the alternating current that would seem to have to exist at any point along the propagation path of the wave. Propagation of waves in a true vacuum would imply the existence of electric fields without associated electric charge, or of electric charge without associated matter. Albeit compatible with Maxwell's equations, electromagnetic induction of electric fields could not be demonstrated in vacuum, because all methods of detecting electric fields required electrically charged matter.\n\nIn addition, Maxwell's equations required that all electromagnetic waves in vacuum propagate at a fixed speed, \"c\". As this can only occur in one reference frame in Newtonian physics (see Galilean-Newtonian relativity), the aether was hypothesized as the absolute and unique frame of reference in which Maxwell's equations hold. That is, the aether must be \"still\" universally, otherwise \"c\" would vary along with any variations that might occur in its supportive medium. Maxwell himself proposed several mechanical models of aether based on wheels and gears, and George Francis FitzGerald even constructed a working model of one of them. These models had to agree with the fact that the electromagnetic waves are transverse but never longitudinal.\n\nBy this point the mechanical qualities of the aether had become more and more magical: it had to be a fluid in order to fill space, but one that was millions of times more rigid than steel in order to support the high frequencies of light waves. It also had to be massless and without viscosity, otherwise it would visibly affect the orbits of planets. Additionally it appeared it had to be completely transparent, non-dispersive, incompressible, and continuous at a very small scale. Maxwell wrote in \"Encyclopædia Britannica\":\n\nAethers were invented for the planets to swim in, to constitute electric atmospheres and magnetic effluvia, to convey sensations from one part of our bodies to another, and so on, until all space had been filled three or four times over with aethers. ... The only aether which has survived is that which was invented by Huygens to explain the propagation of light.\n\nContemporary scientists were aware of the problems, but aether theory was so entrenched in physical law by this point that it was simply assumed to exist. In 1908 Oliver Lodge gave a speech on behalf of Lord Rayleigh to the Royal Institution on this topic, in which he outlined its physical properties, and then attempted to offer reasons why they were not impossible. Nevertheless, he was also aware of the criticisms, and quoted Lord Salisbury as saying that \"aether is little more than a nominative case of the verb \"to undulate\"\". Others criticized it as an \"English invention\", although Rayleigh jokingly stated it was actually an invention of the Royal Institution.\n\nBy the early 20th century, aether theory was in trouble. A series of increasingly complex experiments had been carried out in the late 19th century to try to detect the motion of the Earth through the aether, and had failed to do so. A range of proposed aether-dragging theories could explain the null result but these were more complex, and tended to use arbitrary-looking coefficients and physical assumptions. Lorentz and FitzGerald offered within the framework of Lorentz ether theory a more elegant solution to how the motion of an absolute aether could be undetectable (length contraction), but if their equations were correct, the new special theory of relativity (1905) could generate the same mathematics without referring to an aether at all. Aether fell to Occam's Razor.\n\nThe two most important models, which were aimed to describe the relative motion of the Earth and aether, were Augustin-Jean Fresnel's (1818) model of the (nearly) stationary aether including a partial aether drag determined by Fresnel's dragging coefficient,\nand George Gabriel Stokes' (1844)\nmodel of complete aether drag. The latter theory was not considered as correct, since it was not compatible with the aberration of light, and the auxiliary hypotheses developed to explain this problem were not convincing. Also, subsequent experiments as the Sagnac effect (1913) also showed that this model is untenable. However, the most important experiment supporting Fresnel's theory was Fizeau's 1851 experimental confirmation of Fresnel's 1818 prediction that a medium with refractive index \"n\" moving with a velocity \"v\" would increase the speed of light travelling through the medium in the same direction as \"v\" from \"c\"/\"n\" to:\n\nThat is, movement adds only a fraction of the medium's velocity to the light (predicted by Fresnel in order to make Snell's law work in all frames of reference, consistent with stellar aberration). This was initially interpreted to mean that the medium drags the aether along, with a \"portion\" of the medium's velocity, but that understanding became very problematic after Wilhelm Veltmann demonstrated that the index \"n\" in Fresnel's formula depended upon the wavelength of light, so that the aether could not be moving at a wavelength-independent speed. This implied that there must be a separate aether for each of the infinitely many frequencies.\n\nThe key difficulty with Fresnel's aether hypothesis arose from the juxtaposition of the two well-established theories of Newtonian dynamics and Maxwell's electromagnetism. Under a Galilean transformation the equations of Newtonian dynamics are invariant, whereas those of electromagnetism are not. Basically this means that while physics should remain the same in non-accelerated experiments, light would not follow the same rules because it is travelling in the universal \"aether frame\". Some effect caused by this difference should be detectable.\n\nA simple example concerns the model on which aether was originally built: sound. The speed of propagation for mechanical waves, the speed of sound, is defined by the mechanical properties of the medium. Sound travels 4.3 times faster in water than in air. This explains why a person hearing an explosion underwater and quickly surfacing can hear it again as the slower travelling sound arrives through the air. Similarly, a traveller on an airliner can still carry on a conversation with another traveller because the sound of words is travelling along with the air inside the aircraft. This effect is basic to all Newtonian dynamics, which says that everything from sound to the trajectory of a thrown baseball should all remain the same in the aircraft flying (at least at a constant speed) as if still sitting on the ground. This is the basis of the Galilean transformation, and the concept of frame of reference.\n\nBut the same was not supposed to be true for light, since Maxwell's mathematics demanded a single universal speed for the propagation of light, based, not on local conditions, but on two measured properties, the permittivity and permeability of free space, that were assumed to be the same throughout the universe. If these numbers did change, there should be noticeable effects in the sky; stars in different directions would have different colours, for instance.\n\nThus at any point there should be one special coordinate system, \"at rest relative to the aether\". Maxwell noted in the late 1870s that detecting motion relative to this aether should be easy enough—light travelling along with the motion of the Earth would have a different speed than light travelling backward, as they would both be moving against the unmoving aether. Even if the aether had an overall universal flow, changes in position during the day/night cycle, or over the span of seasons, should allow the drift to be detected.\n\nAlthough the aether is almost stationary according to Fresnel, his theory predicts a positive outcome of aether drift experiments only to \"second\" order in formula_2, because Fresnel's dragging coefficient would cause a negative outcome of all optical experiments capable of measuring effects to \"first\" order in formula_2. This was confirmed by the following first-order experiments, which all gave negative results. The following list is based on the description of Wilhelm Wien (1898), with changes and additional experiments according to the descriptions of Edmund Taylor Whittaker (1910) and Jakob Laub (1910):\n\n\nBesides those optical experiments, also electrodynamic first-order experiments were conducted, which should have led to positive results according to Fresnel. However, Hendrik Antoon Lorentz (1895) modified Fresnel's theory and showed that those experiments can be explained by a stationary aether as well:\n\n\nWhile the \"first\"-order experiments could be explained by a modified stationary aether, more precise \"second\"-order experiments were expected to give positive results, however, no such results could be found.\n\nThe famous Michelson–Morley experiment compared the source light with itself after being sent in different directions, looking for changes in phase in a manner that could be measured with extremely high accuracy. In this experiment, their goal was to determine the velocity of the Earth through the aether. The publication of their result in 1887, the null result, was the first clear demonstration that something was seriously wrong with the aether hypothesis (Michelson's first experiment in 1881 was not entirely conclusive). In this case the MM experiment yielded a shift of the fringing pattern of about 0.01 of a fringe, corresponding to a small velocity. However, it was incompatible with the expected aether wind effect due to the Earth's (seasonally varying) velocity which would have required a shift of 0.4 of a fringe, and the error was small enough that the value may have indeed been zero. Therefore, the null hypothesis, the hypothesis that there was no aether wind, could not be rejected. More modern experiments have since reduced the possible value to a number very close to zero, about 10.\n\nA series of experiments using similar but increasingly sophisticated apparatuses all returned the null result as well. Conceptually different experiments that also attempted to detect the motion of the aether were the Trouton–Noble experiment (1903), whose objective was to detect torsion effects caused by electrostatic fields, and the experiments of Rayleigh and Brace (1902, 1904), to detect double refraction in various media. However, all of them obtained a null result, like Michelson–Morley (MM) previously did.\n\nThese \"aether-wind\" experiments led to a flurry of efforts to \"save\" aether by assigning to it ever more complex properties, while only few scientists, like Emil Cohn or Alfred Bucherer, considered the possibility of the abandonment of the aether hypothesis. Of particular interest was the possibility of \"aether entrainment\" or \"aether drag\", which would lower the magnitude of the measurement, perhaps enough to explain the results of the Michelson-Morley experiment. However, as noted earlier, aether dragging already had problems of its own, notably aberration. In addition, the interference experiments of Lodge (1893, 1897) and Ludwig Zehnder (1895), aimed to show whether the aether is dragged by various, rotating masses, showed no aether drag. A more precise measurement was made in the Hammar experiment (1935), which ran a complete MM experiment with one of the \"legs\" placed between two massive lead blocks. If the aether was dragged by mass then this experiment would have been able to detect the drag caused by the lead, but again the null result was achieved. The theory was again modified, this time to suggest that the entrainment only worked for very large masses or those masses with large magnetic fields. This too was shown to be incorrect by the Michelson–Gale–Pearson experiment, which detected the Sagnac effect due to Earth's rotation (see Aether drag hypothesis).\n\nAnother, completely different attempt to save \"absolute\" aether was made in the Lorentz–FitzGerald contraction hypothesis, which posited that \"everything\" was affected by travel through the aether. In this theory the reason the Michelson–Morley experiment \"failed\" was that the apparatus contracted in length in the direction of travel. That is, the light was being affected in the \"natural\" manner by its travel though the aether as predicted, but so was the apparatus itself, cancelling out any difference when measured. FitzGerald had inferred this hypothesis from a paper by Oliver Heaviside. Without referral to an aether, this physical interpretation of relativistic effects was shared by Kennedy and Thorndike in 1932 as they concluded that the interferometer's arm contracts and also the frequency of its light source \"very nearly\" varies in the way required by relativity.\n\nSimilarly the Sagnac effect, observed by G. Sagnac in 1913, was immediately seen to be fully consistent with special relativity. In fact, the Michelson-Gale-Pearson experiment in 1925 was proposed specifically as a test to confirm the relativity theory, although it was also recognized that such tests, which merely measure absolute rotation, are also consistent with non-relativistic theories.\n\nDuring the 1920s, the experiments pioneered by Michelson were repeated by Dayton Miller, who publicly proclaimed positive results on several occasions, although they were not large enough to be consistent with any known aether theory. However, other researchers were unable to duplicate Miller's claimed results. Over the years the experimental accuracy of such measurements has been raised by many orders of magnitude, and no trace of any violations of Lorentz invariance has been seen. (A later re-analysis of Miller's results concluded that he had underestimated the variations due to temperature.)\n\nSince the Miller experiment and its unclear results there have been many more experimental attempts to detect the aether. Many experimenters have claimed positive results. These results have not gained much attention from mainstream science, since they contradict a large quantity of high-precision measurements, all the results of which were consistent with special relativity.\n\nBetween 1892 and 1904, Hendrik Lorentz developed an electron-aether theory, in which he introduced a strict separation between matter (electrons) and aether. In his model the aether is completely motionless, and won't be set in motion in the neighborhood of ponderable matter. Contrary to earlier electron models, the electromagnetic field of the aether appears as a mediator between the electrons, and changes in this field cannot propagate faster than the speed of light. A fundamental concept of Lorentz's theory in 1895 was the \"theorem of corresponding states\" for terms of order v/c. This theorem states that an observer moving relative to the aether makes the same observations as a resting observer, after a suitable change of variables. Lorentz noticed that it was necessary to change the space-time variables when changing frames and introduced concepts like physical length contraction (1892) to explain the Michelson–Morley experiment, and the mathematical concept of local time (1895) to explain the aberration of light and the Fizeau experiment. This resulted in the formulation of the so-called Lorentz transformation by Joseph Larmor (1897, 1900) and Lorentz (1899, 1904), whereby (it was noted by Larmor) the complete formulation of local time is accompanied by some sort of time dilation of electrons moving in the aether. As Lorentz later noted (1921, 1928), he considered the time indicated by clocks resting in the aether as \"true\" time, while local time was seen by him as a heuristic working hypothesis and a mathematical artifice. Therefore, Lorentz's theorem is seen by modern authors as being a mathematical transformation from a \"real\" system resting in the aether into a \"fictitious\" system in motion.\n\nThe work of Lorentz was mathematically perfected by Henri Poincaré, who formulated on many occasions the Principle of Relativity and tried to harmonize it with electrodynamics. He declared simultaneity only a convenient convention which depends on the speed of light, whereby the constancy of the speed of light would be a useful postulate for making the laws of nature as simple as possible. In 1900 and 1904 he physically interpreted Lorentz's local time as the result of clock synchronization by light signals. In June and July 1905 he declared the relativity principle a general law of nature, including gravitation. He corrected some mistakes of Lorentz and proved the Lorentz covariance of the electromagnetic equations. However, he used the notion of an aether as a perfectly undetectable medium and distinguished between apparent and real time, so most historians of science argue that he failed to invent special relativity.\n\nAether theory was dealt another blow when the Galilean transformation and Newtonian dynamics were both modified by Albert Einstein's special theory of relativity, giving the mathematics of Lorentzian electrodynamics a new, \"non-aether\" context. Unlike most major shifts in scientific thought, special relativity was adopted by the scientific community remarkably quickly, consistent with Einstein's later comment that the laws of physics described by the Special Theory were \"ripe for discovery\" in 1905. Max Planck's early advocacy of the special theory, along with the elegant formulation given to it by Hermann Minkowski, contributed much to the rapid acceptance of special relativity among working scientists.\n\nEinstein based his theory on Lorentz's earlier work. Instead of suggesting that the mechanical properties of objects changed with their constant-velocity motion through an undetectable aether, Einstein proposed to deduce the characteristics that any successful theory must possess in order to be consistent with the most basic and firmly established principles, independent of the existence of a hypothetical aether. He found that the Lorentz transformation must transcend its connection with Maxwell's equations, and must represent the fundamental relations between the space and time coordinates of inertial frames of reference. In this way he demonstrated that the laws of physics remained invariant as they had with the Galilean transformation, but that light was now invariant as well.\n\nWith the development of the special theory of relativity, the need to account for a single universal frame of reference had disappeared – and acceptance of the 19th century theory of a luminiferous aether disappeared with it. For Einstein, the Lorentz transformation implied a conceptual change: that the concept of position in space or time was not absolute, but could differ depending on the observer's location and velocity.\n\nMoreover, in another paper published the same month in 1905, Einstein made several observations on a then-thorny problem, the photoelectric effect. In this work he demonstrated that light can be considered as particles that have a \"wave-like nature\". Particles obviously do not need a medium to travel, and thus, neither did light. This was the first step that would lead to the full development of quantum mechanics, in which the wave-like nature \"and\" the particle-like nature of light are both considered as valid descriptions of light. A summary of Einstein's thinking about the aether hypothesis, relativity and light quanta may be found in his 1909 (originally German) lecture \"The Development of Our Views on the Composition and Essence of Radiation\".\n\nLorentz on his side continued to use the aether hypothesis. In his lectures of around 1911 he pointed out that what \"the theory of relativity has to say ... can be carried out independently of what one thinks of the aether and the time\". He commented that \"whether there is an aether or not, electromagnetic fields certainly exist, and so also does the energy of the electrical oscillations\" so that, \"if we do not like the name of 'aether', we must use another word as a peg to hang all these things upon\". He concluded that \"one cannot deny the bearer of these concepts a certain substantiality\".\n\nIn later years there have been a few individuals who advocated a neo-Lorentzian approach to physics, which is Lorentzian in the sense of positing an absolute true state of rest that is undetectable and which plays no role in the predictions of the theory. (No violations of Lorentz covariance have ever been detected, despite strenuous efforts.) Hence these theories resemble the 19th century aether theories in name only. For example, the founder of quantum field theory, Paul Dirac, stated in 1951 in an article in Nature, titled \"Is there an Aether?\" that \"we are rather forced to have an aether\". However, Dirac never formulated a complete theory, and so his speculations found no acceptance by the scientific community.\n\nWhen Einstein was still a student in the Zurich Polytechnic in 1900, he was very interested in the idea of aether. His initial proposal of research thesis was to do an experiment to measure how fast the Earth was moving through the aether. \"The velocity of a wave is proportional to the square root of the elastic forces which cause [its] propagation, and inversely proportional to the mass of the aether moved by these forces.\"\n\nIn 1916, after Einstein completed his foundational work on general relativity, Lorentz wrote a letter to him in which he speculated that within general relativity the aether was re-introduced. In his response Einstein wrote that one can actually speak about a \"new aether\", but one may not speak of motion in relation to that aether. This was further elaborated by Einstein in some semi-popular articles (1918, 1920, 1924, 1930).\n\nIn 1918 Einstein publicly alluded to that new definition for the first time. Then, in the early 1920s, in a lecture which he was invited to give at Lorentz's university in Leiden, Einstein sought to reconcile the theory of relativity with Lorentzian aether. In this lecture Einstein stressed that special relativity took away the last mechanical property of the aether: immobility. However, he continued that special relativity does not necessarily rule out the aether, because the latter can be used to give physical reality to acceleration and rotation. This concept was fully elaborated within general relativity, in which physical properties (which are partially determined by matter) are attributed to space, but no substance or state of motion can be attributed to that \"aether\" (by which he meant curved space-time).\n\nIn another paper of 1924, named \"Concerning the Aether\", Einstein argued that Newton's absolute space, in which acceleration is absolute, is the \"Aether of Mechanics\". And within the electromagnetic theory of Maxwell and Lorentz one can speak of the \"Aether of Electrodynamics\", in which the aether possesses an absolute state of motion. As regards special relativity, also in this theory acceleration is absolute as in Newton's mechanics. However, the difference from the electromagnetic aether of Maxwell and Lorentz lies in the fact, that \"because it was no longer possible to speak, in any absolute sense, of simultaneous states at different locations in the aether, the aether became, as it were, four dimensional, since there was no objective way of ordering its states by time alone\". Now the \"aether of special relativity\" is still \"absolute\", because matter is affected by the properties of the aether, but the aether is not affected by the presence of matter. This asymmetry was solved within general relativity. Einstein explained that the \"aether of general relativity\" is not absolute, because matter is influenced by the aether, just as matter influences the structure of the aether.\n\nThe only similarity of this relativistic aether concept with the classical aether models lies in the presence of physical properties in space, which can be identified through geodesics. As historians such as John Stachel argue, Einstein's views on the \"new aether\" are not in conflict with his abandonment of the aether in 1905. As Einstein himself pointed out, no \"substance\" and no state of motion can be attributed to that new aether. Einstein's use of the word \"aether\" found little support in the scientific community, and played no role in the continuing development of modern physics.\n\n\n\n \n"}
{"id": "18408", "url": "https://en.wikipedia.org/wiki?curid=18408", "title": "LAME", "text": "LAME\n\nLAME is a software encoder that converts audio to the MP3 file format. LAME is a free software project that was first released in 1998, and has incorporated many improvements since then, including an improved psychoacoustic model. The LAME encoder outperforms early encoders like L3enc.\n\nLAME is required by some programs. In many programs released as free software (e.g., Audacity), LAME must be linked for MP3 support. This avoided including LAME itself, which used patented techniques, and so required patent licenses in many countries.\n\nThe name LAME is a recursive acronym for \"LAME Ain't an MP3 Encoder\".\nAround mid-1998, Mike Cheng created LAME 1.0 as a set of modifications against the \"8Hz-MP3\" encoder source code. After some quality concerns raised by others, he decided to start again from scratch based on the \"dist10\" MPEG reference software sources. His goal was only to speed up the dist10 sources, and leave its quality untouched. That branch (a patch against the reference sources) became Lame 2.0. The project quickly became a team project. Mike Cheng eventually left leadership and started working on tooLAME (an MP2 encoder).\n\nMark Taylor then started pursuing increased quality in addition to better speed, and released version 3.0 featuring gpsycho, a new psychoacoustic model he developed.\n\nA few key improvements, in chronological order:\n\nLike all MP3 encoders, LAME implemented techniques covered by software patents owned by the Fraunhofer Society and others. The developers of LAME did not license the technology described by these patents. Distributing compiled binaries of LAME, its libraries, or programs that derive from LAME in countries that recognize those patents may have constituted infringement, but since April 23, 2017, all of these patents have expired.\n\nThe LAME developers stated that, since their code was only released in source code form, it should only be considered as an educational description of an MP3 encoder, and thus did not infringe any patent in itself. They also advised users to obtain relevant patent licenses before including a compiled version of the encoder in a product. Some software was released using this strategy: companies used the LAME library, but obtained patent licenses.\n\nIn the course of the 2005 Sony BMG copy protection rootkit scandal, there were reports that the Extended Copy Protection rootkit included on some Sony Compact Discs included portions of the LAME library without complying with the terms of the LGPL.\n\n\n"}
{"id": "18414", "url": "https://en.wikipedia.org/wiki?curid=18414", "title": "Leszek Miller", "text": "Leszek Miller\n\nLeszek Cezary Miller ( ; born 3 July 1946) is a Polish left-wing politician who served as Prime Minister of Poland from 2001 to 2004. He was leader of the Democratic Left Alliance to 2016.\n\nBorn in Żyrardów, Miller comes from a poor, working-class family: His father was a tailor and his mother a needlewoman. His parents broke up when Miller was six months old. His father, Florian Miller, an ethnic German, left the family and Leszek has never maintained any contact with him. His mother brought him up in a religious spirit – following her wish, he was even, for some time, an altar boy in their church.\n\nDue to hard life conditions, after graduation from vocational school, 17-year-old Miller got a job in the Textile Linen Plant in Żyrardów, while continuing his education in the evenings at the Vocational Secondary School of Electric Power Engineering. He soon completed his military service on the ORP Bielik submarine.\n\nIn 1969, Miller married Aleksandra, three years his junior, in church. They had a son, Leszek Junior ( August 2018), and a granddaughter, Monika.\n\nMiller started his political career as an activist of the Socialist Youth Union, where he held the position of Chairman of the Plant Board, soon becoming a member of the Town Committee. After the military service, in 1969, he joined the Polish United Workers' Party (PZPR), People's Poland's communist party.\n\nMany people were pressured to join PZPR in order to advance in their careers or to pursue higher education. Miller used his affiliation with the Communist party to effectively advance in his studies and professional goals.\n\nIn 1973 and 1974, Miller was the Secretary of the PZPR Plant Committee. With the party's recommendation, he started political sciences studies at the party's Higher School of Political Sciences (\"Wyższa Szkoła Nauk Społecznych\"), graduating in 1977. After graduation, Miller worked at the PZPR Central Committee, supervising the Group, and later on the Department of Youth, Physical Education and Tourism.\n\nIn July 1986, Miller was elected as First Secretary of the PZPR Provincial Committee in Skierniewice. In December 1988, he returned to Warsaw, due to his promotion to the position of the Secretary of the PZPR Central Committee. As a representative of the government side, he took part in the session of the historic \"Round Table\", where, together with Andrzej Celiński, he co-chaired the sub-team for youth issues (the only one that closed the session without signing the agreement). In 1989, he became a member of the PZPR Political Bureau.\n\nAfter the PZPR was dissolved, Miller became a co-founder of the Social Democracy of the Polish Republic (till March 1993, he was Secretary General, then Deputy Chairman and, from December 1997, the Chairman of that party). In December 1999, at the Founding Congress of the Democratic Left Alliance (SLD), he was elected its Chairman, holding the function continuously until February 2004. In 1997-2001 he was the Chairman of the SLD’s caucus.\n\nIn 1989, he ran unsuccessfully for the Senate as a representative of Skierniewice Province. In subsequent elections (1991), Miller was a leader on the election list of the Social Democracy of the Polish Republic in Łódź and, following a considerable success in elections, he won a seat in the Sejm, becoming Chairman of the Parliamentary Group of the Social Democracy of the Polish Republic. In three subsequent elections to the Sejm, he ran each time from Łódź, each time gaining more and more votes (from 50 thousand in 1991 up to 146 thousand in 2001); he held a seat in Parliament until 2005.\n\nThrough all that time he remained one of the leading politicians on the left wing. In early 1990s, together with Mieczysław Rakowski, he was suspected in the case of the so-called \"Moscow loan\". After revealing that affair in 1991, Włodzimierz Cimoszewicz called Miller to abstain from taking an MP's oath due to accusations laid against him. When Miller was cleared of the charges, Prime Minister Cimoszewicz appointed him later as the Minister in Charge of the Office of the Council of Ministers and in 1997 the Minister of Internal Affairs and Administration in his government. In turn, Cimoszewicz later became the Minister of Foreign Affairs in Miller’s cabinet.\n\nFrom 1993 to 1996, Miller was the Minister of Labour and Social Policy in the governments of Waldemar Pawlak and Józef Oleksy respectively. In 1996, he was nominated as Senior Minister in charge of the Office of the Council of Ministers. He then got the nickname “The Chancellor”.\n\nMiller played an important role in concluding the case of Colonel Ryszard Kukliński, for which he was severely criticised within his political circle. A similar disapproval was expressed after Miller’s support for the Concordat and the candidature of Leszek Balcerowicz to the position of President of the National Bank of Poland.\n\nDuring the period of the Solidarity Electoral Action’s government, Miller was in charge of the parliamentary opposition, leading the political fight with the governing party. He was also consolidating the majority of significant left-wing groups around his person. In 1999, he succeeded in establishing one uniform political party – the Democratic Left Alliance – which turned out to be very successful in following elections.\n\nFollowing the victory of the Left (41% vs. 12% of the subsequent party) in the Parliamentary Election in 2001, on 19 October 2001, President Aleksander Kwaśniewski appointed Miller Prime Minister and obliged to nominate the government. The new government won the parliamentary vote of confidence on 26 October 2001 (306:140 votes with one abstention). The 16-person cabinet of Prime Minister Miller has been the smallest government of the Polish Republic so far.\n\nMiller’s government faced a difficult economic situation in Poland, including an unemployment rate above 18%, a high level of public debt, and economic stagnation. At the end of Miller’s term, economic growth exceeded 6%; still, it was too slow to reduce the unemployment rate. During his term, the unpopular program of cuts in public expenses was implemented, together with a hardly successful reform of health care financing. The reforms of the tax system and of the Social Insurance Institution were continued, and the attempt to settle the mass-media market failed. Taxes were significantly lowered – to 19% for companies and for persons running business activity – and the act of freedom in business activity was voted through. A radical, structural reform of secret services was implemented (the State Security Office was dissolved and replaced by the Internal Security Agency and the Intelligence Agency).\n\nSimultaneously, institutional and legal adjustments were continued, resulting from the accession to the European Union. The Accession conditions were negotiated, being the main strategic goal of Miller’s cabinet. On 13 December 2002, at the summit in Copenhagen (Denmark), Prime Minister Leszek Miller completed the negotiations with the European Union. On 16 April 2003 in Athens, Miller, together with Cimoszewicz, signed the Accession Treaty, bringing Poland into the European Union. Miller’s government, in collaboration with various political and social forces, organized the accession referendum with a successful outcome. On 7 and 8 June 2003, 77.45% of the referendum participants voted in favor of Poland’s accession to the European Union. The referendum turn-out reached 58.85%.\n\nMiller’s government, together with President Kwaśniewski, made a decision (March 2003) to join the international coalition and deploy Polish troops to Iraq, targeting at overthrowing Saddam Hussein’s government. Miller was also a co-signatory of \"the letter of 8\", signed by eight European prime ministers, supporting the US position on Iraq. Already in 2002 Miller gave permission to the U.S. government to run a secret CIA prison at Stare Kiejkuty military training center, three hours North of Warsaw. Years later he is facing accusations of acting anti-constitutionally by having tolerated the imprisonment and torture of prisoners.\nOn 4 December 2003, Leszek Miller suffered injuries in a helicopter crash near Warsaw.\n\nAt the end of its term of office, Miller’s government had the lowest public support of any government since 1989. It was mainly caused by the continuing high unemployment rate, corruption scandals, with Rywingate on top, and by the attempt of fulfilling the plan of reducing social spending (the Hausner’s plan). In result of criticism in his own party, the Democratic Left Alliance, in February 2004, Miller resigned from chairing the party. Miller was criticized for an excessively liberal approach and for stressing the role of free market mechanisms in economy. He was reproached for his acceptance of a flat tax, which ran counter to the left-wing doctrine. He was also identified with the “chieftain-like style” of leadership. On 26 March 2004, following the decision of the Speaker of the Parliament, Marek Borowski, to found a new dissenting party, the Social Democracy of Poland, Miller decided to resign from the position of Prime Minister on 2 May 2004, a day after Poland’s accession to the EU. On 1 May 2004, together with President Kwaśniewski, he was in Dublin, taking part in the Grand Ceremony of accession of 10 states, including Poland, to the European Union.\n\nIn 2005, despite the support of the Łódź Branch of the Democratic Left Alliance, Miller was not registered on the election list to the Parliament. At the same time, he was offered to run for Senate but refused. Retirement of the old activists was presented in media as “inflow of new blood into the Democratic Left Alliance”. After the election, Miller became active in journalism, writing mainly for the “Wprost” weekly on liberal economic concepts and current political issues. In the first half of 2005, he stayed at the Woodrow Wilson International Center for Scholars in Washington, D.C., implementing a research project: “Status of the new Poland in the Eastern Europe’s space”.\n\nIn September 2007, the former Polish Prime Minister Leszek Miller become affiliated with Samoobrona, when he decided to run for the Sejm from their lists.\n\n\n\n \n"}
{"id": "18420", "url": "https://en.wikipedia.org/wiki?curid=18420", "title": "Basis (linear algebra)", "text": "Basis (linear algebra)\n\nIn mathematics, a set of elements (vectors) in a vector space is called a basis, if every element of may be written in a unique way as a (finite) linear combination of elements of . The coefficients of this linear combination are referred to as components or coordinates on of the vector. The elements of a basis are called .\n\nEquivalently is a basis if its elements are linearly independent and every element of is a linear combination of elements of . In more general terms, a basis is a linearly independent spanning set.\n\nA vector space can have generally several bases; however all the bases have the same number of elements, called the dimension of the vector space.\n\nA basis of a vector space over a field (such as the real numbers or the complex numbers ) is a linearly independent subset of that spans .\nThis means that, a subset of is a basis if it satisfies the two following conditions:\n\nThe scalars are called the coordinates of the vector with respect to the basis , and by the first property they are uniquely determined.\n\nA vector space that has a finite basis is called finite-dimensional. In this case, the subset that is considered (twice) in the above definition may be chosen as itself.\n\nIt is often convenient to ordering the basis vectors, typically when one consider the coefficients of a vector on a basis, without referring explicitly to the basis elements. In this case, the ordering is necessary for associating each coefficient to the corresponding basis element. Generally, this ordering is implicitly done by numbering the basis elements. For example, when using matrices, the th row, and th column refer to the th element of a basis of some vector space. For emphasizing that an order has been chosen, one speaks of an ordered basis, which is therefore a sequence rather than a set; see \"Ordered bases and coordinates\" below.\n\n\nMany properties of finite bases result from the Steinitz exchange lemma, which states that, given a finite spanning set and a linearly independent subset of elements of , one may replace well chosen elements of by the elements of for getting a spanning set containing , having its other elements in , and having the same number of elements as .\n\nMost properties resulting from Steinitz exchange lemma remain true when there is no finite spanning set, but their proof in the infinite case requires generally the axiom of choice or a weaker form of it, such as the ultrafilter lemma.\n\nIf is a vector space over a field , then:\n\nIf is a vector space of dimension , then:\n\nLet be a vector space of finite dimension over a field , and \nbe a basis of . By definition of a basis, for every in may be written, in a unique way,\nwhere the coefficients formula_14 are scalars (that is, elements of ), which are called the \"coordinates\" of over . However, if one talks of the \"set\" of the coefficients, one looses the correspondence between coefficients and basis elements, and several vectors may have the same \"set\" of coefficients. For example, formula_15 and formula_16 have the same set of coefficients , and are different. It is therefore often convenient to work with an ordered basis; this is typically done by indexing the basis elements by the first natural numbers. Then, the coordinates of a vector form a sequence similarly indexed, and a vector is completely characterized by the sequence of coordinates. An ordered basis is also called a frame, a word commonly used, in various contexts, for referring to a sequence of data allowing defining coordinates.\n\nLet, as usual, formula_5 be the set of the -tuples of elements of . This set is an -vector space, with addition and scalar multiplication defined component-wise. The map \nis a linear isomorphism from the vector space formula_5 onto . In other words, formula_5 is the coordinate space of , and the -tuple formula_21 is the coordinate vector of .\n\nThe inverse image by formula_22 of formula_23 is the -tuple formula_24 whose all components are 0, except the th that is 1. The formula_24 form an ordered basis of formula_8 which is called its standard basis or canonical basis. The ordered basis is the image by formula_22 of the canonical basis of formula_9 \n\nIt follows from what precedes that every ordered basis is the image by a linear isomorphism of the canonical basis of formula_8 and that every linear isomorphism from formula_5 onto may be defined as the isomorphism that maps the canonical basis of formula_5 onto a given ordered basis of . In other words it is equivalent to define an ordered basis of , or a linear isomorphism from formula_5 onto .\n\nLet be a vector space of dimension over a field . Given two (ordered) bases formula_33 and formula_34 of , it is often useful to express the coordinates of a vector with respect to formula_35 in terms of the coordinates with respect to formula_36 This can be done by the \"change of basis formula\", is described below. The subscripts and have been chosen because it is customary to refer to formula_35 as the \"old basis\" and to formula_38 as the \"new basis\". It is useful to describe the old coordinates in terms of the new ones, because in general one has an expression, in which the old coordinates are to be substituted by these terms in the new coordinates, thus yielding an equivalent expression, involving the new coordinates, instead of the old ones.\n\nTypically, the new basis vectors are given by their coordinates over the old basis, that is, \nIf formula_40 and formula_41 are the coordinates of a vector over the old and the new basis respectively, one has\n\nThe formula for changing the coordinates with respect to the other basis results from the uniqueness of the decomposition of a vector over a basis, and is thus\nfor .\n\nThis formula may be concisely written in matrix notation. Let be the matrix of the formula_44 and\nbe the column vectors of the coordinates of in the old and the new basis respectively, then the formula for changing coordinates is\n\nIf one replaces the field occurring in the definition of a vector space by a ring, one gets the definition of a module. For modules, linear independence and spanning sets are defined exactly as for vector spaces, although \"generating set\" is more commonly used than that of \"spanning set\".\n\nLike for vector spaces, a \"basis\" of a module is a linearly independent subset that is also a generating set. A major difference with the theory of vector spaces is that not every module has a basis. A module that has a basis is called a \"free module\". Free modules play a fundamental role in module theory, as they may be used for describing the structure of non-free modules through free resolutions.\n\nA module over the integers is exactly the same thing as an abelian group. Thus a free module over the integers is also a free abelian group. Free abelian groups have specific properties that are not shared by modules over other rings. Specifically, every subgroup of a free abelian group is a group, and, if is a subgroup of a finitely generated free abelian group (that is an abelian group that has a finite basis), there is a basis formula_7 of and an integer such that formula_49 is a basis of , for some nonzero integers formula_50 For details, see .\n\nIn the context of infinite-dimensional vector spaces over the real or complex numbers, the term (named after Georg Hamel) or algebraic basis can be used to refer to a basis as defined in this article. This is to make a distinction with other notions of \"basis\" that exist when infinite-dimensional vector spaces are endowed with extra structure. The most important alternatives are orthogonal bases on Hilbert spaces, Schauder bases, and Markushevich bases on normed linear spaces. In the case of the real numbers R viewed as a vector space over the field Q of rational numbers, Hamel bases are uncountable, and have specifically the cardinality of the continuum, which is the cardinal number formula_51 where formula_52 is the smallest infinite cardinal, the cardinal of the integers.\n\nThe common feature of the other notions is that they permit the taking of infinite linear combinations of the basis vectors in order to generate the space. This, of course, requires that infinite sums are meaningfully defined on these spaces, as is the case for topological vector spaces – a large class of vector spaces including e.g. Hilbert spaces, Banach spaces, or Fréchet spaces.\n\nThe preference of other types of bases for infinite-dimensional spaces is justified by the fact that the Hamel basis becomes \"too big\" in Banach spaces: If \"X\" is an infinite-dimensional normed vector space which is complete (i.e. \"X\" is a Banach space), then any Hamel basis of \"X\" is necessarily uncountable. This is a consequence of the Baire category theorem. The completeness as well as infinite dimension are crucial assumptions in the previous claim. Indeed, finite-dimensional spaces have by definition finite bases and there are infinite-dimensional (\"non-complete\") normed spaces which have countable Hamel bases. Consider formula_53, the space of the sequences formula_54 of real numbers which have only finitely many non-zero elements, with the norm formula_55 Its standard basis, consisting of the sequences having only one non-zero element, which is equal to 1, is a countable Hamel basis.\n\nIn the study of Fourier series, one learns that the functions {1} ∪ { sin(\"nx\"), cos(\"nx\") : \"n\" = 1, 2, 3, ... } are an \"orthogonal basis\" of the (real or complex) vector space of all (real or complex valued) functions on the interval [0, 2π] that are square-integrable on this interval, i.e., functions \"f\" satisfying\n\nThe functions {1} ∪ { sin(\"nx\"), cos(\"nx\") : \"n\" = 1, 2, 3, ... } are linearly independent, and every function \"f\" that is square-integrable on [0, 2π] is an \"infinite linear combination\" of them, in the sense that\n\nfor suitable (real or complex) coefficients \"a\", \"b\". But many square-integrable functions cannot be represented as \"finite\" linear combinations of these basis functions, which therefore \"do not\" comprise a Hamel basis. Every Hamel basis of this space is much bigger than this merely countably infinite set of functions. Hamel bases of spaces of this kind are typically not useful, whereas orthonormal bases of these spaces are essential in Fourier analysis.\n\nThe geometric notions of an affine space, projective space, convex set, and cone have related notions of \"basis\". An affine basis for an \"n\"-dimensional affine space is formula_58 points in general linear position. A ' is formula_59 points in general position, in a projective space of dimension \"n\". A ' of a polytope is the set of the vertices of its convex hull. A consists of one point by edge of a polygonal cone. See also a Hilbert basis (linear programming).\n\nFor a probability distribution in R with a probability density function, such as the equidistribution in a \"n\"-dimensional ball with respect to Lebesgue measure, it can be shown that \"n\" randomly and independently chosen vectors will form a basis with probability one, which is due to the fact that \"n\" linearly dependent vectors x, ..., x in R should satisfy the equation (zero determinant of the matrix with columns x), and the set of zeros of a non-trivial polynomial has zero measure. This observation has led to techniques for approximating random bases.\n\nIt is difficult to check numerically the linear dependence or exact orthogonality. Therefore, the notion of ε-orthogonality is used. For spaces with inner product, \"x\" is ε-orthogonal to \"y\" if formula_60 (that is, cosine of the angle between \"x\" and \"y\" is less than ε).\n\nIn high dimensions, two independent random vectors are with high probability almost orthogonal, and the number of independent random vectors, which all are with given high probability pairwise almost orthogonal, grows exponentially with dimension. More precisely, consider equidistribution in \"n\"-dimensional ball. Choose \"N\" independent random vectors from a ball (they are independent and identically distributed). Let \"θ\" be a small positive number. Then for\n\n\"N\" random vectors are all pairwise ε-orthogonal with probability . This \"N\" growth exponentially with dimension \"n\" and formula_61 for sufficiently big \"n\". This property of random bases is a manifestation of the so-called \"measure concentration phenomenon\".\n\nThe figure (right) illustrates distribution of lengths N of pairwise almost orthogonal chains of vectors that are independently randomly sampled from the \"n\"-dimensional cube as a function of dimension, \"n\". A point is first randomly selected in the cube. The second point is randomly chosen in the same cube. If the angle between the vectors was within then the vector was retained. At the next step a new vector is generated in the same hypercube, and its angles with the previously generated vectors are evaluated. If these angles are within then the vector is retained. The process is repeated until the chain of almost orthogonality breaks, and the number of such pairwise almost orthogonal vectors (length of the chain) is recorded. For each \"n\", 20 pairwise almost orthogonal chains where constructed numerically for each dimension. Distribution of the length of these chains is presented.\n\nLet V be any vector space over some field F.\nLet X be the set of all linearly independent subsets of V.\n\nThe set X is nonempty since the empty set is an independent subset of V,\nand it is partially ordered by inclusion, which is denoted, as usual, by .\n\nLet Y be a subset of X that is totally ordered by ,\nand let L be the union of all the elements of Y (which are themselves certain subsets of V).\n\nSince (Y, ⊆) is totally ordered, every finite subset of L is a subset of an element of Y,\nwhich is a linearly independent subset of V,\nand hence every finite subset of L is linearly independent.\nThus L is linearly independent, so L is an element of X.\nTherefore, L is an upper bound for Y in (X, ⊆):\nit is an element of X, that contains every element Y.\n\nAs X is nonempty, and every totally ordered subset of (X, ⊆) has an upper bound in X, Zorn's lemma asserts that X has a maximal element. In other words, there exists some element L of X satisfying the condition that whenever L ⊆ L for some element L of X, then L = L.\n\nIt remains to prove that L is a basis of V. Since L belongs to X, we already know that L is a linearly independent subset of V.\n\nIf L would not span V, there would exist some vector w of V that cannot be expressed as a linear combination of elements of L (with coefficients in the field F). In particular, w cannot be an element of L.\nLet L = L ∪ {w}. This set is an element of X, that is, it is a linearly independent subset of V (because w is not in the span of L, and L is independent). As L ⊆ L, and L ≠ L (because L contains the vector w that is not contained in L), this contradicts the maximality of L. Thus this shows that L spans V.\n\nHence L is linearly independent and spans V. It is thus a basis of V, and this proves that every vector space has a basis.\n\nThis proof relies on Zorn's lemma, which is equivalent to the axiom of choice. Conversely, it may be proved that if every vector space has a basis, then the axiom of choice is true; thus the two assertions are equivalent.\n\n\n\n\n"}
{"id": "18422", "url": "https://en.wikipedia.org/wiki?curid=18422", "title": "Linear algebra", "text": "Linear algebra\n\nLinear algebra is the branch of mathematics concerning linear equations such as \nlinear functions such as\nand their representations through matrices and vector spaces.\n\nLinear algebra is central to almost all areas of mathematics. For instance, linear algebra is fundamental in modern presentations of geometry, including for defining basic objects such as lines, planes and rotations. Also, functional analysis may be basically viewed as the application of linear algebra to spaces of functions. Linear algebra is also used in most sciences and engineering areas, because it allows modeling many natural phenomena, and efficiently computing with such models. For nonlinear systems, which cannot be modeled with linear algebra, linear algebra is often used as a first-order approximation.\n\nThe procedure for solving simultaneous linear equations now called Gaussian elimination appears in the ancient Chinese mathematical text Chapter Eight: \"Rectangular Arrays\" of \"The Nine Chapters on the Mathematical Art\". Its use is illustrated in eighteen problems, with two to five equations. \n\nSystems of linear equations arose in Europe with the introduction in 1637 by René Descartes of coordinates in geometry. In fact, in this new geometry, now called Cartesian geometry, lines and planes are represented by linear equations, and computing their intersections amounts to solving systems of linear equations.\n\nThe first systematic methods for solving linear systems used determinants, first considered by Leibniz in 1693. In 1750, Gabriel Cramer used them for giving explicit solutions of linear systems, now called Cramer's Rule. Later, Gauss further described the method of elimination, which was initially listed as an advancement in geodesy.\n\nIn 1844 Hermann Grassmann published his \"Theory of Extension\" which included foundational new topics of what is today called linear algebra. In 1848, James Joseph Sylvester introduced the term \"matrix\", which is Latin for \"womb\". \n\nLinear algebra grew with ideas noted in the complex plane. For instance, two numbers \"w\" and \"z\" in ℂ have a difference \"w\" – \"z\", and the line segments formula_3 are of the same length and direction. The segments are equipollent. The four-dimensional system ℍ of quaternions was started in 1843. The term \"vector\" was introduced as \"v\" = \"x\" i + \"y\" j + \"z\" k representing a point in space. The quaternion difference \"p\" – \"q\" also produces a segment equipollent to formula_4 \nOther hypercomplex number systems also used the idea of a linear space with a basis.\n\nArthur Cayley introduced matrix multiplication and the inverse matrix in 1856, making possible the general linear group. The mechanism of group representation became available for describing complex and hypercomplex numbers. Crucially, Cayley used a single letter to denote a matrix, thus treating a matrix as an aggregate object. He also realized the connection between matrices and determinants, and wrote \"There would be many things to say about this theory of matrices which should, it seems to me, precede the theory of determinants\".\n\nBenjamin Peirce published his \"Linear Associative Algebra\" (1872), and his son Charles Sanders Peirce extended the work later.\n\nThe telegraph required an explanatory system, and the 1873 publication of A Treatise on Electricity and Magnetism instituted a field theory of forces and required differential geometry for expression. Linear algebra is flat differential geometry and serves in tangent spaces to manifolds. Electromagnetic symmetries of spacetime are expressed by the Lorentz transformations, and much of the history of linear algebra is the history of Lorentz transformations.\n\nThe first modern and more precise definition of a vector space was introduced by Peano in 1888; by 1900, a theory of linear transformations of finite-dimensional vector spaces had emerged. Linear algebra took its modern form in the first half of the twentieth century, when many ideas and methods of previous centuries were generalized as abstract algebra. The development of computers led to increased research in efficient algorithms for Gaussian elimination and matrix decompositions, and linear algebra became an essential tool for modelling and simulations.\n\nSee also and .\n\nUntil the 19th century, linear algebra was introduced through systems of linear equations and matrices. In modern mathematics, the presentation through \"vector spaces\" is generally preferred, since it is more synthetic, more general (not limited to the finite-dimensional case), and conceptually simpler, although more abstract.\n\nA vector space over a field (often the field of the real numbers) is a set equipped with two binary operations satisfying the following axioms. \nElements of are called \"vectors\", and elements of \"F\" are called \"scalars\". The first operation, \"vector addition\", takes any two vectors and and outputs a third vector . The second operation, \"scalar multiplication\", takes any scalar and any vector and outputs a new . The axioms that addition and scalar multiplication must satisfy are the following (in the list below, and are arbitrary elements of , and and are arbitrary scalars in the field .\n\nThe first four axioms mean that is an abelian group under addition.\n\nElements of a vector space may have various nature; for example, they can be sequences, functions, polynomials or matrices. Linear algebra is concerned with properties common to all vector spaces.\n\nLinear maps are mappings between vector spaces that preserve the vector-space structure. Given two vector spaces and over a field , a linear map (also called, in some contexts, linear transformation, linear mapping or linear operator) is a map\n\nthat is compatible with addition and scalar multiplication, that is\n\nfor any vectors in and scalar in .\n\nThis implies that for any vectors in and scalars in , one has\n\nWhen a bijective linear map exists between two vector spaces (that is, every vector from the second space is associated with exactly one in the first), the two spaces are isomorphic. Because an isomorphism preserves linear structure, two isomorphic vector spaces are \"essentially the same\" from the linear algebra point of view, in the sense that they cannot be distinguished by using vector space properties. An essential question in linear algebra is testing whether a linear map is an isomorphism or not, and, if it is not an isomorphism, finding its range (or image) and the set of elements that are mapped to the zero vector, called the kernel of the map. All these questions can be solved by using Gaussian elimination or some variant of this algorithm.\n\nThe study of subsets of vector spaces that are themselves vector spaces for the induced operations is fundamental, similarly as for many mathematical structures. These subsets are called linear subspaces. More precisely, a linear subspace of a vector space over a field is a subset of such that and are in , for every , in , and every in . (These conditions suffices for implying that is a vector space.)\n\nFor example, the image of a linear map, and the inverse image of 0 by a linear map (called kernel or null space) are linear subspaces.\n\nAnother important way of forming a subspace is to consider linear combinations of a set of vectors: the set of all sums \nwhere are in , and are in form a linear subspace called the span of . The span of is also the intersection of all linear subspaces containing . In other words, it is the (smallest for the inclusion relation) linear subspace containing .\n\nA set of vectors is linearly independent if none is in the span of the others. Equivalently, a set of vector is linearly independent if the only way to express the zero vector as a linear combination of elements of is to take zero for every coefficient formula_9\n\nA set of vectors that spans a vector space is called a spanning set or generating set. If a spanning set is \"linearly dependent\" (that is not linearly independent), then some element of is in the span of the other elements of , and the span would remain the same if one remove from . One may continue to remove elements of until getting a \"linearly independent spanning set\". Such a linearly independent set that spans a vector space is called a basis of . The importance of bases lies in the fact that there are together minimal generating sets and maximal independent sets. More precisely, if is a linearly independent set, and is a spanning set such that formula_10 then there is a basis such that formula_11\n\nAny two bases of a vector space have the same cardinality, which is called the dimension of ; this is the dimension theorem for vector spaces. Moreover, two vector spaces over the same field are isomorphic if and only if they have the same dimension.\n\nIf any basis of (and therefore every basis) has a finite number of elements, is a \"finite-dimensional vector space\". If is a subspace of , then . In the case where is finite-dimensional, the equality of the dimensions implies .\n\nIf \"U\" and \"U\" are subspaces of \"V\", then\n\nwhere formula_13denotes the span of formula_14\n\nMatrices allow explicit manipulation of finite-dimensional vector spaces and linear maps. Their theory is thus an essential part of linear algebra.\n\nLet be a finite-dimensional vector space over a field , and be a basis of (thus is the dimension of ). By definition of a basis, the map\nis a bijection from formula_16 the set of the sequences of elements of , onto . This is an isomorphism of vector spaces, if formula_17 is equipped of its standard structure of vector space, where vector addition and scalar multiplication are done component by component.\n\nThis isomorphism allows representing a vector by its inverse image under this isomorphism, that is by the coordinates vector formula_18 or by the column matrix\n\nIf is another finite dimensional vector space (possibly the same), with a basis formula_20 a linear map from to is well defined by its values on the basis elements, that is formula_21 Thus, is well represented by the list of the corresponding column matrices. That is, if \nfor , then is represented by the matrix\nwith rows and columns.\n\nMatrix multiplication is defined in such a way that the product of two matrices is the matrix of the composition of the corresponding linear maps, and the product of a matrix and a column matrix is the column matrix representing the result of applying the represented linear map to the represented vector. It follows that the theory of finite-dimensional vector spaces and the theory of matrices are two different languages for expressing exactly the same concepts.\n\nTwo matrices that encode the same linear transformation in different bases are called similar. Equivalently, two matrices are similar if one can transform one in the other by elementary row and column operations. For a matrix representing a linear map from to , the row operations correspond to change of bases in and the column operations correspond to change of bases in . Every matrix is similar to an identity matrix possibly bordered by zero rows and zero columns. In terms of vector space, this means that, for any linear map from to , there are bases such that a part of the basis of is mapped bijectively on a part of the basis of , and that the remaining basis elements of , if any, are mapped to zero (this is a way of expressing the fundamental theorem of linear algebra). Gaussian elimination is the basic algorithm for finding these elementary operations, and proving this theorem.\n\nSystems of linear equations form a fundamental part of linear algebra. Historically, linear algebra and matrix theory has been developed for solving such systems. In the modern presentation of linear algebra through vector spaces and matrices, many problems may be interpreted in terms of linear systems.\n\nFor example, let\nbe a linear system.\n\nTo such a system, one may associate its matrix \nand its right member vector\n\nLet be the linear transformation associated to the matrix . A solution of the system is a vector \nsuch that \nthat is an element of the preimage of by .\n\nLet be the associated homogeneous system, where the right-hand sides of the equations are put to zero. The solutions of are exactly the elements of the kernel of or, equivalently, .\n\nThe Gaussian-elimination consists of performing elementary row operations on the augmented matrix\nfor putting it in reduced row echelon form. These row operations do not change the set of solutions of the system of equations. In the example, the reduced echelon form is \nshowing that the system has the unique solution\n\nIt follows from this matrix interpretation of linear systems that the same methods can be applied for solving linear systems and for many operations on matrices and linear transformations, which include the computation of the ranks, kernels, matrix inverses.\n\nA linear endomorphism is a linear map that maps a vector space to itself. \nIf has a basis of elements, such an endomorphism is represented by a square matrix of size .\n\nWith respect to general linear maps, linear endomorphisms and square matrices have some specific properties that make their study an important part of linear algebra, which is used in many parts of mathematics, including geometric transformations, coordinate changes, quadratic forms, and many other part of mathematics.\n\nThe \"determinant\" of a square matrix is a polynomial function of the entries of the matrix, such that the matrix is invertible if and only if the determinant is not zero. This results from the fact that the determinant of a product of matrices is the product of the determinants, and thus that a matrix is invertible if and only if its determinant is invertible.\n\nCramer's rule is a closed-form expression, in terms of determinants, of the solution of a system of linear equations in unknowns. Cramer's rule is useful for reasoning about the solution, but, except for or , it is rarely used for computing a solution, since Gaussian elimination is a faster algorithm.\n\nThe \"determinant of an endomorphism\" is the determinant of the matrix representing the endomorphism in terms of some ordered basis. This definition makes sense, since this determinant is independent of the choice of the basis.\n\nIf is a linear endomorphism of a vector space over a field , an eigenvector of is a nonzero vector of such that for some scalar in . This scalar is an eigenvalue of .\n\nIf the dimension of is finite, and a basis has been chosen, and may be represented, respectively, by a square matrix and a column matrix and ; the equation defining eigenvectors and eigenvalues becomes\nUsing the identity matrix , whose all entries are zero, except those of the main diagonal, which are equal to one, this may be rewritten\nAs is supposed to be nonzero, this means that is a singular matrix, and thus that its determinant formula_34 equals zero. The eigenvalues are thus the roots of the polynomial\nIf is of dimension , this is a monic polynomial of degree , called the characteristic polynomial of the matrix (or of the endomorphism), and there are, at most, eigenvalues.\n\nIf a basis exists that consists only of eigenvectors, the matrix of on this basis has a very simple structure: it is a diagonal matrix such that the entries on the main diagonal are eigenvalues, and the other entries are zero. In this case, the endomorphism and the matrix are said diagonalizable. More generally, an endomorphism and a matrix are also said diagonalizable, if they become diagonalizable after extending the field of scalars. In this extended sense, if the characteristic polynomial is square-free, then the matrix is diagonalizable.\n\nA symmetric matrix is always diagonalizable. There are non-diagonizable matrices, the simplest being\n(it cannot be diagonalizable since its square is the zero matrix, and the square of a nonzero diagonal matrix is never zero).\n\nWhen an endomorphism is not diagonalizable, there are bases on which it has a simple form, although not as simple as the diagonal form. The Frobenius normal form does not need of extending the field of scalars and makes the characteristic polynomial immediately readable on the matrix. The Jordan normal form requires to extend the field of scalar for containing all eigenvalues, and differs from the diagonal form only by some entries that are just above the main diagonal and are equal to 1.\n\nA linear form is a linear map from a vector space over a field to the field of scalars , viewed as a vector space over itself. Equipped by pointwise addition and multiplication by a scalar, the linear forms form a vector space, called the dual space of , and usually denoted formula_37\n\nIf formula_38 is a basis of (this implies that is finite-dimensional), then one can define, for , a linear map formula_39 such that formula_40 and formula_41 if . These linear maps form a basis of formula_42 called the dual basis of formula_43 (If is not finite-dimensional, the formula_44 may be defined similarly; they are linearly independent, but do not form a basis.)\n\nFor in , the map\nis a linear form on formula_37 This defines the canonical linear map from into formula_47, the dual of formula_42 called the bidual of . This canonical map is an isomorphism if is finite-dimensional, and this allows identifying with its bidual. (In the infinite dimensional case, the canonical map is injective, but not surjective.)\n\nThere is thus a complete symmetry between a finite-dimensional vector space and its dual. This motivates the frequent use, in this context, of the bra–ket notation\nfor denoting .\n\nLet \nbe a linear map. For every linear form on , the composite function is a linear form on . This defines a linear map\nbetween the dual spaces, which is called the dual or the transpose of .\n\nIf and are finite dimensional, and is the matrix of in terms of some ordered bases, then the matrix of formula_52 over the dual bases is the transpose formula_53 of , obtained by exchanging rows and columns.\n\nIf elements of vector spaces and their duals are represented by column vectors, this duality may be expressed in bra–ket notation by \nFor highlighting this symmetry, the two members of this equality are sometimes written \n\nBesides these basic concepts, linear algebra also studies vector spaces with additional structure, such as an inner product. The inner product is an example of a bilinear form, and it gives the vector space a geometric structure by allowing for the definition of length and angles. Formally, an \"inner product\" is a map\n\nthat satisfies the following three axioms for all vectors \"u\", \"v\", \"w\" in \"V\" and all scalars \"a\" in \"F\":\n\nNote that in R, it is symmetric.\n\n\nWe can define the length of a vector \"v\" in \"V\" by\nand we can prove the Cauchy–Schwarz inequality:\n\nIn particular, the quantity\nand so we can call this quantity the cosine of the angle between the two vectors.\n\nTwo vectors are orthogonal if formula_64. An orthonormal basis is a basis where all basis vectors have length 1 and are orthogonal to each other. Given any finite-dimensional vector space, an orthonormal basis could be found by the Gram–Schmidt procedure. Orthonormal bases are particularly easy to deal with, since if \"v\" = \"a\" \"v\" + ... + \"a v\", then formula_65.\n\nThe inner product facilitates the construction of many useful concepts. For instance, given a transform \"T\", we can define its Hermitian conjugate \"T*\" as the linear transform satisfying\nIf \"T\" satisfies \"TT*\" = \"T*T\", we call \"T\" normal. It turns out that normal matrices are precisely the matrices that have an orthonormal system of eigenvectors that span \"V\".\n\nThere is a strong relationship between linear algebra and geometry, which started with the introduction by René Descartes, in 1637, of Cartesian coordinates. In this new (at that time) geometry, now called Cartesian geometry, points are represented by Cartesian coordinates, which are sequences of three real numbers (in the case of the usual three-dimensional space). The basic objects of geometry, which are lines and planes are represented by linear equations. Thus, computing intersections of lines and planes amounts solving systems of linear equations. This was one of the main motivations for developing linear algebra.\n\nMost geometric transformation, such as translations, rotations, reflections, rigid motions, isometries, and projections transform lines into lines. It follows that they can be defined, specified and studied in terms of linear maps. This is also the case of homographies and Möbius transformations, when considered as transformations of a projective space. \n\nUntil the end of 19th century, geometric spaces were defined by axioms relating points, lines and planes (synthetic geometry). Around this date, it appeared that one may also define geometric spaces by constructions involving vector spaces (see, for example, Projective space and Affine space) It has been shown that the two approaches are essentially equivalent. In classical geometry, the involved vector spaces are vector spaces over the reals, but the constructions may be extended to vector spaces over any field, allowing considering geometry over arbitrary fields, including finite fields. \n\nPresently, most textbooks, introduce geometric spaces from linear algebra, and geometry is often presented, at elementary level, as a subfield of linear algebra.\n\nLinear algebra is used in almost all areas of mathematics, and therefore in almost all scientific domains that use mathematics. These applications may be divided into several wide categories.\n\nThe modeling of our ambient space is based on geometry. Sciences concerned with this space use geometry widely. This is the case with mechanics and robotics, for describing rigid body dynamics; geodesy for describing Earth shape; perspectivity, computer vision, and computer graphics, for describing the relationship between a scene and its plane representation; and many other scientific domains.\n\nIn all these applications, synthetic geometry is often used for general descriptions and a qualitative approach, but for the study of explicit situations, one must compute with coordinates. This requires the heavy use of linear algebra.\n\nFunctional analysis studies function spaces. These are vector spaces with additional structure, such as Hilbert spaces. Linear algebra is thus a fundamental part of functional analysis and its applications, which include, in particular, quantum mechanics (wave functions).\n\nMost physical phenomena are modeled by partial differential equations. To solve them, one usually decomposes the space in which the solutions are searched into small, mutually interacting cells. For linear systems this interaction involves linear functions. For nonlinear systems, this interaction is often approximated by linear functions. In both cases, very large matrices are generally involved. Weather forecasting is a typical example, where the whole Earth atmosphere is divided in cells of, say, 100 km of width and 100 m of height.\n\nNearly all scientific computations involve linear algebra. Consequently, linear algebra algorithms have been highly optimized. BLAS and LAPACK are the best known implementations. For improving efficiency, some of them configure the algorithms automatically, at run time, for adapting them to the specificities of the computer (cache size, number of available cores, ...).\n\nSome processors, typically graphics processing units (GPU), are designed with a matrix structure, for optimizing the operations of linear algebra.\n\nThis section presents several related topics that do not appear generally in elementary textbooks on linear algebra, but are commonly considered, in advanced mathematics, as parts of linear algebra.\n\nThe existence of multiplicative inverses in fields is not involved in the axioms defining a vector space. One may thus replace the field of scalars by a ring , and this gives a structure called module over , or -module.\n\nThe concepts of linear independence, span, basis, and linear maps (also called module homomorphisms) are defined for modules exactly as for vector spaces, with the essential difference that, if is not a field, there are modules that do not have any basis. The modules that have a basis are the free modules, and those that are spanned by a finite set are the finitely generated modules. Module homomorphisms between finitely generated free modules may be represented by matrices. The theory of matrices over a ring is similar to that of matrices over a field, except that determinants exist only if the ring is commutative, and that a square matrix over a commutative ring is invertible only if its determinant has a multiplicative inverse in the ring.\n\nVector spaces are completely characterized by their dimension (up to an isomorphism). In general, there is not such a complete classification for modules, even if one restricts oneself to finitely generated modules. However, every module is a cokernel of a homomorphism of free modules.\n\nModules over the integers can be identified with abelian groups, since the multiplication by an integer may identified to a repeated addition. Most of the theory of abelian groups may be extended to modules over a principal ideal domain. In particular, over a principal ideal domain, every submodule of a free module is free, and the fundamental theorem of finitely generated abelian groups may be extended straightforwardly to finitely generated modules over a principal ring.\n\nThere are many rings for which there are algorithms for solving linear equations and systems of linear equations. However, these algorithms have generally a computational complexity that is much higher than the similar algorithms over a field. For more details, see Linear equation over a ring.\n\nIn multilinear algebra, one considers multivariable linear transformations, that is, mappings that are linear in each of a number of different variables. This line of inquiry naturally leads to the idea of the dual space, the vector space \"V\" consisting of linear maps where \"F\" is the field of scalars. Multilinear maps can be described via tensor products of elements of \"V\".\n\nIf, in addition to vector addition and scalar multiplication, there is a bilinear vector product , the vector space is called an algebra; for instance, associative algebras are algebras with an associate vector product (like the algebra of square matrices, or the algebra of polynomials).\n\nFunctional analysis mixes the methods of linear algebra with those of mathematical analysis and studies various function spaces, such as L spaces.\n\n\n\n\n\n\n\n"}
{"id": "18423", "url": "https://en.wikipedia.org/wiki?curid=18423", "title": "Labia majora", "text": "Labia majora\n\nThe labia majora (singular: \"labium majus\") are two prominent longitudinal cutaneous folds that extend downward and backward from the mons pubis to the perineum. Together with the labia minora they form the labia of the vulva.\n\nThe labia majora are homologous to the male scrotum.\n\n\"Labia majora\" is the Latin plural for big (\"major\") lips; the singular is \"labium majus.\" The Latin term \"labium/labia\" is used in anatomy for a number of usually paired parallel structures, but in English it is mostly applied to two pairs of parts of female external genitals (vulva)—labia majora and labia minora. Labia majora are commonly known as the outer lips, while labia minora (Latin for \"small lips\"), which run alongside between them, are referred to as the inner lips. Traditionally, to avoid confusion with other lip-like structures of the body, the labia of female genitals were termed by anatomists in Latin as \"labia majora (\"or \"minora) pudendi.\"\n\nEmbryologically, they develop from labioscrotal folds. It means that they develop in the female foetus from the same previously sexually undifferentiated anatomical structure as the scrotum, the sac of skin below the penis in males.\n\nThe same process of sex differentiation concerns other male and female reproductive organs (see List of related male and female reproductive organs), with some organs of both sexes developing similar, yet not identical, structure and functions (like the gonads - male testicles and female ovaries, like male and female urethras, erectile corpus cavernosum penis and prepuce in the penis (foreskin) and the corpus cavernosum clitoridis in the clitoris and (clitoral hood) and their frenula). But other male and female sex organs become absolutely different and unique, like the internal female genitalia.\n\nThe scrotum and labia majora develop to have both similarities and crucial differences. Like the scrotum, labia majora after puberty may become of a darker color than the skin outside them, and, similarly, also grow pubic hair on their external surface (the female genitals on accompanying photos are shaved to show their structure clearer). But, during sexual differentiation of the foetus, labioscrotal folds in the males normally fuse longitudinally in the middle, forming a sack for male gonads (testicles) to descend into it from the pelvis, while in the females these folds normally do not fuse, forming the two labia majora and the pudendal cleft between them. Female gonads (ovaries) do not descend from the pelvis, thus the structure of labia majora may seem simpler (just fatty tissue covered with skin) and of lesser significance for functioning of the female body as a whole than the scrotum with testicles for males. The ridge or groove remaining of the fusion can be traced on the scrotum.\n\nIn some cases of intersex with disorders of sex development male/female genitalia may look ambiguous for either gender with phallus too small for a typical penis yet too big for a clitoris, with external urethral opening in an atypical location, and with labia/scrotum fully or partially fused but without descended gonads in them. Undescended testicles, though, may also occur in otherwise generally healthy male infants.\n\nThe labia majora constitute the lateral boundaries of the pudendal cleft, which contains the labia minora, interlabial sulci, clitoral hood, clitoral glans, frenulum clitoridis, the Hart's Line, and the vulval vestibule, which contains the external openings of the urethra and the vagina. Each labium majus has two surfaces, an outer, pigmented and covered with strong, pubic hair; and an inner, smooth and beset with large sebaceous follicles. The labia majora are covered with squamous epithelium. Between the two there is a considerable quantity of areolar tissue, fat, and a tissue resembling the dartos tunic of the scrotum, besides vessels, nerves, and glands. The labia majora are thicker in front, and form the anterior labial commissure where they meet below the mons pubis. Posteriorly, they are not really joined, but appear to become lost in the neighboring integument, ending close to, and nearly parallel to, each other. Together with the connecting skin between them, they form another commissure the posterior labial commissure which is also the posterior boundary of the pudendum. The interval between the posterior commissure and the anus, from 2.5 to 3 cm in length, constitutes the perineum. The anterior region of the perineum is known as the urogenital triangle which separates it from the anal region. Between the labia majora and the inner thighs are the labiocrural folds. Between the labia majora and labia minora are the interlabial sulci. Labia majora atrophy after menopause.\n\nThe fat pad of the labia majora can be used as a graft, often as a so-called \"Martius labial fat pad graft\", and can be used, for example, in urethrolysis.\n\n\n"}
{"id": "18424", "url": "https://en.wikipedia.org/wiki?curid=18424", "title": "Labia minora", "text": "Labia minora\n\nThe labia minora, Latin for \"smaller lips,\" singular: \"labium minus \"\"smaller lip\"\"\", also known as the inner labia, inner lips, vaginal lips or nymphae, are two flaps of skin on either side of the human vaginal opening in the vulva, situated between the labia majora (the Latin for \"larger lips;\" also called outer labia, or outer lips). The labia minora vary widely in size, color, and shape from individual to individual.\n\nThe labia minora extend from the clitoris obliquely downward, laterally, and backward on either side of the vulval vestibule, ending between the bottom of the vulval vestibule and the labia majora. The posterior ends (bottom) of the labia minora are usually joined across the middle line by a fold of skin, named the frenulum of labia minora or fourchette.\n\nOn the front, each lip forks dividing into two portions surrounding the clitoris. The upper part of each lip passes above the clitoris to meet the upper part of the other lip—which will often be a little larger or smaller—forming a fold which overhangs the glans clitoridis (clitoral tip or head); this fold is named the clitoral hood. The lower part passes beneath the glans clitoridis and becomes united to its under surface, forming, with the inner lip of the opposite side, the \"frenulum clitoridis\".\n\nThe clitoral hood, analogously to the foreskin of the penis in men and also termed, like the latter, by the Latin word \"prepuce\", serves to cover most of the time the shaft and sometimes the glans (which is very sensitive to the touch) to protect the clitoris from mechanical irritation and from dryness. Yet the hood is movable and can slide during clitoral erection or be pulled upwards a little for greater exposure of the clitoris to sexual stimulation.\n\nThe frenulum (Latin for \"little bridle\") is an elastic band of tissue attached by its one end to the clitoral shaft and glans and by its other end to the prepuce. It allows two-way shifting of the clitoral hood: firstly, it can extend to let the hood be moved upwards to expose the glans for stimulation or hygienic cleansing, and secondly, it contracts to pull the hood back to protect it.\n\nOn the opposed surfaces of the labia minora are numerous sebaceous glands not associated with hair follicles. They are lined by stratified squamous epithelium on those surfaces.\n\nLike the whole area of the vulval vestibule, the mucus secreted by those glands protects the labia from dryness and mechanical irritation.\n\nBeing thinner than the outer labia, the inner labia can be also more narrow than the former, or wider than labia majora, thus protruding in the pudendal cleft and making the term \"minora\" (Latin for smaller) essentially inapplicable in these cases.\n\nThe reception of wider and/or longer labia varies considerably between different people, with some men and women stressing the beauty of bigger labia while other women who have such ones complain of some discomfort either from mechanical irritation by their tighter clothes or from their own or their peers' negative attitude to the image of less compact female genitalia than is stereotypical for them.\n\nThey can also be smooth or frilled, the latter being more typical of longer or wider inner labia.\n\nFrom 2003 to 2004, researchers from the Department of Gynaecology, Elizabeth Garret Anderson Hospital in London, measured the labia and other genital structures of 50 women from the age of 18 to 50, with a mean age of 35.6. The results were:\n\nDue to the frequent portrayal of the pudendal cleft without protrusion in art and pornography, there has been a rise in the popularity of labiaplasty, surgery to alter the labia - usually, to make them smaller. On the other hand, there is an opposite movement of labia stretching. Its proponents stress the beauty of long labia and their positive role in sexual stimulation of both partners.\n\nLabiaplasty is also sometimes sought by women who have asymmetrical labia minora to adjust the shape of the structures towards identical size.\n\nLabia stretching has traditionally been practiced in some African nations.\n\nThe inner lips serve to protect from mechanical irritation, dryness and infections the highly sensitive area of the vulval vestibule with vaginal and urethral openings in it between them. During vaginal sexual intercourse they may contribute to stimulation of the whole vestibule area, the clitoris and the vagina of the woman and the penis of her partner. Stimulation of the clitoris may occur through tension of the clitoral hood and its frenulum by inner labia pulling at them. During sexual arousal they are lubricated by the mucus secreted in the vagina and around it to make penetration painless and protect them from irritation.\n\nAs the female external urethral opening (meatus) is also situated between labia minora, they may play a role in guiding the stream of the urine during female urination.\n\nBeing very sensitive by their structure to any irritation, and situated in the excretion area where traces of urine, vaginal discharge, smegma and even feces may be present, the inner lips may be susceptible to inflammatory infections of the vulva such as vulvitis.\n\nThe likelihood of inflammation may be reduced through appropriate regular hygienic cleansing of the whole vulval vestibule, using water and medically tested cleansing agents designed for female intimate areas. To avoid contamination of the vulva with fecal bacteria, it is recommended that the vulva is washed only from front to back, from mons pubis to the perineum and anus. Apart from water and special liquid cleansing agents (lotions), there are commercially available wet wipes for female intimate hygiene. Some women wipe the vulval vestibule dry with toilet tissue after urination to avoid irritation and infections from residual drops of the urine in the area.\n\nHowever, incorrect choice of cleansing agents, or their incorrect application, may itself cause labial irritation and require medical attention. Over-vigorous rubbing of the labia of little girls while washing, combined with the lack of estrogen in their bodies, may lead to the mostly pediatric condition known as labial fusion. If fused labia prevent urination, urine may accumulate and cause pain and inflammation.\n\nIn adult females, irritation of the area may be caused by wearing too-tight underwear (especially where wider inner labia protrude in the pudendal cleft); while G-strings, which rub against the labia during body movements, may cause irritation or lead to infection from bacteria transferred from either the external environment or the anus.\n\n"}
{"id": "18425", "url": "https://en.wikipedia.org/wiki?curid=18425", "title": "Leopold von Sacher-Masoch", "text": "Leopold von Sacher-Masoch\n\nLeopold Ritter von Sacher-Masoch (27 January 1836 – 9 March 1895) was an Austrian nobleman, writer and journalist, who gained renown for his romantic stories of Galician life. The term \"masochism\" is derived from his name, invented by his contemporary, the Austrian psychiatrist Richard von Krafft-Ebing. Masoch did not consent to or approve of this use of his name.\n\nDuring his lifetime, Sacher-Masoch was well known as a man of letters, in particular a utopian thinker who espoused socialist and humanist ideals in his fiction and non-fiction. Most of his works remain untranslated into English. Until recently, his novel \"Venus in Furs\" was his only book commonly available in English, but an English translation by William Holmes of \"Die Gottesmutter\" was released in 2015 as \"The Mother of God\".\n\nVon Sacher-Masoch was born in the city of Lemberg (now Lviv, Ukraine), the capital of the Kingdom of Galicia and Lodomeria, at the time a province of the Austrian Empire, into the Roman Catholic family of an Austrian civil servant, Leopold Johann Nepomuk Ritter von Sacher, and Charlotte von Masoch, a Ukrainian noblewoman. The father later combined his surname with his wife's 'von Masoch', at the request of her family (she was the last of the line). Von Sacher served as a Commissioner of the Imperial Police Forces in Lemberg, and he was recognised with a new title of nobility as Sacher-Masoch awarded by the Austrian Emperor.\n\nLeopold studied law, history and mathematics at Graz University, and after graduating moved back to Lemberg where he became a professor. His early, non-fictional publications dealt mostly with Austrian history. At the same time, Masoch turned to the folklore and culture of his homeland, Galicia. Soon he abandoned lecturing and became a free man of letters. Within a decade his short stories and novels prevailed over his historical non-fiction works, though historical themes continued to imbue his fiction.\n\nPanslavist ideas were prevalent in Masoch's literary work, and he found a particular interest in depicting picturesque types among the various ethnicities that inhabited Galicia. From the 1860s to the 1880s he published a number of volumes of \"Jewish Short Stories\", \"Polish Short Stories\", \"Galician Short Stories\", \"German Court Stories\" and \"Russian Court Stories\". His works were published in translation in Ukrainian, Polish, Russian and French.\n\nIn 1869, Sacher-Masoch conceived a grandiose series of short stories under the collective title \"Legacy of Cain\" that would represent the author's aesthetic \"Weltanschauung\". The cycle opened with the manifesto \"The Wanderer\" that brought out misogynist themes that became peculiar to Masoch's writings. Of the six planned volumes, only the first two were ever completed. By the middle of the 1880s, Masoch abandoned the \"Legacy of Cain\". Nevertheless, the published volumes of the series included Masoch's best-known stories, and of them, \"Venus in Furs\" (1869) is the most famous today. The short novel expressed Sacher-Masoch's fantasies and fetishes (especially for dominant women wearing fur). He did his best to live out his fantasies with his mistresses and wives.\n\nSacher-Masoch edited the Leipzig-based monthly literary magazine \"Auf der Höhe. Internationale Review\" (\"At the Pinnacle. International Review\"), which was published from October, 1881 to September, 1885. This was a progressive magazine aimed at tolerance and integration for Jews in Saxony, as well as for the emancipation of women with articles on women's education and suffrage.\n\nIn his later years, he worked against local antisemitism through an association for adult education called the \"Oberhessischer Verein für Volksbildung\" (OVV), founded in 1893 with his second wife, Hulda Meister, who had also been his assistant for some years.\n\nOn 9 December 1869, Sacher-Masoch and his mistress Baroness Fanny Pistor signed a contract making him her slave for a period of six months, with the stipulation that the Baroness wear furs as often as possible, especially when she was in a cruel mood. Sacher-Masoch took the alias of \"Gregor\", a stereotypical male servant's name, and assumed a disguise as the servant of the Baroness. The two travelled by train to Italy. As in \"Venus in Furs\", he traveled in the third-class compartment, while she had a seat in first-class, arriving in Venice (Florence, in the novel), where they were not known, and would not arouse suspicion.\n\nSacher-Masoch pressured his first wife – Aurora von Rümelin, whom he married in 1873 – to live out the experience of the book, against her preferences. Sacher-Masoch found his family life to be unexciting, and eventually got a divorce and married his assistant.\n\nIn 1875, Masoch wrote \"The Ideals of Our Time\", an attempt to give a portrait of German society during its Gründerzeit period.\n\nIn his late fifties, his mental health began to deteriorate, and he spent the last years of his life under psychiatric care. According to official reports, he died in Lindheim, Altenstadt, Hesse, in 1895. It is also claimed that he died in an asylum in Mannheim in 1905.\n\nSacher-Masoch is the great-great-uncle to the British singer and actress Marianne Faithfull on the side of her mother, the Viennese Baroness Eva Erisso.\n\nThe term \"masochism\" was coined in 1886 by the Austrian psychiatrist Richard Freiherr von Krafft-Ebing (1840–1902) in his book \"Psychopathia Sexualis\":\n\nSacher-Masoch was not pleased with Krafft-Ebing's assertions. Nevertheless, details of Masoch's private life were obscure until Aurora von Rümelin's memoirs, \"Meine Lebensbeichte\" (My Life Confession;1906), were published in Berlin under the pseudonym Wanda v. Dunajew. The following year, a French translation, \"Confession de Ma Vie\" (1907) by \"Wanda von Sacher-Masoch\", was printed in Paris by Mercure de France. An English translation of the French edition was published as \"The Confessions of Wanda von Sacher-Masoch\" (1991) by RE/Search Publications.\n\n\n\n\n"}
{"id": "18426", "url": "https://en.wikipedia.org/wiki?curid=18426", "title": "Lithography", "text": "Lithography\n\nLithography () is a method of printing originally based on the immiscibility of oil and water. The printing is from a stone (lithographic limestone) or a metal plate with a smooth surface. It was invented in 1796 by German author and actor Alois Senefelder as a cheap method of publishing theatrical works. Lithography can be used to print text or artwork onto paper or other suitable material.\n\nLithography originally used an image drawn with oil, fat, or wax onto the surface of a smooth, level lithographic limestone plate. The stone was treated with a mixture of acid and gum arabic, \"etching\" the portions of the stone that were not protected by the grease-based image. When the stone was subsequently moistened, these etched areas retained water; an oil-based ink could then be applied and would be repelled by the water, sticking only to the original drawing. The ink would finally be transferred to a blank paper sheet, producing a printed page. This traditional technique is still used in some fine art printmaking applications.\n\nIn modern lithography, the image is made of a polymer coating applied to a flexible plastic or metal plate. The image can be printed directly from the plate (the orientation of the image is reversed), or it can be offset, by transferring the image onto a flexible sheet (rubber) for printing and publication.\n\nAs a printing technology, lithography is different from intaglio printing (gravure), wherein a plate is either engraved, etched, or stippled to score cavities to contain the printing ink; and woodblock printing or letterpress printing, wherein ink is applied to the raised surfaces of letters or images. Today, most types of high-volume books and magazines, especially when illustrated in colour, are printed with offset lithography, which has become the most common form of printing technology since the 1960s.\n\nThe related term \"photolithography\" refers to when photographic images are used in lithographic printing, whether these images are printed directly from a stone or from a metal plate, as in offset printing. \"Photolithography\" is used synonymously with \"offset printing\". The technique as well as the term were introduced in Europe in the 1850s. Beginning in the 1960s, photolithography has played an important role in the fabrication and mass production of integrated circuits in the microelectronics industry.\n\nLithography uses simple chemical processes to create an image. For instance, the positive part of an image is a water-repelling (\"hydrophobic\") substance, while the negative image would be water-retaining (\"hydrophilic\"). Thus, when the plate is introduced to a compatible printing ink and water mixture, the ink will adhere to the positive image and the water will clean the negative image. This allows a flat print plate to be used, enabling much longer and more detailed print runs than the older physical methods of printing (e.g., intaglio printing, letterpress printing).\n\nLithography was invented by Alois Senefelder in the Kingdom of Bavaria in 1796. In the early days of lithography, a smooth piece of limestone was used (hence the name \"lithography\": \"lithos\" (λιθος) is the ancient Greek word for stone). After the oil-based image was put on the surface, a solution of gum arabic in water was applied, the gum sticking only to the non-oily surface. During printing, water adhered to the gum arabic surfaces and was repelled by the oily parts, while the oily ink used for printing did the opposite.\n\nLithography works because of the mutual repulsion of oil and water. The image is drawn on the surface of the print plate with a fat or oil-based medium (hydrophobic) such as a wax crayon, which may be pigmented to make the drawing visible. A wide range of oil-based media is available, but the durability of the image on the stone depends on the lipid content of the material being used, and its ability to withstand water and acid. After the drawing of the image, an aqueous solution of gum arabic, weakly acidified with nitric acid is applied to the stone. The function of this solution is to create a hydrophilic layer of calcium nitrate salt, , and gum arabic on all non-image surfaces. The gum solution penetrates into the pores of the stone, completely surrounding the original image with a hydrophilic layer that will not accept the printing ink. Using lithographic turpentine, the printer then removes any excess of the greasy drawing material, but a hydrophobic molecular film of it remains tightly bonded to the surface of the stone, rejecting the gum arabic and water, but ready to accept the oily ink.\n\nSenefelder had experimented during the early 19th century with multicolor lithography; in his 1819 book, he predicted that the process would eventually be perfected and used to reproduce paintings. Multi-color printing was introduced by a new process developed by Godefroy Engelmann (France) in 1837 known as chromolithography. A separate stone was used for each color, and a print went through the press separately for each stone. The main challenge was to keep the images aligned (\"in register\"). This method lent itself to images consisting of large areas of flat color, and resulted in the characteristic poster designs of this period.\n\n\"Lithography, or printing from soft stone, largely took the place of engraving in the production of English commercial maps after about 1852. It was a quick, cheap process and had been used to print British army maps during the Peninsula War. Most of the commercial maps of the second half of the 19th century were lithographed and unattractive, though accurate enough.\"\n\nHigh-volume lithography is used presently to produce posters, maps, books, newspapers, and packaging—just about any smooth, mass-produced item with print and graphics on it. Most books, indeed all types of high-volume text, are now printed using offset lithography.\n\nFor offset lithography, which depends on photographic processes, flexible aluminum, polyester, mylar or paper printing plates are used instead of stone tablets. Modern printing plates have a brushed or roughened texture and are covered with a photosensitive emulsion. A photographic negative of the desired image is placed in contact with the emulsion and the plate is exposed to ultraviolet light. After development, the emulsion shows a reverse of the negative image, which is thus a duplicate of the original (positive) image. The image on the plate emulsion can also be created by direct laser imaging in a CTP (Computer-To-Plate) device known as a platesetter. The positive image is the emulsion that remains after imaging. Non-image portions of the emulsion have traditionally been removed by a chemical process, though in recent times plates have come available that do not require such processing.\n\nThe plate is affixed to a cylinder on a printing press. Dampening rollers apply water, which covers the blank portions of the plate but is repelled by the emulsion of the image area. Hydrophobic ink, which is repelled by the water and only adheres to the emulsion of the image area, is then applied by the inking rollers.\n\nIf this image were transferred directly to paper, it would create a mirror-type image and the paper would become too wet. Instead, the plate rolls against a cylinder covered with a rubber \"blanket\", which squeezes away the water, picks up the ink and transfers it to the paper with uniform pressure. The paper passes between the blanket cylinder and a counter-pressure or impression cylinder and the image is transferred to the paper. Because the image is first transferred, or \"offset\" to the rubber blanket cylinder, this reproduction method is known as \"offset lithography\" or \"offset printing\".\n\nMany innovations and technical refinements have been made in printing processes and presses over the years, including the development of presses with multiple units (each containing one printing plate) that can print multi-color images in one pass on both sides of the sheet, and presses that accommodate continuous rolls (\"webs\") of paper, known as web presses. Another innovation was the continuous dampening system first introduced by Dahlgren, instead of the old method (conventional dampening) which is still used on older presses, using rollers covered with molleton (cloth) that absorbs the water. This increased control of the water flow to the plate and allowed for better ink and water balance. Current dampening systems include a \"delta effect or vario,\" which slows the roller in contact with the plate, thus creating a sweeping movement over the ink image to clean impurities known as \"hickies\".\n\nThe process of lithography printing is illustrated by this simplified diagram. This press is also called an ink pyramid because the ink is transferred through several layers of rollers with different purposes. Fast lithographic 'web' printing presses are commonly used in newspaper production.\n\nThe advent of desktop publishing made it possible for type and images to be modified easily on personal computers for eventual printing by desktop or commercial presses. The development of digital imagesetters enabled print shops to produce negatives for platemaking directly from digital input, skipping the intermediate step of photographing an actual page layout. The development of the digital platesetter during the late 20th century eliminated film negatives altogether by exposing printing plates directly from digital input, a process known as computer to plate printing.\n\nMicrolithography and nanolithography refer specifically to lithographic patterning methods capable of structuring material on a fine scale. Typically, features smaller than 10 micrometers are considered microlithographic, and features smaller than 100 nanometers are considered nanolithographic. Photolithography is one of these methods, often applied to semiconductor device fabrication. Photolithography is also commonly used for fabricating microelectromechanical systems (MEMS) devices. Photolithography generally uses a pre-fabricated photomask or reticle as a master from which the final pattern is derived.\n\nAlthough photolithographic technology is the most commercially advanced form of nanolithography, other techniques are also used. Some, for example electron beam lithography, are capable of much greater patterning resolution (sometimes as small as a few nanometers). Electron beam lithography is also important commercially, primarily for its use in the manufacture of photomasks. Electron beam lithography as it is usually practiced is a form of maskless lithography, in that a mask is not required to generate the final pattern. Instead, the final pattern is created directly from a digital representation on a computer, by controlling an electron beam as it scans across a resist-coated substrate. Electron beam lithography has the disadvantage of being much slower than photolithography.\n\nIn addition to these commercially well-established techniques, a large number of promising microlithographic and nanolithographic technologies exist or are being developed, including nanoimprint lithography, interference lithography, X-ray lithography, extreme ultraviolet lithography, magnetolithography and scanning probe lithography. Some of these new techniques have been used successfully for small-scale commercial and important research applications.\nSurface-charge lithography, in fact Plasma desorption mass spectrometry can be directly patterned on polar dielectric crystals via pyroelectric effect, \nDiffraction lithography.\n\nDuring the first years of the 19th century, lithography had only a limited effect on printmaking, mainly because technical difficulties remained to be overcome. Germany was the main center of production in this period. Godefroy Engelmann, who moved his press from Mulhouse to Paris in 1816, largely succeeded in resolving the technical problems, and during the 1820s lithography was adopted by artists such as Delacroix and Géricault. After early experiments such as \"Specimens of Polyautography\" (1803), which had experimental works by a number of British artists including Benjamin West, Henry Fuseli, James Barry, Thomas Barker of Bath, Thomas Stothard, Henry Richard Greville, Richard Cooper, Henry Singleton, and William Henry Pyne, London also became a center, and some of Géricault's prints were in fact produced there. Goya in Bordeaux produced his last series of prints by lithography—\"The Bulls of Bordeaux\" of 1828. By the mid-century the initial enthusiasm had somewhat diminished in both countries, although the use of lithography was increasingly favored for commercial applications, which included the prints of Daumier, published in newspapers. Rodolphe Bresdin and Jean-François Millet also continued to practice the medium in France, and Adolf Menzel in Germany. In 1862 the publisher Cadart tried to initiate a portfolio of lithographs by various artists, which was not successful but included several prints by Manet. The revival began during the 1870s, especially in France with artists such as Odilon Redon, Henri Fantin-Latour and Degas producing much of their work in this manner. The need for strictly limited editions to maintain the price had now been realized, and the medium became more accepted.\nIn the 1890s, color lithography gained success in part by the emergence of Jules Chéret, known as the \"father of the modern poster\", whose work went on to inspire a new generation of poster designers and painters, most notably Toulouse-Lautrec, and former student of Chéret, Georges de Feure. By 1900 the medium in both color and monotone was an accepted part of printmaking.\n\nDuring the 20th century, a group of artists, including Braque, Calder, Chagall, Dufy, Léger, Matisse, Miró, and Picasso, rediscovered the largely undeveloped artform of lithography thanks to the Mourlot Studios, also known as \"Atelier Mourlot\", a Parisian printshop founded in 1852 by the Mourlot family. The Atelier Mourlot originally specialized in the printing of wallpaper; but it was transformed when the founder's grandson, Fernand Mourlot, invited a number of 20th-century artists to explore the complexities of fine art printing. Mourlot encouraged the painters to work directly on lithographic stones in order to create original artworks that could then be executed under the direction of master printers in small editions. The combination of modern artist and master printer resulted in lithographs that were used as posters to promote the artists' work.\n\nGrant Wood, George Bellows, Alphonse Mucha, Max Kahn, Pablo Picasso, Eleanor Coen, Jasper Johns, David Hockney, Susan Dorothea White and Robert Rauschenberg are a few of the artists who have produced most of their prints in the medium. M. C. Escher is considered a master of lithography, and many of his prints were created using this process. More than other printmaking techniques, printmakers in lithography still largely depend on access to good printers, and the development of the medium has been greatly influenced by when and where these have been established.\n\nAs a special form of lithography, the serilith process is sometimes used. Seriliths are mixed media original prints created in a process in which an artist uses the lithograph and serigraph processes. The separations for both processes are hand-drawn by the artist. The serilith technique is used primarily to create fine art limited print editions.\n\n\n"}
{"id": "18430", "url": "https://en.wikipedia.org/wiki?curid=18430", "title": "Library management", "text": "Library management\n\nLibrary management is a sub-discipline of institutional management that focuses on specific issues faced by libraries and library management professionals. Library management encompasses normal managerial tasks, as well as intellectual freedom and fundraising responsibilities. Issues faced in library management frequently overlap with those faced in managing non-profit organizations.\n\nThe basic functions of library management include, but are not limited to: planning and negotiating the acquisition of materials, Interlibrary Loan (ILL) requests, stacks maintenance, overseeing fee collection, event planning, fundraising, and human resources.\n\nMost libraries that store physical media like books, periodicals, film, and other objects adhere to some derivative of the Dewey Decimal System as their method for tagging, storing, and retrieving materials based on unique identifiers. The use of such systems have caused librarians to develop and leverage common constructs that act as tools for both library professionals and library users alike. These constructs include master catalogs, domain catalogs, indexes, unique identifiers, unique identifier tokens, and artifacts .\n\n\n\n\n\n\n\nAn important aspect of library management is planning and maintaining library facilities. Successful planning is defined as \"active planning that ensures an organization will have the right people in the right place at the right time for right job\" Planning the construction of new libraries or remodeling those that exist is integral since user needs are often changing. To supplement their operating budget, managers often secure funding through donor gifts and fundraising. Many facilities have begun including cafes, Friends of the Library spaces, and even exhibits to help generate additional revenue. These areas should be taken into account when planning for building expansions.\n\nThe site for new construction must be found, then the building must be designed, constructed, and eventually evaluated. Once established, it is important that the building is regularly maintained. This may be completed by delegating tasks to maintenance personnel or by hiring an outside company through bids.\n\nDisaster planning must be taken into account in the library context as well: not only the impact of a disaster on the library, but the library's potential role as a support service just after a disaster.\n\nThe Library Leadership and Management Association (LLAMA) is a division of the American Library Association that provides leaders with webinars, conferences, and a variety of industry publications, in addition to funding through awards and grants. LLAMA membership includes a free subscription to the online quarterly magazine \"Library Leadership & Management\", as well as discounts on other publications and related conferences.\n\nThe \"Journal of Library Administration\" began in 1980 and is currently published by Routledge eight times per year. It is a peer-reviewed academic journal that discusses issues pertaining to library management.\n\n\n"}
{"id": "18432", "url": "https://en.wikipedia.org/wiki?curid=18432", "title": "English longbow", "text": "English longbow\n\nThe English longbow was a powerful medieval type of longbow (a tall bow for archery) about long used by the English and Welsh for hunting and as a weapon in medieval warfare. English use of longbows was effective against the French during the Hundred Years' War, particularly at the start of the war in the battles of Sluys (1340), Crécy (1346), and Poitiers (1356), and perhaps most famously at the Battle of Agincourt (1415). They were less successful after this, with longbowmen having their lines broken at the Battle of Verneuil (1424), and being completely routed at the Battle of Patay (1429) when they were charged before they had set up their defensive position.\n\nThe earliest longbow known, from what is now England, found at Ashcott Heath, Somerset, is dated to 2665 BC, but no longbows survive from the period when the longbow was dominant (c. 1250–1450 AD), probably because bows became weaker, broke and were replaced, rather than being handed down through generations. More than 130 bows survive from the Renaissance period, however. More than 3,500 arrows and 137 whole longbows were recovered from the \"Mary Rose\", a ship of Henry VIII's navy that sank at Portsmouth in 1545.\n\nA longbow must be long enough to allow its user to draw the string to a point on the face or body, and the length therefore varies with the user. In continental Europe it was generally seen as any bow longer than . The Society of Antiquaries of London says it is of in length. Richard Bartelot, of the Royal Artillery Institution, said that the bow was of yew, long, with a arrow. Gaston III, Count of Foix, wrote in 1388 that a longbow should be \"of yew or boxwood, seventy inches [] between the points of attachment for the cord\". Historian Jim Bradbury said they were an average of about 5 feet and 8 inches. All but the last estimate were made before the excavation of the \"Mary Rose\", where bows were found ranging in length from with an average length of .\n\nEstimates for the draw of these bows varies considerably. Before the recovery of the \"Mary Rose\", Count M. Mildmay Stayner, Recorder of the British Long Bow Society, estimated the bows of the Medieval period drew , maximum, and Mr. W.F. Paterson, Chairman of the Society of Archer-Antiquaries, believed the weapon had a supreme draw weight of only . Other sources suggest significantly higher draw weights. The original draw forces of examples from the \"Mary Rose\" are estimated by Robert Hardy at at a draw length; the full range of draw weights was between . The draw length was used because that is the length allowed by the arrows commonly found on the \"Mary Rose\".\n\nA modern longbow's draw is typically or less, and by modern convention measured at . Historically, hunting bows usually had draw weights of , which is enough for all but the very largest game and which most reasonably fit adults can manage with practice. Today, there are few modern longbowmen capable of using bows accurately.\n\nA record of how boys and men trained to use the bows with high draw weights survives from the reign of Henry VII.\nWhat Latimer meant when he describes laying his body into the bow was described thus:\n\nThe preferred material to make the longbow was yew, although ash, elm and other woods were also used. Gerald of Wales speaking of the bows used by the Welsh men of Gwent, says: \"They are made neither of horn, ash nor yew, but of elm; ugly unfinished-looking weapons, but astonishingly stiff, large and strong, and equally capable of use for long or short shooting\". The traditional construction of a longbow consists of drying the yew wood for 1 to 2 years, then slowly working the wood into shape, with the entire process taking up to four years. (This can be done far more quickly by working the wood down when wet, as a thinner piece of wood will dry much faster.) The bow stave is shaped into a D-section. The outer \"back\" of sapwood, approximately flat, follows the natural growth rings; modern bowyers often thin the sapwood, while in the \"Mary Rose\" bows the back of the bow was the natural surface of the wood, only the bark being removed. The inner side (\"belly\") of the bow stave consists of rounded heartwood. The heartwood resists compression and the outer sapwood performs better in tension. This combination in a single piece of wood (a self bow) forms a natural \"laminate\", somewhat similar in effect to the construction of a composite bow. Longbows will last a long time if protected with a water-resistant coating, traditionally of \"wax, resin and fine tallow\".\n\nThe trade of yew wood to England for longbows was such that it depleted the stocks of yew over a huge area. The first documented import of yew bowstaves to England was in 1294. In 1350 there was a serious shortage, and Henry IV of England ordered his royal bowyer to enter private land and cut yew and other woods. In 1470 compulsory practice was renewed, and hazel, ash, and laburnum were specifically allowed for practice bows. Supplies still proved insufficient, until by the Statute of Westminster 1472, every ship coming to an English port had to bring four bowstaves for every tun. Richard III of England increased this to ten for every tun. This stimulated a vast network of extraction and supply, which formed part of royal monopolies in southern Germany and Austria. In 1483, the price of bowstaves rose from two to eight pounds per hundred, and in 1510 the Venetians obtained sixteen pounds per hundred.\n\nIn 1507 the Holy Roman Emperor asked the Duke of Bavaria to stop cutting yew, but the trade was profitable, and in 1532 the royal monopoly was granted for the usual quantity \"if there are that many\". In 1562, the Bavarian government sent a long plea to the Holy Roman Emperor asking him to stop the cutting of yew, and outlining the damage done to the forests by its selective extraction, which broke the canopy and allowed wind to destroy neighbouring trees. In 1568, despite a request from Saxony, no royal monopoly was granted because there was no yew to cut, and the next year Bavaria and Austria similarly failed to produce enough yew to justify a royal monopoly.\n\nForestry records in this area in the 17th century do not mention yew, and it seems that no mature trees were to be had. The English tried to obtain supplies from the Baltic, but at this period bows were being replaced by guns in any case.\n\nBowstrings are made of hemp, flax or silk, and attached to the wood via horn \"nocks\" that fit onto the end of the bow. Modern synthetic materials (often Dacron) are now commonly also used for strings.\n\nA wide variety of arrows were shot from the English longbow. Variations in length, fletchings and heads are all recorded. Perhaps the greatest diversity lies in hunting arrows, with varieties like broad-arrow, wolf-arrow, dog-arrow, Welsh arrow and Scottish arrow being recorded. War arrows were ordered in the thousands for medieval armies and navies, supplied in sheaves normally of 24 arrows. For example, between 1341 and 1359 the English crown is known to have obtained 51,350 sheaves (1,232,400 arrows).\n\nOnly one significant group of arrows, found at the wreck of the \"Mary Rose\", has survived. Over 3500 arrows were found, mainly made of poplar but also of ash, beech and hazel. Analysis of the intact specimens shows their length to vary from , with an average length of . Because of the preservation conditions of the \"Mary Rose\" no arrowheads survived. However, many heads have survived in other places, which has allowed typologies of arrow heads to be produced, the most modern being the Jessop typology. The most common arrowheads in military use were the short bodkin point (Jessop M10) and a small barbed arrow (Jessop M4).\n\nLongbows were very difficult to master because the force required to deliver an arrow through the improving armour of medieval Europe was very high by modern standards. Although the draw weight of a typical English longbow is disputed, it was at least and possibly more than . Considerable practice was required to produce the swift and effective combat shooting required. Skeletons of longbow archers are recognisably affected, with enlarged left arms and often osteophytes on left wrists, left shoulders and right fingers.\n\nIt was the difficulty in using the longbow that led various monarchs of England to issue instructions encouraging their ownership and practice, including the Assize of Arms of 1252 and Edward III of England's declaration of 1363:\n\nIf the people practised archery, it would be that much easier for the king to recruit the proficient longbowmen he needed for his wars. Along with the improving ability of gunfire to penetrate plate armour, it was the long training needed by longbowmen that eventually led to their being replaced by musketeers.\n\nThe range of the medieval weapon is not accurately known, with much depending on both the power of the bow and the type of arrow. It has been suggested that a flight arrow of a professional archer of Edward III's time would reach but the longest mark shot at on the London practice ground of Finsbury Fields in the 16th century was . In 1542, Henry VIII set a minimum practice range for adults using flight arrows of ; ranges below this had to be shot with heavy arrows. Modern experiments broadly concur with these historical ranges. A 667 N (150 lbf) \"Mary Rose\" replica longbow was able to shoot a arrow and a a distance of . In 2012, Joe Gibbs shot a livery arrow with a 170 lbf yew bow. The effective combat range of longbowmen was generally lower than what could be achieved on the practice range as sustained shooting was tiring and the rigors of campaigning would sap soldiers' strength. Writing 30 years after the Mary Rose sank, Barnabe Rich estimated that if 1,000 English archers were mustered then after one week only 100 of them would be able to shoot farther than 200 paces, while 200 would not be able to shoot farther than 180 paces.\n\nIn an early modern test by Saxton Pope, a direct hit from a steel bodkin point penetrated Damascus mail armour.\n\nA 2006 test was made by Matheus Bane using a draw (at 28\") bow, shooting at 10 yards; according to Bane's calculations, this would be approximately equivalent to a bow at 250 yards. Measured against a replica of the thinnest contemporary \"Jack coat\" armour, a 905 grain needle bodkin and a 935 grain curved broadhead penetrated over . (\"Jack coat\" armour could be up to twice as thick as the coat tested; in Bane's opinion such a thick coat would have stopped bodkin arrows but not the cutting force of broadhead arrows.) Against \"high quality riveted maille\", the needle bodkin and curved broadhead penetrated 2.8\". Against a coat of plates, the needle bodkin achieved 0.3\" penetration. The curved broadhead did not penetrate but caused 0.3\" of deformation of the metal. Results against plate armour of \"minimum thickness\" (1.2mm) were similar to the coat of plates, in that the needle bodkin penetrated to a shallow depth, the other arrows not at all. In Bane's view, the plate armour would have kept out all the arrows if thicker or worn with more padding.\n\nOther modern tests described by Bane include those by Williams (which concluded that longbows could \"not\" penetrate mail, but in Bane's view did not use a realistic arrow tip), Robert Hardy's tests (which achieved broadly similar results to Bane), and a \"Primitive Archer\" test which demonstrated that a longbow could penetrate a plate armour breastplate. However, the \"Primitive Archer\" test used a longbow at very short range, generating 160 joules (vs. 73 for Bane and 80 for Williams), so probably not representative of battles of the time.\n\nTests conducted by Mark Stretton examined the effects of heavier war shafts (as opposed to lighter hunting or distance-shooting 'flight arrows'). The quarrel-like 102 gram arrow from a yew 'self bow' (with a draw weight of 144lbs at 32 inches) while travelling at 47.23 metres per second yielded 113.76 joules, more kinetic energy than the lighter broad-heads while achieving 90% of the range. The short, heavy quarrel-form bodkin could penetrate a replica brigandine at up to 40° from perpendicular.\n\nIn 2011, Mike Loades conducted an experiment in which short bodkin arrows were shot at a range of by bows of - powerful bows at less than normal battlefield range. The target was covered in a riveted mail over a fabric armour of deerskin over 24 linen layers. While most arrows went through the mail layer, none fully penetrated the textile armour.\n\nOther research has also concluded that later medieval armour, such as that of the Italian city state mercenary companies, was effective at stopping contemporary arrows.\n\nGerald of Wales commented on the power of the Welsh longbow in the 12th century:\nAgainst massed men in armour, massed longbows were murderously effective on many battlefields.\n\nStrickland and Hardy suggest that \"even at a range of 240 yards heavy war arrows shot from bows of poundages in the mid- to upper range possessed by the Mary Rose bows would have been capable of killing or severely wounding men equipped with armour of wrought iron. Higher-quality armour of steel would have given considerably greater protection, which accords well with the experience of Oxford's men against the elite French vanguard at Poitiers in 1356, and des Ursin's statement that the French knights of the first ranks at Agincourt, which included some of the most important (and thus best-equipped) nobles, remained comparatively unhurt by the English arrows\".\n\nArchery was described by contemporaries as ineffective against plate armour in the Battle of Neville's Cross (1346), the siege of Bergerac (1345), and the Battle of Poitiers (1356); such armour became available to European knights and men at arms of fairly modest means by the late 14th century, though never to all soldiers in any army. Longbowmen were however effective at Poitiers, and this success stimulated changes in armour manufacture partly intended to make armoured men less vulnerable to archery. Nevertheless, at the battle of Agincourt in 1415 and for some decades thereafter, English longbowmen continued to be an effective battlefield force.\n\nFollowing the Battle of Crécy, the longbow did not always prove as effective. For example, at the Battle of Poitiers (1356), the French men-at-arms formed a shieldwall with which Geoffrey le Baker recounts \"‘protecting their bodies with joined shields, [and] turned their faces away from the missiles. So the archers emptied their quivers in vain\".\n\nModern tests and contemporary accounts agree therefore that well-made plate armour could protect against longbows. However this did not necessarily make the longbow ineffective; thousands of longbowmen were deployed in the English victory at Agincourt against plate armoured French knights in 1415. Clifford Rogers has argued that while longbows might not have been able to penetrate steel breastplates at Agincourt they could still penetrate the thinner armour on the limbs. Most of the French knights advanced on foot but, exhausted by walking across wet muddy terrain in heavy armour enduring a \"terrifying hail of arrow shot\", they were overwhelmed in the melee.\n\nLess heavily armoured soldiers were more vulnerable than knights. For example, enemy crossbowmen were forced to retreat at Crécy when deployed without their protecting pavises. Horses were generally less well protected than the knights themselves; shooting the French knights' horses from the side (where they were less well armoured) is described by contemporary accounts of the Battle of Poitiers (1356), and at Agincourt John Keegan has argued that the main effect of the longbow would have been in injuring the horses of the mounted French knights.\n\nA typical military longbow archer would be provided with between 60 and 72 arrows at the time of battle. Most archers would not shoot arrows at maximum rate, as it would exhaust even the most experienced man. \"With the heaviest bows [a modern war bow archer] does not like to try for more than six a minute.\" Not only do the arms and shoulder muscles tire from the exertion, but the fingers holding the bowstring become strained; therefore, actual rates of shooting in combat would vary considerably. Ranged volleys at the beginning of the battle would differ markedly from the closer, aimed shots as the battle progressed and the enemy neared. On the battlefield English archers stored their arrows stabbed upright into the ground at their feet, reducing the time it took to nock, draw and loose.\n\nArrows were not unlimited, so archers and their commanders took every effort to ration their use to the situation at hand. Nonetheless, resupply during battle was available. Young boys were often employed to run additional arrows to longbow archers while in their positions on the battlefield. \"The longbow was the machine gun of the Middle Ages: accurate, deadly, possessed of a long range and rapid rate of fire, the flight of its missiles was likened to a storm\".\n\nIn tests against a moving target simulating a galloping knight it took some approximately seven seconds to draw, aim and loose an armour-piercing heavy arrow using a replica war bow. It was found that in the seven seconds between the first and second shots the target advanced 70 yards and that the second shot occurred at such close range that, if it was a realistic contest, running away was the only option.\n\nA Tudor English author expects eight shots from a longbow in the same time as five from a musket. He points out that the musket also shoots at a flatter trajectory, so is more likely to hit its target and its shot is likely to be more damaging in the event of a hit. The advantage of early firearms lay in the lower training requirements, the opportunity to take cover while shooting, flatter trajectory, and greater penetration.\n\nThe only way to remove an arrow cleanly was to tie a piece of cloth soaked in water to the end of it and push it through the victim's wound and out the other side — this was extremely painful. Specialised tools have existed since ancient times: Diocles (successor of Hippocrates) devised the graphiscos, a form of cannula with hooks, and the duck-billed forceps (allegedly invented by Heras of Cappadocia) employed during the medieval period to extract arrows from places where bone prevented the arrow being pushed through.\n\nHenry, Prince of Wales, later Henry V, was wounded in the face by an arrow at the Battle of Shrewsbury (1403). The royal physician John Bradmore had such a tool made, which consisted of a pair of smooth tongs. Once carefully inserted into the socket of the arrowhead, the tongs screwed apart till they gripped its walls and allowed the head to be extracted from the wound. Prior to the extraction, the hole made by the arrow shaft had been widened by inserting larger and larger dowels of elder pith wrapped in linen down the entry wound. The dowels were soaked in honey, now known to have antiseptic properties. The wound was then dressed with a poultice of barley and honey mixed in turpentine (pre-dating Ambroise Paré but whose therapeutic use of turpentine was inspired by Roman medical texts that may have been familiar to Bradmore). After 20 days the wound was free of infection.\n\nThe word may have been coined to distinguish the longbow from the crossbow. The first recorded use of the term \"longbow\", as distinct from simply 'bow', is possibly in a 1386 administrative document which refers in Latin to \"arcus vocati longbowes\", \"bows called 'longbows'\", though unfortunately the reading of the last word in the original document is not certain. A 1444 will proved in York bequeaths \"a sadil, alle my longe bowis, a bedde\".\n\nThe origins of the English longbow are disputed. While it is hard to assess the significance of military archery in pre-Norman Conquest Anglo-Saxon warfare, it is clear that archery played a prominent role under the Normans, as the story of the Battle of Hastings shows. Their Anglo-Norman descendants also made use of military archery, as exemplified by their victory at the Battle of the Standard in 1138. During the Anglo-Norman invasions of Wales, Welsh bowmen took a heavy toll of the invaders and Welsh archers would feature in English armies from this point on. However, historians dispute whether this archery used a different kind of bow to the later English Longbow. Traditionally it has been argued that prior to the beginning of the 14th century, the weapon was a self bow between four and five feet in length, known since the 19th century as the shortbow. This weapon, drawn to the chest rather than the ear, was much weaker. However, in 1985, Jim Bradbury reclassified this weapon as the \"ordinary wooden bow\", reserving the term shortbow for short composite bows and arguing that longbows were a developed form of this ordinary bow. Strickland and Hardy in 2005 took this argument further, suggesting that the shortbow was a myth and all early English bows were a form of longbow. In 2011, Clifford Rogers forcefully restated the traditional case based upon a variety of evidence, including a large scale iconographic survey. In 2012, Richard Wadge added to the debate with an extensive survey of record, iconographic and archaeological evidence, concluding that longbows co-existed with shorter self-wood bows in England in the period between the Norman conquest and the reign of Edward III, but that powerful longbows shooting heavy arrows were a rarity until the later 13th century. Whether or not there was a technological revolution at the end of the 13th century therefore remains in dispute. What is agreed, however, is that the English longbow as an effective weapon system evolved in the late 13th and early 14th centuries.\n\nThe longbow decided many medieval battles fought by the English and Welsh, the most significant of which were the Battle of Crécy (1346) and the Battle of Agincourt (1415), during the Hundred Years' War and followed earlier successes, notably at the Battle of Falkirk (1298) and the Battle of Halidon Hill (1333) during the Wars of Scottish Independence. They were less successful after this, with longbowmen having their lines broken at the Battle of Verneuil (1424), and being routed at the Battle of Patay (1429) when they were charged before they had set up their defenses.\n\nThe longbow was also used against the English by their Welsh neighbours. The Welsh used the longbow mostly in a different manner than the English. In many early period English campaigns, the Welsh used the longbow in ambushes, often at point blank range that allowed their missiles to penetrate armour and generally do a lot of damage.\n\nAlthough longbows were much faster and more accurate than the black-powder weapons which replaced them, longbowmen always took a long time to train because of the years of practice necessary before a war longbow could be used effectively (examples of longbows from the \"Mary Rose\" typically had draws greater than ). In an era in which warfare was usually seasonal, and non-noble soldiers spent part of the year working at farms, the year-round training required for the effective use of the longbow was a challenge. A standing army was an expensive proposition to a medieval ruler. Mainland European armies seldom trained a significant longbow corps. Due to their specialized training, English longbowmen were sought as mercenaries in other European countries, most notably in the Italian city-states and in Spain.\nThe White Company, comprising men-at-arms and longbowmen and commanded by Sir John Hawkwood, is the best known English Free Company of the 14th century. The powerful Hungarian king, Louis the Great, is an example of someone who used longbowmen in his Italian campaigns.\n\nLongbows remained in use until around the 16th century, when advances in firearms made gunpowder weapons a significant factor in warfare and such units as arquebusiers and grenadiers began appearing. Despite this, the English Crown made numerous efforts to continue to promote archery practice by banning other sports and fining people for not possessing bows. Indeed, just before the English Civil War, a pamphlet by William Neade entitled \"The Double-Armed Man\" advocated that soldiers be trained in both the longbow and pike; although this advice was followed only by a few town militias.\n\nThe Battle of Flodden (1513) was \"a landmark in the history of archery, as the last battle on English soil to be fought with the longbow as the principal weapon...\" The last recorded use of bows in an English battle may have been a skirmish at Bridgnorth, in October 1642, during the Civil War, when an impromptu town militia, armed with bows, proved effective against un-armoured musketeers. The Battle of Tippermuir (1644), in Scotland, may have been the last battle involving the longbow. Longbowmen remained a feature of the Royalist Army, but were not used by the Roundheads.\n\nLongbows have been in continuous production and use for sport and for hunting to the present day, but since 1642 they have been a minority interest, and very few have had the high draw weights of the medieval weapons. Other differences include the use of a stiffened non-bending centre section, rather than a continuous bend.\n\nSerious military interest in the longbow faded after the seventeenth century but occasionally schemes to resurrect its military use were proposed. Benjamin Franklin was a proponent in the 1770s; the Honourable Artillery Company had an archer company between 1784 and 1794; and a man named Richard Mason wrote a book proposing the arming of militia with pike and longbow in 1798. Donald Featherstone also records a Lt. Col. Richard Lee of 44th Foot advocated the military use of the longbow in 1792. There is a record of the use of the longbow in action as late as WWII, when Jack Churchill is credited with a longbow kill in France in 1940. The weapon was certainly considered for use by Commandos during the war but it is not known whether it was used in action.\n\nThe idea that there was a standard formation for English longbow armies was argued by Alfred Byrne in his influential work on the battles of the Hundred Years' War, \"The Crecy War\". This view was challenged by Jim Bradbury in his book \"The Medieval Archer\" and more modern works are more ready to accept a variety of formations.\n\nIn summary, however, the usual English deployment in the 14th and 15th centuries was as follows:\n\nIn the 16th century, these formations evolved in line with new technologies and techniques from the continent. Formations with a central core of pikes and bills were flanked by companies of \"shot\" made up of a mixture of archers and arquebusiers, sometimes with a skirmish screen of archers and arquebusiers in front.\n\nMore than 3,500 arrows and 137 whole longbows were recovered from the \"Mary Rose\", a ship of Henry VIII's navy that capsized and sank at Portsmouth in 1545. It is an important source for the history of the longbow, as the bows, archery implements and the skeletons of archers have been preserved. The bows range in length from with an average length of . The majority of the arrows were made of poplar, others were made of beech, ash and hazel. Draw lengths of the arrows varied between with the majority having a draw length of . The head would add 5–15 cm depending on type, though some 2–4.5 cm must be allowed for the insertion of the shaft into the socket.\n\nThe longbows on the \"Mary Rose\" were in excellent finished condition. There were enough bows to test some to destruction which resulted in draw forces of 450 N (100 lbf) on average. However, analysis of the wood indicated that they had degraded significantly in the seawater and mud, which had weakened their draw forces. Replicas were made and when tested had draw forces of from 445 N to 823 N (100 to 185 lbf).\n\nIn 1980, before the finds from the \"Mary Rose\", Robert E. Kaiser published a paper stating that there were five known surviving longbows:\n\n\nThe importance of the longbow in English culture can be seen in the legends of Robin Hood, which increasingly depicted him as a master archer, and also in the \"Song of the Bow\", a poem from \"The White Company\" by Sir Arthur Conan Doyle.\n\nDuring the reign of Henry III the Assize of Arms of 1252 required that all \"citizens, burgesses, free tenants, villeins and others from 15 to 60 years of age\" should be armed. The poorest of them were expected to have a halberd and a knife, and a bow if they owned land worth more than £2. This made it easier for the King to raise an army, but also meant that the bow was a weapon commonly used by rebels during the Peasants' Revolt. From the time that the yeoman class of England became proficient with the longbow, the nobility in England had to be careful not to push them into open rebellion.\n\nIt has been conjectured that yew trees were commonly planted in English churchyards to have readily available longbow wood.\n\n\n\n\n\n\n\n"}
{"id": "18433", "url": "https://en.wikipedia.org/wiki?curid=18433", "title": "Lee Marvin", "text": "Lee Marvin\n\nLee Marvin (February 19, 1924 – August 29, 1987) was an American film and television actor.\n\nKnown for his distinctive voice and premature white hair, Marvin initially appeared in supporting roles, mostly villains, soldiers, and other hardboiled characters. A prominent television role was that of Detective Lieutenant Frank Ballinger in the NBC crime series \"M Squad\" (1957–1960).\n\nOne of Marvin's most notable film projects was \"Cat Ballou\" (1965), a comedy Western in which he played dual roles. For portraying both gunfighter Kid Shelleen and criminal Tim Strawn, he won the Academy Award for Best Actor, along with a BAFTA Award, a Golden Globe Award, an NBR Award, and the Silver Bear for Best Actor.\n\nMarvin was born in New York City. He was the son of two working professionals, Lamont Waltman Marvin, an advertising executive and later the head of the New York and New England Apple Institute, and Courtenay Washington (née Davidge), a well respected fashion and beauty writer/editor.\n\nAs with his elder brother, Robert, he was named in honor of Confederate General Robert E. Lee, who was his first cousin, four times removed. His father was a direct descendant of Matthew Marvin Sr., who emigrated from Great Bentley, Essex, England, in 1635, and helped found Hartford, Connecticut.\n\nMarvin studied violin when he was young. As a teenager, Marvin \"spent weekends and spare time hunting deer, puma, wild turkey, and bobwhite in the wilds of the then-uncharted Everglades\".\n\nHe attended Manumit School, a Christian socialist boarding school in Pawling, New York, during the late 1930s, and later attended St. Leo College Preparatory School, a Catholic school in St. Leo, Florida, after being expelled from several other schools for bad behavior.\n\nMarvin left school at 18 to enlist in the United States Marine Corps Reserve on August 12, 1942. He served with the 4th Marine Division in the Pacific Theater during World War II. While serving as a member of \"I\" Company, 3rd Battalion, 24th Marines, 4th Marine Division, he was wounded in action on June 18, 1944, during the assault on Mount Tapochau in the Battle of Saipan, during which most of his company were casualties. He was hit by machine gun fire, which severed his sciatic nerve, and then was hit again in the foot by a sniper. After over a year of medical treatment in naval hospitals, Marvin was given a medical discharge with the rank of private first class (he had been a corporal years earlier but had been demoted after causing trouble) in 1945 at Philadelphia.\n\nMarvin's military awards include: the Purple Heart Medal, the Presidential Unit Citation, the American Campaign Medal, the Asiatic-Pacific Campaign Medal, and the World War II Victory Medal, Combat Action Ribbon.\n\nAfter the war, while working as a plumber's assistant at a local community theatre in upstate New York, Marvin was asked to replace an actor who had fallen ill during rehearsals. He caught the acting bug and got a job with the company at $7 a week. He moved to Greenwich Village and used the GI Bill to study at the American Theatre Wing.\n\nHe appeared on stage in a production of \"Uniform of Flesh\", an adaptation of \"Billy Budd\" (1949). It was done at the Experimental Theatre, where a few months later Marvin also appeared in \"The Nineteenth Hole of Europe\" (1949).\n\nMarvin began appearing on television shows like \"Escape\", \"The Big Story\", and \"Treasury Men in Action\". \n\nHe made it to Broadway with a small role in a production of \"Uniform of Flesh\", now called \"Billy Budd\" in February 1951.\nMarvin's film debut was in \"You're in the Navy Now\" (1951), directed by Henry Hathaway, a film which also marked the debuts of Charles Bronson and Jack Warden. This required some filming in Hollywood. Marvin decided to stay there.\n\nHe had a similar small part in \"Teresa\" 1951) directed by Fred Zinnemann. As a decorated combat veteran, Marvin was a natural in war dramas, where he frequently assisted the director and other actors in realistically portraying infantry movement, arranging costumes, and the use of firearms. \n\nHe guest starred on episodes of \"Fireside Theatre\", \"Suspense\" and \"Rebound\". Hathaway used him again on \"Diplomatic Courier\" (1952) and he could be seen in \"Down Among the Sheltering Palms\" (1952), directed by Edmund Goulding, \"We're Not Married!\" (1952), also for Goulding, \"The Duel at Silver Creek\" (1952) directed by Don Siegel, and \"Hangman's Knot\" (1952), directed by Roy Huggins.\n\nHe guest starred on \"Biff Baker, U.S.A.\" and \"Dragnet\", and had a decent role in a feature with \"Eight Iron Men\" (1952), a war film produced by Stanley Kramer (Marvin's role had been played on Broadway by Burt Lancaster).\n\nHe was a sergeant in \"Seminole\" (1953), a Western directed by Budd Boetticher, and was a corporal in \"The Glory Brigade\" (1953), a Korean War film.\n\nMarvin guest starred in \"The Doctor\", \"The Revlon Mirror Theater \", \"Suspense\" again and \"The Motorola Television Hour\". \n\nHe was now in much demand for Westerns: \"The Stranger Wore a Gun\" (1953) with Randolph Scott, and \"Gun Fury\" (1953) with Rock Hudson.\n\nMarvin received much acclaim for his portrayal as villains in two films: \"The Big Heat\" (1953) where he played Gloria Grahame's vicious boyfriend, directed by Fritz Lang; and \"The Wild One\" (1953) opposite Marlon Brando (Marvin's gang in the film was called \"The Beetles\"), produced by Kramer.\n\nHe continued on TV shows such as \"The Plymouth Playhouse\" and \"The Pepsi-Cola Playhouse\". He had support roles in \"Gorilla at Large\" (1954) and had a notable small role as smart-aleck sailor Meatball in \"The Caine Mutiny\" (1954), produced by Kramer.\n\nMarvin was in \"The Raid\" (1954), \"Center Stage\", \"Medic\" and \"TV Reader's Digest\".\n\nHe had an excellent part as Hector, the small-town hood in \"Bad Day at Black Rock\" (1955) with Spencer Tracy. Also in 1955, he played a conflicted, brutal bank-robber in \"Violent Saturday\". A latter-day critic wrote of the character, \"Marvin brings a multi-faceted complexity to the role and gives a great example of the early promise that launched his long and successful career.\"\n\nMarvin played Robert Mitchum's friend in \"Not as a Stranger\" (1955), a medical drama produced by Kramer. He had good support roles in \"A Life in the Balance\" (1955) (he was third billed), and \"Pete Kelly's Blues\" (1955) and appeared on TV in \"Jane Wyman Presents The Fireside Theatre\" and \"Studio One in Hollywood.\"\n\nMarvin was in \"I Died a Thousand Times\" (1955) with Jack Palance, \"Shack Out on 101\" (1955), \"Kraft Theatre\", and \"Front Row Center.\"\nMarvin was the villain in \"7 Men from Now\" (1956) with Randolph Scott directed by Boetticher. He was second billed to Palance in \"Attack\" (1956) directed by Robert Aldrich.\n\nMarvin had good roles in \"Pillars of the Sky\" (1956) with Jeff Chandler, \"The Rack\" (1956) with Paul Newman, \"Raintree County\" (1956) and \"The Missouri Traveler\" (1958). He also guest starred on \"Climax!\" (several times), \"Studio 57\", \"The United States Steel Hour\" and \"Schlitz Playhouse\".\n\nMarvin finally got to be a leading man in 100 episodes as Chicago cop Frank Ballinger in the successful 1957–1960 television series \"M Squad\". One critic described the show as \"a hyped-up, violent \"Dragnet\" ... with a hard-as-nails Marvin\" playing a tough police lieutenant. Marvin received the role after guest-starring in a memorable \"Dragnet\" episode as a serial killer.\n\nWhen the series ended Marvin appeared on \"Westinghouse Desilu Playhouse\", \"Sunday Showcase\", \"The Barbara Stanwyck Show\", \"The Americans\", \"Wagon Train\", \"Checkmate\", \"General Electric Theater, Alcoa Premiere\", \"The Investigators\", \"Route 66\" (he was injured during a fight scene), Ben Casey, \"Bonanza\", \"The Untouchables\" (several times), \"The Virginian\", \"The Twilight Zone\" (\"The Grave\", \"Steel\") and \"The Dick Powell Theatre\".\n\nMarvin returned to features with a prominent role in \"The Comancheros\" (1961) starring John Wayne. He played in two more films with Wayne, both directed by John Ford: \"The Man Who Shot Liberty Valance\" (1962), and \"Donovan's Reef\" (1963). As the vicious Liberty Valance, Marvin played his first title role and held his own with two of the screen's biggest stars (Wayne and James Stewart).\n\nHe continued to guest star on shows like \"Combat!\", \"Dr. Kildare\" and \"The Great Adventure\". He did \"The Case Against Paul Ryker\" for \"Kraft Suspense Theatre.\"\n\nFor director Don Siegel, Marvin appeared in \"The Killers\" (1964) playing an efficient professional assassin alongside Clu Gulager. \"The Killers\" was also the first film in which Marvin received top billing.\n\nHe guest starred on \"Bob Hope Presents the Chrysler Theatre\".\nMarvin finally became a star for his comic role in the offbeat Western \"Cat Ballou\" starring Jane Fonda. This was a surprise hit and Marvin won the 1965 Academy Award for Best Actor. He also won the 1965 Silver Bear for Best Actor at the 15th Berlin International Film Festival.\n\nPlaying alongside Vivien Leigh and Simone Signoret, Marvin won the 1966 National Board of Review Award for male actors for his role in \"Ship of Fools\" (1965) directed by Kramer.\n\nMarvin next performed in the hit Western \"The Professionals\" (1966), in which he played the leader of a small band of skilled mercenaries (Burt Lancaster, Robert Ryan, and Woody Strode) rescuing a kidnap victim (Claudia Cardinale) shortly after the Mexican Revolution. \n\nHe followed that film with the hugely successful World War II epic \"The Dirty Dozen\" (1967) in which top-billed Marvin again portrayed an intrepid commander of a colorful group (future stars John Cassavetes, Charles Bronson, Telly Savalas, Jim Brown, and Donald Sutherland) performing an almost impossible mission. Robert Aldrich directed. \n\nIn the wake of these two films and after having received an Oscar, Marvin was a huge star, given enormous control over his next film \"Point Blank\". In \"Point Blank\", an influential film for director John Boorman, he portrayed a hard-nosed criminal bent on revenge. Marvin, who had selected Boorman himself for the director's slot, had a central role in the film's development, plot line, and staging.\n\nIn 1968, Marvin also appeared in another Boorman film, the critically acclaimed but commercially unsuccessful World War II character study \"Hell in the Pacific\", also starring famed Japanese actor Toshiro Mifune. John Boorman recounted his work with Lee Marvin on these two films and Marvin's influence on his career in the 1998 documentary \"\". \"Paul Ryker\", which Marvin shot for TV in 1963 was released theatrically as \"Sergeant Ryker\".\n\nMarvin was originally cast as Pike Bishop (later played by William Holden) in \"The Wild Bunch\" (1969), but fell out with director Sam Peckinpah and pulled out to star in the Western musical \"Paint Your Wagon\" (1969), in which he was top-billed over a singing Clint Eastwood. Despite his limited singing ability, he had a hit song with \"Wand'rin' Star\". By this time, he was getting paid a million dollars per film, $200,000 less than top star Paul Newman was making at the time, yet he was ambivalent about the film business, even with its financial rewards:\n\nYou spend the first forty years of your life trying to get in this business, and the next forty years trying to get out. And then when you're making the bread, who needs it?\nMarvin had a much greater variety of roles in the 1970s, with fewer 'bad-guy' roles than in earlier years. His 1970s films included \"Monte Walsh\" (1970), a Western with Palance and Jeanne Moreau; the violent \"Prime Cut\" (1972) with Gene Hackman; \"Pocket Money\" (1972) with Paul Newman, for Stuart Rosenberg; \"Emperor of the North\" (1973) opposite Ernest Borgnine for Aldrich; as Hickey in \"The Iceman Cometh\" (1973) with Fredric March and Robert Ryan, for John Frankenheimer; \"The Spikes Gang\" (1974) with Noah Beery Jr. for Richard Fleischer; \"The Klansman\" (1974) with Richard Burton; \"Shout at the Devil\" (1976), a World War One adventure with Roger Moore, directed by Peter Hunt; \"The Great Scout and Cathouse Thursday\" (1976), a comic Western with Oliver Reed; and \"Avalanche Express\" (1978), a Cold War thriller with Robert Shaw who died during production. None of these films were big box office hits.\n\nMarvin was offered the role of Quint in \"Jaws\" (1975) but declined, stating \"What would I tell my fishing friends who'd see me come off a hero against a dummy shark?\".\nMarvin's last big role was in Samuel Fuller's \"The Big Red One\" (1980), a war film based on Fuller's own war experiences. \n\nHis remaining films were \"Death Hunt\" (1981), a Canadian action film with Charles Bronson, directed by Hunt; \"Gorky Park\" (1983) with William Hurt; and \"Dog Day\" (1984), shot in France.\n\nFor TV he did \"\" (1985; a sequel with Marvin, Ernest Borgnine, and Richard Jaeckel picking up where they had left off despite being 18 years older).\n\nHis final appearance was in \"The Delta Force\" (1986) with Chuck Norris, playing a role turned down by Charles Bronson.\n\nMarvin was a Democrat who opposed the Vietnam War. He publicly endorsed John F. Kennedy in the 1960 presidential election.\n\nLee married Betty Ebeling in February 1951 and together they had four children. Married 16 years, they divorced in 1967. Ebeling and he had a son, Christopher Lamont (1952–2013), and three daughters: Courtenay Lee (b. 1954), Cynthia Louise (b. 1956), and Claudia Leslie (1958–2012).\n\nMarvin married Pamela Feeley in October 1970. She had four children with three previous husbands, they had no children together. They were married until his death.\n\nIn 1971, Marvin was sued by Michelle Triola, his live-in girlfriend from 1965 to 1970, who legally changed her surname to \"Marvin\". Although the couple never married, she sought financial compensation similar to that available to spouses under California's alimony and community property laws. Triola claimed Marvin made her pregnant three times and paid for two abortions, while one pregnancy ended in miscarriage. She claimed the second abortion left her unable to bear children. The result was the landmark \"palimony\" case, \"Marvin v. Marvin\", 18 Cal. 3d 660 (1976).\n\nIn 1979, Marvin was ordered to pay $104,000 to Triola for \"rehabilitation purposes\", but the court denied her community property claim for one-half of the $3.6 million which Marvin had earned during their six years of cohabitation – distinguishing nonmarital relationship contracts from marriage, with community property rights only attaching to the latter by operation of law. Rights equivalent to community property only apply in nonmarital relationship contracts when the parties expressly, whether orally or in writing, contract for such rights to operate between them. In August 1981, the California Court of Appeal found that no such contract existed between them and nullified the award she had received. Michelle Triola died of lung cancer on October 30, 2009, having been with actor Dick Van Dyke since 1976.\n\nLater there was controversy after Marvin characterized the trial as a \"circus\", saying \"everyone was lying, even I lied\". There were official comments about possibly charging Marvin with perjury, but no charges were filed.\n\nThis case was used as fodder for a mock debate skit on \"Saturday Night Live\" called \"Point Counterpoint\", and on \"The Tonight Show Starring Johnny Carson\" as a skit with Carson as Adam, and Betty White as Eve.\n\nIn December 1986, Marvin was hospitalized for more than two weeks because of a condition related to coccidioidomycosis. He went into respiratory distress and was administered steroids to help his breathing. He had major intestinal ruptures as a result, and underwent a colectomy. Marvin died of a heart attack on August 29, 1987, aged 63. He was buried with full military honors at Arlington National Cemetery.\n\nMarvin's appearances on television included\n\"Suspense\" (1 episode, 1950),\n\"Rebound\",\n\"M Squad\",\n\"Climax!\",\n\"Biff Baker, U.S.A.\",\n\"Dragnet\",\n\"The Tonight Show Starring Johnny Carson\",\n\"The Ford Show Starring Tennessee Ernie Ford\",\n\"General Electric Theater\",\n\"The Americans\",\n\"The Investigators\",\n\"The Barbara Stanwyck Show\",\n\"Route 66\",\n\"The Untouchables\",\n\"Checkmate\",\n\"The Dick Powell Show\",\n\"Combat!\",\n\"The Twilight Zone\",\n\"Kraft Suspense Theatre\",\n\"Dr. Kildare\",\n\"Wagon Train\",\n\"Bonanza\",\nPerry Mason (The Case of the Angry Astronaut),\n\"The Virginian\"\nand \"The Muppet Show\".\n\n\n"}
{"id": "18434", "url": "https://en.wikipedia.org/wiki?curid=18434", "title": "Lead Belly", "text": "Lead Belly\n\nHuddie William Ledbetter (January 20, 1888 – December 6, 1949) was an American folk and blues musician notable for his strong vocals, virtuosity on the twelve-string guitar, and the folk standards he introduced. He is best known as Lead Belly. Though many releases credit him as \"Leadbelly\", he himself wrote it as \"Lead Belly\", which is also the spelling on his tombstone and the spelling used by the Lead Belly Foundation.\n\nLead Belly usually played a twelve-string guitar, but he also played the piano, mandolin, harmonica, violin, and \"windjammer\" (diatonic accordion). In some of his recordings, he sang while clapping his hands or stomping his foot.\n\nLead Belly's songs covered a wide range of genres and topics including gospel music; blues about women, liquor, prison life, and racism; and folk songs about cowboys, prison, work, sailors, cattle herding, and dancing. He also wrote songs about people in the news, such as Franklin D. Roosevelt, Adolf Hitler, Jean Harlow, Jack Johnson, the Scottsboro Boys and Howard Hughes. Lead Belly was inducted into the Rock and Roll Hall of Fame in 1988 and the Louisiana Music Hall of Fame in 2008.\n\nLead Belly was born Huddie William Ledbetter to Sally and Wesley Ledbetter on a plantation near Mooringsport, Louisiana, on January 20, 1888. The 1900 United States Census lists \"Hudy Ledbetter\" as 12 years old, born January 1888, and the 1910 and 1930 censuses also give his age as corresponding to a birth in 1888. The 1940 census lists his age as 51, with information supplied by wife Martha. However, in April 1942, when Ledbetter filled out his World War II draft registration, he gave his birth date as January 23, 1889, and his birthplace as Freeport, Louisiana (\"Shreveport\"). His grave marker bears the date given on his draft registration.\n\nLedbetter was the younger of two children born to Wesley Ledbetter and Sallie Brown. The pronunciation of his name is often purported to be \"HYEW-dee\" or \"HUGH-dee\". Leadbelly, himself, can be heard pronouncing his name correctly as \"HUH-dee\" on the track \"Boll Weevil,\" from the Smithsonian Folkways album \"Lead Belly Sings for Children.\" His parents had cohabited for several years, but they legally married on February 26, 1888. When Huddie was five years old, the family settled in Bowie County, Texas.\n\nThe 1910 census of Harrison County, Texas, shows \"Hudy\" Ledbetter living next door to his parents with his first wife, Aletha \"Lethe\" Henderson. Aletha is registered as age 19 and married one year. Others say she was 15 when they married in 1908. It was in Texas that Ledbetter received his first instrument, an accordion, from his uncle Terrell. By his early twenties, having fathered at least two children, Ledbetter left home to make his living as a guitarist and occasional laborer. When Lead Belly was released from his last prison sentence, the United States was deep in the Great Depression, and jobs were very scarce. In September 1934, in need of regular work in order to avoid cancellation of his release from prison, Lead Belly asked John Lomax to take him on as a driver. For three months, he assisted the 67-year-old in his folk song collecting around the South (Alan Lomax was ill and did not accompany his father on this trip).\n\nBy 1903, Huddie was already a \"musicianer\", a singer and guitarist of some note. He performed for nearby Shreveport audiences in St. Paul's Bottoms, a notorious red-light district there. He began to develop his own style of music after exposure to various musical influences on Shreveport's Fannin Street, a row of saloons, brothels, and dance halls in the Bottoms, now referred to as Ledbetter Heights. While in prison, Lead Belly may have first heard the traditional prison song \"Midnight Special\".\nHe was \"discovered\" there three years later during a visit by folklorists John Lomax and his son Alan Lomax.\n\nDeeply impressed by Ledbetter's vibrant tenor and extensive repertoire, the Lomaxes recorded him in 1933 on portable aluminum disc recording equipment for the Library of Congress. They returned with new and better equipment in July 1934, recording hundreds of his songs. On August 1, Ledbetter was released after having again served nearly all of his minimum sentence, following a petition the Lomaxes had taken to Louisiana Governor Oscar K. Allen at his urgent request. It was on the other side of a recording of his signature song, \"Goodnight Irene.\"\nA prison official later wrote to John Lomax denying that Ledbetter's singing had anything to do with his release from Angola (state prison records confirm he was eligible for early release due to good behavior). However, both Ledbetter and the Lomaxes believed that the record they had taken to the governor had hastened his release from prison.\n\nIn December 1934, Lead Belly participated in a \"smoker\" (group sing) at a Modern Language Association meeting at Bryn Mawr College in Pennsylvania, where the senior Lomax had a prior lecturing engagement. He was written up in the press as a convict who had sung his way out of prison. On New Year's Day, 1935, the pair arrived in New York City, where Lomax was scheduled to meet with his publisher, Macmillan, about a new collection of folk songs. The newspapers were eager to write about the \"singing convict,\" and \"Time\" magazine made one of its first \"March of Time\" newsreels about him. Lead Belly attained fame (although not fortune).\nThe following week, he began recording for the American Record Corporation, but these recordings achieved little commercial success. He recorded over 40 sides for ARC (intended to be released on their Banner, Melotone, Oriole, Perfect, and Romeo labels and their short-lived Paramount series), but only five sides were actually issued. Part of the reason for the poor sales may have been that ARC released only his blues songs rather than the folk songs for which he would later become better known. Lead Belly continued to struggle financially. Like many performers, what income he made during his career would come from touring, not from record sales.\n\nIn February 1935, he married his girlfriend, Martha Promise, who came North from Louisiana to join him.\n\nThe month of February was spent recording his repertoire and those of other African Americans and interviews about his life with Alan Lomax for their forthcoming book, \"Negro Folk Songs As Sung by Lead Belly\" (1936). Concert appearances were slow to materialize. In March 1935, Lead Belly accompanied John Lomax on a previously scheduled two-week lecture tour of colleges and universities in the Northeast, culminating at Harvard.\nAt the end of the month, John Lomax decided he could no longer work with Lead Belly and gave him and Martha money to go back to Louisiana by bus. He gave Martha the money her husband had earned during three months of performing, but in installments, on the pretext Lead Belly would spend it all on drinking if given a lump sum. From Louisiana, Lead Belly successfully sued Lomax for both the full amount and release from his management contract. The quarrel was bitter, with hard feelings on both sides. Curiously, in the midst of the legal wrangling, Lead Belly wrote to Lomax proposing they team up again, but it was not to be. Further, the book about Lead Belly published by the Lomaxes in the fall of the following year proved a commercial failure.\n\nIn January 1936, Lead Belly returned to New York on his own, without John Lomax, in an attempted comeback. He performed twice a day at Harlem's Apollo Theater during the Easter season in a live dramatic recreation of the \"March of Time\" newsreel (itself a recreation) about his prison encounter with John Lomax, where he had worn stripes, though by this time he was no longer associated with Lomax.\n\n\"Life\" magazine ran a three-page article titled \"Lead Belly: Bad Nigger Makes Good Minstrel\" in its issue of April 19, 1937. It included a full-page, color (rare in those days) picture of him sitting on grain sacks playing his guitar and singing. Also included was a striking picture of Martha Promise (identified in the article as his manager); photos showing Lead Belly's hands playing the guitar (with the caption \"these hands once killed a man\"); Texas Governor Pat M. Neff; and the \"ramshackle\" Texas State Penitentiary. The article attributes both of his pardons to his singing of his petitions to the governors, who were so moved that they pardoned him. The text of the article ends with \"he... may well be on the brink of a new and prosperous period.\"\n\nLead Belly failed to stir the enthusiasm of Harlem audiences. Instead, he attained success playing at concerts and benefits for an audience of leftist folk music aficionados. He developed his own style of singing and explaining his repertoire in the context of Southern black culture having learned from his participation in Lomax's college lectures. He was especially successful with his repertoire of children's game songs (as a younger man in Louisiana he had sung regularly at children's birthday parties in the black community). He was written about as a heroic figure by the black novelist Richard Wright, then a member of the Communist Party, in the columns of the \"Daily Worker,\" of which Wright was the Harlem editor. The two men became personal friends, though some say Lead Belly himself was apolitical and, if anything, was a supporter of Wendell Willkie, the centrist Republican candidate for President, for whom he wrote a campaign song. However, he also wrote the song \"Bourgeois Blues\", which has radical or left-wing lyrics.\n\nAlan Lomax, then 24, took him under his wing and helped raise money for his legal expenses, dropping out of graduate school to do so. After his release (in 1940–41), Lead Belly appeared as a regular on Alan Lomax and Nicholas Ray's groundbreaking CBS radio show \"Back Where I Come From\", broadcast nationwide. He also appeared in nightclubs with Josh White, becoming a fixture in New York City's surging folk music scene and befriending the likes of Sonny Terry, Brownie McGhee, Woody Guthrie, and a young Pete Seeger, all fellow performers on \"Back Where I Come From\". During the first half of the decade, he recorded for RCA, the Library of Congress, and Moe Asch (future founder of Folkways Records) and in 1944 went to California, where he recorded strong sessions for Capitol Records. He lodged with a studio guitar player on Merrywood Drive in Laurel Canyon.\nLead Belly was the first American country blues musician to achieve success in Europe.\n\nIn 1949, Lead Belly had a regular radio show, \"Folk Songs of America\", broadcast on station WNYC in New York, on Henrietta Yurchenco's show on Sunday nights. Later in the year he began his first European tour with a trip to France, but fell ill before its completion and was diagnosed with amyotrophic lateral sclerosis (ALS), or Lou Gehrig's disease (a motor neuron disease). His final concert was at the University of Texas at Austin in a tribute to his former mentor, John Lomax, who had died the previous year. Martha also performed at that concert, singing spirituals with her husband.\n\nLead Belly died later that year in New York City and was buried in the Shiloh Baptist Church cemetery, in Mooringsport, Louisiana, west of Blanchard, in Caddo Parish. He is honored with a statue across from the Caddo Parish Courthouse, in Shreveport.\n\nLead Belly was imprisoned multiple times beginning in 1915 when he was convicted of carrying a pistol and sentenced to time on the Harrison County chain gang. He later escaped and found work in nearby Bowie County under the assumed name of Walter Boyd. Later, in January 1918, he was imprisoned at the Imperial Farm (now Central Unit) in Sugar Land, Texas, after killing one of his relatives, Will Stafford, in a fight over a woman. During his second prison term, another inmate stabbed him in the neck (leaving him with a fearsome scar he subsequently covered with a bandana); Ledbetter nearly killed his attacker with his own knife. In 1925 he was pardoned and released after writing a song to Governor Pat Morris Neff seeking his freedom, having served the minimum seven years of a 7-to-35-year sentence. Combined with his good behavior, which included entertaining the guards and fellow prisoners, his appeal to Neff's strong religious beliefs proved sufficient. It was a testament to his persuasive powers, as Neff had run for governor on a pledge not to issue pardons (the only recourse for prisoners, since in most Southern prisons there was no provision for parole). According to Charles K. Wolfe and Kip Lornell in their book \"The Life and Legend of Leadbelly\" (1999), Neff had regularly brought guests to the prison on Sunday picnics to hear Ledbetter perform. In 1930, Ledbetter was sentenced to Louisiana's Angola Prison Farm after a summary trial for attempted homicide for stabbing a white man in a fight. In 1939, Lead Belly served his final jail term for assault after stabbing a man in a fight in Manhattan.\n\nThere are several conflicting stories about how Ledbetter acquired the nickname \"Lead Belly\", but he probably acquired it while in prison. Some claim his fellow inmates called him \"Lead Belly\" as a play on his family name and his physical toughness. Others say he earned the name after being wounded in the stomach with buckshot. Another theory is that the name refers to his ability to drink moonshine, the homemade liquor that Southern farmers, black and white, made to supplement their incomes. Blues singer Big Bill Broonzy thought it came from a supposed tendency to lie about as if \"with a stomach weighted down by lead\" in the shade when the chain gang was supposed to be working. Yet another theory is that it may be a corruption of his last name pronounced with a Southern accent. Whatever its origin, he adopted the nickname as a pseudonym while performing.\n\nLead Belly styled himself \"King of the Twelve-String Guitar,\" and despite his use of other instruments like the accordion, the most enduring image of Lead Belly as a performer is wielding his unusually large Stella twelve-string. This guitar had a slightly longer scale length than a standard guitar, increasing the tension on the instrument, which, given the added tension of the six extra strings, meant that a trapeze-style tailpiece helped resist bridge lifting. It had slotted tuners and ladder bracing.\n\nLead Belly played with finger picks much of the time, using a thumb pick to provide a walking bass line and occasionally to strum. This technique, combined with low tunings and heavy strings, gives many of his recordings a piano-like sound. Lead Belly's tunings are debated by both modern and contemporary musicians and blues enthusiasts alike exacerbated by the lack of film footage of his performing rendering chord decoding difficult but it seems to be a down-tuned variant of standard tuning; it is likely that he tuned his guitar strings relative to one another, so that the actual notes shifted as the strings wore. Lead Belly's playing style was popularized by Pete Seeger, who adopted the twelve-string guitar in the 1950s and released an instructional LP and book using Lead Belly as an exemplar of technique.\n\nIn some of the recordings in which Lead Belly accompanied himself, he would make an unusual type of grunt between his verses, best described as \"Haah!\"; \"Looky Looky Yonder,\" \"Take This Hammer,\" \"Linin' Track\" and \"Julie Ann Johnson\" feature this unusual vocalization. In \"Take This Hammer,\" Lead Belly explained, \"Every time the men say, 'Haah,' the hammer falls. The hammer rings, and we swing, and we sing.\" The \"haah\" sound can be heard in work chants sung by Southern railroad section workers, \"gandy dancers,\" in which it was used to coordinate work crews as they laid and maintained tracks.\n\nIn 1976, a biopic entitled \"Leadbelly\" was released, directed by Gordon Parks and featuring Roger E. Mosley as Lead Belly.\n\nKurt Cobain promoted the legacy of Lead Belly, and some modern rock audiences often owe their familiarity with Lead Belly to Nirvana's performance of \"Where Did You Sleep Last Night\" on a televised concert later released as \"MTV Unplugged in New York\". Singer-guitarist Kurt Cobain refers to his attempt to convince David Geffen to purchase Lead Belly's guitar for him in an interval before the song is played (connecting the song with Lead Belly in a way that is more tangible than the liner notes where Lead Belly appears on other albums). In his notebooks, Cobain listed Lead Belly's \"Last Session Vol. 1\" as one of the 50 albums most influential in the formation of Nirvana's sound. It was included in \"NME's\" \"The 100 Greatest Albums You've Never Heard list\".\n\nInfluenced by the sinking of the \"Titanic\" in April 1912, Ledbetter wrote the song \"The Titanic\", his first composed on the twelve-string guitar, which later became his signature instrument. Initially played when performing with Blind Lemon Jefferson (1893–1929) in and around Dallas, Texas, the song is about champion African-American boxer Jack Johnson's being denied passage on the \"Titanic\". Johnson had in fact been denied passage on a ship for being black, but it was not the \"Titanic\". Still, the song includes the lyric \"Jack Johnson tried to get on board. The Captain, he says, 'I ain't haulin' no coal!' Fare thee, \"Titanic\"! Fare thee well!\" Ledbetter later noted he had to leave out this passage when playing in front of white audiences.\n\n\n\nThe Library of Congress recordings, made by John and Alan Lomax from 1934 to 1943, were released in a six-volume series by Rounder Records:\n\n\nThe Folkways recordings, done for Moses Asch from 1941 to 1947, were released in a three-volume series by Smithsonian Folkways:\n\n\nSmithsonian Folkways has released several other collections of his recordings:\n\n\n\n\n\n"}
{"id": "18435", "url": "https://en.wikipedia.org/wiki?curid=18435", "title": "Lower Saxony", "text": "Lower Saxony\n\nLower Saxony ( (); ) is a German state (\"Land\") situated in northwestern Germany. It is the second-largest state by land area, with , and fourth-largest in population (7.9 million) among the 16 \"Länder\" federated as the Federal Republic of Germany. In rural areas, Northern Low Saxon (a dialect of Low German) and Saterland Frisian (a variety of the Frisian language) are still spoken, but the number of speakers is declining.\n\nLower Saxony borders on (from north and clockwise) the North Sea, the states of Schleswig-Holstein, Hamburg, Mecklenburg-Vorpommern, Brandenburg, Saxony-Anhalt, Thuringia, Hesse and North Rhine-Westphalia, and the Netherlands. Furthermore, the state of Bremen forms two enclaves within Lower Saxony, one being the city of Bremen, the other, its seaport city of Bremerhaven. In fact, Lower Saxony borders more neighbours than any other single \"Bundesland.\" The state's principal cities include the state capital Hanover, Braunschweig (Brunswick), Lüneburg, Osnabrück, Oldenburg, Hildesheim, Wolfenbüttel, Wolfsburg, and Göttingen.\n\nThe northwestern area of Lower Saxony, which lies on the coast of the North Sea, is called East Frisia and the seven East Frisian Islands offshore are popular with tourists. In the extreme west of Lower Saxony is the Emsland, a traditionally poor and sparsely populated area, once dominated by inaccessible swamps. The northern half of Lower Saxony, also known as the North German Plains, is almost invariably flat except for the gentle hills around the Bremen geestland. Towards the south and southwest lie the northern parts of the German Central Uplands: the Weser Uplands and the Harz mountains. Between these two lie the Lower Saxon Hills, a range of low ridges. Thus, Lower Saxony is the only \"Bundesland\" that encompasses both maritime and mountainous areas.\n\nLower Saxony's major cities and economic centres are mainly situated in its central and southern parts, namely Hanover, Braunschweig, Osnabrück, Wolfsburg, Salzgitter, Hildesheim, and Göttingen. Oldenburg, near the northwestern coastline, is another economic centre. The region in the northeast is called the Lüneburg Heath (\"Lüneburger Heide\"), the largest heathland area of Germany and in medieval times wealthy due to salt mining and salt trade, as well as to a lesser degree the exploitation of its peat bogs until about the 1960s. To the north, the Elbe River separates Lower Saxony from Hamburg, Schleswig-Holstein, Mecklenburg-Vorpommern, and Brandenburg. The banks just south of the Elbe are known as \"Altes Land\" (Old Country). Due to its gentle local climate and fertile soil, it is the state's largest area of fruit farming, its chief produce being apples.\n\nMost of the state's territory was part of the historic Kingdom of Hanover; the state of Lower Saxony has adopted the coat of arms and other symbols of the former kingdom. It was created by the merger of the State of Hanover with three smaller states on 1 November 1946.\n\nLower Saxony has a natural boundary in the north in the North Sea and the lower and middle reaches of the River Elbe, although parts of the city of Hamburg lie south of the Elbe. The state and city of Bremen is an enclave entirely surrounded by Lower Saxony. The Bremen/Oldenburg Metropolitan Region is a cooperative body for the enclave area. To the southeast, the state border runs through the Harz, low mountains that are part of the German Central Uplands. The northeast and west of the state, which form roughly three-quarters of its land area, belong to the North German Plain, while the south is in the Lower Saxon Hills, including the Weser Uplands, Leine Uplands, Schaumburg Land, Brunswick Land, Untereichsfeld, Elm, and Lappwald. In northeast, Lower Saxony is Lüneburg Heath. The heath is dominated by the poor, sandy soils of the geest, whilst in the central east and southeast in the loess \"börde\" zone, productive soils with high natural fertility occur. Under these conditions—with loam and sand-containing soils—the land is well-developed agriculturally. In the west lie the County of Bentheim, Osnabrück Land, Emsland, Oldenburg Land, Ammerland, Oldenburg Münsterland, and on the coast East Frisia.\n\nThe state is dominated by several large rivers running northwards through the state: the Ems, Weser, Aller, and Elbe.\n\nThe highest mountain in Lower Saxony is the Wurmberg (971 m) in the Harz. For other significant elevations see: List of mountains and hills in Lower Saxony. Most of the mountains and hills are found in the southeastern part of the state. The lowest point in the state, at about 2.5 m below sea level, is a depression near Freepsum in East Frisia.\n\nThe state's economy, population, and infrastructure are centred on the cities and towns of Hanover, Stadthagen, Celle, Braunschweig, Wolfsburg, Hildesheim, and Salzgitter. Together with Göttingen in southern Lower Saxony, they form the core of the Hannover–Braunschweig–Göttingen–Wolfsburg Metropolitan Region.\n\nLower Saxony has clear regional divisions that manifest themselves geographically, as well as historically and culturally. In the regions that used to be independent, especially the heartlands of the former states of Brunswick, Hanover, Oldenburg and Schaumburg-Lippe, a marked local regional awareness exists. By contrast, the areas surrounding the Hanseatic cities of Bremen and Hamburg are much more oriented towards those centres.\n\nSometimes, overlaps and transition areas happen between the various regions of Lower Saxony. Several of the regions listed here are part of other, larger regions, that are also included in the list.\nJust under 20% of the land area of Lower Saxony is designated as nature parks, i.e.: Dümmer, Elbhöhen-Wendland, Elm-Lappwald, Harz, Lüneburger Heide, Münden, Terra.vita, Solling-Vogler, Lake Steinhude, Südheide, Weser Uplands, Wildeshausen Geest, Bourtanger Moor-Bargerveen.\nLower Saxony falls climatically into the north temperate zone of central Europe that is affected by prevailing Westerlies and is located in a transition zone between the maritime climate of Western Europe and the continental climate of Eastern Europe. This transition is clearly noticeable within the state: whilst the northwest experiences an Atlantic (North Sea coastal) to Sub-Atlantic climate, with comparatively low variations in temperature during the course of the year and a surplus water budget, the climate towards the southeast is increasingly affected by the Continent. This is clearly shown by greater temperature variations between the summer and winter halves of the year and in lower and more variable amounts of precipitation across the year. This sub-continental effect is most sharply seen in the Wendland, in the Weser Uplands (Hamelin to Göttingen) and in the area of Helmstedt. The highest levels of precipitation are experienced in the Harz because the Lower Saxon part forms the windward side of this mountain range against which orographic rain falls. The average annual temperature is 8 °C (7.5 °C in the Altes Land and 8.5 °C in the district of Cloppenburg).\n\nLower Saxony is divided into 37 districts (\"Landkreise\" or simply \"Kreise\"):\n\nFurthermore, there are eight urban districts and two cities with special status:\n¹ \"following the \"Göttingen Law\" of 1 January 1964, the town of Göttingen is incorporated into the rural district (\"Landkreis\") of Göttingen, but is treated as an urban district unless other rules apply. On 1 November 2016 the districts of Osterode and Göttingen were merged under the name Göttingen, not influencing the city's special status.\"\n² \"following the \"Law on the region of Hanover\", Hanover merged with the district of Hanover to form the Hanover Region, which has been treated mostly as a rural district, but Hanover is treated as an urban district since 1 November 2001 unless other rules apply.\"\n\nThe name of Saxony derives from that of the Germanic tribe of the Saxons. Before the late medieval period, there was a single Duchy of Saxony. The term \"Lower Saxony\" was used after the dissolution of the stem duchy in the late 13th century to disambiguate the parts of the former duchy ruled by the House of Welf from the Electorate of Saxony on one hand, and from the Duchy of Westphalia on the other.\n\nThe name and coat of arms of the present state go back to the Germanic tribe of Saxons. During the Migration Period some of the Saxon peoples left their homeland in Holstein about the 3rd century and pushed southwards over the Elbe, where they expanded into the sparsely populated regions in the rest of the lowlands, in the present-day Northwest Germany and the northeastern part of what is now the Netherlands. From about the 7th century the Saxons had occupied a settlement area that roughly corresponds to the present state of Lower Saxony, of Westphalia and a number of areas to the east, for example, in what is now west and north Saxony-Anhalt. The land of the Saxons was divided into about 60 \"Gaue\". The Frisians had not moved into this region; for centuries they preserved their independence in the most northwesterly region of the present-day Lower Saxon territory. The original language of the folk in the area of Old Saxony was West Low German, one of the varieties of language in the Low German dialect group.\n\nThe establishment of permanent boundaries between what later became Lower Saxony and Westphalia began in the 12th century. In 1260, in a treaty between the Archbishopric of Cologne and the Duchy of Brunswick-Lüneburg the lands claimed by the two territories were separated from each other. The border ran along the Weser to a point north of Nienburg. The northern part of the Weser-Ems region was placed under the rule of Brunswick-Lüneburg.\n\nThe word \"Niedersachsen\" was first used before 1300 in a Dutch rhyming chronicle (\"Reimchronik\"). From the 14th century it referred to the Duchy of Saxe-Lauenburg (as opposed to Saxe-Wittenberg). On the creation of the imperial circles in 1500, a Lower Saxon Circle was distinguished from a Lower Rhenish–Westphalian Circle. The latter included the following territories that, in whole or in part, belong today to the state of Lower Saxony: the Bishopric of Osnabrück, the Bishopric of Münster, the County of Bentheim, the County of Hoya, the Principality of East Frisia, the Principality of Verden, the County of Diepholz, the County of Oldenburg, the County of Schaumburg and the County of Spiegelberg. At the same time a distinction was made with the eastern part of the old Saxon lands from the central German principalities later called Upper Saxony for dynastic reasons. (see also → Electorate of Saxony, History of Saxony).\n\nThe close historical links between the domains of the Lower Saxon Circle now in modern Lower Saxony survived for centuries especially from a dynastic point of view. The majority of historic territories whose land now lies within Lower Saxony were sub-principalities of the medieval, Welf estates of the Duchy of Brunswick-Lüneburg. All the Welf princes called themselves dukes \"of Brunswick and Lüneburg\" despite often ruling parts of a duchy that was forever being divided and reunited as various Welf lines multiplied or died out.\n\nOver the course of time two great principalities survived east of the Weser: the Kingdom of Hanover and the Duchy of Brunswick (after 1866 Hanover became a Prussian province; after 1919 Brunswick became a free state). Historically a close tie exists between the royal house of Hanover (Electorate of Brunswick-Lüneburg) to the United Kingdom of Great Britain and Northern Ireland as a result of their personal union in the 18th century.\n\nWest of the River Hunte a \"de-Westphalianising process\" began in 1815: After the Congress of Vienna the territories of the later administrative regions (\"Regierungsbezirke\") of Osnabrück and Aurich transferred to the Kingdom of Hanover. Until 1946, the Grand Duchy of Oldenburg and the Principality of Schaumburg-Lippe retained their stately authority. Nevertheless, the entire Weser-Ems region (including the city of Bremen) were grouped in 1920 into a Lower Saxon Constituency Association (\"Wahlkreisverband IX (Niedersachsen)\"). This indicates that at that time the western administrations of the Prussian Province of Hanover and the state of Oldenburg were perceived as being \"Lower Saxon\".\n\nThe forerunners of today's state of Lower Saxony were lands that were geographically and, to some extent, institutionally interrelated from very early on. The County of Schaumburg (not to be confused with the Principality of Schaumburg-Lippe) around the towns of Rinteln and Hessisch Oldendorf did indeed belong to the Prussian province of Hesse-Nassau until 1932, a province that also included large parts of the present state of Hesse, including the cities of Kassel, Wiesbaden and Frankfurt am Main; but in 1932, however, the County of Schaumburg became part of the Prussian Province of Hanover. Also before 1945, namely 1937, the city of Cuxhaven has been fully integrated into the Prussian Province of Hanover by the Greater Hamburg Act, so that in 1946, when the state of Lower Saxony was founded, only four states needed to be merged. With the exception of Bremen and the areas that were ceded to the Soviet Occupation Zone in 1945, all those areas allocated to the new state of Lower Saxony in 1946, had already been merged into the \"Constituency Association of Lower Saxony\" in 1920.\n\nIn a lecture on 14 September 2007, Dietmar von Reeken described the emergence of a \"Lower Saxony consciousness\" in the 19th century, the geographical basis of which was used to invent a territorial construct: the resulting local heritage societies (\"Heimatvereine\") and their associated magazines routinely used the terms \"Lower Saxony\" or \"Lower Saxon\" in their names. At the end of the 1920s in the context of discussions about a reform of the Reich, and promoted by the expanding local heritage movement (\"Heimatbewegung\"), a 25-year conflict started between \"Lower Saxony\" and \"Westphalia\". The supporters of this dispute were administrative officials and politicians, but regionally focussed scientists of various disciplines were supposed to have fuelled the arguments. In the 1930s, a real Lower Saxony did not yet exist, but there was a plethora of institutions that would have called themselves \"Lower Saxon\". The motives and arguments in the disputes between \"Lower Saxony\" and \"Westphalia\" were very similar on both sides: economic interests, political aims, cultural interests and historical aspects.\n\nAfter the Second World War most of Northwest Germany lay within the British Zone of Occupation. On 23 August 1946, the British Military Government issued Ordinance No. 46 \"\"Concerning the dissolution of the provinces of the former state of Prussia in the British Zone and their reconstitution as independent states\"\", which initially established the State of Hanover on the territory of the former Prussian Province of Hanover. Its minister president, Hinrich Wilhelm Kopf, had already suggested in June 1945 the formation of a state of Lower Saxony, that was to include the largest possible region in the middle of the British Zone. In addition to the regions that actually became Lower Saxony subsequently, Kopf asked, in a memorandum dated April 1946, for the inclusion of the former Prussian district of Minden-Ravensberg (i.e. the Westphalian city of Bielefeld as well as the Westphalian districts of Minden, Lübbecke, Bielefeld, Herford and Halle), the district of Tecklenburg and the state of Lippe. Kopf's plan was ultimately based on a draft for the reform of the German Empire from the late 1920s by Georg Schnath and Kurt Brüning. The strong Welf connotations of this draft, according to Thomas Vogtherr, did not simplify the development of a Lower Saxon identity after 1946.\n\nAn alternative model, proposed by politicians in Oldenburg and Brunswick, envisaged the foundation of the independent state of \"Weser-Ems\", that would be formed from the state of Oldenburg, the Hanseatic City of Bremen and the administrative regions of Aurich and Osnabrück. Several representatives of the state of Oldenburg even demanded the inclusion of the Hanoverian districts of Diepholz, Syke, Osterholz-Scharmbeck and Wesermünde in the proposed state of \"Weser-Ems\". Likewise an enlarged State of Brunswick was proposed in the southeast to include the \"Regierungsbezirk\" of Hildesheim and the district of Gifhorn. Had this plan come to fruition, the territory of the present Lower Saxony would have consisted of three states of roughly equal size.\n\nThe district council of Vechta protested on 12 June 1946 against being incorporated into the metropolitan area of Hanover (\"Großraum Hannover\"). If the State of Oldenburg was to be dissolved, Vechta District would much rather be included in the Westphalian region. Particularly in the districts where there was a political Catholicism the notion was widespread, that Oldenburg Münsterland and the \"Regierungsbezirk\" of Osnabrück should be part of a newly formed State of Westphalia.\n\nSince the foundation of the states of North Rhine-Westphalia and Hanover on 23 August 1946 the northern and eastern border of North Rhine-Westphalia has largely been identical with that of the Prussian Province of Westphalia. Only the Free State of Lippe was not incorporated into North Rhine-Westphalia until January 1947. With that the majority of the regions left of the Upper Weser became North Rhine-Westphalian.\n\nIn the end, at the meeting of the Zone Advisory Board on 20 September 1946, Kopf's proposal with regard to the division of the British occupation zone into three large states proved to be capable of gaining a majority. Because this division of their occupation zone into relatively large states also met the interests of the British, on 8 November 1946 Regulation No. 55 of the British military government was issued, by which the State of Lower Saxony with its capital Hanover were founded, backdated to 1 November 1946. The state was formed by a merger of the Free States of Brunswick, of Oldenburg and of Schaumburg-Lippe with the previously formed State of Hanover. But there were exceptions:\n\nThe demands of Dutch politicians that the Netherlands should be given the German regions east of the Dutch-German border as war reparations, were roundly rejected at the London Conference of 26 March 1949. In fact only about 1.3 km² of West Lower Saxony was transferred to the Netherlands, in 1949.\n\n\"→ see main article Dutch annexation of German territory after World War II\"\n\nThe first Lower Saxon parliament or \"Landtag\" met on 9 December 1946. It was not elected; rather it was established by the British Occupation Administration (a so-called \"appointed parliament\"). That same day the parliament elected the Social Democrat, Hinrich Wilhelm Kopf, the former Hanoverian president (\"Regierungspräsident\") as their first minister president. Kopf led a five-party coalition, whose basic task was to rebuild a state afflicted by the war's rigours. Kopf's cabinet had to organise an improvement of food supplies and the reconstruction of the cities and towns destroyed by Allied air raids during the war years. Hinrich Wilhelm Kopf remained – interrupted by the time in office of Heinrich Hellwege (1955–1959) – as the head of government in Lower Saxony until 1961.\n\nThe greatest problem facing the first state government in the immediate post-war years was the challenge of integrating hundreds of thousands of refugees from Germany's former territories in the east (such as Silesia and East Prussia), which had been annexed by Poland and the Soviet Union. Lower Saxony was at the western end of the direct escape route from East Prussia and had the longest border with the Soviet Zone. On 3 October 1950 Lower Saxony took over the sponsorship of the very large number of refugees from Silesia. In 1950 there was still a shortage of 730,000 homes according to official figures.\n\nDuring the period when Germany was divided, the Lower Saxon border crossing at Helmstedt found itself on the main transport artery to West Berlin and, from 1945 to 1990 was the busiest European border crossing point.\n\nOf economic significance for the state was the \"Volkswagen\" concern, that restarted the production of civilian vehicles in 1945, initially under British management, and in 1949 transferred into the ownership of the newly founded country of West Germany and state of Lower Saxony. Overall, Lower Saxony, with its large tracts of rural countryside and few urban centres, was one of the industrially weaker regions of the federal republic for a long time. In 1960, 20% of the working population worked on the land. In the rest of the federal territory the figure was just 14%. Even in economically prosperous times the jobless totals in Lower Saxony are constantly higher than the federal average.\n\nIn 1961 Georg Diederichs took office as the minister president of Lower Saxony as the successor to Hinrich Wilhelm Kopf. He was replaced in 1970 by Alfred Kubel. The arguments about the Gorleben Nuclear Waste Repository, that began during the time in office of minister president Ernst Albrecht (1976–1990), have played an important role in state and federal politics since the end of the 1970s.\n\nIn 1990 Gerhard Schröder entered the office of minister president. On 1 June 1993 the new Lower Saxon constitution entered force, replacing the \"Provisional Lower Saxon Constitution\" of 1951. It enables referenda and plebiscites and establishes environmental protection as a fundamental state principle.\n\nThe former Hanoverian Amt Neuhaus with its parishes of Dellien, Haar, Kaarßen, Neuhaus (Elbe), Stapel, Sückau, Sumte and Tripkau as well as the villages of Neu Bleckede, Neu Wendischthun and Stiepelse in the parish of Teldau and the historic Hanoverian region in the forest district of Bohldamm in the parish of Garlitz transferred with effect from 30 June 1993 from Mecklenburg-Vorpommern to Lower Saxony (Lüneburg district). From these parishes the new municipality of Amt Neuhaus was created on 1 October 1993.\n\nIn 1998 Gerhard Glogowski succeeded Gerhard Schröder who became Federal Chancellor. Because he had been linked with various scandals in his home city of Brunswick, he resigned in 1999 and was replaced by Sigmar Gabriel.\n\nFrom 2003 to his election as Federal President in 2010 Christian Wulff was minister president in Lower Saxony. The Osnabrücker headed a CDU-led coalition with the FDP as does his successor, David McAllister. After the elections on 20 January 2013 McAllister was deselected.\n\nBetween 1946 and 2004, the state's districts and independent towns were grouped into eight regions, with different status for the two regions (\"Verwaltungsbezirke\") comprising the formerly free states of Brunswick and Oldenburg. In 1978 the regions were merged into four governorates (\"Regierungsbezirke\"): Since 2004 the Bezirksregierungen (regional governments) have been broken up again.\n\n1946–1978:\n1978–2004:\n\nOn 1 January 2005 the four administrative regions or governorates (\"Regierungsbezirke\"), into which Lower Saxony had been hitherto divided, were dissolved. These were the governorates of Braunschweig, Hanover, Lüneburg and Weser-Ems.\n\nAt the end of 2014, there were almost 571.000 non-German citizens in Lower Saxony. The following table illustrates the largest minority groups in Lower Saxony:\n\n\n\n\nThe 2011 census stated that a majority of the population were Christians (71.93%); 51.48% of the total population were member of the Evangelical Church in Germany, 18.34% were Catholics, 2.11% were member of other Christian denominations, 2.27% were member of other religions. 25.8% have no denomination. Even there is a high level of official belonging to a Christian denomination, the people - especially in the cities - are highly secular in faith and behavior.\n\nAs of 2016, the Evangelical Church in Germany was the faith of 44.9% of the population. It is organised in the five Landeskirchen named Evangelical Lutheran State Church in Brunswick (comprising the former Free State of Brunswick), Evangelical Lutheran Church of Hanover (comprising the former Province of Hanover), Evangelical Lutheran Church in Oldenburg (comprising the former Free State of Oldenburg), Evangelical Lutheran Church of Schaumburg-Lippe (comprising the former Free State of Schaumburg-Lippe), and Evangelical Reformed Church (covering all the state).\n\nTogether, these member churches of the Evangelical Church in Germany gather a substantial part of the Protestant population in Germany.\n\nThe Catholic Church was the faith of 17.1% of the population in 2016. It is organised in the three dioceses of Osnabrück (western part of the state), Münster (comprising the former Free State of Oldenburg) and Hildesheim (northern and eastern part of the state). The Catholic faith is mainly concentrated to the regions of Oldenburger Münsterland, region of Osnabrück, region of Hildesheim and in the Western Eichsfeld.\n38.0% of the Low Saxons were irreligious or adhere to other religions. Judaism, Islam and Buddhism are minority faiths.\n\nAgriculture, strongly weighted towards the livestock sector, has always been a very important economic factor in the state. The north and northwest of Lower Saxony are mainly made up of coarse sandy soil that makes crop farming difficult and therefore grassland and cattle farming are more prevalent in those areas. Lower Saxony is home, in 2017, to one in five of Germany's cattle, one in three of the country's pigs, and 50% of its hens. Wheat, potatoes, rye, and oats are among the state's present-day arable crops. Towards the south and southeast, extensive loess layers in the soil left behind by the last ice age allow high-yield crop farming. One of the principal crops there is sugar beet. Consequently, the Land has a big food industry, mainly organized in small and medium-sized enterprises (SME). Big players are Deutsches Milchkontor and PHW Group (biggest German poultry farmer and producer).\n\nMining has also been an important source of income in Lower Saxony for centuries. Silver ore became a foundation of notable economic prosperity in the Harz Mountains as early as the 12th century, while iron mining in the Salzgitter area and salt mining in various areas of the state became another important economic backbone. Although overall yields are comparatively low, Lower Saxony is also an important supplier of crude oil in the European Union. Mineral products still mined today include iron and lignite.\n\nRadioactive waste is frequently transported in the area to the city of Salzgitter, for the deep geological repository Schacht Konrad and between Schacht Asse II in the Wolfenbüttel district and Lindwedel and Höfer.\n\nManufacturing is another large part of the regional economy. Despite decades of gradual downsizing and restructuring, the car maker Volkswagen with its five production plants within the state's borders still remains the single biggest private-sector employer, its world headquarters in Wolfsburg. Due to the Volkswagen Law, which has recently been ruled illegal by the European Union's high court, the state of Lower Saxony is still the second largest shareholder, owning 20.3% of the company. Thanks to the importance of car manufacturing in Lower Saxony, a thriving supply industry is centred around its regional focal points. Other mainstays of the Lower Saxon industrial sector include aviation (the region of Stade is called CFK-Valley), shipbuilding (e.g. Meyer Werft), biotechnology, and steel. Medicine plays a major role: Hanover and Göttingen have two large University Medical Schools and hospitals and Otto Bock in Duderstadt is the word leader in prosthetics.\n\nThe service sector has gained importance following the demise of manufacturing in the 1970s and 1980s. Important branches today are the tourism industry with TUI AG in Hanover, one of Europe's largest travel companies, as well as trade and telecommunication. Hanover is one of Germany's main location of insurance companies e. g. Talanx, Hannover Re .\n\nIn October 2018 the unemployment rate stood at 5.0% and was marginally higher than the national average.\nSince 1948, politics in the state has been dominated by the rightist Christian Democratic Union (CDU) and the leftist Social Democratic Party. Lower Saxony was one of the origins of the German environmentalist movement in reaction to the state government's support for underground nuclear waste disposal. This led to the formation of the German Green Party in 1980.\n\nThe former Minister-President, Christian Wulff, led a coalition of his CDU with the Free Democratic Party between 2003 and 2010. In the 2008 election, the ruling CDU held on to its position as the leading party in the state, despite losing votes and seats. The CDU's coalition with the Free Democratic Party retained its majority although it was cut from 29 to 10. The election also saw the entry into the state parliament for the first time of the leftist The Left party. On 1 July 2010 David McAllister was elected Minister-President.\n\nAfter the state election on 20 January 2013, Stephan Weil of the Social Democrats was elected as the new Minister-President. He governed in coalition with the Greens.\n\nAfter the state election in September 2017, Stephan Weil of the Social Democrats was again elected as the new Minister-President. He governs in coalition with the CDU.\n\nThe state of Lower Saxony was formed after World War II by merging the former states of Hanover, Oldenburg, Brunswick and Schaumburg-Lippe. Hanover, a former kingdom, is by far the largest of these contributors by area and population and has been a province of Prussia since 1866. The city of Hanover is the largest and capital city of Lower Saxony.\n\nThe constitution states that Lower Saxony be a free, republican, democratic, social and environmentally sustainable state inside the Federal Republic of Germany; universal human rights, peace and justice are preassigned guidelines of society, and the human rights and civil liberties proclaimed by the constitution of the Federal Republic are genuine constituents of the constitution of Lower Saxony. Each citizen is entitled to education and there is universal compulsory school attendance.\n\nAll government authority is to be sanctioned by the will of the people, which expresses itself via elections and plebiscites. The legislative assembly is a unicameral parliament elected for terms of five years. The composition of the parliament obeys to the principle of proportional representation of the participating political parties, but it is also ensured that each constituency delegates one directly elected representative. If a party wins more constituency delegates than their statewide share among the parties would determine, it can keep all these constituency delegates.\n\nThe governor of the state (prime minister) and his ministers are elected by the parliament. As there is a system of five political parties in Germany and so also in Lower Saxony, it is usually the case that two or more parties negotiate for a common political agenda and a commonly determined composition of government where the party with the biggest share of the electorate fills the seat of the governor.\n\nThe states of the Federal Republic of Germany, and so Lower Saxony, have legislative responsibility and power mainly reduced to the policy fields of the school system, higher education, culture and media and police, whereas the more important policy fields like economic and social policies, foreign policy etc. are a prerogative of the federal government. Hence the probably most important function of the federal states is their representation in the Federal Council (Bundesrat), where their approval on many crucial federal policy fields, including the tax system, is required for laws to become enacted.\n\nThe Minister-President heads the state government, acting as a head of state (even if the federated states have the status of a state, they don't established the office of a head of state but merged the functions with the head of the executive branch) as well as the government leader. They are elected by the Landtag of Lower Saxony.\n\nThe coat of arms shows a white horse (Saxon Steed) on red ground, which is an old symbol of the Saxon people. Legend has it that the horse was a symbol of the Saxon leader Widukind. But this one should have been black. The colour has been changed by Christian baptism of Widukind into white. White and red are the other colours (despite to Gold and black) of the Holy Roman Empire symbolizing Christ as the Saviour, who is still shown with a white flag with a red cross.\n\n\n"}
{"id": "18439", "url": "https://en.wikipedia.org/wiki?curid=18439", "title": "LTJ Bukem", "text": "LTJ Bukem\n\nLTJ Bukem (born Danny Williamson September 20, 1967) is a British drum and bass musician, producer and DJ. He and his record label Good Looking are most associated with the jazzy, atmospheric side of drum and bass music.\n\nHe was trained as a classical pianist and discovered jazz fusion in his teenage years, having a jazz funk band at one stage. However, by the late 1980s he decided to become a DJ, and gained fame in the rave scene of the early 1990s. As a producer, he released a series of drum and bass tracks such as \"Logical Progression\" (1991), \"Demon's Theme\" (1992), \"Atlantis\" and \"Music\" (1993). His most notable release was the track \"Horizons\" (1995) which attained considerable popularity.\n\nHe then dipped in visibility as a producer, with his work running the London club night \"Speed\" and his record label Good Looking Records coming to the fore. A series of compilations entitled \"Logical Progression\" highlighted a jazz and ambient influenced side of drum and bass. The style became widely known as intelligent drum and bass, although Bukem himself was opposed to the moniker, unhappy with the implication that other styles of jungle were not intelligent. Bukem also explored the downtempo end of electronic lounge music, with sister label Cookin' and the \"Earth\" series of compilations. Some of the artists who rose to fame under Good Looking in this period include Blame, Seba, Big Bud, Blu Mar Ten, DJ Dream (Aslan Davis), Future Engineers, Tayla, Aquarius (an alias of Photek), Peshay, Source Direct and Artemis.\n\nOn 16 July 1995 he did an Essential Mix alongside MC Conrad. In 1997 he remixed the James Bond theme for David Arnold's concept album of James Bond music \"\". In 2000 he finally released a debut solo album, the double-CD \"Journey Inwards\". The album heavily emphasised his jazz fusion influences. 2001 saw a remix of Herbie Hancock.\n\nHe ran the Speed clubnight in London with fellow drum and bass DJ Fabio.\n\nHe DJs extensively around the world, often under the 'Progression Sessions' or 'Bukem in Session' banners. However, his former companion and vocalist, MC Conrad left the label and ultimately their musical partnership in 2012.\n\nIn 2007, he revealed that he had found his biological birth mother, a Ugandan woman living in Paris that revealed that his father was Egyptian. \n\nViewed as an innovator in the drum and bass style, Bukem is known for developing an accessible alternative to that hardcore genre's speedy, assaultive energies. His style pays homage to the Detroit-based sound of early techno, but Bukem also incorporates still earlier influences, particularly the mellow, melodic sonorities of 1970s era jazz fusion as exemplified by Lonnie Liston Smith and Roy Ayers. Early in his career, Bukem was identified for his response to the \"almost paranoid hyperkinesis\" of breakbeat-based house music, and specifically for his reservations regarding the overbearing force of the hardcore mentality.\n\nBukem's music from the early 1990s onward represents his efforts to map out an alternative future for drum and bass by incorporating softer-edged influences culled from London's 1980s rare groove and acid jazz scenes. Music on \"Logical Progression\" reveals these influences, as does his approach on 1993's \"Music / Enchanted\", which features string arrangements and sounds from nature. His use of keyboards, live vocals and slow- motion breaks on these and future releases earned Bukem's music the tag intelligent drum and bass. While this designation caused controversy within the drum and bass community, it also influenced the popularisation of hardcore music in the UK during the mid-1990s.\n\nRemixes\n\n"}
{"id": "18443", "url": "https://en.wikipedia.org/wiki?curid=18443", "title": "Lindsay Anderson", "text": "Lindsay Anderson\n\nLindsay Gordon Anderson (17 April 1923 – 30 August 1994) was a British feature film, theatre and documentary director, film critic, and leading light of the Free Cinema movement and the British New Wave. He is most widely remembered for his 1968 film \"if...\", which won the \"Palme d'Or\" at Cannes Film Festival and was Malcolm McDowell's cinematic debut. He is also notable, though not a professional actor, for playing a minor role in the Academy Award winning film \"Chariots of Fire\". McDowell produced a 2007 documentary about his experiences with Anderson, \"Never Apologize\".\n\nLindsay Gordon Anderson was born in Bangalore, South India, where his father had been stationed with the Royal Engineers, on the 17th of April 1923. His father Captain (later Major General) Alexander Vass Anderson was a British Army Officer that had been born in North India and his mother Estelle Bell Gasson was born in Queenstown, South Africa, the daughter of a wool merchant. Lindsay's parents separated in 1926 and Estelle returned to England with her sons; however, they tried to reconcile in 1932 in Bangalore, and when Estelle returned to England she was pregnant with her third son, Alexander Vass Anderson. The Andersons divorced and Estelle remarried Major Cuthbert Sleigh in 1936. Lindsay's father re-married in India; although Gavin Lambert writes, in 'Mainly About Lindsay Anderson: A Memoir' (Faber and Faber, 2000, p. 18), that Alexander Vass Anderson 'cut (his first family) out of his life', making no reference to them in his 'Who's Who' entry, Lindsay often saw his father and looked after his house and dogs when he was away.\n\nBoth Lindsay and his older brother Murray Anderson (1919-2016) were educated at Saint Ronan's School in Worthing, West Sussex, and at Cheltenham College. It was at Cheltenham that Lindsay had met his lifelong friend and biographer, the screenwriter and novelist Gavin Lambert. Lindsay won a scholarship for classical studies at Wadham College at the University of Oxford, in 1942.\n\nAnderson served in the Army from 1943 until 1946, first with the 60th King's Royal Rifle Groups, and then in the final year of World War II as a cryptographer for the Intelligence Corps, at the Wireless Experimental Centre in Delhi. Anderson assisted in nailing the Red flag to the roof of the Junior Officers' mess in Annan Parbat, in August 1945, after the victory of the Labour Party in the general election was confirmed. The colonel did not approve, he recalled a decade later, but no disciplinary action was taken against them.\n\nLindsay returned to Oxford in 1946 but changed from classical studies to English; he graduated with an MA in 1948.\n\nBefore going into film-making, Anderson was a prominent film critic writing for the influential \"Sequence\" magazine (1947–52), which he co-founded with Gavin Lambert, Peter Ericsson and Karel Reisz; later writing for the British Film Institute's journal \"Sight and Sound\" and the left-wing political weekly the \"New Statesman\". In a 1956 polemical article, \"Stand Up, Stand Up\" for \"Sight and Sound\", he attacked contemporary critical practices, in particular the pursuit of objectivity. Taking as an example some comments made by Alistair Cooke in 1935, where Cooke claimed to be without politics as a critic, Anderson responded:\nFollowing a series of screenings which he and the National Film Theatre programmer Karel Reisz organized for the venue of independently-produced short films by himself and others, he developed a philosophy of cinema which found expression in what became known, by the late-1950s, as the Free Cinema movement. This was the belief that the British cinema must break away from its class-bound attitudes and that non-metropolitan Britain ought to be shown on the nation's screens. He had already begun to make films himself, starting in 1948 with \"Meet the Pioneers\", a documentary about a conveyor-belt factory.\n\nAlong with Karel Reisz, Tony Richardson, and others, he secured funding from a variety of sources (including Ford of Britain) and they each made a series of short documentaries on a variety of subjects. One of Anderson's early short films, \"Thursday's Children\" (1954), concerning the education of deaf children, made in collaboration with Guy Brenton, a friend from his Oxford days, won an Oscar for Best Documentary Short in 1954.\n\nThese films, influenced by one of Anderson' heroes, the French filmmaker Jean Vigo, and made in the tradition of the British documentaries of Humphrey Jennings, foreshadowed much of the social realism of British cinema that emerged in the next decade, with Reisz's \"Saturday Night and Sunday Morning\" (1960), Richardson's \"The Loneliness of the Long Distance Runner\" (1962) and Anderson's own \"This Sporting Life\" (1963), produced by Reisz. Anderson's film met with mixed reviews at the time, and was not a commercial success.\n\nAnderson is perhaps best remembered as a filmmaker for his \"Mick Travis trilogy\", all of which star Malcolm McDowell as the title character: \"if...\" (1968), a satire on public schools; \"O Lucky Man!\" (1973) a \"Pilgrim's Progress\" inspired road movie; and \"Britannia Hospital\" (1982), a fantasia taking stylistic influence from the populist wing of British cinema represented by Hammer horror films and Carry On comedies.\n\nIn 1981, Anderson played the role of the Master of Caius College at Cambridge University in the film \"Chariots of Fire\".\n\nAnderson developed an acquaintance from 1950 with John Ford, which led to what has come to be regarded as one of the standard books on that director, Anderson's \"About John Ford\" (1983). Based on half a dozen meetings over more than two decades, and a lifetime's study of the man's work, the book has been described as \"One of the best books published by a film-maker on a film-maker\".\n\nIn 1985, producer Martin Lewis invited Anderson to chronicle Wham!'s visit to China, among the first-ever visits by Western pop artists, which resulted in Anderson's film \"Foreign Skies: Wham! In China\". He admitted in his diary on 31 March 1985, to having \"no interest in Wham!\", or China, and he was simply \"'doing this for the money'\". In 1986, he was a member of the jury at the 36th Berlin International Film Festival.\n\nAnderson was also a significant British theatre director. He was long associated with London's Royal Court Theatre, where he was Co-Artistic Director 1969–70, and Associate Artistic Director 1971–75, directing premiere productions of plays by David Storey, among others.\n\nIn 1992, as a close friend of actresses Jill Bennett and Rachel Roberts, Anderson included a touching episode in his autobiographical BBC film \"Is That All There Is?\", with a boat trip down the River Thames (several of their professional colleagues and friends aboard) to scatter their ashes on the waters while musician Alan Price sang the song \"Is That All There Is?\".\n\nEvery year, the International Documentary Festival in Amsterdam (IDFA) gives an acclaimed filmmaker the chance to screen his or her personal Top 10 favorite films. In 2007, Iranian filmmaker Maziar Bahari selected \"O Dreamland\" and \"Every Day Except Christmas\" (1957), a record of a day in the old Covent Garden market, for his top 10 classics from the history of documentary.[3]\n\nGavin Lambert's memoir, \"Mainly About Lindsay Anderson\", in which he wrote that Anderson repressed his homosexuality, was seen as a betrayal by his other friends. In November 2006 Malcolm McDowell told \"The Independent\":\nAnderson died from a heart attack on 30 August 1994 at the age of 71.\n\nAll Royal Court, London, unless otherwise indicated:\n\n\n\n\n\n\n"}
{"id": "18444", "url": "https://en.wikipedia.org/wiki?curid=18444", "title": "Loch", "text": "Loch\n\nLoch () is the Irish, Scottish Gaelic and Scots word for a lake or for a sea inlet. It is cognate with the Manx lough, Cornish logh, and one of the Welsh words for lake, llwch.\n\nIn English English and Hiberno-English, the anglicised spelling lough is commonly found in place names; in Lowland Scots and Scottish English, the spelling \"loch\" is always used.\n\nSome lochs could also be called firths, fjords, estuaries, straits or bays. Sea-inlet lochs are often called sea lochs or sea loughs. Many loughs are connected to stories of lake-bursts, signifying their mythical origin.\n\nThis name for a body of water is Insular Celtic in origin and is applied to most lakes in\nScotland and to many sea inlets in the west and north of Scotland. The word is Indo-European in origin; cf. Latin \"lacus\".\n\nLowland Scots orthography, like Scottish Gaelic, Welsh and Irish, represents with \"ch\", so the word was borrowed with identical spelling.\n\nEnglish borrowed the word separately from a number of loughs in the previous Cumbric language areas of Northumbria and Cumbria. Earlier forms of English included the sound as \"gh\" (compare Scots \"bricht\" with English \"bright\"). However, by the time Scotland and England joined under a single parliament, English had lost the sound. This form was therefore used when the English settled Ireland. The Scots convention of using \"ch\" remained, hence the modern Scottish English \"loch\".\n\nLikewise, in the Insular Celtic languages, the representation of (), is \"lu\" in Old Welsh and \"llw\" in Middle Welsh such as in today's Welsh placenames Llanllwchaiarn, Llwchwr, Llyn Cwm Llwch, Amlwch, Maesllwch. The Goidelic \"lo\" being taken into Scottish Gaelic by the gradual replacement of much Brittonic orthography with Goidelic orthography in Scotland.\n\nMany of the loughs in Northern England have also previously been called \"meres\" (a Northern English dialect word for \"lake\" and an archaic Standard English word meaning \"a lake that is broad in relation to its depth\") such as the \"Black Lough\" in Northumberland. However, reference to the latter as \"loughs\" (lower case initial), rather than as \"lakes\", \"inlets\" and so on, is unusual.\n\nSome lochs in Southern Scotland have a Brythonic rather than Goidelic etymology, such as Loch Ryan where the Gaelic \"loch\" has replaced a Cumbric equivalent of Welsh \"llwch\". The same is perhaps the case for water bodies in Northern England named with 'Low' or 'Lough' or otherwise it represents a borrowing of the Brythonic word into the Northumbrian dialect of Old English.\n\nAlthough there is no strict size definition, a small loch is often known as a lochan (so spelled also in Scottish Gaelic; in Irish it is spelled lochán).\n\nPerhaps the most famous Scottish loch is Loch Ness, although there are other large examples such as Loch Awe, Loch Lomond and Loch Tay.\n\nExamples of sea lochs in Scotland include Loch Long, Loch Fyne, Loch Linnhe, and Loch Eriboll.\n\nSome new reservoirs for hydroelectric schemes have been given names faithful to the names for natural bodies of water – for example, the Loch Sloy scheme, and Lochs Laggan and Treig (which form part of the Lochaber hydroelectric scheme near Fort William). Other expanses are simply called reservoirs, e.g. Blackwater Reservoir above Kinlochleven.\n\nScotland has very few bodies of water called lakes. The Lake of Menteith, an Anglicisation of the Scots \"Laich o Menteith\" meaning a \"low-lying bit of land in Menteith\", is applied to the loch there because of the similarity of the sounds of the words \"laich\" and \"lake\". Until the 19th century the body of water was known as the \"Loch of Menteith\". The Lake of the Hirsel, Pressmennan Lake and Lake Louise are man-made bodies of water in Scotland known as lakes.\n\nThe word \"loch\" is sometimes used as a shibboleth to identify natives of England, because the fricative sound is used in Scotland whereas most English people pronounce the word like \"lock\".\n\nAs \"loch\" is a common Gaelic word, it is found as the root of several Manx place names.\n\nThe United States naval port of Pearl Harbor, on the south coast of the main Hawaiian island of Oahu, is one of a complex of sea inlets. Several are named as lochs, including South East Loch, Merry Loch, East Loch, Middle Loch and West Loch.\n\nLoch Raven Reservoir is a reservoir in Baltimore County, Maryland.\n\nBrenton Loch in the Falkland Islands is a sea loch, near Lafonia, East Falkland.\n\nIn the Scottish settlement of Glengarry County in present-day Eastern Ontario, there is a lake called Loch Garry. Loch Garry was named by those who settled in the area, Clan MacDonell of Glengarry, after the well-known loch their clan is from, Loch Garry in Scotland. Similarly, lakes named Loch Broom, Big Loch, Greendale Loch, and Loch Lomond can be found in Nova Scotia, along with Loch Leven in Newfoundland, and Loch Leven in Saskatchewan.\n\n"}
{"id": "18446", "url": "https://en.wikipedia.org/wiki?curid=18446", "title": "Leo Marks", "text": "Leo Marks\n\nLeopold Samuel \"Leo\" Marks, MBE (24 September 1920 – 15 January 2001) was an English writer, screenwriter, and cryptographer. During the Second World War he headed the codes office supporting resistance agents in occupied Europe for the secret Special Operations Executive organisation. After the war, Marks became a playwright and screenwriter, writing scripts that frequently utilised his war-time cryptographic experiences. He wrote the script for \"Peeping Tom\", the controversial film directed by Michael Powell which had a disastrous effect on Powell's career, but was later described by Martin Scorsese as a masterpiece. In 1998, towards the end of his life, Marks published a personal history of his experiences during the war, \"Between Silk and Cyanide\", which was critical of the leadership of SOE.\n\nMarks was the son of Benjamin Marks, the joint owner of Marks & Co, an antiquarian bookseller in Charing Cross Road, London. He was introduced at an early age to cryptography when his father showed him Edgar Allan Poe's story, \"The Gold-Bug\".\n\nFrom this early interest, he demonstrated his skill at codebreaking by deciphering the secret price codes which his father wrote inside the covers of books. The bookshop subsequently became famous as a result of the book \"84, Charing Cross Road\", which was based on correspondence between American writer Helene Hanff and the shop's chief buyer, Frank Doel.\n\nMarks was conscripted in January 1942, and trained as a cryptographer; apparently he demonstrated the ability to complete one week's work in decipherment exercise in a few hours. Unlike the rest of his intake, who were sent to the main British codebreaking centre at Bletchley Park, Marks was regarded as a misfit and he was assigned the newly formed Special Operations Executive (SOE) in Baker Street, which was set up to train agents to operate behind enemy lines in occupied Europe and to assist local resistance groups. SOE has been described as \"a mixture of brilliant brains and bungling amateurs\". Marks wrote that he had an inauspicious arrival at SOE when it took him all day to decipher a code he had been expected to finish in 20 minutes, because, not atypically, SOE had forgotten to supply the cipher key.\n\nMarks briefed many Allied agents sent into occupied Europe, including Noor Inayat Khan, the Grouse/Swallow team of four Norwegian Telemark saboteurs and his own close friend 'Tommy' Yeo-Thomas, nicknamed \"the White Rabbit\". In an interview which accompanied the DVD of the film \"Peeping Tom\", Marks quoted General Eisenhower as saying that his group's work shortened the war by three months, saving countless lives.\n\nMarks was portrayed by Anton Lesser in David Morley's BBC Radio drama \"A Cold Supper Behind Harrods\". The fiction play was inspired by conversations between Marks and David Morley and real events in SOE. It featured David Jason, and Stephanie Cole as Vera Atkins.\n\nOne of Marks's first challenges was to phase out double transposition ciphers using keys based on preselected poems. These poem ciphers had the limited advantage of being easy to memorise, but significant disadvantages, including limited cryptographic security, substantial minimum message sizes (short ones were easy to crack), and the fact that the method's complexity caused encoding errors.\n\nCryptographic security was enhanced by Marks's innovations, especially \"worked-out keys\". He was credited with inventing the letter one-time pad, but while he did independently discover the method, he later found it already in use at Bletchley.\n\nWhile attempting to relegate poem codes to emergency use, he enhanced their security by promoting the use of original poems in preference to widely known ones, forcing a cryptanalyst to work it out the hard way for each message instead of guessing an agent's entire set of keys after breaking the key to a single message (or possibly just part of the key.) Marks wrote many poems later used by agents, the most famous being one he gave to the agent Violette Szabo, \"The Life That I Have\", which gained popularity when it was used in the 1958 film about her, \"Carve Her Name With Pride\". According to his book, Marks wrote the poem in Christmas 1943 about a girlfriend, Ruth, who had recently died in an air crash in Canada; supposedly the god-daughter of the head of SOE, Sir Charles Jocelyn Hambro.\nThe life that I have \nIs all that I have \nAnd the life that I have \nIs yours. \n\nThe love that I have \nOf the life that I have \nIs yours and yours and yours. \n\nA sleep I shall have\nA rest I shall have \nYet death will be but a pause. \n\nFor the peace of my years \nIn the long green grass \nWill be yours and yours and yours.\nGestapo signal tracers endangered clandestine radio operators, and their life expectancy averaged about six weeks. Therefore, short and less frequent transmissions from the codemaster were of value. The pressure could cause agents to make mistakes encoding messages, and the practice was for the home station to tell them to recode it (usually a safe activity) and retransmit it (dangerous, and increasingly so the longer it took). In response to this problem, Marks established, staffed and trained a group based at Grendon Underwood, Buckinghamshire to cryptanalyse garbled messages (\"indecipherables\") so they could be dealt with in England without forcing the agent to risk retransmitting from the field. Other innovations of his simplified encoding in the field, which reduced errors and made shorter messages possible, both of which reduced transmission time.\n\nThe Germans generally did not execute captured radio operators out of hand. The goal was to turn and use them, or to extract enough information to imitate them. For the safety of entire underground \"circuits\", it was important to determine if an operator was genuine and still free, but means of independently checking were primitive. Marks claims that he became convinced (but was unable to prove) that their agents in the Netherlands had been compromised by the German counter-intelligence Abwehr. The Germans referred to their operation as \"a game\"—Das Englandspiel. Marks's warnings fell on deaf ears and perhaps as many as 50 further agents were sent to meet their deaths in Holland. The other side of this story was published in 1953 by Marks's German opposite number in the Netherlands, Hermann Giskes, in his book \"London Calling North Pole\".\n\nIn his book (pp. 222–3), Marks describes the memorandum he wrote detailing his conviction that messages from the Netherlands were being sent either by Germans or by agents who had been turned. He argued that, despite harrowing circumstances, \"not a single Dutch agent has been so overwrought that he's made a mistake in his coding...\" Marks had to face Brigadier (later Sir) Colin Gubbins:\n\nGubbins grills Marks. In particular he wants to know who has seen this report, who typed it (Marks did):\n\nAfter the war, Marks went on to write plays and films, including \"The Girl Who Couldn't Quite!\" (1947), \"Cloudburst\" (1951), \"The Best Damn Lie\" (1957), \"Guns at Batasi\" (co-writer) (1964), \"Sebastian\" (1968) and \"Twisted Nerve\" (1968).\n\nMarks wrote the script for Michael Powell's film \"Peeping Tom\" (1960), the story of a serial killer who films his victims while stabbing them. The film provoked critical revulsion, at the time, and was described as \"evil and pornographic\". The film was critically rehabilitated when younger directors, including Martin Scorsese, expressed admiration for Marks's script. Scorsese subsequently asked Marks to supply the voice of Satan in his 1988 film \"The Last Temptation of Christ\".\n\nIn 1998, Marks published his account of his work in SOE – \"\". The book was written in the early 1980s, but didn't receive UK Government approval for publication until 1998. Three of the poems published in the book were scrambled into the song \"Dead Agents\" by John Cale performed at the Institute of Contemporary Arts, London, in April 1999.\n\nMarks describes himself as an agnostic in \"Between Silk and Cyanide\", but frequently refers to his Jewish heritage.\n\nHe married the portrait painter Elena Gaussen in 1966. The marriage lasted until shortly before his death at home from cancer in January 2001.\n\n\n"}
